{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Titanic model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import warnings\n",
    "\n",
    "import utils\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=SettingWithCopyWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from loadDataUtils import loadDataUtils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "path_train = r'C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\data\\train.csv'\n",
    "path_test = r'C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\data\\test.csv'\n",
    "data = loadDataUtils(path_train, path_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_train, df_test = data.get_train_and_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clean data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from titanicPreprocessing import preprocess"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "p = preprocess(df_train.copy(), df_test.copy())\n",
    "p.do_preprocess()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train, test = p.get_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 889 entries, 0 to 890\n",
      "Data columns (total 23 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   PassengerId      889 non-null    int64  \n",
      " 1   Survived         889 non-null    int64  \n",
      " 2   Pclass           889 non-null    int64  \n",
      " 3   Age              889 non-null    float64\n",
      " 4   SibSp            889 non-null    int64  \n",
      " 5   Parch            889 non-null    int64  \n",
      " 6   Fare             889 non-null    float64\n",
      " 7   cabin_multiple   889 non-null    int64  \n",
      " 8   Sex_female       889 non-null    uint8  \n",
      " 9   Sex_male         889 non-null    uint8  \n",
      " 10  Embarked_C       889 non-null    uint8  \n",
      " 11  Embarked_Q       889 non-null    uint8  \n",
      " 12  Embarked_S       889 non-null    uint8  \n",
      " 13  cabin_letter_0   889 non-null    uint8  \n",
      " 14  cabin_letter_A   889 non-null    uint8  \n",
      " 15  cabin_letter_B   889 non-null    uint8  \n",
      " 16  cabin_letter_C   889 non-null    uint8  \n",
      " 17  cabin_letter_D   889 non-null    uint8  \n",
      " 18  cabin_letter_E   889 non-null    uint8  \n",
      " 19  cabin_letter_F   889 non-null    uint8  \n",
      " 20  cabin_letter_G   889 non-null    uint8  \n",
      " 21  cabin_letter_T   889 non-null    uint8  \n",
      " 22  name_title_Rare  889 non-null    uint8  \n",
      "dtypes: float64(2), int64(6), uint8(15)\n",
      "memory usage: 107.8 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_target = train['Survived']\n",
    "train.drop(columns=['Survived'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, train_target, test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model building"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Baseline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "the gender submission provided by kaggle could be our baseline. In fact, this dataset is characterized by the fact that they assumed that all women would have survived, so we expect an accuracy of about 50%."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "baseline = pd.read_csv(r'C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\data\\gender_submission.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   PassengerId  418 non-null    int64\n",
      " 1   Survived     418 non-null    int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 6.7 KB\n"
     ]
    }
   ],
   "source": [
    "baseline.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0.49760765550239233"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "baseline_acc = accuracy_score(baseline['Survived'], y_train[0:418])\n",
    "baseline_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "we put the value of 418 in the y_train to make a comparison. When we divided the dataset our trainset had more than 418 observations, so we put the limit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Gaussian Naive Bayes (GaussianNB)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.624      0.656      0.83870968 0.72580645 0.68548387]\n",
      "0.7060000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#I usually use Naive Bayes as a baseline for my classification tasks\n",
    "gnb = GaussianNB()\n",
    "cv = cross_val_score(gnb,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nlr = LogisticRegression(max_iter = 20000)\\ncv = cross_val_score(lr,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\\nprint(cv)\\nprint(cv.mean())\\n\""
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\"\"\"\n",
    "lr = LogisticRegression(max_iter = 20000)\n",
    "cv = cross_val_score(lr,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85714286 0.77777778 0.83870968 0.79032258 0.80645161 0.77419355\n",
      " 0.79032258 0.77419355 0.72580645 0.75806452]\n",
      "0.7892985151049666\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter = 2000)\n",
    "cv = cross_val_score(lr,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=10)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "we can already observe that with the logistic regression we get almost 10% more accuracy than the GaussianNB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Deciosion tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72       0.8        0.79032258 0.75       0.78225806]\n",
      "0.7685161290322581\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(random_state = 1)\n",
    "cv = cross_val_score(dt,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7528089887640449"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "dt.score(X_test.loc[:, X_test.columns != 'PassengerId'],y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "'Titanic_decision_tree.pdf'"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "dot_data = tree.export_graphviz(dt, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"Titanic_decision_tree\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"4653pt\" height=\"2453pt\"\n viewBox=\"0.00 0.00 4653.00 2453.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 2449)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-2449 4649,-2449 4649,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#f5d0b5\" stroke=\"black\" d=\"M2826.5,-2445C2826.5,-2445 2720.5,-2445 2720.5,-2445 2714.5,-2445 2708.5,-2439 2708.5,-2433 2708.5,-2433 2708.5,-2389 2708.5,-2389 2708.5,-2383 2714.5,-2377 2720.5,-2377 2720.5,-2377 2826.5,-2377 2826.5,-2377 2832.5,-2377 2838.5,-2383 2838.5,-2389 2838.5,-2389 2838.5,-2433 2838.5,-2433 2838.5,-2439 2832.5,-2445 2826.5,-2445\"/>\n<text text-anchor=\"start\" x=\"2717.5\" y=\"-2429.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Sex_female ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"2736\" y=\"-2414.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.474</text>\n<text text-anchor=\"start\" x=\"2726\" y=\"-2399.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 622</text>\n<text text-anchor=\"start\" x=\"2716.5\" y=\"-2384.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [382, 240]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#eba06a\" stroke=\"black\" d=\"M2344.5,-2341C2344.5,-2341 2226.5,-2341 2226.5,-2341 2220.5,-2341 2214.5,-2335 2214.5,-2329 2214.5,-2329 2214.5,-2285 2214.5,-2285 2214.5,-2279 2220.5,-2273 2226.5,-2273 2226.5,-2273 2344.5,-2273 2344.5,-2273 2350.5,-2273 2356.5,-2279 2356.5,-2285 2356.5,-2285 2356.5,-2329 2356.5,-2329 2356.5,-2335 2350.5,-2341 2344.5,-2341\"/>\n<text text-anchor=\"start\" x=\"2222.5\" y=\"-2325.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_0 ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"2248\" y=\"-2310.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.317</text>\n<text text-anchor=\"start\" x=\"2238\" y=\"-2295.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 410</text>\n<text text-anchor=\"start\" x=\"2232.5\" y=\"-2280.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [329, 81]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2708.45,-2396.4C2620.23,-2377.96 2462.69,-2345.03 2366.78,-2324.99\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2367.34,-2321.53 2356.83,-2322.91 2365.91,-2328.38 2367.34,-2321.53\"/>\n<text text-anchor=\"middle\" x=\"2370.52\" y=\"-2340.13\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 204 -->\n<g id=\"node205\" class=\"node\">\n<title>204</title>\n<path fill=\"#7bbeee\" stroke=\"black\" d=\"M3408.5,-2341C3408.5,-2341 3310.5,-2341 3310.5,-2341 3304.5,-2341 3298.5,-2335 3298.5,-2329 3298.5,-2329 3298.5,-2285 3298.5,-2285 3298.5,-2279 3304.5,-2273 3310.5,-2273 3310.5,-2273 3408.5,-2273 3408.5,-2273 3414.5,-2273 3420.5,-2279 3420.5,-2285 3420.5,-2285 3420.5,-2329 3420.5,-2329 3420.5,-2335 3414.5,-2341 3408.5,-2341\"/>\n<text text-anchor=\"start\" x=\"3320\" y=\"-2325.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pclass ≤ 2.5</text>\n<text text-anchor=\"start\" x=\"3322\" y=\"-2310.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"3312\" y=\"-2295.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 212</text>\n<text text-anchor=\"start\" x=\"3306.5\" y=\"-2280.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [53, 159]</text>\n</g>\n<!-- 0&#45;&gt;204 -->\n<g id=\"edge204\" class=\"edge\">\n<title>0&#45;&gt;204</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2838.73,-2398.65C2949.5,-2379.37 3173.48,-2340.38 3288.22,-2320.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3289.06,-2323.81 3298.31,-2318.65 3287.86,-2316.92 3289.06,-2323.81\"/>\n<text text-anchor=\"middle\" x=\"3283.92\" y=\"-2335.4\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#f7d6be\" stroke=\"black\" d=\"M1142,-2237C1142,-2237 1053,-2237 1053,-2237 1047,-2237 1041,-2231 1041,-2225 1041,-2225 1041,-2181 1041,-2181 1041,-2175 1047,-2169 1053,-2169 1053,-2169 1142,-2169 1142,-2169 1148,-2169 1154,-2175 1154,-2181 1154,-2181 1154,-2225 1154,-2225 1154,-2231 1148,-2237 1142,-2237\"/>\n<text text-anchor=\"start\" x=\"1060\" y=\"-2221.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.94</text>\n<text text-anchor=\"start\" x=\"1060\" y=\"-2206.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.481</text>\n<text text-anchor=\"start\" x=\"1054\" y=\"-2191.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 82</text>\n<text text-anchor=\"start\" x=\"1049\" y=\"-2176.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [49, 33]</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2214.3,-2299.89C2001.39,-2281.61 1371.54,-2227.53 1164.38,-2209.74\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1164.52,-2206.24 1154.26,-2208.87 1163.92,-2213.22 1164.52,-2206.24\"/>\n</g>\n<!-- 49 -->\n<g id=\"node50\" class=\"node\">\n<title>49</title>\n<path fill=\"#e9975b\" stroke=\"black\" d=\"M2334.5,-2237C2334.5,-2237 2236.5,-2237 2236.5,-2237 2230.5,-2237 2224.5,-2231 2224.5,-2225 2224.5,-2225 2224.5,-2181 2224.5,-2181 2224.5,-2175 2230.5,-2169 2236.5,-2169 2236.5,-2169 2334.5,-2169 2334.5,-2169 2340.5,-2169 2346.5,-2175 2346.5,-2181 2346.5,-2181 2346.5,-2225 2346.5,-2225 2346.5,-2231 2340.5,-2237 2334.5,-2237\"/>\n<text text-anchor=\"start\" x=\"2244\" y=\"-2221.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;2.019</text>\n<text text-anchor=\"start\" x=\"2252\" y=\"-2206.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.25</text>\n<text text-anchor=\"start\" x=\"2238\" y=\"-2191.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 328</text>\n<text text-anchor=\"start\" x=\"2232.5\" y=\"-2176.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [280, 48]</text>\n</g>\n<!-- 1&#45;&gt;49 -->\n<g id=\"edge49\" class=\"edge\">\n<title>1&#45;&gt;49</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2285.5,-2272.88C2285.5,-2264.78 2285.5,-2255.98 2285.5,-2247.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2289,-2247.3 2285.5,-2237.3 2282,-2247.3 2289,-2247.3\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1011,-2125.5C1011,-2125.5 938,-2125.5 938,-2125.5 932,-2125.5 926,-2119.5 926,-2113.5 926,-2113.5 926,-2084.5 926,-2084.5 926,-2078.5 932,-2072.5 938,-2072.5 938,-2072.5 1011,-2072.5 1011,-2072.5 1017,-2072.5 1023,-2078.5 1023,-2084.5 1023,-2084.5 1023,-2113.5 1023,-2113.5 1023,-2119.5 1017,-2125.5 1011,-2125.5\"/>\n<text text-anchor=\"start\" x=\"945.5\" y=\"-2110.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"935\" y=\"-2095.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"934\" y=\"-2080.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 7]</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1057.57,-2168.88C1043.37,-2157.12 1027.43,-2143.89 1013.33,-2132.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1015.21,-2129.21 1005.27,-2125.52 1010.74,-2134.6 1015.21,-2129.21\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#f3c4a2\" stroke=\"black\" d=\"M1142,-2133C1142,-2133 1053,-2133 1053,-2133 1047,-2133 1041,-2127 1041,-2121 1041,-2121 1041,-2077 1041,-2077 1041,-2071 1047,-2065 1053,-2065 1053,-2065 1142,-2065 1142,-2065 1148,-2065 1154,-2071 1154,-2077 1154,-2077 1154,-2121 1154,-2121 1154,-2127 1148,-2133 1142,-2133\"/>\n<text text-anchor=\"start\" x=\"1054.5\" y=\"-2117.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.799</text>\n<text text-anchor=\"start\" x=\"1060\" y=\"-2102.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.453</text>\n<text text-anchor=\"start\" x=\"1054\" y=\"-2087.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 75</text>\n<text text-anchor=\"start\" x=\"1049\" y=\"-2072.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [49, 26]</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1097.5,-2168.88C1097.5,-2160.78 1097.5,-2151.98 1097.5,-2143.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1101,-2143.3 1097.5,-2133.3 1094,-2143.3 1101,-2143.3\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1011,-2021.5C1011,-2021.5 938,-2021.5 938,-2021.5 932,-2021.5 926,-2015.5 926,-2009.5 926,-2009.5 926,-1980.5 926,-1980.5 926,-1974.5 932,-1968.5 938,-1968.5 938,-1968.5 1011,-1968.5 1011,-1968.5 1017,-1968.5 1023,-1974.5 1023,-1980.5 1023,-1980.5 1023,-2009.5 1023,-2009.5 1023,-2015.5 1017,-2021.5 1011,-2021.5\"/>\n<text text-anchor=\"start\" x=\"945.5\" y=\"-2006.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"935\" y=\"-1991.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"934\" y=\"-1976.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 0]</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1057.57,-2064.88C1043.37,-2053.12 1027.43,-2039.89 1013.33,-2028.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1015.21,-2025.21 1005.27,-2021.52 1010.74,-2030.6 1015.21,-2025.21\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#f5d1b7\" stroke=\"black\" d=\"M1142,-2029C1142,-2029 1053,-2029 1053,-2029 1047,-2029 1041,-2023 1041,-2017 1041,-2017 1041,-1973 1041,-1973 1041,-1967 1047,-1961 1053,-1961 1053,-1961 1142,-1961 1142,-1961 1148,-1961 1154,-1967 1154,-1973 1154,-1973 1154,-2017 1154,-2017 1154,-2023 1148,-2029 1142,-2029\"/>\n<text text-anchor=\"start\" x=\"1064\" y=\"-2013.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.4</text>\n<text text-anchor=\"start\" x=\"1060\" y=\"-1998.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.475</text>\n<text text-anchor=\"start\" x=\"1054\" y=\"-1983.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 67</text>\n<text text-anchor=\"start\" x=\"1049\" y=\"-1968.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [41, 26]</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1097.5,-2064.88C1097.5,-2056.78 1097.5,-2047.98 1097.5,-2039.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1101,-2039.3 1097.5,-2029.3 1094,-2039.3 1101,-2039.3\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1011,-1917.5C1011,-1917.5 938,-1917.5 938,-1917.5 932,-1917.5 926,-1911.5 926,-1905.5 926,-1905.5 926,-1876.5 926,-1876.5 926,-1870.5 932,-1864.5 938,-1864.5 938,-1864.5 1011,-1864.5 1011,-1864.5 1017,-1864.5 1023,-1870.5 1023,-1876.5 1023,-1876.5 1023,-1905.5 1023,-1905.5 1023,-1911.5 1017,-1917.5 1011,-1917.5\"/>\n<text text-anchor=\"start\" x=\"945.5\" y=\"-1902.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"935\" y=\"-1887.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"934\" y=\"-1872.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 0]</text>\n</g>\n<!-- 6&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>6&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1057.57,-1960.88C1043.37,-1949.12 1027.43,-1935.89 1013.33,-1924.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1015.21,-1921.21 1005.27,-1917.52 1010.74,-1926.6 1015.21,-1921.21\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#f8dcc8\" stroke=\"black\" d=\"M1142,-1925C1142,-1925 1053,-1925 1053,-1925 1047,-1925 1041,-1919 1041,-1913 1041,-1913 1041,-1869 1041,-1869 1041,-1863 1047,-1857 1053,-1857 1053,-1857 1142,-1857 1142,-1857 1148,-1857 1154,-1863 1154,-1869 1154,-1869 1154,-1913 1154,-1913 1154,-1919 1148,-1925 1142,-1925\"/>\n<text text-anchor=\"start\" x=\"1058\" y=\"-1909.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 1.064</text>\n<text text-anchor=\"start\" x=\"1060\" y=\"-1894.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.487</text>\n<text text-anchor=\"start\" x=\"1054\" y=\"-1879.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 62</text>\n<text text-anchor=\"start\" x=\"1049\" y=\"-1864.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [36, 26]</text>\n</g>\n<!-- 6&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>6&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1097.5,-1960.88C1097.5,-1952.78 1097.5,-1943.98 1097.5,-1935.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1101,-1935.3 1097.5,-1925.3 1094,-1935.3 1101,-1935.3\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#d3e9f9\" stroke=\"black\" d=\"M983,-1821C983,-1821 864,-1821 864,-1821 858,-1821 852,-1815 852,-1809 852,-1809 852,-1765 852,-1765 852,-1759 858,-1753 864,-1753 864,-1753 983,-1753 983,-1753 989,-1753 995,-1759 995,-1765 995,-1765 995,-1809 995,-1809 995,-1815 989,-1821 983,-1821\"/>\n<text text-anchor=\"start\" x=\"860\" y=\"-1805.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_A ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"886\" y=\"-1790.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.492</text>\n<text text-anchor=\"start\" x=\"880\" y=\"-1775.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 32</text>\n<text text-anchor=\"start\" x=\"875\" y=\"-1760.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [14, 18]</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1041.01,-1856.88C1024.36,-1847.12 1006.01,-1836.37 988.85,-1826.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"990.4,-1823.16 980.01,-1821.12 986.86,-1829.2 990.4,-1823.16\"/>\n</g>\n<!-- 32 -->\n<g id=\"node33\" class=\"node\">\n<title>32</title>\n<path fill=\"#eeaf81\" stroke=\"black\" d=\"M1153.5,-1821C1153.5,-1821 1041.5,-1821 1041.5,-1821 1035.5,-1821 1029.5,-1815 1029.5,-1809 1029.5,-1809 1029.5,-1765 1029.5,-1765 1029.5,-1759 1035.5,-1753 1041.5,-1753 1041.5,-1753 1153.5,-1753 1153.5,-1753 1159.5,-1753 1165.5,-1759 1165.5,-1765 1165.5,-1765 1165.5,-1809 1165.5,-1809 1165.5,-1815 1159.5,-1821 1153.5,-1821\"/>\n<text text-anchor=\"start\" x=\"1037.5\" y=\"-1805.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Embarked_C ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1060\" y=\"-1790.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.391</text>\n<text text-anchor=\"start\" x=\"1054\" y=\"-1775.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30</text>\n<text text-anchor=\"start\" x=\"1053\" y=\"-1760.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [22, 8]</text>\n</g>\n<!-- 8&#45;&gt;32 -->\n<g id=\"edge32\" class=\"edge\">\n<title>8&#45;&gt;32</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1097.5,-1856.88C1097.5,-1848.78 1097.5,-1839.98 1097.5,-1831.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1101,-1831.3 1097.5,-1821.3 1094,-1831.3 1101,-1831.3\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#a7d3f3\" stroke=\"black\" d=\"M836.5,-1717C836.5,-1717 716.5,-1717 716.5,-1717 710.5,-1717 704.5,-1711 704.5,-1705 704.5,-1705 704.5,-1661 704.5,-1661 704.5,-1655 710.5,-1649 716.5,-1649 716.5,-1649 836.5,-1649 836.5,-1649 842.5,-1649 848.5,-1655 848.5,-1661 848.5,-1661 848.5,-1705 848.5,-1705 848.5,-1711 842.5,-1717 836.5,-1717\"/>\n<text text-anchor=\"start\" x=\"712.5\" y=\"-1701.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_C ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"739\" y=\"-1686.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.459</text>\n<text text-anchor=\"start\" x=\"733\" y=\"-1671.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 28</text>\n<text text-anchor=\"start\" x=\"728\" y=\"-1656.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [10, 18]</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M875.77,-1752.88C861.97,-1743.3 846.77,-1732.76 832.51,-1722.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"834.45,-1719.95 824.24,-1717.12 830.46,-1725.7 834.45,-1719.95\"/>\n</g>\n<!-- 31 -->\n<g id=\"node32\" class=\"node\">\n<title>31</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M960,-1709.5C960,-1709.5 887,-1709.5 887,-1709.5 881,-1709.5 875,-1703.5 875,-1697.5 875,-1697.5 875,-1668.5 875,-1668.5 875,-1662.5 881,-1656.5 887,-1656.5 887,-1656.5 960,-1656.5 960,-1656.5 966,-1656.5 972,-1662.5 972,-1668.5 972,-1668.5 972,-1697.5 972,-1697.5 972,-1703.5 966,-1709.5 960,-1709.5\"/>\n<text text-anchor=\"start\" x=\"894.5\" y=\"-1694.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"884\" y=\"-1679.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"883\" y=\"-1664.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 0]</text>\n</g>\n<!-- 9&#45;&gt;31 -->\n<g id=\"edge31\" class=\"edge\">\n<title>9&#45;&gt;31</title>\n<path fill=\"none\" stroke=\"black\" d=\"M923.5,-1752.88C923.5,-1742.33 923.5,-1730.6 923.5,-1719.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"927,-1719.52 923.5,-1709.52 920,-1719.52 927,-1719.52\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<path fill=\"#55abe9\" stroke=\"black\" d=\"M673,-1613C673,-1613 554,-1613 554,-1613 548,-1613 542,-1607 542,-1601 542,-1601 542,-1557 542,-1557 542,-1551 548,-1545 554,-1545 554,-1545 673,-1545 673,-1545 679,-1545 685,-1551 685,-1557 685,-1557 685,-1601 685,-1601 685,-1607 679,-1613 673,-1613\"/>\n<text text-anchor=\"start\" x=\"550\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_F ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"576\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.219</text>\n<text text-anchor=\"start\" x=\"570\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"start\" x=\"569\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 14]</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M723.58,-1648.88C708.13,-1639.21 691.11,-1628.56 675.16,-1618.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"676.77,-1615.46 666.43,-1613.12 673.06,-1621.4 676.77,-1615.46\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M816,-1613C816,-1613 737,-1613 737,-1613 731,-1613 725,-1607 725,-1601 725,-1601 725,-1557 725,-1557 725,-1551 731,-1545 737,-1545 737,-1545 816,-1545 816,-1545 822,-1545 828,-1551 828,-1557 828,-1557 828,-1601 828,-1601 828,-1607 822,-1613 816,-1613\"/>\n<text text-anchor=\"start\" x=\"735\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.246</text>\n<text text-anchor=\"start\" x=\"739\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"733\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\n<text text-anchor=\"start\" x=\"736\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 4]</text>\n</g>\n<!-- 10&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>10&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"black\" d=\"M776.5,-1648.88C776.5,-1640.78 776.5,-1631.98 776.5,-1623.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"780,-1623.3 776.5,-1613.3 773,-1623.3 780,-1623.3\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<path fill=\"#47a4e7\" stroke=\"black\" d=\"M535,-1509C535,-1509 416,-1509 416,-1509 410,-1509 404,-1503 404,-1497 404,-1497 404,-1453 404,-1453 404,-1447 410,-1441 416,-1441 416,-1441 535,-1441 535,-1441 541,-1441 547,-1447 547,-1453 547,-1453 547,-1497 547,-1497 547,-1503 541,-1509 535,-1509\"/>\n<text text-anchor=\"start\" x=\"412\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_B ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"438\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.124</text>\n<text text-anchor=\"start\" x=\"432\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\n<text text-anchor=\"start\" x=\"431\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 14]</text>\n</g>\n<!-- 11&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>11&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M568.7,-1544.88C555.92,-1535.44 541.88,-1525.06 528.66,-1515.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"530.67,-1512.43 520.55,-1509.3 526.51,-1518.06 530.67,-1512.43\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M650,-1501.5C650,-1501.5 577,-1501.5 577,-1501.5 571,-1501.5 565,-1495.5 565,-1489.5 565,-1489.5 565,-1460.5 565,-1460.5 565,-1454.5 571,-1448.5 577,-1448.5 577,-1448.5 650,-1448.5 650,-1448.5 656,-1448.5 662,-1454.5 662,-1460.5 662,-1460.5 662,-1489.5 662,-1489.5 662,-1495.5 656,-1501.5 650,-1501.5\"/>\n<text text-anchor=\"start\" x=\"584.5\" y=\"-1486.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"574\" y=\"-1471.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"573\" y=\"-1456.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 11&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>11&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"black\" d=\"M613.5,-1544.88C613.5,-1534.33 613.5,-1522.6 613.5,-1511.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"617,-1511.52 613.5,-1501.52 610,-1511.52 617,-1511.52\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M456,-1397.5C456,-1397.5 375,-1397.5 375,-1397.5 369,-1397.5 363,-1391.5 363,-1385.5 363,-1385.5 363,-1356.5 363,-1356.5 363,-1350.5 369,-1344.5 375,-1344.5 375,-1344.5 456,-1344.5 456,-1344.5 462,-1344.5 468,-1350.5 468,-1356.5 468,-1356.5 468,-1385.5 468,-1385.5 468,-1391.5 462,-1397.5 456,-1397.5\"/>\n<text text-anchor=\"start\" x=\"386.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"372\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"371\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 10]</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M456.02,-1440.88C449.49,-1429.78 442.19,-1417.37 435.61,-1406.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"438.6,-1404.36 430.51,-1397.52 432.57,-1407.91 438.6,-1404.36\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<path fill=\"#6ab6ec\" stroke=\"black\" d=\"M572.5,-1405C572.5,-1405 498.5,-1405 498.5,-1405 492.5,-1405 486.5,-1399 486.5,-1393 486.5,-1393 486.5,-1349 486.5,-1349 486.5,-1343 492.5,-1337 498.5,-1337 498.5,-1337 572.5,-1337 572.5,-1337 578.5,-1337 584.5,-1343 584.5,-1349 584.5,-1349 584.5,-1393 584.5,-1393 584.5,-1399 578.5,-1405 572.5,-1405\"/>\n<text text-anchor=\"start\" x=\"494.5\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 1.092</text>\n<text text-anchor=\"start\" x=\"502\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"496\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"495\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 4]</text>\n</g>\n<!-- 12&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>12&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M494.98,-1440.88C500.01,-1432.33 505.49,-1423.01 510.75,-1414.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"513.86,-1415.69 515.91,-1405.3 507.83,-1412.14 513.86,-1415.69\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M497,-1293.5C497,-1293.5 424,-1293.5 424,-1293.5 418,-1293.5 412,-1287.5 412,-1281.5 412,-1281.5 412,-1252.5 412,-1252.5 412,-1246.5 418,-1240.5 424,-1240.5 424,-1240.5 497,-1240.5 497,-1240.5 503,-1240.5 509,-1246.5 509,-1252.5 509,-1252.5 509,-1281.5 509,-1281.5 509,-1287.5 503,-1293.5 497,-1293.5\"/>\n<text text-anchor=\"start\" x=\"431.5\" y=\"-1278.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"421\" y=\"-1263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"420\" y=\"-1248.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M511.15,-1336.88C502.9,-1325.67 493.68,-1313.13 485.39,-1301.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"488.01,-1299.5 479.26,-1293.52 482.37,-1303.65 488.01,-1299.5\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M612,-1293.5C612,-1293.5 539,-1293.5 539,-1293.5 533,-1293.5 527,-1287.5 527,-1281.5 527,-1281.5 527,-1252.5 527,-1252.5 527,-1246.5 533,-1240.5 539,-1240.5 539,-1240.5 612,-1240.5 612,-1240.5 618,-1240.5 624,-1246.5 624,-1252.5 624,-1252.5 624,-1281.5 624,-1281.5 624,-1287.5 618,-1293.5 612,-1293.5\"/>\n<text text-anchor=\"start\" x=\"546.5\" y=\"-1278.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"536\" y=\"-1263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"535\" y=\"-1248.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4]</text>\n</g>\n<!-- 14&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>14&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M548.49,-1336.88C552.76,-1326 557.51,-1313.86 561.83,-1302.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"565.1,-1304.11 565.49,-1293.52 558.58,-1301.55 565.1,-1304.11\"/>\n</g>\n<!-- 19 -->\n<g id=\"node20\" class=\"node\">\n<title>19</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M765,-1501.5C765,-1501.5 692,-1501.5 692,-1501.5 686,-1501.5 680,-1495.5 680,-1489.5 680,-1489.5 680,-1460.5 680,-1460.5 680,-1454.5 686,-1448.5 692,-1448.5 692,-1448.5 765,-1448.5 765,-1448.5 771,-1448.5 777,-1454.5 777,-1460.5 777,-1460.5 777,-1489.5 777,-1489.5 777,-1495.5 771,-1501.5 765,-1501.5\"/>\n<text text-anchor=\"start\" x=\"699.5\" y=\"-1486.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"689\" y=\"-1471.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"688\" y=\"-1456.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 18&#45;&gt;19 -->\n<g id=\"edge19\" class=\"edge\">\n<title>18&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"black\" d=\"M760.92,-1544.88C755.79,-1534 750.08,-1521.86 744.9,-1510.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"747.93,-1509.08 740.51,-1501.52 741.6,-1512.06 747.93,-1509.08\"/>\n</g>\n<!-- 20 -->\n<g id=\"node21\" class=\"node\">\n<title>20</title>\n<path fill=\"#efb083\" stroke=\"black\" d=\"M886,-1509C886,-1509 807,-1509 807,-1509 801,-1509 795,-1503 795,-1497 795,-1497 795,-1453 795,-1453 795,-1447 801,-1441 807,-1441 807,-1441 886,-1441 886,-1441 892,-1441 898,-1447 898,-1453 898,-1453 898,-1497 898,-1497 898,-1503 892,-1509 886,-1509\"/>\n<text text-anchor=\"start\" x=\"807\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.052</text>\n<text text-anchor=\"start\" x=\"809\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.397</text>\n<text text-anchor=\"start\" x=\"803\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"start\" x=\"806\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 3]</text>\n</g>\n<!-- 18&#45;&gt;20 -->\n<g id=\"edge20\" class=\"edge\">\n<title>18&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"black\" d=\"M799.23,-1544.88C805.16,-1536.24 811.62,-1526.82 817.82,-1517.79\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"820.87,-1519.52 823.65,-1509.3 815.1,-1515.56 820.87,-1519.52\"/>\n</g>\n<!-- 21 -->\n<g id=\"node22\" class=\"node\">\n<title>21</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M769,-1397.5C769,-1397.5 696,-1397.5 696,-1397.5 690,-1397.5 684,-1391.5 684,-1385.5 684,-1385.5 684,-1356.5 684,-1356.5 684,-1350.5 690,-1344.5 696,-1344.5 696,-1344.5 769,-1344.5 769,-1344.5 775,-1344.5 781,-1350.5 781,-1356.5 781,-1356.5 781,-1385.5 781,-1385.5 781,-1391.5 775,-1397.5 769,-1397.5\"/>\n<text text-anchor=\"start\" x=\"703.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"693\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"692\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 20&#45;&gt;21 -->\n<g id=\"edge21\" class=\"edge\">\n<title>20&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"black\" d=\"M809.49,-1440.88C796.34,-1429.12 781.56,-1415.89 768.49,-1404.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"770.81,-1401.58 761.02,-1397.52 766.14,-1406.8 770.81,-1401.58\"/>\n</g>\n<!-- 22 -->\n<g id=\"node23\" class=\"node\">\n<title>22</title>\n<path fill=\"#f5cdb0\" stroke=\"black\" d=\"M884,-1405C884,-1405 811,-1405 811,-1405 805,-1405 799,-1399 799,-1393 799,-1393 799,-1349 799,-1349 799,-1343 805,-1337 811,-1337 811,-1337 884,-1337 884,-1337 890,-1337 896,-1343 896,-1349 896,-1349 896,-1393 896,-1393 896,-1399 890,-1405 884,-1405\"/>\n<text text-anchor=\"start\" x=\"810\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"810\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.469</text>\n<text text-anchor=\"start\" x=\"808\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"807\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 3]</text>\n</g>\n<!-- 20&#45;&gt;22 -->\n<g id=\"edge22\" class=\"edge\">\n<title>20&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"black\" d=\"M846.82,-1440.88C846.9,-1432.78 846.99,-1423.98 847.07,-1415.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"850.58,-1415.33 847.17,-1405.3 843.58,-1415.26 850.58,-1415.33\"/>\n</g>\n<!-- 23 -->\n<g id=\"node24\" class=\"node\">\n<title>23</title>\n<path fill=\"#efb388\" stroke=\"black\" d=\"M797.5,-1301C797.5,-1301 723.5,-1301 723.5,-1301 717.5,-1301 711.5,-1295 711.5,-1289 711.5,-1289 711.5,-1245 711.5,-1245 711.5,-1239 717.5,-1233 723.5,-1233 723.5,-1233 797.5,-1233 797.5,-1233 803.5,-1233 809.5,-1239 809.5,-1245 809.5,-1245 809.5,-1289 809.5,-1289 809.5,-1295 803.5,-1301 797.5,-1301\"/>\n<text text-anchor=\"start\" x=\"719.5\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.577</text>\n<text text-anchor=\"start\" x=\"723\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.408</text>\n<text text-anchor=\"start\" x=\"721\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"720\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 2]</text>\n</g>\n<!-- 22&#45;&gt;23 -->\n<g id=\"edge23\" class=\"edge\">\n<title>22&#45;&gt;23</title>\n<path fill=\"none\" stroke=\"black\" d=\"M819.25,-1336.88C811.66,-1327.98 803.35,-1318.24 795.43,-1308.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"798.05,-1306.64 788.9,-1301.3 792.73,-1311.18 798.05,-1306.64\"/>\n</g>\n<!-- 30 -->\n<g id=\"node31\" class=\"node\">\n<title>30</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M913,-1293.5C913,-1293.5 840,-1293.5 840,-1293.5 834,-1293.5 828,-1287.5 828,-1281.5 828,-1281.5 828,-1252.5 828,-1252.5 828,-1246.5 834,-1240.5 840,-1240.5 840,-1240.5 913,-1240.5 913,-1240.5 919,-1240.5 925,-1246.5 925,-1252.5 925,-1252.5 925,-1281.5 925,-1281.5 925,-1287.5 919,-1293.5 913,-1293.5\"/>\n<text text-anchor=\"start\" x=\"847.5\" y=\"-1278.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"837\" y=\"-1263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"836\" y=\"-1248.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 22&#45;&gt;30 -->\n<g id=\"edge30\" class=\"edge\">\n<title>22&#45;&gt;30</title>\n<path fill=\"none\" stroke=\"black\" d=\"M856.92,-1336.88C859.98,-1326.11 863.39,-1314.11 866.5,-1303.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"869.88,-1304.1 869.24,-1293.52 863.14,-1302.18 869.88,-1304.1\"/>\n</g>\n<!-- 24 -->\n<g id=\"node25\" class=\"node\">\n<title>24</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M744,-1197C744,-1197 671,-1197 671,-1197 665,-1197 659,-1191 659,-1185 659,-1185 659,-1141 659,-1141 659,-1135 665,-1129 671,-1129 671,-1129 744,-1129 744,-1129 750,-1129 756,-1135 756,-1141 756,-1141 756,-1185 756,-1185 756,-1191 750,-1197 744,-1197\"/>\n<text text-anchor=\"start\" x=\"668\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.322</text>\n<text text-anchor=\"start\" x=\"678.5\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"668\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"667\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 2]</text>\n</g>\n<!-- 23&#45;&gt;24 -->\n<g id=\"edge24\" class=\"edge\">\n<title>23&#45;&gt;24</title>\n<path fill=\"none\" stroke=\"black\" d=\"M743.29,-1232.88C738.9,-1224.42 734.11,-1215.21 729.51,-1206.35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"732.52,-1204.56 724.8,-1197.3 726.31,-1207.79 732.52,-1204.56\"/>\n</g>\n<!-- 29 -->\n<g id=\"node30\" class=\"node\">\n<title>29</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M859,-1189.5C859,-1189.5 786,-1189.5 786,-1189.5 780,-1189.5 774,-1183.5 774,-1177.5 774,-1177.5 774,-1148.5 774,-1148.5 774,-1142.5 780,-1136.5 786,-1136.5 786,-1136.5 859,-1136.5 859,-1136.5 865,-1136.5 871,-1142.5 871,-1148.5 871,-1148.5 871,-1177.5 871,-1177.5 871,-1183.5 865,-1189.5 859,-1189.5\"/>\n<text text-anchor=\"start\" x=\"793.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"783\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"782\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 23&#45;&gt;29 -->\n<g id=\"edge29\" class=\"edge\">\n<title>23&#45;&gt;29</title>\n<path fill=\"none\" stroke=\"black\" d=\"M780.63,-1232.88C787.38,-1221.78 794.92,-1209.37 801.72,-1198.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"804.78,-1199.88 806.99,-1189.52 798.8,-1196.25 804.78,-1199.88\"/>\n</g>\n<!-- 25 -->\n<g id=\"node26\" class=\"node\">\n<title>25</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M703.5,-1093C703.5,-1093 629.5,-1093 629.5,-1093 623.5,-1093 617.5,-1087 617.5,-1081 617.5,-1081 617.5,-1037 617.5,-1037 617.5,-1031 623.5,-1025 629.5,-1025 629.5,-1025 703.5,-1025 703.5,-1025 709.5,-1025 715.5,-1031 715.5,-1037 715.5,-1037 715.5,-1081 715.5,-1081 715.5,-1087 709.5,-1093 703.5,-1093\"/>\n<text text-anchor=\"start\" x=\"625.5\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.425</text>\n<text text-anchor=\"start\" x=\"629\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"627\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"626\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 24&#45;&gt;25 -->\n<g id=\"edge25\" class=\"edge\">\n<title>24&#45;&gt;25</title>\n<path fill=\"none\" stroke=\"black\" d=\"M694.19,-1128.88C690.82,-1120.51 687.16,-1111.4 683.64,-1102.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"686.86,-1101.27 679.89,-1093.3 680.37,-1103.88 686.86,-1101.27\"/>\n</g>\n<!-- 28 -->\n<g id=\"node29\" class=\"node\">\n<title>28</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M819,-1085.5C819,-1085.5 746,-1085.5 746,-1085.5 740,-1085.5 734,-1079.5 734,-1073.5 734,-1073.5 734,-1044.5 734,-1044.5 734,-1038.5 740,-1032.5 746,-1032.5 746,-1032.5 819,-1032.5 819,-1032.5 825,-1032.5 831,-1038.5 831,-1044.5 831,-1044.5 831,-1073.5 831,-1073.5 831,-1079.5 825,-1085.5 819,-1085.5\"/>\n<text text-anchor=\"start\" x=\"753.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"743\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"742\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 24&#45;&gt;28 -->\n<g id=\"edge28\" class=\"edge\">\n<title>24&#45;&gt;28</title>\n<path fill=\"none\" stroke=\"black\" d=\"M731.85,-1128.88C740.1,-1117.67 749.32,-1105.13 757.61,-1093.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"760.63,-1095.65 763.74,-1085.52 754.99,-1091.5 760.63,-1095.65\"/>\n</g>\n<!-- 26 -->\n<g id=\"node27\" class=\"node\">\n<title>26</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M685,-981.5C685,-981.5 612,-981.5 612,-981.5 606,-981.5 600,-975.5 600,-969.5 600,-969.5 600,-940.5 600,-940.5 600,-934.5 606,-928.5 612,-928.5 612,-928.5 685,-928.5 685,-928.5 691,-928.5 697,-934.5 697,-940.5 697,-940.5 697,-969.5 697,-969.5 697,-975.5 691,-981.5 685,-981.5\"/>\n<text text-anchor=\"start\" x=\"619.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"609\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"608\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 25&#45;&gt;26 -->\n<g id=\"edge26\" class=\"edge\">\n<title>25&#45;&gt;26</title>\n<path fill=\"none\" stroke=\"black\" d=\"M660.66,-1024.88C658.77,-1014.22 656.68,-1002.35 654.77,-991.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"658.19,-990.76 653,-981.52 651.29,-991.98 658.19,-990.76\"/>\n</g>\n<!-- 27 -->\n<g id=\"node28\" class=\"node\">\n<title>27</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M800,-981.5C800,-981.5 727,-981.5 727,-981.5 721,-981.5 715,-975.5 715,-969.5 715,-969.5 715,-940.5 715,-940.5 715,-934.5 721,-928.5 727,-928.5 727,-928.5 800,-928.5 800,-928.5 806,-928.5 812,-934.5 812,-940.5 812,-940.5 812,-969.5 812,-969.5 812,-975.5 806,-981.5 800,-981.5\"/>\n<text text-anchor=\"start\" x=\"734.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"724\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"723\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 25&#45;&gt;27 -->\n<g id=\"edge27\" class=\"edge\">\n<title>25&#45;&gt;27</title>\n<path fill=\"none\" stroke=\"black\" d=\"M697.99,-1024.88C708.97,-1013.34 721.29,-1000.39 732.25,-988.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"734.88,-991.18 739.23,-981.52 729.8,-986.35 734.88,-991.18\"/>\n</g>\n<!-- 33 -->\n<g id=\"node34\" class=\"node\">\n<title>33</title>\n<path fill=\"#ea975c\" stroke=\"black\" d=\"M1139,-1717C1139,-1717 1020,-1717 1020,-1717 1014,-1717 1008,-1711 1008,-1705 1008,-1705 1008,-1661 1008,-1661 1008,-1655 1014,-1649 1020,-1649 1020,-1649 1139,-1649 1139,-1649 1145,-1649 1151,-1655 1151,-1661 1151,-1661 1151,-1705 1151,-1705 1151,-1711 1145,-1717 1139,-1717\"/>\n<text text-anchor=\"start\" x=\"1016\" y=\"-1701.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_A ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1042\" y=\"-1686.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.255</text>\n<text text-anchor=\"start\" x=\"1036\" y=\"-1671.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 20</text>\n<text text-anchor=\"start\" x=\"1035\" y=\"-1656.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 3]</text>\n</g>\n<!-- 32&#45;&gt;33 -->\n<g id=\"edge33\" class=\"edge\">\n<title>32&#45;&gt;33</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1091.66,-1752.88C1090.21,-1744.69 1088.64,-1735.79 1087.12,-1727.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1090.56,-1726.54 1085.38,-1717.3 1083.67,-1727.76 1090.56,-1726.54\"/>\n</g>\n<!-- 42 -->\n<g id=\"node43\" class=\"node\">\n<title>42</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M1260,-1717C1260,-1717 1181,-1717 1181,-1717 1175,-1717 1169,-1711 1169,-1705 1169,-1705 1169,-1661 1169,-1661 1169,-1655 1175,-1649 1181,-1649 1181,-1649 1260,-1649 1260,-1649 1266,-1649 1272,-1655 1272,-1661 1272,-1661 1272,-1705 1272,-1705 1272,-1711 1266,-1717 1260,-1717\"/>\n<text text-anchor=\"start\" x=\"1179.5\" y=\"-1701.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.648</text>\n<text text-anchor=\"start\" x=\"1191.5\" y=\"-1686.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"1177\" y=\"-1671.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"1180\" y=\"-1656.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 5]</text>\n</g>\n<!-- 32&#45;&gt;42 -->\n<g id=\"edge42\" class=\"edge\">\n<title>32&#45;&gt;42</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1137.43,-1752.88C1148.61,-1743.62 1160.86,-1733.45 1172.45,-1723.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1174.88,-1726.38 1180.34,-1717.3 1170.41,-1720.99 1174.88,-1726.38\"/>\n</g>\n<!-- 34 -->\n<g id=\"node35\" class=\"node\">\n<title>34</title>\n<path fill=\"#e89050\" stroke=\"black\" d=\"M1005,-1613C1005,-1613 924,-1613 924,-1613 918,-1613 912,-1607 912,-1601 912,-1601 912,-1557 912,-1557 912,-1551 918,-1545 924,-1545 924,-1545 1005,-1545 1005,-1545 1011,-1545 1017,-1551 1017,-1557 1017,-1557 1017,-1601 1017,-1601 1017,-1607 1011,-1613 1005,-1613\"/>\n<text text-anchor=\"start\" x=\"923.5\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.404</text>\n<text text-anchor=\"start\" x=\"927\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.188</text>\n<text text-anchor=\"start\" x=\"921\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\n<text text-anchor=\"start\" x=\"920\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 2]</text>\n</g>\n<!-- 33&#45;&gt;34 -->\n<g id=\"edge34\" class=\"edge\">\n<title>33&#45;&gt;34</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1042.16,-1648.88C1031.82,-1639.71 1020.48,-1629.65 1009.74,-1620.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1011.85,-1617.32 1002.04,-1613.3 1007.2,-1622.55 1011.85,-1617.32\"/>\n</g>\n<!-- 41 -->\n<g id=\"node42\" class=\"node\">\n<title>41</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1120,-1605.5C1120,-1605.5 1047,-1605.5 1047,-1605.5 1041,-1605.5 1035,-1599.5 1035,-1593.5 1035,-1593.5 1035,-1564.5 1035,-1564.5 1035,-1558.5 1041,-1552.5 1047,-1552.5 1047,-1552.5 1120,-1552.5 1120,-1552.5 1126,-1552.5 1132,-1558.5 1132,-1564.5 1132,-1564.5 1132,-1593.5 1132,-1593.5 1132,-1599.5 1126,-1605.5 1120,-1605.5\"/>\n<text text-anchor=\"start\" x=\"1054.5\" y=\"-1590.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1044\" y=\"-1575.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1043\" y=\"-1560.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 33&#45;&gt;41 -->\n<g id=\"edge41\" class=\"edge\">\n<title>33&#45;&gt;41</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1080.8,-1648.88C1081.22,-1638.22 1081.68,-1626.35 1082.11,-1615.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1085.6,-1615.65 1082.5,-1605.52 1078.61,-1615.38 1085.6,-1615.65\"/>\n</g>\n<!-- 35 -->\n<g id=\"node36\" class=\"node\">\n<title>35</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M1001,-1509C1001,-1509 928,-1509 928,-1509 922,-1509 916,-1503 916,-1497 916,-1497 916,-1453 916,-1453 916,-1447 922,-1441 928,-1441 928,-1441 1001,-1441 1001,-1441 1007,-1441 1013,-1447 1013,-1453 1013,-1453 1013,-1497 1013,-1497 1013,-1503 1007,-1509 1001,-1509\"/>\n<text text-anchor=\"start\" x=\"925\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 1.373</text>\n<text text-anchor=\"start\" x=\"927\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"925\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"924\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 2]</text>\n</g>\n<!-- 34&#45;&gt;35 -->\n<g id=\"edge35\" class=\"edge\">\n<title>34&#45;&gt;35</title>\n<path fill=\"none\" stroke=\"black\" d=\"M964.5,-1544.88C964.5,-1536.78 964.5,-1527.98 964.5,-1519.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"968,-1519.3 964.5,-1509.3 961,-1519.3 968,-1519.3\"/>\n</g>\n<!-- 40 -->\n<g id=\"node41\" class=\"node\">\n<title>40</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1124,-1501.5C1124,-1501.5 1043,-1501.5 1043,-1501.5 1037,-1501.5 1031,-1495.5 1031,-1489.5 1031,-1489.5 1031,-1460.5 1031,-1460.5 1031,-1454.5 1037,-1448.5 1043,-1448.5 1043,-1448.5 1124,-1448.5 1124,-1448.5 1130,-1448.5 1136,-1454.5 1136,-1460.5 1136,-1460.5 1136,-1489.5 1136,-1489.5 1136,-1495.5 1130,-1501.5 1124,-1501.5\"/>\n<text text-anchor=\"start\" x=\"1054.5\" y=\"-1486.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1040\" y=\"-1471.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13</text>\n<text text-anchor=\"start\" x=\"1039\" y=\"-1456.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 0]</text>\n</g>\n<!-- 34&#45;&gt;40 -->\n<g id=\"edge40\" class=\"edge\">\n<title>34&#45;&gt;40</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1003.14,-1544.88C1016.86,-1533.12 1032.29,-1519.89 1045.93,-1508.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1048.41,-1510.69 1053.73,-1501.52 1043.86,-1505.37 1048.41,-1510.69\"/>\n</g>\n<!-- 36 -->\n<g id=\"node37\" class=\"node\">\n<title>36</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1000,-1397.5C1000,-1397.5 927,-1397.5 927,-1397.5 921,-1397.5 915,-1391.5 915,-1385.5 915,-1385.5 915,-1356.5 915,-1356.5 915,-1350.5 921,-1344.5 927,-1344.5 927,-1344.5 1000,-1344.5 1000,-1344.5 1006,-1344.5 1012,-1350.5 1012,-1356.5 1012,-1356.5 1012,-1385.5 1012,-1385.5 1012,-1391.5 1006,-1397.5 1000,-1397.5\"/>\n<text text-anchor=\"start\" x=\"934.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"924\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"923\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 35&#45;&gt;36 -->\n<g id=\"edge36\" class=\"edge\">\n<title>35&#45;&gt;36</title>\n<path fill=\"none\" stroke=\"black\" d=\"M964.18,-1440.88C964.07,-1430.33 963.96,-1418.6 963.85,-1407.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"967.35,-1407.49 963.75,-1397.52 960.35,-1407.55 967.35,-1407.49\"/>\n</g>\n<!-- 37 -->\n<g id=\"node38\" class=\"node\">\n<title>37</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M1115,-1405C1115,-1405 1042,-1405 1042,-1405 1036,-1405 1030,-1399 1030,-1393 1030,-1393 1030,-1349 1030,-1349 1030,-1343 1036,-1337 1042,-1337 1042,-1337 1115,-1337 1115,-1337 1121,-1337 1127,-1343 1127,-1349 1127,-1349 1127,-1393 1127,-1393 1127,-1399 1121,-1405 1115,-1405\"/>\n<text text-anchor=\"start\" x=\"1039\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 2.066</text>\n<text text-anchor=\"start\" x=\"1049.5\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"1039\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"1038\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 2]</text>\n</g>\n<!-- 35&#45;&gt;37 -->\n<g id=\"edge37\" class=\"edge\">\n<title>35&#45;&gt;37</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1001.51,-1440.88C1011.77,-1431.71 1023.01,-1421.65 1033.66,-1412.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1036.16,-1414.58 1041.28,-1405.3 1031.5,-1409.36 1036.16,-1414.58\"/>\n</g>\n<!-- 38 -->\n<g id=\"node39\" class=\"node\">\n<title>38</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1058,-1293.5C1058,-1293.5 985,-1293.5 985,-1293.5 979,-1293.5 973,-1287.5 973,-1281.5 973,-1281.5 973,-1252.5 973,-1252.5 973,-1246.5 979,-1240.5 985,-1240.5 985,-1240.5 1058,-1240.5 1058,-1240.5 1064,-1240.5 1070,-1246.5 1070,-1252.5 1070,-1252.5 1070,-1281.5 1070,-1281.5 1070,-1287.5 1064,-1293.5 1058,-1293.5\"/>\n<text text-anchor=\"start\" x=\"992.5\" y=\"-1278.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"982\" y=\"-1263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"981\" y=\"-1248.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 37&#45;&gt;38 -->\n<g id=\"edge38\" class=\"edge\">\n<title>37&#45;&gt;38</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1059.99,-1336.88C1053.85,-1325.89 1046.99,-1313.62 1040.79,-1302.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1043.69,-1300.54 1035.76,-1293.52 1037.58,-1303.96 1043.69,-1300.54\"/>\n</g>\n<!-- 39 -->\n<g id=\"node40\" class=\"node\">\n<title>39</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1173,-1293.5C1173,-1293.5 1100,-1293.5 1100,-1293.5 1094,-1293.5 1088,-1287.5 1088,-1281.5 1088,-1281.5 1088,-1252.5 1088,-1252.5 1088,-1246.5 1094,-1240.5 1100,-1240.5 1100,-1240.5 1173,-1240.5 1173,-1240.5 1179,-1240.5 1185,-1246.5 1185,-1252.5 1185,-1252.5 1185,-1281.5 1185,-1281.5 1185,-1287.5 1179,-1293.5 1173,-1293.5\"/>\n<text text-anchor=\"start\" x=\"1107.5\" y=\"-1278.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1097\" y=\"-1263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1096\" y=\"-1248.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 37&#45;&gt;39 -->\n<g id=\"edge39\" class=\"edge\">\n<title>37&#45;&gt;39</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1097.33,-1336.88C1103.58,-1325.89 1110.56,-1313.62 1116.87,-1302.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1120.09,-1303.94 1121.99,-1293.52 1114,-1300.48 1120.09,-1303.94\"/>\n</g>\n<!-- 43 -->\n<g id=\"node44\" class=\"node\">\n<title>43</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1235,-1605.5C1235,-1605.5 1162,-1605.5 1162,-1605.5 1156,-1605.5 1150,-1599.5 1150,-1593.5 1150,-1593.5 1150,-1564.5 1150,-1564.5 1150,-1558.5 1156,-1552.5 1162,-1552.5 1162,-1552.5 1235,-1552.5 1235,-1552.5 1241,-1552.5 1247,-1558.5 1247,-1564.5 1247,-1564.5 1247,-1593.5 1247,-1593.5 1247,-1599.5 1241,-1605.5 1235,-1605.5\"/>\n<text text-anchor=\"start\" x=\"1169.5\" y=\"-1590.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1159\" y=\"-1575.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1158\" y=\"-1560.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 42&#45;&gt;43 -->\n<g id=\"edge43\" class=\"edge\">\n<title>42&#45;&gt;43</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1213.36,-1648.88C1211.06,-1638.22 1208.5,-1626.35 1206.16,-1615.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1209.53,-1614.56 1204,-1605.52 1202.69,-1616.03 1209.53,-1614.56\"/>\n</g>\n<!-- 44 -->\n<g id=\"node45\" class=\"node\">\n<title>44</title>\n<path fill=\"#88c4ef\" stroke=\"black\" d=\"M1396,-1613C1396,-1613 1277,-1613 1277,-1613 1271,-1613 1265,-1607 1265,-1601 1265,-1601 1265,-1557 1265,-1557 1265,-1551 1271,-1545 1277,-1545 1277,-1545 1396,-1545 1396,-1545 1402,-1545 1408,-1551 1408,-1557 1408,-1557 1408,-1601 1408,-1601 1408,-1607 1402,-1613 1396,-1613\"/>\n<text text-anchor=\"start\" x=\"1273\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_multiple ≤ 1.5</text>\n<text text-anchor=\"start\" x=\"1299\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.408</text>\n<text text-anchor=\"start\" x=\"1297\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"1296\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 5]</text>\n</g>\n<!-- 42&#45;&gt;44 -->\n<g id=\"edge44\" class=\"edge\">\n<title>42&#45;&gt;44</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1258.16,-1648.88C1268.6,-1639.71 1280.04,-1629.65 1290.87,-1620.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1293.43,-1622.53 1298.63,-1613.3 1288.81,-1617.27 1293.43,-1622.53\"/>\n</g>\n<!-- 45 -->\n<g id=\"node46\" class=\"node\">\n<title>45</title>\n<path fill=\"#61b1ea\" stroke=\"black\" d=\"M1257.5,-1509C1257.5,-1509 1183.5,-1509 1183.5,-1509 1177.5,-1509 1171.5,-1503 1171.5,-1497 1171.5,-1497 1171.5,-1453 1171.5,-1453 1171.5,-1447 1177.5,-1441 1183.5,-1441 1183.5,-1441 1257.5,-1441 1257.5,-1441 1263.5,-1441 1269.5,-1447 1269.5,-1453 1269.5,-1453 1269.5,-1497 1269.5,-1497 1269.5,-1503 1263.5,-1509 1257.5,-1509\"/>\n<text text-anchor=\"start\" x=\"1179.5\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 1.706</text>\n<text text-anchor=\"start\" x=\"1183\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.278</text>\n<text text-anchor=\"start\" x=\"1181\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"1180\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 5]</text>\n</g>\n<!-- 44&#45;&gt;45 -->\n<g id=\"edge45\" class=\"edge\">\n<title>44&#45;&gt;45</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1298.84,-1544.88C1288.4,-1535.71 1276.96,-1525.65 1266.13,-1516.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1268.19,-1513.27 1258.37,-1509.3 1263.57,-1518.53 1268.19,-1513.27\"/>\n</g>\n<!-- 48 -->\n<g id=\"node49\" class=\"node\">\n<title>48</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1373,-1501.5C1373,-1501.5 1300,-1501.5 1300,-1501.5 1294,-1501.5 1288,-1495.5 1288,-1489.5 1288,-1489.5 1288,-1460.5 1288,-1460.5 1288,-1454.5 1294,-1448.5 1300,-1448.5 1300,-1448.5 1373,-1448.5 1373,-1448.5 1379,-1448.5 1385,-1454.5 1385,-1460.5 1385,-1460.5 1385,-1489.5 1385,-1489.5 1385,-1495.5 1379,-1501.5 1373,-1501.5\"/>\n<text text-anchor=\"start\" x=\"1307.5\" y=\"-1486.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1297\" y=\"-1471.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1296\" y=\"-1456.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 44&#45;&gt;48 -->\n<g id=\"edge48\" class=\"edge\">\n<title>44&#45;&gt;48</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1336.5,-1544.88C1336.5,-1534.33 1336.5,-1522.6 1336.5,-1511.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1340,-1511.52 1336.5,-1501.52 1333,-1511.52 1340,-1511.52\"/>\n</g>\n<!-- 46 -->\n<g id=\"node47\" class=\"node\">\n<title>46</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1244,-1397.5C1244,-1397.5 1171,-1397.5 1171,-1397.5 1165,-1397.5 1159,-1391.5 1159,-1385.5 1159,-1385.5 1159,-1356.5 1159,-1356.5 1159,-1350.5 1165,-1344.5 1171,-1344.5 1171,-1344.5 1244,-1344.5 1244,-1344.5 1250,-1344.5 1256,-1350.5 1256,-1356.5 1256,-1356.5 1256,-1385.5 1256,-1385.5 1256,-1391.5 1250,-1397.5 1244,-1397.5\"/>\n<text text-anchor=\"start\" x=\"1178.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1168\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"1167\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 5]</text>\n</g>\n<!-- 45&#45;&gt;46 -->\n<g id=\"edge46\" class=\"edge\">\n<title>45&#45;&gt;46</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1216.28,-1440.88C1214.92,-1430.22 1213.41,-1418.35 1212.03,-1407.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1215.49,-1407 1210.75,-1397.52 1208.54,-1407.88 1215.49,-1407\"/>\n</g>\n<!-- 47 -->\n<g id=\"node48\" class=\"node\">\n<title>47</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1359,-1397.5C1359,-1397.5 1286,-1397.5 1286,-1397.5 1280,-1397.5 1274,-1391.5 1274,-1385.5 1274,-1385.5 1274,-1356.5 1274,-1356.5 1274,-1350.5 1280,-1344.5 1286,-1344.5 1286,-1344.5 1359,-1344.5 1359,-1344.5 1365,-1344.5 1371,-1350.5 1371,-1356.5 1371,-1356.5 1371,-1385.5 1371,-1385.5 1371,-1391.5 1365,-1397.5 1359,-1397.5\"/>\n<text text-anchor=\"start\" x=\"1293.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1283\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1282\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 45&#45;&gt;47 -->\n<g id=\"edge47\" class=\"edge\">\n<title>45&#45;&gt;47</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1253.62,-1440.88C1265.16,-1429.34 1278.11,-1416.39 1289.64,-1404.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1292.38,-1407.07 1296.98,-1397.52 1287.43,-1402.12 1292.38,-1407.07\"/>\n</g>\n<!-- 50 -->\n<g id=\"node51\" class=\"node\">\n<title>50</title>\n<path fill=\"#aad5f4\" stroke=\"black\" d=\"M2258,-2133C2258,-2133 2179,-2133 2179,-2133 2173,-2133 2167,-2127 2167,-2121 2167,-2121 2167,-2077 2167,-2077 2167,-2071 2173,-2065 2179,-2065 2179,-2065 2258,-2065 2258,-2065 2264,-2065 2270,-2071 2270,-2077 2270,-2077 2270,-2121 2270,-2121 2270,-2127 2264,-2133 2258,-2133\"/>\n<text text-anchor=\"start\" x=\"2181\" y=\"-2117.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 2.5</text>\n<text text-anchor=\"start\" x=\"2181\" y=\"-2102.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.463</text>\n<text text-anchor=\"start\" x=\"2175\" y=\"-2087.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"start\" x=\"2178\" y=\"-2072.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 7]</text>\n</g>\n<!-- 49&#45;&gt;50 -->\n<g id=\"edge50\" class=\"edge\">\n<title>49&#45;&gt;50</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2263.75,-2168.88C2258.07,-2160.24 2251.88,-2150.82 2245.95,-2141.79\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2248.79,-2139.74 2240.37,-2133.3 2242.94,-2143.58 2248.79,-2139.74\"/>\n</g>\n<!-- 53 -->\n<g id=\"node54\" class=\"node\">\n<title>53</title>\n<path fill=\"#e99456\" stroke=\"black\" d=\"M2402.5,-2133C2402.5,-2133 2304.5,-2133 2304.5,-2133 2298.5,-2133 2292.5,-2127 2292.5,-2121 2292.5,-2121 2292.5,-2077 2292.5,-2077 2292.5,-2071 2298.5,-2065 2304.5,-2065 2304.5,-2065 2402.5,-2065 2402.5,-2065 2408.5,-2065 2414.5,-2071 2414.5,-2077 2414.5,-2077 2414.5,-2121 2414.5,-2121 2414.5,-2127 2408.5,-2133 2402.5,-2133\"/>\n<text text-anchor=\"start\" x=\"2312.5\" y=\"-2117.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 1.088</text>\n<text text-anchor=\"start\" x=\"2316\" y=\"-2102.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.225</text>\n<text text-anchor=\"start\" x=\"2306\" y=\"-2087.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 317</text>\n<text text-anchor=\"start\" x=\"2300.5\" y=\"-2072.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [276, 41]</text>\n</g>\n<!-- 49&#45;&gt;53 -->\n<g id=\"edge53\" class=\"edge\">\n<title>49&#45;&gt;53</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2307.58,-2168.88C2313.34,-2160.24 2319.62,-2150.82 2325.64,-2141.79\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2328.67,-2143.56 2331.3,-2133.3 2322.84,-2139.68 2328.67,-2143.56\"/>\n</g>\n<!-- 51 -->\n<g id=\"node52\" class=\"node\">\n<title>51</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2140,-2021.5C2140,-2021.5 2067,-2021.5 2067,-2021.5 2061,-2021.5 2055,-2015.5 2055,-2009.5 2055,-2009.5 2055,-1980.5 2055,-1980.5 2055,-1974.5 2061,-1968.5 2067,-1968.5 2067,-1968.5 2140,-1968.5 2140,-1968.5 2146,-1968.5 2152,-1974.5 2152,-1980.5 2152,-1980.5 2152,-2009.5 2152,-2009.5 2152,-2015.5 2146,-2021.5 2140,-2021.5\"/>\n<text text-anchor=\"start\" x=\"2074.5\" y=\"-2006.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2064\" y=\"-1991.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"2063\" y=\"-1976.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 7]</text>\n</g>\n<!-- 50&#45;&gt;51 -->\n<g id=\"edge51\" class=\"edge\">\n<title>50&#45;&gt;51</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2181.16,-2064.88C2167.9,-2053.12 2152.99,-2039.89 2139.81,-2028.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2142.08,-2025.54 2132.27,-2021.52 2137.43,-2030.77 2142.08,-2025.54\"/>\n</g>\n<!-- 52 -->\n<g id=\"node53\" class=\"node\">\n<title>52</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2255,-2021.5C2255,-2021.5 2182,-2021.5 2182,-2021.5 2176,-2021.5 2170,-2015.5 2170,-2009.5 2170,-2009.5 2170,-1980.5 2170,-1980.5 2170,-1974.5 2176,-1968.5 2182,-1968.5 2182,-1968.5 2255,-1968.5 2255,-1968.5 2261,-1968.5 2267,-1974.5 2267,-1980.5 2267,-1980.5 2267,-2009.5 2267,-2009.5 2267,-2015.5 2261,-2021.5 2255,-2021.5\"/>\n<text text-anchor=\"start\" x=\"2189.5\" y=\"-2006.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2179\" y=\"-1991.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"2178\" y=\"-1976.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 0]</text>\n</g>\n<!-- 50&#45;&gt;52 -->\n<g id=\"edge52\" class=\"edge\">\n<title>50&#45;&gt;52</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2218.5,-2064.88C2218.5,-2054.33 2218.5,-2042.6 2218.5,-2031.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2222,-2031.52 2218.5,-2021.52 2215,-2031.52 2222,-2031.52\"/>\n</g>\n<!-- 54 -->\n<g id=\"node55\" class=\"node\">\n<title>54</title>\n<path fill=\"#e89253\" stroke=\"black\" d=\"M2409.5,-2029C2409.5,-2029 2297.5,-2029 2297.5,-2029 2291.5,-2029 2285.5,-2023 2285.5,-2017 2285.5,-2017 2285.5,-1973 2285.5,-1973 2285.5,-1967 2291.5,-1961 2297.5,-1961 2297.5,-1961 2409.5,-1961 2409.5,-1961 2415.5,-1961 2421.5,-1967 2421.5,-1973 2421.5,-1973 2421.5,-2017 2421.5,-2017 2421.5,-2023 2415.5,-2029 2409.5,-2029\"/>\n<text text-anchor=\"start\" x=\"2293.5\" y=\"-2013.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Embarked_C ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"2316\" y=\"-1998.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.206</text>\n<text text-anchor=\"start\" x=\"2306\" y=\"-1983.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 300</text>\n<text text-anchor=\"start\" x=\"2300.5\" y=\"-1968.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [265, 35]</text>\n</g>\n<!-- 53&#45;&gt;54 -->\n<g id=\"edge54\" class=\"edge\">\n<title>53&#45;&gt;54</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2353.5,-2064.88C2353.5,-2056.78 2353.5,-2047.98 2353.5,-2039.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2357,-2039.3 2353.5,-2029.3 2350,-2039.3 2357,-2039.3\"/>\n</g>\n<!-- 197 -->\n<g id=\"node198\" class=\"node\">\n<title>197</title>\n<path fill=\"#f3c6a5\" stroke=\"black\" d=\"M2533,-2029C2533,-2029 2452,-2029 2452,-2029 2446,-2029 2440,-2023 2440,-2017 2440,-2017 2440,-1973 2440,-1973 2440,-1967 2446,-1961 2452,-1961 2452,-1961 2533,-1961 2533,-1961 2539,-1961 2545,-1967 2545,-1973 2545,-1973 2545,-2017 2545,-2017 2545,-2023 2539,-2029 2533,-2029\"/>\n<text text-anchor=\"start\" x=\"2451.5\" y=\"-2013.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 1.172</text>\n<text text-anchor=\"start\" x=\"2455\" y=\"-1998.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.457</text>\n<text text-anchor=\"start\" x=\"2449\" y=\"-1983.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\n<text text-anchor=\"start\" x=\"2448\" y=\"-1968.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 6]</text>\n</g>\n<!-- 53&#45;&gt;197 -->\n<g id=\"edge197\" class=\"edge\">\n<title>53&#45;&gt;197</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2398.63,-2064.88C2411.5,-2055.44 2425.64,-2045.06 2438.96,-2035.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2441.13,-2038.04 2447.12,-2029.3 2436.99,-2032.39 2441.13,-2038.04\"/>\n</g>\n<!-- 55 -->\n<g id=\"node56\" class=\"node\">\n<title>55</title>\n<path fill=\"#e88f4f\" stroke=\"black\" d=\"M1939.5,-1925C1939.5,-1925 1841.5,-1925 1841.5,-1925 1835.5,-1925 1829.5,-1919 1829.5,-1913 1829.5,-1913 1829.5,-1869 1829.5,-1869 1829.5,-1863 1835.5,-1857 1841.5,-1857 1841.5,-1857 1939.5,-1857 1939.5,-1857 1945.5,-1857 1951.5,-1863 1951.5,-1869 1951.5,-1869 1951.5,-1913 1951.5,-1913 1951.5,-1919 1945.5,-1925 1939.5,-1925\"/>\n<text text-anchor=\"start\" x=\"1849\" y=\"-1909.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;1.556</text>\n<text text-anchor=\"start\" x=\"1857\" y=\"-1894.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.18</text>\n<text text-anchor=\"start\" x=\"1843\" y=\"-1879.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 260</text>\n<text text-anchor=\"start\" x=\"1837.5\" y=\"-1864.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [234, 26]</text>\n</g>\n<!-- 54&#45;&gt;55 -->\n<g id=\"edge55\" class=\"edge\">\n<title>54&#45;&gt;55</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2285.33,-1964.14C2282.03,-1963.02 2278.74,-1961.96 2275.5,-1961 2168.51,-1929.21 2040.19,-1909.8 1962.04,-1899.97\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1962.18,-1896.46 1951.82,-1898.71 1961.32,-1903.41 1962.18,-1896.46\"/>\n</g>\n<!-- 164 -->\n<g id=\"node165\" class=\"node\">\n<title>164</title>\n<path fill=\"#eda672\" stroke=\"black\" d=\"M2396,-1925C2396,-1925 2315,-1925 2315,-1925 2309,-1925 2303,-1919 2303,-1913 2303,-1913 2303,-1869 2303,-1869 2303,-1863 2309,-1857 2315,-1857 2315,-1857 2396,-1857 2396,-1857 2402,-1857 2408,-1863 2408,-1869 2408,-1869 2408,-1913 2408,-1913 2408,-1919 2402,-1925 2396,-1925\"/>\n<text text-anchor=\"start\" x=\"2314\" y=\"-1909.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.631</text>\n<text text-anchor=\"start\" x=\"2318\" y=\"-1894.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.349</text>\n<text text-anchor=\"start\" x=\"2312\" y=\"-1879.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 40</text>\n<text text-anchor=\"start\" x=\"2311\" y=\"-1864.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 9]</text>\n</g>\n<!-- 54&#45;&gt;164 -->\n<g id=\"edge164\" class=\"edge\">\n<title>54&#45;&gt;164</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2354.15,-1960.88C2354.31,-1952.78 2354.48,-1943.98 2354.65,-1935.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2358.15,-1935.37 2354.85,-1925.3 2351.15,-1935.23 2358.15,-1935.37\"/>\n</g>\n<!-- 56 -->\n<g id=\"node57\" class=\"node\">\n<title>56</title>\n<path fill=\"#efb083\" stroke=\"black\" d=\"M1734,-1821C1734,-1821 1655,-1821 1655,-1821 1649,-1821 1643,-1815 1643,-1809 1643,-1809 1643,-1765 1643,-1765 1643,-1759 1649,-1753 1655,-1753 1655,-1753 1734,-1753 1734,-1753 1740,-1753 1746,-1759 1746,-1765 1746,-1765 1746,-1809 1746,-1809 1746,-1815 1740,-1821 1734,-1821\"/>\n<text text-anchor=\"start\" x=\"1657\" y=\"-1805.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 2.0</text>\n<text text-anchor=\"start\" x=\"1657\" y=\"-1790.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.397</text>\n<text text-anchor=\"start\" x=\"1651\" y=\"-1775.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"start\" x=\"1654\" y=\"-1760.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 3]</text>\n</g>\n<!-- 55&#45;&gt;56 -->\n<g id=\"edge56\" class=\"edge\">\n<title>55&#45;&gt;56</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1829.29,-1858.15C1805.59,-1845.81 1778.52,-1831.73 1754.9,-1819.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1756.51,-1816.33 1746.02,-1814.81 1753.28,-1822.53 1756.51,-1816.33\"/>\n</g>\n<!-- 59 -->\n<g id=\"node60\" class=\"node\">\n<title>59</title>\n<path fill=\"#e88e4d\" stroke=\"black\" d=\"M1939.5,-1821C1939.5,-1821 1841.5,-1821 1841.5,-1821 1835.5,-1821 1829.5,-1815 1829.5,-1809 1829.5,-1809 1829.5,-1765 1829.5,-1765 1829.5,-1759 1835.5,-1753 1841.5,-1753 1841.5,-1753 1939.5,-1753 1939.5,-1753 1945.5,-1753 1951.5,-1759 1951.5,-1765 1951.5,-1765 1951.5,-1809 1951.5,-1809 1951.5,-1815 1945.5,-1821 1939.5,-1821\"/>\n<text text-anchor=\"start\" x=\"1853\" y=\"-1805.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1853\" y=\"-1790.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.168</text>\n<text text-anchor=\"start\" x=\"1843\" y=\"-1775.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 249</text>\n<text text-anchor=\"start\" x=\"1837.5\" y=\"-1760.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [226, 23]</text>\n</g>\n<!-- 55&#45;&gt;59 -->\n<g id=\"edge59\" class=\"edge\">\n<title>55&#45;&gt;59</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1890.5,-1856.88C1890.5,-1848.78 1890.5,-1839.98 1890.5,-1831.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1894,-1831.3 1890.5,-1821.3 1887,-1831.3 1894,-1831.3\"/>\n</g>\n<!-- 57 -->\n<g id=\"node58\" class=\"node\">\n<title>57</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1616,-1709.5C1616,-1709.5 1543,-1709.5 1543,-1709.5 1537,-1709.5 1531,-1703.5 1531,-1697.5 1531,-1697.5 1531,-1668.5 1531,-1668.5 1531,-1662.5 1537,-1656.5 1543,-1656.5 1543,-1656.5 1616,-1656.5 1616,-1656.5 1622,-1656.5 1628,-1662.5 1628,-1668.5 1628,-1668.5 1628,-1697.5 1628,-1697.5 1628,-1703.5 1622,-1709.5 1616,-1709.5\"/>\n<text text-anchor=\"start\" x=\"1550.5\" y=\"-1694.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1540\" y=\"-1679.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1539\" y=\"-1664.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\n</g>\n<!-- 56&#45;&gt;57 -->\n<g id=\"edge57\" class=\"edge\">\n<title>56&#45;&gt;57</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1657.16,-1752.88C1643.9,-1741.12 1628.99,-1727.89 1615.81,-1716.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1618.08,-1713.54 1608.27,-1709.52 1613.43,-1718.77 1618.08,-1713.54\"/>\n</g>\n<!-- 58 -->\n<g id=\"node59\" class=\"node\">\n<title>58</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1731,-1709.5C1731,-1709.5 1658,-1709.5 1658,-1709.5 1652,-1709.5 1646,-1703.5 1646,-1697.5 1646,-1697.5 1646,-1668.5 1646,-1668.5 1646,-1662.5 1652,-1656.5 1658,-1656.5 1658,-1656.5 1731,-1656.5 1731,-1656.5 1737,-1656.5 1743,-1662.5 1743,-1668.5 1743,-1668.5 1743,-1697.5 1743,-1697.5 1743,-1703.5 1737,-1709.5 1731,-1709.5\"/>\n<text text-anchor=\"start\" x=\"1665.5\" y=\"-1694.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1655\" y=\"-1679.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"1654\" y=\"-1664.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 0]</text>\n</g>\n<!-- 56&#45;&gt;58 -->\n<g id=\"edge58\" class=\"edge\">\n<title>56&#45;&gt;58</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1694.5,-1752.88C1694.5,-1742.33 1694.5,-1730.6 1694.5,-1719.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1698,-1719.52 1694.5,-1709.52 1691,-1719.52 1698,-1719.52\"/>\n</g>\n<!-- 60 -->\n<g id=\"node61\" class=\"node\">\n<title>60</title>\n<path fill=\"#e89051\" stroke=\"black\" d=\"M1871.5,-1717C1871.5,-1717 1773.5,-1717 1773.5,-1717 1767.5,-1717 1761.5,-1711 1761.5,-1705 1761.5,-1705 1761.5,-1661 1761.5,-1661 1761.5,-1655 1767.5,-1649 1773.5,-1649 1773.5,-1649 1871.5,-1649 1871.5,-1649 1877.5,-1649 1883.5,-1655 1883.5,-1661 1883.5,-1661 1883.5,-1705 1883.5,-1705 1883.5,-1711 1877.5,-1717 1871.5,-1717\"/>\n<text text-anchor=\"start\" x=\"1781.5\" y=\"-1701.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.359</text>\n<text text-anchor=\"start\" x=\"1785\" y=\"-1686.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.195</text>\n<text text-anchor=\"start\" x=\"1775\" y=\"-1671.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 201</text>\n<text text-anchor=\"start\" x=\"1769.5\" y=\"-1656.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [179, 22]</text>\n</g>\n<!-- 59&#45;&gt;60 -->\n<g id=\"edge60\" class=\"edge\">\n<title>59&#45;&gt;60</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1868.42,-1752.88C1862.66,-1744.24 1856.38,-1734.82 1850.36,-1725.79\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1853.16,-1723.68 1844.7,-1717.3 1847.33,-1727.56 1853.16,-1723.68\"/>\n</g>\n<!-- 157 -->\n<g id=\"node158\" class=\"node\">\n<title>157</title>\n<path fill=\"#e6843d\" stroke=\"black\" d=\"M1995,-1717C1995,-1717 1914,-1717 1914,-1717 1908,-1717 1902,-1711 1902,-1705 1902,-1705 1902,-1661 1902,-1661 1902,-1655 1908,-1649 1914,-1649 1914,-1649 1995,-1649 1995,-1649 2001,-1649 2007,-1655 2007,-1661 2007,-1661 2007,-1705 2007,-1705 2007,-1711 2001,-1717 1995,-1717\"/>\n<text text-anchor=\"start\" x=\"1911.5\" y=\"-1701.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.755</text>\n<text text-anchor=\"start\" x=\"1917\" y=\"-1686.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.041</text>\n<text text-anchor=\"start\" x=\"1911\" y=\"-1671.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 48</text>\n<text text-anchor=\"start\" x=\"1910\" y=\"-1656.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [47, 1]</text>\n</g>\n<!-- 59&#45;&gt;157 -->\n<g id=\"edge157\" class=\"edge\">\n<title>59&#45;&gt;157</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1911.28,-1752.88C1916.7,-1744.24 1922.61,-1734.82 1928.28,-1725.79\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1931.26,-1727.63 1933.61,-1717.3 1925.33,-1723.91 1931.26,-1727.63\"/>\n</g>\n<!-- 61 -->\n<g id=\"node62\" class=\"node\">\n<title>61</title>\n<path fill=\"#e88f50\" stroke=\"black\" d=\"M1645.5,-1613C1645.5,-1613 1547.5,-1613 1547.5,-1613 1541.5,-1613 1535.5,-1607 1535.5,-1601 1535.5,-1601 1535.5,-1557 1535.5,-1557 1535.5,-1551 1541.5,-1545 1547.5,-1545 1547.5,-1545 1645.5,-1545 1645.5,-1545 1651.5,-1545 1657.5,-1551 1657.5,-1557 1657.5,-1557 1657.5,-1601 1657.5,-1601 1657.5,-1607 1651.5,-1613 1645.5,-1613\"/>\n<text text-anchor=\"start\" x=\"1557\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 1.257</text>\n<text text-anchor=\"start\" x=\"1559\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.183</text>\n<text text-anchor=\"start\" x=\"1549\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 196</text>\n<text text-anchor=\"start\" x=\"1543.5\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [176, 20]</text>\n</g>\n<!-- 60&#45;&gt;61 -->\n<g id=\"edge61\" class=\"edge\">\n<title>60&#45;&gt;61</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1761.34,-1653.5C1758.01,-1651.97 1754.72,-1650.46 1751.5,-1649 1723.92,-1636.45 1693.48,-1622.85 1666.92,-1611.06\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1668.27,-1607.83 1657.71,-1606.97 1665.43,-1614.23 1668.27,-1607.83\"/>\n</g>\n<!-- 152 -->\n<g id=\"node153\" class=\"node\">\n<title>152</title>\n<path fill=\"#f6d5bd\" stroke=\"black\" d=\"M1859.5,-1613C1859.5,-1613 1785.5,-1613 1785.5,-1613 1779.5,-1613 1773.5,-1607 1773.5,-1601 1773.5,-1601 1773.5,-1557 1773.5,-1557 1773.5,-1551 1779.5,-1545 1785.5,-1545 1785.5,-1545 1859.5,-1545 1859.5,-1545 1865.5,-1545 1871.5,-1551 1871.5,-1557 1871.5,-1557 1871.5,-1601 1871.5,-1601 1871.5,-1607 1865.5,-1613 1859.5,-1613\"/>\n<text text-anchor=\"start\" x=\"1781.5\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.516</text>\n<text text-anchor=\"start\" x=\"1789\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n<text text-anchor=\"start\" x=\"1783\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"1782\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 2]</text>\n</g>\n<!-- 60&#45;&gt;152 -->\n<g id=\"edge152\" class=\"edge\">\n<title>60&#45;&gt;152</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1822.5,-1648.88C1822.5,-1640.78 1822.5,-1631.98 1822.5,-1623.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1826,-1623.3 1822.5,-1613.3 1819,-1623.3 1826,-1623.3\"/>\n</g>\n<!-- 62 -->\n<g id=\"node63\" class=\"node\">\n<title>62</title>\n<path fill=\"#e89152\" stroke=\"black\" d=\"M1513.5,-1509C1513.5,-1509 1415.5,-1509 1415.5,-1509 1409.5,-1509 1403.5,-1503 1403.5,-1497 1403.5,-1497 1403.5,-1453 1403.5,-1453 1403.5,-1447 1409.5,-1441 1415.5,-1441 1415.5,-1441 1513.5,-1441 1513.5,-1441 1519.5,-1441 1525.5,-1447 1525.5,-1453 1525.5,-1453 1525.5,-1497 1525.5,-1497 1525.5,-1503 1519.5,-1509 1513.5,-1509\"/>\n<text text-anchor=\"start\" x=\"1425\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.891</text>\n<text text-anchor=\"start\" x=\"1427\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.198</text>\n<text text-anchor=\"start\" x=\"1417\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 179</text>\n<text text-anchor=\"start\" x=\"1411.5\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [159, 20]</text>\n</g>\n<!-- 61&#45;&gt;62 -->\n<g id=\"edge62\" class=\"edge\">\n<title>61&#45;&gt;62</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1553.64,-1544.88C1541.54,-1535.53 1528.25,-1525.26 1515.71,-1515.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1517.65,-1512.64 1507.59,-1509.3 1513.37,-1518.18 1517.65,-1512.64\"/>\n</g>\n<!-- 151 -->\n<g id=\"node152\" class=\"node\">\n<title>151</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1637,-1501.5C1637,-1501.5 1556,-1501.5 1556,-1501.5 1550,-1501.5 1544,-1495.5 1544,-1489.5 1544,-1489.5 1544,-1460.5 1544,-1460.5 1544,-1454.5 1550,-1448.5 1556,-1448.5 1556,-1448.5 1637,-1448.5 1637,-1448.5 1643,-1448.5 1649,-1454.5 1649,-1460.5 1649,-1460.5 1649,-1489.5 1649,-1489.5 1649,-1495.5 1643,-1501.5 1637,-1501.5\"/>\n<text text-anchor=\"start\" x=\"1567.5\" y=\"-1486.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1553\" y=\"-1471.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\n<text text-anchor=\"start\" x=\"1552\" y=\"-1456.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 0]</text>\n</g>\n<!-- 61&#45;&gt;151 -->\n<g id=\"edge151\" class=\"edge\">\n<title>61&#45;&gt;151</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1596.5,-1544.88C1596.5,-1534.33 1596.5,-1522.6 1596.5,-1511.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1600,-1511.52 1596.5,-1501.52 1593,-1511.52 1600,-1511.52\"/>\n</g>\n<!-- 63 -->\n<g id=\"node64\" class=\"node\">\n<title>63</title>\n<path fill=\"#e88f4f\" stroke=\"black\" d=\"M1513.5,-1405C1513.5,-1405 1415.5,-1405 1415.5,-1405 1409.5,-1405 1403.5,-1399 1403.5,-1393 1403.5,-1393 1403.5,-1349 1403.5,-1349 1403.5,-1343 1409.5,-1337 1415.5,-1337 1415.5,-1337 1513.5,-1337 1513.5,-1337 1519.5,-1337 1525.5,-1343 1525.5,-1349 1525.5,-1349 1525.5,-1393 1525.5,-1393 1525.5,-1399 1519.5,-1405 1513.5,-1405\"/>\n<text text-anchor=\"start\" x=\"1423\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;1.017</text>\n<text text-anchor=\"start\" x=\"1431\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.18</text>\n<text text-anchor=\"start\" x=\"1417\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 170</text>\n<text text-anchor=\"start\" x=\"1411.5\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [153, 17]</text>\n</g>\n<!-- 62&#45;&gt;63 -->\n<g id=\"edge63\" class=\"edge\">\n<title>62&#45;&gt;63</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1464.5,-1440.88C1464.5,-1432.78 1464.5,-1423.98 1464.5,-1415.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1468,-1415.3 1464.5,-1405.3 1461,-1415.3 1468,-1415.3\"/>\n</g>\n<!-- 138 -->\n<g id=\"node139\" class=\"node\">\n<title>138</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M1631,-1405C1631,-1405 1558,-1405 1558,-1405 1552,-1405 1546,-1399 1546,-1393 1546,-1393 1546,-1349 1546,-1349 1546,-1343 1552,-1337 1558,-1337 1558,-1337 1631,-1337 1631,-1337 1637,-1337 1643,-1343 1643,-1349 1643,-1349 1643,-1393 1643,-1393 1643,-1399 1637,-1405 1631,-1405\"/>\n<text text-anchor=\"start\" x=\"1555\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pclass ≤ 2.5</text>\n<text text-anchor=\"start\" x=\"1557\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"1555\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"1554\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 3]</text>\n</g>\n<!-- 62&#45;&gt;138 -->\n<g id=\"edge138\" class=\"edge\">\n<title>62&#45;&gt;138</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1506.71,-1440.88C1518.63,-1431.53 1531.72,-1421.26 1544.07,-1411.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1546.35,-1414.23 1552.06,-1405.3 1542.03,-1408.72 1546.35,-1414.23\"/>\n</g>\n<!-- 64 -->\n<g id=\"node65\" class=\"node\">\n<title>64</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M1370.5,-1301C1370.5,-1301 1292.5,-1301 1292.5,-1301 1286.5,-1301 1280.5,-1295 1280.5,-1289 1280.5,-1289 1280.5,-1245 1280.5,-1245 1280.5,-1239 1286.5,-1233 1292.5,-1233 1292.5,-1233 1370.5,-1233 1370.5,-1233 1376.5,-1233 1382.5,-1239 1382.5,-1245 1382.5,-1245 1382.5,-1289 1382.5,-1289 1382.5,-1295 1376.5,-1301 1370.5,-1301\"/>\n<text text-anchor=\"start\" x=\"1288.5\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.798</text>\n<text text-anchor=\"start\" x=\"1294\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"1292\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1291\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 1]</text>\n</g>\n<!-- 63&#45;&gt;64 -->\n<g id=\"edge64\" class=\"edge\">\n<title>63&#45;&gt;64</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1421.32,-1336.88C1409.12,-1327.53 1395.73,-1317.26 1383.09,-1307.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1384.98,-1304.61 1374.92,-1301.3 1380.72,-1310.16 1384.98,-1304.61\"/>\n</g>\n<!-- 67 -->\n<g id=\"node68\" class=\"node\">\n<title>67</title>\n<path fill=\"#e88e4e\" stroke=\"black\" d=\"M1513.5,-1301C1513.5,-1301 1415.5,-1301 1415.5,-1301 1409.5,-1301 1403.5,-1295 1403.5,-1289 1403.5,-1289 1403.5,-1245 1403.5,-1245 1403.5,-1239 1409.5,-1233 1415.5,-1233 1415.5,-1233 1513.5,-1233 1513.5,-1233 1519.5,-1233 1525.5,-1239 1525.5,-1245 1525.5,-1245 1525.5,-1289 1525.5,-1289 1525.5,-1295 1519.5,-1301 1513.5,-1301\"/>\n<text text-anchor=\"start\" x=\"1421.5\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.313</text>\n<text text-anchor=\"start\" x=\"1427\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.173</text>\n<text text-anchor=\"start\" x=\"1417\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 167</text>\n<text text-anchor=\"start\" x=\"1411.5\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [151, 16]</text>\n</g>\n<!-- 63&#45;&gt;67 -->\n<g id=\"edge67\" class=\"edge\">\n<title>63&#45;&gt;67</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1464.5,-1336.88C1464.5,-1328.78 1464.5,-1319.98 1464.5,-1311.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1468,-1311.3 1464.5,-1301.3 1461,-1311.3 1468,-1311.3\"/>\n</g>\n<!-- 65 -->\n<g id=\"node66\" class=\"node\">\n<title>65</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1253,-1189.5C1253,-1189.5 1180,-1189.5 1180,-1189.5 1174,-1189.5 1168,-1183.5 1168,-1177.5 1168,-1177.5 1168,-1148.5 1168,-1148.5 1168,-1142.5 1174,-1136.5 1180,-1136.5 1180,-1136.5 1253,-1136.5 1253,-1136.5 1259,-1136.5 1265,-1142.5 1265,-1148.5 1265,-1148.5 1265,-1177.5 1265,-1177.5 1265,-1183.5 1259,-1189.5 1253,-1189.5\"/>\n<text text-anchor=\"start\" x=\"1187.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1177\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1176\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 64&#45;&gt;65 -->\n<g id=\"edge65\" class=\"edge\">\n<title>64&#45;&gt;65</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1294.16,-1232.88C1280.9,-1221.12 1265.99,-1207.89 1252.81,-1196.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1255.08,-1193.54 1245.27,-1189.52 1250.43,-1198.77 1255.08,-1193.54\"/>\n</g>\n<!-- 66 -->\n<g id=\"node67\" class=\"node\">\n<title>66</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M1368,-1189.5C1368,-1189.5 1295,-1189.5 1295,-1189.5 1289,-1189.5 1283,-1183.5 1283,-1177.5 1283,-1177.5 1283,-1148.5 1283,-1148.5 1283,-1142.5 1289,-1136.5 1295,-1136.5 1295,-1136.5 1368,-1136.5 1368,-1136.5 1374,-1136.5 1380,-1142.5 1380,-1148.5 1380,-1148.5 1380,-1177.5 1380,-1177.5 1380,-1183.5 1374,-1189.5 1368,-1189.5\"/>\n<text text-anchor=\"start\" x=\"1302.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"1292\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1291\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 64&#45;&gt;66 -->\n<g id=\"edge66\" class=\"edge\">\n<title>64&#45;&gt;66</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1331.5,-1232.88C1331.5,-1222.33 1331.5,-1210.6 1331.5,-1199.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1335,-1199.52 1331.5,-1189.52 1328,-1199.52 1335,-1199.52\"/>\n</g>\n<!-- 68 -->\n<g id=\"node69\" class=\"node\">\n<title>68</title>\n<path fill=\"#e89050\" stroke=\"black\" d=\"M1508.5,-1197C1508.5,-1197 1410.5,-1197 1410.5,-1197 1404.5,-1197 1398.5,-1191 1398.5,-1185 1398.5,-1185 1398.5,-1141 1398.5,-1141 1398.5,-1135 1404.5,-1129 1410.5,-1129 1410.5,-1129 1508.5,-1129 1508.5,-1129 1514.5,-1129 1520.5,-1135 1520.5,-1141 1520.5,-1141 1520.5,-1185 1520.5,-1185 1520.5,-1191 1514.5,-1197 1508.5,-1197\"/>\n<text text-anchor=\"start\" x=\"1416.5\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.636</text>\n<text text-anchor=\"start\" x=\"1422\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.185</text>\n<text text-anchor=\"start\" x=\"1412\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 155</text>\n<text text-anchor=\"start\" x=\"1406.5\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [139, 16]</text>\n</g>\n<!-- 67&#45;&gt;68 -->\n<g id=\"edge68\" class=\"edge\">\n<title>67&#45;&gt;68</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1462.88,-1232.88C1462.48,-1224.78 1462.05,-1215.98 1461.63,-1207.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1465.12,-1207.12 1461.13,-1197.3 1458.13,-1207.46 1465.12,-1207.12\"/>\n</g>\n<!-- 137 -->\n<g id=\"node138\" class=\"node\">\n<title>137</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1632,-1189.5C1632,-1189.5 1551,-1189.5 1551,-1189.5 1545,-1189.5 1539,-1183.5 1539,-1177.5 1539,-1177.5 1539,-1148.5 1539,-1148.5 1539,-1142.5 1545,-1136.5 1551,-1136.5 1551,-1136.5 1632,-1136.5 1632,-1136.5 1638,-1136.5 1644,-1142.5 1644,-1148.5 1644,-1148.5 1644,-1177.5 1644,-1177.5 1644,-1183.5 1638,-1189.5 1632,-1189.5\"/>\n<text text-anchor=\"start\" x=\"1562.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1548\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\n<text text-anchor=\"start\" x=\"1547\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [12, 0]</text>\n</g>\n<!-- 67&#45;&gt;137 -->\n<g id=\"edge137\" class=\"edge\">\n<title>67&#45;&gt;137</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1505.73,-1232.88C1520.52,-1221.01 1537.16,-1207.65 1551.81,-1195.88\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1554.12,-1198.51 1559.73,-1189.52 1549.74,-1193.05 1554.12,-1198.51\"/>\n</g>\n<!-- 69 -->\n<g id=\"node70\" class=\"node\">\n<title>69</title>\n<path fill=\"#e88d4d\" stroke=\"black\" d=\"M1160.5,-1093C1160.5,-1093 1062.5,-1093 1062.5,-1093 1056.5,-1093 1050.5,-1087 1050.5,-1081 1050.5,-1081 1050.5,-1037 1050.5,-1037 1050.5,-1031 1056.5,-1025 1062.5,-1025 1062.5,-1025 1160.5,-1025 1160.5,-1025 1166.5,-1025 1172.5,-1031 1172.5,-1037 1172.5,-1037 1172.5,-1081 1172.5,-1081 1172.5,-1087 1166.5,-1093 1160.5,-1093\"/>\n<text text-anchor=\"start\" x=\"1072\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.679</text>\n<text text-anchor=\"start\" x=\"1074\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.164</text>\n<text text-anchor=\"start\" x=\"1064\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 122</text>\n<text text-anchor=\"start\" x=\"1058.5\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [111, 11]</text>\n</g>\n<!-- 68&#45;&gt;69 -->\n<g id=\"edge69\" class=\"edge\">\n<title>68&#45;&gt;69</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1398.23,-1132.65C1394.96,-1131.36 1391.7,-1130.13 1388.5,-1129 1320.06,-1104.82 1239.27,-1085.72 1182.66,-1073.81\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1183.23,-1070.35 1172.73,-1071.74 1181.81,-1077.21 1183.23,-1070.35\"/>\n</g>\n<!-- 118 -->\n<g id=\"node119\" class=\"node\">\n<title>118</title>\n<path fill=\"#ea985c\" stroke=\"black\" d=\"M1500,-1093C1500,-1093 1419,-1093 1419,-1093 1413,-1093 1407,-1087 1407,-1081 1407,-1081 1407,-1037 1407,-1037 1407,-1031 1413,-1025 1419,-1025 1419,-1025 1500,-1025 1500,-1025 1506,-1025 1512,-1031 1512,-1037 1512,-1037 1512,-1081 1512,-1081 1512,-1087 1506,-1093 1500,-1093\"/>\n<text text-anchor=\"start\" x=\"1418\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.092</text>\n<text text-anchor=\"start\" x=\"1422\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.257</text>\n<text text-anchor=\"start\" x=\"1416\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 33</text>\n<text text-anchor=\"start\" x=\"1415\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [28, 5]</text>\n</g>\n<!-- 68&#45;&gt;118 -->\n<g id=\"edge118\" class=\"edge\">\n<title>68&#45;&gt;118</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1459.5,-1128.88C1459.5,-1120.78 1459.5,-1111.98 1459.5,-1103.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1463,-1103.3 1459.5,-1093.3 1456,-1103.3 1463,-1103.3\"/>\n</g>\n<!-- 70 -->\n<g id=\"node71\" class=\"node\">\n<title>70</title>\n<path fill=\"#e78d4b\" stroke=\"black\" d=\"M952.5,-989C952.5,-989 854.5,-989 854.5,-989 848.5,-989 842.5,-983 842.5,-977 842.5,-977 842.5,-933 842.5,-933 842.5,-927 848.5,-921 854.5,-921 854.5,-921 952.5,-921 952.5,-921 958.5,-921 964.5,-927 964.5,-933 964.5,-933 964.5,-977 964.5,-977 964.5,-983 958.5,-989 952.5,-989\"/>\n<text text-anchor=\"start\" x=\"860.5\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.803</text>\n<text text-anchor=\"start\" x=\"866\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.154</text>\n<text text-anchor=\"start\" x=\"856\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 119</text>\n<text text-anchor=\"start\" x=\"850.5\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [109, 10]</text>\n</g>\n<!-- 69&#45;&gt;70 -->\n<g id=\"edge70\" class=\"edge\">\n<title>69&#45;&gt;70</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1050.5,-1028.09C1026.37,-1016.25 998.49,-1002.58 973.55,-990.35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"975.02,-987.17 964.5,-985.91 971.94,-993.46 975.02,-987.17\"/>\n</g>\n<!-- 115 -->\n<g id=\"node116\" class=\"node\">\n<title>115</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M1148,-989C1148,-989 1075,-989 1075,-989 1069,-989 1063,-983 1063,-977 1063,-977 1063,-933 1063,-933 1063,-927 1069,-921 1075,-921 1075,-921 1148,-921 1148,-921 1154,-921 1160,-927 1160,-933 1160,-933 1160,-977 1160,-977 1160,-983 1154,-989 1148,-989\"/>\n<text text-anchor=\"start\" x=\"1072\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.756</text>\n<text text-anchor=\"start\" x=\"1074\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"1072\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1071\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 1]</text>\n</g>\n<!-- 69&#45;&gt;115 -->\n<g id=\"edge115\" class=\"edge\">\n<title>69&#45;&gt;115</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1111.5,-1024.88C1111.5,-1016.78 1111.5,-1007.98 1111.5,-999.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1115,-999.3 1111.5,-989.3 1108,-999.3 1115,-999.3\"/>\n</g>\n<!-- 71 -->\n<g id=\"node72\" class=\"node\">\n<title>71</title>\n<path fill=\"#e99355\" stroke=\"black\" d=\"M631,-885C631,-885 550,-885 550,-885 544,-885 538,-879 538,-873 538,-873 538,-829 538,-829 538,-823 544,-817 550,-817 550,-817 631,-817 631,-817 637,-817 643,-823 643,-829 643,-829 643,-873 643,-873 643,-879 637,-885 631,-885\"/>\n<text text-anchor=\"start\" x=\"547.5\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.813</text>\n<text text-anchor=\"start\" x=\"553\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.219</text>\n<text text-anchor=\"start\" x=\"547\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 56</text>\n<text text-anchor=\"start\" x=\"546\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [49, 7]</text>\n</g>\n<!-- 70&#45;&gt;71 -->\n<g id=\"edge71\" class=\"edge\">\n<title>70&#45;&gt;71</title>\n<path fill=\"none\" stroke=\"black\" d=\"M842.08,-928.89C834.84,-926.14 827.53,-923.45 820.5,-921 764.44,-901.49 699.6,-882.34 653.08,-869.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"654.02,-865.81 643.44,-866.47 652.12,-872.55 654.02,-865.81\"/>\n</g>\n<!-- 102 -->\n<g id=\"node103\" class=\"node\">\n<title>102</title>\n<path fill=\"#e68743\" stroke=\"black\" d=\"M944,-885C944,-885 863,-885 863,-885 857,-885 851,-879 851,-873 851,-873 851,-829 851,-829 851,-823 857,-817 863,-817 863,-817 944,-817 944,-817 950,-817 956,-823 956,-829 956,-829 956,-873 956,-873 956,-879 950,-885 944,-885\"/>\n<text text-anchor=\"start\" x=\"862\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.785</text>\n<text text-anchor=\"start\" x=\"866\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.091</text>\n<text text-anchor=\"start\" x=\"860\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 63</text>\n<text text-anchor=\"start\" x=\"859\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [60, 3]</text>\n</g>\n<!-- 70&#45;&gt;102 -->\n<g id=\"edge102\" class=\"edge\">\n<title>70&#45;&gt;102</title>\n<path fill=\"none\" stroke=\"black\" d=\"M903.5,-920.88C903.5,-912.78 903.5,-903.98 903.5,-895.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"907,-895.3 903.5,-885.3 900,-895.3 907,-895.3\"/>\n</g>\n<!-- 72 -->\n<g id=\"node73\" class=\"node\">\n<title>72</title>\n<path fill=\"#e88d4c\" stroke=\"black\" d=\"M394,-781C394,-781 313,-781 313,-781 307,-781 301,-775 301,-769 301,-769 301,-725 301,-725 301,-719 307,-713 313,-713 313,-713 394,-713 394,-713 400,-713 406,-719 406,-725 406,-725 406,-769 406,-769 406,-775 400,-781 394,-781\"/>\n<text text-anchor=\"start\" x=\"312\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.015</text>\n<text text-anchor=\"start\" x=\"316\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.162</text>\n<text text-anchor=\"start\" x=\"310\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 45</text>\n<text text-anchor=\"start\" x=\"309\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [41, 4]</text>\n</g>\n<!-- 71&#45;&gt;72 -->\n<g id=\"edge72\" class=\"edge\">\n<title>71&#45;&gt;72</title>\n<path fill=\"none\" stroke=\"black\" d=\"M537.9,-827.36C501.82,-811.83 453.79,-791.16 415.79,-774.81\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"416.93,-771.49 406.36,-770.75 414.16,-777.92 416.93,-771.49\"/>\n</g>\n<!-- 89 -->\n<g id=\"node90\" class=\"node\">\n<title>89</title>\n<path fill=\"#efb083\" stroke=\"black\" d=\"M630,-781C630,-781 551,-781 551,-781 545,-781 539,-775 539,-769 539,-769 539,-725 539,-725 539,-719 545,-713 551,-713 551,-713 630,-713 630,-713 636,-713 642,-719 642,-725 642,-725 642,-769 642,-769 642,-775 636,-781 630,-781\"/>\n<text text-anchor=\"start\" x=\"551\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.129</text>\n<text text-anchor=\"start\" x=\"553\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.397</text>\n<text text-anchor=\"start\" x=\"547\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"start\" x=\"550\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 3]</text>\n</g>\n<!-- 71&#45;&gt;89 -->\n<g id=\"edge89\" class=\"edge\">\n<title>71&#45;&gt;89</title>\n<path fill=\"none\" stroke=\"black\" d=\"M590.5,-816.88C590.5,-808.78 590.5,-799.98 590.5,-791.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"594,-791.3 590.5,-781.3 587,-791.3 594,-791.3\"/>\n</g>\n<!-- 73 -->\n<g id=\"node74\" class=\"node\">\n<title>73</title>\n<path fill=\"#ea9a61\" stroke=\"black\" d=\"M215,-677C215,-677 134,-677 134,-677 128,-677 122,-671 122,-665 122,-665 122,-621 122,-621 122,-615 128,-609 134,-609 134,-609 215,-609 215,-609 221,-609 227,-615 227,-621 227,-621 227,-665 227,-665 227,-671 221,-677 215,-677\"/>\n<text text-anchor=\"start\" x=\"133\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.516</text>\n<text text-anchor=\"start\" x=\"137\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.278</text>\n<text text-anchor=\"start\" x=\"131\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n<text text-anchor=\"start\" x=\"130\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [15, 3]</text>\n</g>\n<!-- 72&#45;&gt;73 -->\n<g id=\"edge73\" class=\"edge\">\n<title>72&#45;&gt;73</title>\n<path fill=\"none\" stroke=\"black\" d=\"M300.76,-715.95C280.46,-704.38 257.1,-691.07 236.04,-679.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"237.59,-675.92 227.17,-674.01 234.13,-682 237.59,-675.92\"/>\n</g>\n<!-- 86 -->\n<g id=\"node87\" class=\"node\">\n<title>86</title>\n<path fill=\"#e68641\" stroke=\"black\" d=\"M394,-677C394,-677 313,-677 313,-677 307,-677 301,-671 301,-665 301,-665 301,-621 301,-621 301,-615 307,-609 313,-609 313,-609 394,-609 394,-609 400,-609 406,-615 406,-621 406,-621 406,-665 406,-665 406,-671 400,-677 394,-677\"/>\n<text text-anchor=\"start\" x=\"310.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.815</text>\n<text text-anchor=\"start\" x=\"316\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.071</text>\n<text text-anchor=\"start\" x=\"310\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 27</text>\n<text text-anchor=\"start\" x=\"309\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [26, 1]</text>\n</g>\n<!-- 72&#45;&gt;86 -->\n<g id=\"edge86\" class=\"edge\">\n<title>72&#45;&gt;86</title>\n<path fill=\"none\" stroke=\"black\" d=\"M353.5,-712.88C353.5,-704.78 353.5,-695.98 353.5,-687.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"357,-687.3 353.5,-677.3 350,-687.3 357,-687.3\"/>\n</g>\n<!-- 74 -->\n<g id=\"node75\" class=\"node\">\n<title>74</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M93,-565.5C93,-565.5 12,-565.5 12,-565.5 6,-565.5 0,-559.5 0,-553.5 0,-553.5 0,-524.5 0,-524.5 0,-518.5 6,-512.5 12,-512.5 12,-512.5 93,-512.5 93,-512.5 99,-512.5 105,-518.5 105,-524.5 105,-524.5 105,-553.5 105,-553.5 105,-559.5 99,-565.5 93,-565.5\"/>\n<text text-anchor=\"start\" x=\"23.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"9\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 0]</text>\n</g>\n<!-- 73&#45;&gt;74 -->\n<g id=\"edge74\" class=\"edge\">\n<title>73&#45;&gt;74</title>\n<path fill=\"none\" stroke=\"black\" d=\"M134.89,-608.88C120.81,-597.12 105,-583.89 91.02,-572.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"92.94,-569.25 83.02,-565.52 88.45,-574.62 92.94,-569.25\"/>\n</g>\n<!-- 75 -->\n<g id=\"node76\" class=\"node\">\n<title>75</title>\n<path fill=\"#f8e0ce\" stroke=\"black\" d=\"M213.5,-573C213.5,-573 135.5,-573 135.5,-573 129.5,-573 123.5,-567 123.5,-561 123.5,-561 123.5,-517 123.5,-517 123.5,-511 129.5,-505 135.5,-505 135.5,-505 213.5,-505 213.5,-505 219.5,-505 225.5,-511 225.5,-517 225.5,-517 225.5,-561 225.5,-561 225.5,-567 219.5,-573 213.5,-573\"/>\n<text text-anchor=\"start\" x=\"131.5\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.815</text>\n<text text-anchor=\"start\" x=\"141\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.49</text>\n<text text-anchor=\"start\" x=\"135\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"134\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 3]</text>\n</g>\n<!-- 73&#45;&gt;75 -->\n<g id=\"edge75\" class=\"edge\">\n<title>73&#45;&gt;75</title>\n<path fill=\"none\" stroke=\"black\" d=\"M174.5,-608.88C174.5,-600.78 174.5,-591.98 174.5,-583.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"178,-583.3 174.5,-573.3 171,-583.3 178,-583.3\"/>\n</g>\n<!-- 76 -->\n<g id=\"node77\" class=\"node\">\n<title>76</title>\n<path fill=\"#bddef6\" stroke=\"black\" d=\"M195.5,-469C195.5,-469 117.5,-469 117.5,-469 111.5,-469 105.5,-463 105.5,-457 105.5,-457 105.5,-413 105.5,-413 105.5,-407 111.5,-401 117.5,-401 117.5,-401 195.5,-401 195.5,-401 201.5,-401 207.5,-407 207.5,-413 207.5,-413 207.5,-457 207.5,-457 207.5,-463 201.5,-469 195.5,-469\"/>\n<text text-anchor=\"start\" x=\"113.5\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;1.981</text>\n<text text-anchor=\"start\" x=\"123\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n<text text-anchor=\"start\" x=\"117\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"116\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 3]</text>\n</g>\n<!-- 75&#45;&gt;76 -->\n<g id=\"edge76\" class=\"edge\">\n<title>75&#45;&gt;76</title>\n<path fill=\"none\" stroke=\"black\" d=\"M168.66,-504.88C167.21,-496.69 165.64,-487.79 164.12,-479.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"167.56,-478.54 162.38,-469.3 160.67,-479.76 167.56,-478.54\"/>\n</g>\n<!-- 85 -->\n<g id=\"node86\" class=\"node\">\n<title>85</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M311,-461.5C311,-461.5 238,-461.5 238,-461.5 232,-461.5 226,-455.5 226,-449.5 226,-449.5 226,-420.5 226,-420.5 226,-414.5 232,-408.5 238,-408.5 238,-408.5 311,-408.5 311,-408.5 317,-408.5 323,-414.5 323,-420.5 323,-420.5 323,-449.5 323,-449.5 323,-455.5 317,-461.5 311,-461.5\"/>\n<text text-anchor=\"start\" x=\"245.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"235\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"234\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 75&#45;&gt;85 -->\n<g id=\"edge85\" class=\"edge\">\n<title>75&#45;&gt;85</title>\n<path fill=\"none\" stroke=\"black\" d=\"M206.97,-504.88C218.29,-493.34 230.98,-480.39 242.28,-468.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"244.98,-471.11 249.48,-461.52 239.98,-466.21 244.98,-471.11\"/>\n</g>\n<!-- 77 -->\n<g id=\"node78\" class=\"node\">\n<title>77</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M132,-357.5C132,-357.5 59,-357.5 59,-357.5 53,-357.5 47,-351.5 47,-345.5 47,-345.5 47,-316.5 47,-316.5 47,-310.5 53,-304.5 59,-304.5 59,-304.5 132,-304.5 132,-304.5 138,-304.5 144,-310.5 144,-316.5 144,-316.5 144,-345.5 144,-345.5 144,-351.5 138,-357.5 132,-357.5\"/>\n<text text-anchor=\"start\" x=\"66.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"56\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"55\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 76&#45;&gt;77 -->\n<g id=\"edge77\" class=\"edge\">\n<title>76&#45;&gt;77</title>\n<path fill=\"none\" stroke=\"black\" d=\"M136.7,-400.88C130.05,-389.78 122.63,-377.37 115.94,-366.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"118.9,-364.31 110.76,-357.52 112.89,-367.9 118.9,-364.31\"/>\n</g>\n<!-- 78 -->\n<g id=\"node79\" class=\"node\">\n<title>78</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M252.5,-365C252.5,-365 174.5,-365 174.5,-365 168.5,-365 162.5,-359 162.5,-353 162.5,-353 162.5,-309 162.5,-309 162.5,-303 168.5,-297 174.5,-297 174.5,-297 252.5,-297 252.5,-297 258.5,-297 264.5,-303 264.5,-309 264.5,-309 264.5,-353 264.5,-353 264.5,-359 258.5,-365 252.5,-365\"/>\n<text text-anchor=\"start\" x=\"170.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.897</text>\n<text text-anchor=\"start\" x=\"184.5\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"174\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"173\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 2]</text>\n</g>\n<!-- 76&#45;&gt;78 -->\n<g id=\"edge78\" class=\"edge\">\n<title>76&#45;&gt;78</title>\n<path fill=\"none\" stroke=\"black\" d=\"M175.01,-400.88C179.78,-392.33 184.99,-383.01 189.99,-374.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"193.07,-375.74 194.89,-365.3 186.96,-372.32 193.07,-375.74\"/>\n</g>\n<!-- 79 -->\n<g id=\"node80\" class=\"node\">\n<title>79</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M241,-253.5C241,-253.5 168,-253.5 168,-253.5 162,-253.5 156,-247.5 156,-241.5 156,-241.5 156,-212.5 156,-212.5 156,-206.5 162,-200.5 168,-200.5 168,-200.5 241,-200.5 241,-200.5 247,-200.5 253,-206.5 253,-212.5 253,-212.5 253,-241.5 253,-241.5 253,-247.5 247,-253.5 241,-253.5\"/>\n<text text-anchor=\"start\" x=\"175.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"165\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"164\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 78&#45;&gt;79 -->\n<g id=\"edge79\" class=\"edge\">\n<title>78&#45;&gt;79</title>\n<path fill=\"none\" stroke=\"black\" d=\"M210.58,-296.88C209.64,-286.22 208.59,-274.35 207.63,-263.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"211.12,-263.17 206.75,-253.52 204.14,-263.79 211.12,-263.17\"/>\n</g>\n<!-- 80 -->\n<g id=\"node81\" class=\"node\">\n<title>80</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M394,-261C394,-261 283,-261 283,-261 277,-261 271,-255 271,-249 271,-249 271,-205 271,-205 271,-199 277,-193 283,-193 283,-193 394,-193 394,-193 400,-193 406,-199 406,-205 406,-205 406,-249 406,-249 406,-255 400,-261 394,-261\"/>\n<text text-anchor=\"start\" x=\"279\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Embarked_S ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"301\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"299\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"298\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 78&#45;&gt;80 -->\n<g id=\"edge80\" class=\"edge\">\n<title>78&#45;&gt;80</title>\n<path fill=\"none\" stroke=\"black\" d=\"M254.08,-296.88C265.44,-287.62 277.89,-277.45 289.67,-267.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"292.16,-270.33 297.69,-261.3 287.73,-264.91 292.16,-270.33\"/>\n</g>\n<!-- 81 -->\n<g id=\"node82\" class=\"node\">\n<title>81</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M292,-157C292,-157 217,-157 217,-157 211,-157 205,-151 205,-145 205,-145 205,-101 205,-101 205,-95 211,-89 217,-89 217,-89 292,-89 292,-89 298,-89 304,-95 304,-101 304,-101 304,-145 304,-145 304,-151 298,-157 292,-157\"/>\n<text text-anchor=\"start\" x=\"213\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.207</text>\n<text text-anchor=\"start\" x=\"225.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"215\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"214\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 80&#45;&gt;81 -->\n<g id=\"edge81\" class=\"edge\">\n<title>80&#45;&gt;81</title>\n<path fill=\"none\" stroke=\"black\" d=\"M311.23,-192.88C303.97,-184.07 296.03,-174.43 288.46,-165.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"290.98,-162.79 281.92,-157.3 285.58,-167.24 290.98,-162.79\"/>\n</g>\n<!-- 84 -->\n<g id=\"node85\" class=\"node\">\n<title>84</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M407,-149.5C407,-149.5 334,-149.5 334,-149.5 328,-149.5 322,-143.5 322,-137.5 322,-137.5 322,-108.5 322,-108.5 322,-102.5 328,-96.5 334,-96.5 334,-96.5 407,-96.5 407,-96.5 413,-96.5 419,-102.5 419,-108.5 419,-108.5 419,-137.5 419,-137.5 419,-143.5 413,-149.5 407,-149.5\"/>\n<text text-anchor=\"start\" x=\"341.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"331\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"330\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 80&#45;&gt;84 -->\n<g id=\"edge84\" class=\"edge\">\n<title>80&#45;&gt;84</title>\n<path fill=\"none\" stroke=\"black\" d=\"M348.89,-192.88C352.27,-182.11 356.03,-170.11 359.46,-159.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"362.84,-160.11 362.49,-149.52 356.16,-158.01 362.84,-160.11\"/>\n</g>\n<!-- 82 -->\n<g id=\"node83\" class=\"node\">\n<title>82</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M234,-53C234,-53 161,-53 161,-53 155,-53 149,-47 149,-41 149,-41 149,-12 149,-12 149,-6 155,0 161,0 161,0 234,0 234,0 240,0 246,-6 246,-12 246,-12 246,-41 246,-41 246,-47 240,-53 234,-53\"/>\n<text text-anchor=\"start\" x=\"168.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"158\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"157\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 81&#45;&gt;82 -->\n<g id=\"edge82\" class=\"edge\">\n<title>81&#45;&gt;82</title>\n<path fill=\"none\" stroke=\"black\" d=\"M234.56,-88.95C229.27,-80.17 223.53,-70.66 218.2,-61.82\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"221.19,-59.99 213.02,-53.24 215.19,-63.61 221.19,-59.99\"/>\n</g>\n<!-- 83 -->\n<g id=\"node84\" class=\"node\">\n<title>83</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M349,-53C349,-53 276,-53 276,-53 270,-53 264,-47 264,-41 264,-41 264,-12 264,-12 264,-6 270,0 276,0 276,0 349,0 349,0 355,0 361,-6 361,-12 361,-12 361,-41 361,-41 361,-47 355,-53 349,-53\"/>\n<text text-anchor=\"start\" x=\"283.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"273\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"272\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 81&#45;&gt;83 -->\n<g id=\"edge83\" class=\"edge\">\n<title>81&#45;&gt;83</title>\n<path fill=\"none\" stroke=\"black\" d=\"M274.79,-88.95C280.18,-80.17 286.01,-70.66 291.44,-61.82\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"294.46,-63.59 296.7,-53.24 288.49,-59.93 294.46,-63.59\"/>\n</g>\n<!-- 87 -->\n<g id=\"node88\" class=\"node\">\n<title>87</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M337,-565.5C337,-565.5 256,-565.5 256,-565.5 250,-565.5 244,-559.5 244,-553.5 244,-553.5 244,-524.5 244,-524.5 244,-518.5 250,-512.5 256,-512.5 256,-512.5 337,-512.5 337,-512.5 343,-512.5 349,-518.5 349,-524.5 349,-524.5 349,-553.5 349,-553.5 349,-559.5 343,-565.5 337,-565.5\"/>\n<text text-anchor=\"start\" x=\"267.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"253\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 26</text>\n<text text-anchor=\"start\" x=\"252\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [26, 0]</text>\n</g>\n<!-- 86&#45;&gt;87 -->\n<g id=\"edge87\" class=\"edge\">\n<title>86&#45;&gt;87</title>\n<path fill=\"none\" stroke=\"black\" d=\"M334.99,-608.88C328.85,-597.89 321.99,-585.62 315.79,-574.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"318.69,-572.54 310.76,-565.52 312.58,-575.96 318.69,-572.54\"/>\n</g>\n<!-- 88 -->\n<g id=\"node89\" class=\"node\">\n<title>88</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M452,-565.5C452,-565.5 379,-565.5 379,-565.5 373,-565.5 367,-559.5 367,-553.5 367,-553.5 367,-524.5 367,-524.5 367,-518.5 373,-512.5 379,-512.5 379,-512.5 452,-512.5 452,-512.5 458,-512.5 464,-518.5 464,-524.5 464,-524.5 464,-553.5 464,-553.5 464,-559.5 458,-565.5 452,-565.5\"/>\n<text text-anchor=\"start\" x=\"386.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"376\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"375\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 86&#45;&gt;88 -->\n<g id=\"edge88\" class=\"edge\">\n<title>86&#45;&gt;88</title>\n<path fill=\"none\" stroke=\"black\" d=\"M373.63,-608.88C380.38,-597.78 387.92,-585.37 394.72,-574.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"397.78,-575.88 399.99,-565.52 391.8,-572.25 397.78,-575.88\"/>\n</g>\n<!-- 90 -->\n<g id=\"node91\" class=\"node\">\n<title>90</title>\n<path fill=\"#eca06a\" stroke=\"black\" d=\"M571,-677C571,-677 492,-677 492,-677 486,-677 480,-671 480,-665 480,-665 480,-621 480,-621 480,-615 486,-609 492,-609 492,-609 571,-609 571,-609 577,-609 583,-615 583,-621 583,-621 583,-665 583,-665 583,-671 577,-677 571,-677\"/>\n<text text-anchor=\"start\" x=\"488.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.811</text>\n<text text-anchor=\"start\" x=\"498\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"488\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"491\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 2]</text>\n</g>\n<!-- 89&#45;&gt;90 -->\n<g id=\"edge90\" class=\"edge\">\n<title>89&#45;&gt;90</title>\n<path fill=\"none\" stroke=\"black\" d=\"M571.34,-712.88C566.4,-704.33 561.01,-695.01 555.84,-686.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"558.8,-684.2 550.76,-677.3 552.74,-687.71 558.8,-684.2\"/>\n</g>\n<!-- 101 -->\n<g id=\"node102\" class=\"node\">\n<title>101</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M686,-669.5C686,-669.5 613,-669.5 613,-669.5 607,-669.5 601,-663.5 601,-657.5 601,-657.5 601,-628.5 601,-628.5 601,-622.5 607,-616.5 613,-616.5 613,-616.5 686,-616.5 686,-616.5 692,-616.5 698,-622.5 698,-628.5 698,-628.5 698,-657.5 698,-657.5 698,-663.5 692,-669.5 686,-669.5\"/>\n<text text-anchor=\"start\" x=\"620.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"610\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"609\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 89&#45;&gt;101 -->\n<g id=\"edge101\" class=\"edge\">\n<title>89&#45;&gt;101</title>\n<path fill=\"none\" stroke=\"black\" d=\"M609.66,-712.88C616.08,-701.78 623.26,-689.37 629.73,-678.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"632.76,-679.93 634.74,-669.52 626.7,-676.42 632.76,-679.93\"/>\n</g>\n<!-- 91 -->\n<g id=\"node92\" class=\"node\">\n<title>91</title>\n<path fill=\"#f6d5bd\" stroke=\"black\" d=\"M569,-573C569,-573 494,-573 494,-573 488,-573 482,-567 482,-561 482,-561 482,-517 482,-517 482,-511 488,-505 494,-505 494,-505 569,-505 569,-505 575,-505 581,-511 581,-517 581,-517 581,-561 581,-561 581,-567 575,-573 569,-573\"/>\n<text text-anchor=\"start\" x=\"490\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.785</text>\n<text text-anchor=\"start\" x=\"498\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n<text text-anchor=\"start\" x=\"492\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"491\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 2]</text>\n</g>\n<!-- 90&#45;&gt;91 -->\n<g id=\"edge91\" class=\"edge\">\n<title>90&#45;&gt;91</title>\n<path fill=\"none\" stroke=\"black\" d=\"M531.5,-608.88C531.5,-600.78 531.5,-591.98 531.5,-583.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"535,-583.3 531.5,-573.3 528,-583.3 535,-583.3\"/>\n</g>\n<!-- 100 -->\n<g id=\"node101\" class=\"node\">\n<title>100</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M684,-565.5C684,-565.5 611,-565.5 611,-565.5 605,-565.5 599,-559.5 599,-553.5 599,-553.5 599,-524.5 599,-524.5 599,-518.5 605,-512.5 611,-512.5 611,-512.5 684,-512.5 684,-512.5 690,-512.5 696,-518.5 696,-524.5 696,-524.5 696,-553.5 696,-553.5 696,-559.5 690,-565.5 684,-565.5\"/>\n<text text-anchor=\"start\" x=\"618.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"608\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"607\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 0]</text>\n</g>\n<!-- 90&#45;&gt;100 -->\n<g id=\"edge100\" class=\"edge\">\n<title>90&#45;&gt;100</title>\n<path fill=\"none\" stroke=\"black\" d=\"M569.16,-608.88C582.54,-597.12 597.58,-583.89 610.88,-572.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"613.28,-574.75 618.48,-565.52 608.66,-569.49 613.28,-574.75\"/>\n</g>\n<!-- 92 -->\n<g id=\"node93\" class=\"node\">\n<title>92</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M457,-461.5C457,-461.5 384,-461.5 384,-461.5 378,-461.5 372,-455.5 372,-449.5 372,-449.5 372,-420.5 372,-420.5 372,-414.5 378,-408.5 384,-408.5 384,-408.5 457,-408.5 457,-408.5 463,-408.5 469,-414.5 469,-420.5 469,-420.5 469,-449.5 469,-449.5 469,-455.5 463,-461.5 457,-461.5\"/>\n<text text-anchor=\"start\" x=\"391.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"381\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"380\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 91&#45;&gt;92 -->\n<g id=\"edge92\" class=\"edge\">\n<title>91&#45;&gt;92</title>\n<path fill=\"none\" stroke=\"black\" d=\"M495.46,-504.88C482.78,-493.23 468.54,-480.14 455.9,-468.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"458,-465.71 448.27,-461.52 453.27,-470.86 458,-465.71\"/>\n</g>\n<!-- 93 -->\n<g id=\"node94\" class=\"node\">\n<title>93</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M574,-469C574,-469 499,-469 499,-469 493,-469 487,-463 487,-457 487,-457 487,-413 487,-413 487,-407 493,-401 499,-401 499,-401 574,-401 574,-401 580,-401 586,-407 586,-413 586,-413 586,-457 586,-457 586,-463 580,-469 574,-469\"/>\n<text text-anchor=\"start\" x=\"495\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.554</text>\n<text text-anchor=\"start\" x=\"507.5\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"497\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"496\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 2]</text>\n</g>\n<!-- 91&#45;&gt;93 -->\n<g id=\"edge93\" class=\"edge\">\n<title>91&#45;&gt;93</title>\n<path fill=\"none\" stroke=\"black\" d=\"M533.12,-504.88C533.52,-496.78 533.95,-487.98 534.37,-479.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"537.87,-479.46 534.87,-469.3 530.88,-479.12 537.87,-479.46\"/>\n</g>\n<!-- 94 -->\n<g id=\"node95\" class=\"node\">\n<title>94</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M493,-357.5C493,-357.5 420,-357.5 420,-357.5 414,-357.5 408,-351.5 408,-345.5 408,-345.5 408,-316.5 408,-316.5 408,-310.5 414,-304.5 420,-304.5 420,-304.5 493,-304.5 493,-304.5 499,-304.5 505,-310.5 505,-316.5 505,-316.5 505,-345.5 505,-345.5 505,-351.5 499,-357.5 493,-357.5\"/>\n<text text-anchor=\"start\" x=\"427.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"417\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"416\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 93&#45;&gt;94 -->\n<g id=\"edge94\" class=\"edge\">\n<title>93&#45;&gt;94</title>\n<path fill=\"none\" stroke=\"black\" d=\"M510.53,-400.88C501.64,-389.56 491.7,-376.88 482.79,-365.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"485.44,-363.23 476.52,-357.52 479.93,-367.55 485.44,-363.23\"/>\n</g>\n<!-- 95 -->\n<g id=\"node96\" class=\"node\">\n<title>95</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M610,-365C610,-365 535,-365 535,-365 529,-365 523,-359 523,-353 523,-353 523,-309 523,-309 523,-303 529,-297 535,-297 535,-297 610,-297 610,-297 616,-297 622,-303 622,-309 622,-309 622,-353 622,-353 622,-359 616,-365 610,-365\"/>\n<text text-anchor=\"start\" x=\"531\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.323</text>\n<text text-anchor=\"start\" x=\"535\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"533\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"532\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 1]</text>\n</g>\n<!-- 93&#45;&gt;95 -->\n<g id=\"edge95\" class=\"edge\">\n<title>93&#45;&gt;95</title>\n<path fill=\"none\" stroke=\"black\" d=\"M548.19,-400.88C551.11,-392.6 554.29,-383.6 557.35,-374.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"560.72,-375.89 560.75,-365.3 554.12,-373.56 560.72,-375.89\"/>\n</g>\n<!-- 96 -->\n<g id=\"node97\" class=\"node\">\n<title>96</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M553,-253.5C553,-253.5 480,-253.5 480,-253.5 474,-253.5 468,-247.5 468,-241.5 468,-241.5 468,-212.5 468,-212.5 468,-206.5 474,-200.5 480,-200.5 480,-200.5 553,-200.5 553,-200.5 559,-200.5 565,-206.5 565,-212.5 565,-212.5 565,-241.5 565,-241.5 565,-247.5 559,-253.5 553,-253.5\"/>\n<text text-anchor=\"start\" x=\"487.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"477\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"476\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 95&#45;&gt;96 -->\n<g id=\"edge96\" class=\"edge\">\n<title>95&#45;&gt;96</title>\n<path fill=\"none\" stroke=\"black\" d=\"M554.32,-296.88C548.28,-285.89 541.54,-273.62 535.45,-262.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"538.39,-260.6 530.51,-253.52 532.26,-263.97 538.39,-260.6\"/>\n</g>\n<!-- 97 -->\n<g id=\"node98\" class=\"node\">\n<title>97</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M670,-261C670,-261 595,-261 595,-261 589,-261 583,-255 583,-249 583,-249 583,-205 583,-205 583,-199 589,-193 595,-193 595,-193 670,-193 670,-193 676,-193 682,-199 682,-205 682,-205 682,-249 682,-249 682,-255 676,-261 670,-261\"/>\n<text text-anchor=\"start\" x=\"591\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.169</text>\n<text text-anchor=\"start\" x=\"603.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"593\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"592\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 95&#45;&gt;97 -->\n<g id=\"edge97\" class=\"edge\">\n<title>95&#45;&gt;97</title>\n<path fill=\"none\" stroke=\"black\" d=\"M591.98,-296.88C597.01,-288.33 602.49,-279.01 607.75,-270.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"610.86,-271.69 612.91,-261.3 604.83,-268.14 610.86,-271.69\"/>\n</g>\n<!-- 98 -->\n<g id=\"node99\" class=\"node\">\n<title>98</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M611,-149.5C611,-149.5 538,-149.5 538,-149.5 532,-149.5 526,-143.5 526,-137.5 526,-137.5 526,-108.5 526,-108.5 526,-102.5 532,-96.5 538,-96.5 538,-96.5 611,-96.5 611,-96.5 617,-96.5 623,-102.5 623,-108.5 623,-108.5 623,-137.5 623,-137.5 623,-143.5 617,-149.5 611,-149.5\"/>\n<text text-anchor=\"start\" x=\"545.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"535\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"534\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 97&#45;&gt;98 -->\n<g id=\"edge98\" class=\"edge\">\n<title>97&#45;&gt;98</title>\n<path fill=\"none\" stroke=\"black\" d=\"M613.67,-192.88C607.42,-181.89 600.44,-169.62 594.13,-158.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"597,-156.48 589.01,-149.52 590.91,-159.94 597,-156.48\"/>\n</g>\n<!-- 99 -->\n<g id=\"node100\" class=\"node\">\n<title>99</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M726,-149.5C726,-149.5 653,-149.5 653,-149.5 647,-149.5 641,-143.5 641,-137.5 641,-137.5 641,-108.5 641,-108.5 641,-102.5 647,-96.5 653,-96.5 653,-96.5 726,-96.5 726,-96.5 732,-96.5 738,-102.5 738,-108.5 738,-108.5 738,-137.5 738,-137.5 738,-143.5 732,-149.5 726,-149.5\"/>\n<text text-anchor=\"start\" x=\"660.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"650\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"649\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 97&#45;&gt;99 -->\n<g id=\"edge99\" class=\"edge\">\n<title>97&#45;&gt;99</title>\n<path fill=\"none\" stroke=\"black\" d=\"M651.01,-192.88C657.15,-181.89 664.01,-169.62 670.21,-158.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"673.42,-159.96 675.24,-149.52 667.31,-156.54 673.42,-159.96\"/>\n</g>\n<!-- 103 -->\n<g id=\"node104\" class=\"node\">\n<title>103</title>\n<path fill=\"#eeab7b\" stroke=\"black\" d=\"M922.5,-781C922.5,-781 844.5,-781 844.5,-781 838.5,-781 832.5,-775 832.5,-769 832.5,-769 832.5,-725 832.5,-725 832.5,-719 838.5,-713 844.5,-713 844.5,-713 922.5,-713 922.5,-713 928.5,-713 934.5,-719 934.5,-725 934.5,-725 934.5,-769 934.5,-769 934.5,-775 928.5,-781 922.5,-781\"/>\n<text text-anchor=\"start\" x=\"840.5\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.768</text>\n<text text-anchor=\"start\" x=\"846\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"844\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"843\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 2]</text>\n</g>\n<!-- 102&#45;&gt;103 -->\n<g id=\"edge103\" class=\"edge\">\n<title>102&#45;&gt;103</title>\n<path fill=\"none\" stroke=\"black\" d=\"M897.01,-816.88C895.4,-808.69 893.65,-799.79 891.97,-791.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"895.39,-790.44 890.03,-781.3 888.52,-791.79 895.39,-790.44\"/>\n</g>\n<!-- 110 -->\n<g id=\"node111\" class=\"node\">\n<title>110</title>\n<path fill=\"#e5833d\" stroke=\"black\" d=\"M1046,-781C1046,-781 965,-781 965,-781 959,-781 953,-775 953,-769 953,-769 953,-725 953,-725 953,-719 959,-713 965,-713 965,-713 1046,-713 1046,-713 1052,-713 1058,-719 1058,-725 1058,-725 1058,-769 1058,-769 1058,-775 1052,-781 1046,-781\"/>\n<text text-anchor=\"start\" x=\"962.5\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.778</text>\n<text text-anchor=\"start\" x=\"968\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.036</text>\n<text text-anchor=\"start\" x=\"962\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 55</text>\n<text text-anchor=\"start\" x=\"961\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [54, 1]</text>\n</g>\n<!-- 102&#45;&gt;110 -->\n<g id=\"edge110\" class=\"edge\">\n<title>102&#45;&gt;110</title>\n<path fill=\"none\" stroke=\"black\" d=\"M936.62,-816.88C945.7,-807.8 955.65,-797.85 965.1,-788.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"967.6,-790.85 972.2,-781.3 962.65,-785.9 967.6,-790.85\"/>\n</g>\n<!-- 104 -->\n<g id=\"node105\" class=\"node\">\n<title>104</title>\n<path fill=\"#f6d5bd\" stroke=\"black\" d=\"M806.5,-677C806.5,-677 728.5,-677 728.5,-677 722.5,-677 716.5,-671 716.5,-665 716.5,-665 716.5,-621 716.5,-621 716.5,-615 722.5,-609 728.5,-609 728.5,-609 806.5,-609 806.5,-609 812.5,-609 818.5,-615 818.5,-621 818.5,-621 818.5,-665 818.5,-665 818.5,-671 812.5,-677 806.5,-677\"/>\n<text text-anchor=\"start\" x=\"724.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.791</text>\n<text text-anchor=\"start\" x=\"734\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n<text text-anchor=\"start\" x=\"728\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"727\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 2]</text>\n</g>\n<!-- 103&#45;&gt;104 -->\n<g id=\"edge104\" class=\"edge\">\n<title>103&#45;&gt;104</title>\n<path fill=\"none\" stroke=\"black\" d=\"M845.84,-712.88C835.4,-703.71 823.96,-693.65 813.13,-684.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"815.19,-681.27 805.37,-677.3 810.57,-686.53 815.19,-681.27\"/>\n</g>\n<!-- 109 -->\n<g id=\"node110\" class=\"node\">\n<title>109</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M922,-669.5C922,-669.5 849,-669.5 849,-669.5 843,-669.5 837,-663.5 837,-657.5 837,-657.5 837,-628.5 837,-628.5 837,-622.5 843,-616.5 849,-616.5 849,-616.5 922,-616.5 922,-616.5 928,-616.5 934,-622.5 934,-628.5 934,-628.5 934,-657.5 934,-657.5 934,-663.5 928,-669.5 922,-669.5\"/>\n<text text-anchor=\"start\" x=\"856.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"846\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"845\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 103&#45;&gt;109 -->\n<g id=\"edge109\" class=\"edge\">\n<title>103&#45;&gt;109</title>\n<path fill=\"none\" stroke=\"black\" d=\"M884.15,-712.88C884.36,-702.22 884.59,-690.35 884.8,-679.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"888.3,-679.59 885,-669.52 881.3,-679.45 888.3,-679.59\"/>\n</g>\n<!-- 105 -->\n<g id=\"node106\" class=\"node\">\n<title>105</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M801,-565.5C801,-565.5 728,-565.5 728,-565.5 722,-565.5 716,-559.5 716,-553.5 716,-553.5 716,-524.5 716,-524.5 716,-518.5 722,-512.5 728,-512.5 728,-512.5 801,-512.5 801,-512.5 807,-512.5 813,-518.5 813,-524.5 813,-524.5 813,-553.5 813,-553.5 813,-559.5 807,-565.5 801,-565.5\"/>\n<text text-anchor=\"start\" x=\"735.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"725\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"724\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 104&#45;&gt;105 -->\n<g id=\"edge105\" class=\"edge\">\n<title>104&#45;&gt;105</title>\n<path fill=\"none\" stroke=\"black\" d=\"M766.53,-608.88C766.21,-598.22 765.86,-586.35 765.54,-575.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"769.04,-575.41 765.25,-565.52 762.05,-575.62 769.04,-575.41\"/>\n</g>\n<!-- 106 -->\n<g id=\"node107\" class=\"node\">\n<title>106</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M918,-573C918,-573 843,-573 843,-573 837,-573 831,-567 831,-561 831,-561 831,-517 831,-517 831,-511 837,-505 843,-505 843,-505 918,-505 918,-505 924,-505 930,-511 930,-517 930,-517 930,-561 930,-561 930,-567 924,-573 918,-573\"/>\n<text text-anchor=\"start\" x=\"839\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.863</text>\n<text text-anchor=\"start\" x=\"843\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"841\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"840\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 104&#45;&gt;106 -->\n<g id=\"edge106\" class=\"edge\">\n<title>104&#45;&gt;106</title>\n<path fill=\"none\" stroke=\"black\" d=\"M804.19,-608.88C814.35,-599.71 825.5,-589.65 836.05,-580.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"838.53,-582.6 843.61,-573.3 833.84,-577.4 838.53,-582.6\"/>\n</g>\n<!-- 107 -->\n<g id=\"node108\" class=\"node\">\n<title>107</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M859,-461.5C859,-461.5 786,-461.5 786,-461.5 780,-461.5 774,-455.5 774,-449.5 774,-449.5 774,-420.5 774,-420.5 774,-414.5 780,-408.5 786,-408.5 786,-408.5 859,-408.5 859,-408.5 865,-408.5 871,-414.5 871,-420.5 871,-420.5 871,-449.5 871,-449.5 871,-455.5 865,-461.5 859,-461.5\"/>\n<text text-anchor=\"start\" x=\"793.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"783\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"782\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 106&#45;&gt;107 -->\n<g id=\"edge107\" class=\"edge\">\n<title>106&#45;&gt;107</title>\n<path fill=\"none\" stroke=\"black\" d=\"M861.67,-504.88C855.42,-493.89 848.44,-481.62 842.13,-470.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"845,-468.48 837.01,-461.52 838.91,-471.94 845,-468.48\"/>\n</g>\n<!-- 108 -->\n<g id=\"node109\" class=\"node\">\n<title>108</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M974,-461.5C974,-461.5 901,-461.5 901,-461.5 895,-461.5 889,-455.5 889,-449.5 889,-449.5 889,-420.5 889,-420.5 889,-414.5 895,-408.5 901,-408.5 901,-408.5 974,-408.5 974,-408.5 980,-408.5 986,-414.5 986,-420.5 986,-420.5 986,-449.5 986,-449.5 986,-455.5 980,-461.5 974,-461.5\"/>\n<text text-anchor=\"start\" x=\"908.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"898\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"897\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 106&#45;&gt;108 -->\n<g id=\"edge108\" class=\"edge\">\n<title>106&#45;&gt;108</title>\n<path fill=\"none\" stroke=\"black\" d=\"M899.01,-504.88C905.15,-493.89 912.01,-481.62 918.21,-470.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"921.42,-471.96 923.24,-461.52 915.31,-468.54 921.42,-471.96\"/>\n</g>\n<!-- 111 -->\n<g id=\"node112\" class=\"node\">\n<title>111</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1045,-669.5C1045,-669.5 964,-669.5 964,-669.5 958,-669.5 952,-663.5 952,-657.5 952,-657.5 952,-628.5 952,-628.5 952,-622.5 958,-616.5 964,-616.5 964,-616.5 1045,-616.5 1045,-616.5 1051,-616.5 1057,-622.5 1057,-628.5 1057,-628.5 1057,-657.5 1057,-657.5 1057,-663.5 1051,-669.5 1045,-669.5\"/>\n<text text-anchor=\"start\" x=\"975.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"961\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 47</text>\n<text text-anchor=\"start\" x=\"960\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [47, 0]</text>\n</g>\n<!-- 110&#45;&gt;111 -->\n<g id=\"edge111\" class=\"edge\">\n<title>110&#45;&gt;111</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1005.18,-712.88C1005.07,-702.33 1004.96,-690.6 1004.85,-679.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1008.35,-679.49 1004.75,-669.52 1001.35,-679.55 1008.35,-679.49\"/>\n</g>\n<!-- 112 -->\n<g id=\"node113\" class=\"node\">\n<title>112</title>\n<path fill=\"#e99355\" stroke=\"black\" d=\"M1165.5,-677C1165.5,-677 1087.5,-677 1087.5,-677 1081.5,-677 1075.5,-671 1075.5,-665 1075.5,-665 1075.5,-621 1075.5,-621 1075.5,-615 1081.5,-609 1087.5,-609 1087.5,-609 1165.5,-609 1165.5,-609 1171.5,-609 1177.5,-615 1177.5,-621 1177.5,-621 1177.5,-665 1177.5,-665 1177.5,-671 1171.5,-677 1165.5,-677\"/>\n<text text-anchor=\"start\" x=\"1083.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.745</text>\n<text text-anchor=\"start\" x=\"1089\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.219</text>\n<text text-anchor=\"start\" x=\"1087\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"1086\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 1]</text>\n</g>\n<!-- 110&#45;&gt;112 -->\n<g id=\"edge112\" class=\"edge\">\n<title>110&#45;&gt;112</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1044.79,-712.88C1055.77,-703.62 1067.83,-693.45 1079.23,-683.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1081.61,-686.42 1087,-677.3 1077.1,-681.07 1081.61,-686.42\"/>\n</g>\n<!-- 113 -->\n<g id=\"node114\" class=\"node\">\n<title>113</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1106,-565.5C1106,-565.5 1033,-565.5 1033,-565.5 1027,-565.5 1021,-559.5 1021,-553.5 1021,-553.5 1021,-524.5 1021,-524.5 1021,-518.5 1027,-512.5 1033,-512.5 1033,-512.5 1106,-512.5 1106,-512.5 1112,-512.5 1118,-518.5 1118,-524.5 1118,-524.5 1118,-553.5 1118,-553.5 1118,-559.5 1112,-565.5 1106,-565.5\"/>\n<text text-anchor=\"start\" x=\"1040.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1030\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1029\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 112&#45;&gt;113 -->\n<g id=\"edge113\" class=\"edge\">\n<title>112&#45;&gt;113</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1107.99,-608.88C1101.85,-597.89 1094.99,-585.62 1088.79,-574.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1091.69,-572.54 1083.76,-565.52 1085.58,-575.96 1091.69,-572.54\"/>\n</g>\n<!-- 114 -->\n<g id=\"node115\" class=\"node\">\n<title>114</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1221,-565.5C1221,-565.5 1148,-565.5 1148,-565.5 1142,-565.5 1136,-559.5 1136,-553.5 1136,-553.5 1136,-524.5 1136,-524.5 1136,-518.5 1142,-512.5 1148,-512.5 1148,-512.5 1221,-512.5 1221,-512.5 1227,-512.5 1233,-518.5 1233,-524.5 1233,-524.5 1233,-553.5 1233,-553.5 1233,-559.5 1227,-565.5 1221,-565.5\"/>\n<text text-anchor=\"start\" x=\"1155.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1145\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"1144\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 0]</text>\n</g>\n<!-- 112&#45;&gt;114 -->\n<g id=\"edge114\" class=\"edge\">\n<title>112&#45;&gt;114</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1145.33,-608.88C1151.58,-597.89 1158.56,-585.62 1164.87,-574.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1168.09,-575.94 1169.99,-565.52 1162,-572.48 1168.09,-575.94\"/>\n</g>\n<!-- 116 -->\n<g id=\"node117\" class=\"node\">\n<title>116</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1090,-877.5C1090,-877.5 1017,-877.5 1017,-877.5 1011,-877.5 1005,-871.5 1005,-865.5 1005,-865.5 1005,-836.5 1005,-836.5 1005,-830.5 1011,-824.5 1017,-824.5 1017,-824.5 1090,-824.5 1090,-824.5 1096,-824.5 1102,-830.5 1102,-836.5 1102,-836.5 1102,-865.5 1102,-865.5 1102,-871.5 1096,-877.5 1090,-877.5\"/>\n<text text-anchor=\"start\" x=\"1024.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1014\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1013\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 115&#45;&gt;116 -->\n<g id=\"edge116\" class=\"edge\">\n<title>115&#45;&gt;116</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1092.67,-920.88C1086.42,-909.89 1079.44,-897.62 1073.13,-886.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1076,-884.48 1068.01,-877.52 1069.91,-887.94 1076,-884.48\"/>\n</g>\n<!-- 117 -->\n<g id=\"node118\" class=\"node\">\n<title>117</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1205,-877.5C1205,-877.5 1132,-877.5 1132,-877.5 1126,-877.5 1120,-871.5 1120,-865.5 1120,-865.5 1120,-836.5 1120,-836.5 1120,-830.5 1126,-824.5 1132,-824.5 1132,-824.5 1205,-824.5 1205,-824.5 1211,-824.5 1217,-830.5 1217,-836.5 1217,-836.5 1217,-865.5 1217,-865.5 1217,-871.5 1211,-877.5 1205,-877.5\"/>\n<text text-anchor=\"start\" x=\"1139.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1129\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1128\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 115&#45;&gt;117 -->\n<g id=\"edge117\" class=\"edge\">\n<title>115&#45;&gt;117</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1130.01,-920.88C1136.15,-909.89 1143.01,-897.62 1149.21,-886.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1152.42,-887.96 1154.24,-877.52 1146.31,-884.54 1152.42,-887.96\"/>\n</g>\n<!-- 119 -->\n<g id=\"node120\" class=\"node\">\n<title>119</title>\n<path fill=\"#e78945\" stroke=\"black\" d=\"M1500,-989C1500,-989 1419,-989 1419,-989 1413,-989 1407,-983 1407,-977 1407,-977 1407,-933 1407,-933 1407,-927 1413,-921 1419,-921 1419,-921 1500,-921 1500,-921 1506,-921 1512,-927 1512,-933 1512,-933 1512,-977 1512,-977 1512,-983 1506,-989 1500,-989\"/>\n<text text-anchor=\"start\" x=\"1418\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.785</text>\n<text text-anchor=\"start\" x=\"1422\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.111</text>\n<text text-anchor=\"start\" x=\"1416\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\n<text text-anchor=\"start\" x=\"1415\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [16, 1]</text>\n</g>\n<!-- 118&#45;&gt;119 -->\n<g id=\"edge119\" class=\"edge\">\n<title>118&#45;&gt;119</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1459.5,-1024.88C1459.5,-1016.78 1459.5,-1007.98 1459.5,-999.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1463,-999.3 1459.5,-989.3 1456,-999.3 1463,-999.3\"/>\n</g>\n<!-- 126 -->\n<g id=\"node127\" class=\"node\">\n<title>126</title>\n<path fill=\"#eeab7b\" stroke=\"black\" d=\"M1624,-989C1624,-989 1543,-989 1543,-989 1537,-989 1531,-983 1531,-977 1531,-977 1531,-933 1531,-933 1531,-927 1537,-921 1543,-921 1543,-921 1624,-921 1624,-921 1630,-921 1636,-927 1636,-933 1636,-933 1636,-977 1636,-977 1636,-983 1630,-989 1624,-989\"/>\n<text text-anchor=\"start\" x=\"1544\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.139</text>\n<text text-anchor=\"start\" x=\"1546\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"1540\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"start\" x=\"1539\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [12, 4]</text>\n</g>\n<!-- 118&#45;&gt;126 -->\n<g id=\"edge126\" class=\"edge\">\n<title>118&#45;&gt;126</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1499.76,-1024.88C1511.02,-1015.62 1523.38,-1005.45 1535.06,-995.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1537.52,-998.36 1543.02,-989.3 1533.07,-992.95 1537.52,-998.36\"/>\n</g>\n<!-- 120 -->\n<g id=\"node121\" class=\"node\">\n<title>120</title>\n<path fill=\"#ea9a61\" stroke=\"black\" d=\"M1376.5,-885C1376.5,-885 1298.5,-885 1298.5,-885 1292.5,-885 1286.5,-879 1286.5,-873 1286.5,-873 1286.5,-829 1286.5,-829 1286.5,-823 1292.5,-817 1298.5,-817 1298.5,-817 1376.5,-817 1376.5,-817 1382.5,-817 1388.5,-823 1388.5,-829 1388.5,-829 1388.5,-873 1388.5,-873 1388.5,-879 1382.5,-885 1376.5,-885\"/>\n<text text-anchor=\"start\" x=\"1294.5\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.491</text>\n<text text-anchor=\"start\" x=\"1300\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.278</text>\n<text text-anchor=\"start\" x=\"1298\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"1297\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 1]</text>\n</g>\n<!-- 119&#45;&gt;120 -->\n<g id=\"edge120\" class=\"edge\">\n<title>119&#45;&gt;120</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1419.89,-920.88C1408.81,-911.62 1396.65,-901.45 1385.16,-891.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1387.25,-889.03 1377.33,-885.3 1382.76,-894.4 1387.25,-889.03\"/>\n</g>\n<!-- 125 -->\n<g id=\"node126\" class=\"node\">\n<title>125</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1500,-877.5C1500,-877.5 1419,-877.5 1419,-877.5 1413,-877.5 1407,-871.5 1407,-865.5 1407,-865.5 1407,-836.5 1407,-836.5 1407,-830.5 1413,-824.5 1419,-824.5 1419,-824.5 1500,-824.5 1500,-824.5 1506,-824.5 1512,-830.5 1512,-836.5 1512,-836.5 1512,-865.5 1512,-865.5 1512,-871.5 1506,-877.5 1500,-877.5\"/>\n<text text-anchor=\"start\" x=\"1430.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1416\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"start\" x=\"1415\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 0]</text>\n</g>\n<!-- 119&#45;&gt;125 -->\n<g id=\"edge125\" class=\"edge\">\n<title>119&#45;&gt;125</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1459.5,-920.88C1459.5,-910.33 1459.5,-898.6 1459.5,-887.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1463,-887.52 1459.5,-877.52 1456,-887.52 1463,-887.52\"/>\n</g>\n<!-- 121 -->\n<g id=\"node122\" class=\"node\">\n<title>121</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M1330.5,-781C1330.5,-781 1252.5,-781 1252.5,-781 1246.5,-781 1240.5,-775 1240.5,-769 1240.5,-769 1240.5,-725 1240.5,-725 1240.5,-719 1246.5,-713 1252.5,-713 1252.5,-713 1330.5,-713 1330.5,-713 1336.5,-713 1342.5,-719 1342.5,-725 1342.5,-725 1342.5,-769 1342.5,-769 1342.5,-775 1336.5,-781 1330.5,-781\"/>\n<text text-anchor=\"start\" x=\"1248.5\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.549</text>\n<text text-anchor=\"start\" x=\"1254\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"1252\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1251\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 1]</text>\n</g>\n<!-- 120&#45;&gt;121 -->\n<g id=\"edge121\" class=\"edge\">\n<title>120&#45;&gt;121</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1322.57,-816.88C1318.79,-808.51 1314.68,-799.4 1310.73,-790.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1313.82,-788.98 1306.52,-781.3 1307.44,-791.85 1313.82,-788.98\"/>\n</g>\n<!-- 124 -->\n<g id=\"node125\" class=\"node\">\n<title>124</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1446,-773.5C1446,-773.5 1373,-773.5 1373,-773.5 1367,-773.5 1361,-767.5 1361,-761.5 1361,-761.5 1361,-732.5 1361,-732.5 1361,-726.5 1367,-720.5 1373,-720.5 1373,-720.5 1446,-720.5 1446,-720.5 1452,-720.5 1458,-726.5 1458,-732.5 1458,-732.5 1458,-761.5 1458,-761.5 1458,-767.5 1452,-773.5 1446,-773.5\"/>\n<text text-anchor=\"start\" x=\"1380.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1370\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1369\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 120&#45;&gt;124 -->\n<g id=\"edge124\" class=\"edge\">\n<title>120&#45;&gt;124</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1360.88,-816.88C1368.79,-805.67 1377.65,-793.13 1385.6,-781.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1388.58,-783.71 1391.49,-773.52 1382.86,-779.67 1388.58,-783.71\"/>\n</g>\n<!-- 122 -->\n<g id=\"node123\" class=\"node\">\n<title>122</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1281,-669.5C1281,-669.5 1208,-669.5 1208,-669.5 1202,-669.5 1196,-663.5 1196,-657.5 1196,-657.5 1196,-628.5 1196,-628.5 1196,-622.5 1202,-616.5 1208,-616.5 1208,-616.5 1281,-616.5 1281,-616.5 1287,-616.5 1293,-622.5 1293,-628.5 1293,-628.5 1293,-657.5 1293,-657.5 1293,-663.5 1287,-669.5 1281,-669.5\"/>\n<text text-anchor=\"start\" x=\"1215.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1205\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1204\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 121&#45;&gt;122 -->\n<g id=\"edge122\" class=\"edge\">\n<title>121&#45;&gt;122</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1276.24,-712.88C1271.22,-702 1265.63,-689.86 1260.56,-678.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1263.62,-677.14 1256.26,-669.52 1257.27,-680.07 1263.62,-677.14\"/>\n</g>\n<!-- 123 -->\n<g id=\"node124\" class=\"node\">\n<title>123</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M1396,-669.5C1396,-669.5 1323,-669.5 1323,-669.5 1317,-669.5 1311,-663.5 1311,-657.5 1311,-657.5 1311,-628.5 1311,-628.5 1311,-622.5 1317,-616.5 1323,-616.5 1323,-616.5 1396,-616.5 1396,-616.5 1402,-616.5 1408,-622.5 1408,-628.5 1408,-628.5 1408,-657.5 1408,-657.5 1408,-663.5 1402,-669.5 1396,-669.5\"/>\n<text text-anchor=\"start\" x=\"1330.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"1320\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1319\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 121&#45;&gt;123 -->\n<g id=\"edge123\" class=\"edge\">\n<title>121&#45;&gt;123</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1313.58,-712.88C1321.06,-701.67 1329.42,-689.13 1336.93,-677.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1339.85,-679.78 1342.49,-669.52 1334.03,-675.9 1339.85,-679.78\"/>\n</g>\n<!-- 127 -->\n<g id=\"node128\" class=\"node\">\n<title>127</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M1622.5,-885C1622.5,-885 1544.5,-885 1544.5,-885 1538.5,-885 1532.5,-879 1532.5,-873 1532.5,-873 1532.5,-829 1532.5,-829 1532.5,-823 1538.5,-817 1544.5,-817 1544.5,-817 1622.5,-817 1622.5,-817 1628.5,-817 1634.5,-823 1634.5,-829 1634.5,-829 1634.5,-873 1634.5,-873 1634.5,-879 1628.5,-885 1622.5,-885\"/>\n<text text-anchor=\"start\" x=\"1540.5\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.581</text>\n<text text-anchor=\"start\" x=\"1554.5\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"1544\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"1543\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 4]</text>\n</g>\n<!-- 126&#45;&gt;127 -->\n<g id=\"edge127\" class=\"edge\">\n<title>126&#45;&gt;127</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1583.5,-920.88C1583.5,-912.78 1583.5,-903.98 1583.5,-895.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1587,-895.3 1583.5,-885.3 1580,-895.3 1587,-895.3\"/>\n</g>\n<!-- 136 -->\n<g id=\"node137\" class=\"node\">\n<title>136</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1738,-877.5C1738,-877.5 1665,-877.5 1665,-877.5 1659,-877.5 1653,-871.5 1653,-865.5 1653,-865.5 1653,-836.5 1653,-836.5 1653,-830.5 1659,-824.5 1665,-824.5 1665,-824.5 1738,-824.5 1738,-824.5 1744,-824.5 1750,-830.5 1750,-836.5 1750,-836.5 1750,-865.5 1750,-865.5 1750,-871.5 1744,-877.5 1738,-877.5\"/>\n<text text-anchor=\"start\" x=\"1672.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1662\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"1661\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 0]</text>\n</g>\n<!-- 126&#45;&gt;136 -->\n<g id=\"edge136\" class=\"edge\">\n<title>126&#45;&gt;136</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1621.81,-920.88C1635.42,-909.12 1650.72,-895.89 1664.25,-884.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1666.7,-886.71 1671.98,-877.52 1662.12,-881.41 1666.7,-886.71\"/>\n</g>\n<!-- 128 -->\n<g id=\"node129\" class=\"node\">\n<title>128</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M1620,-781C1620,-781 1547,-781 1547,-781 1541,-781 1535,-775 1535,-769 1535,-769 1535,-725 1535,-725 1535,-719 1541,-713 1547,-713 1547,-713 1620,-713 1620,-713 1626,-713 1632,-719 1632,-725 1632,-725 1632,-769 1632,-769 1632,-775 1626,-781 1620,-781\"/>\n<text text-anchor=\"start\" x=\"1544\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.052</text>\n<text text-anchor=\"start\" x=\"1546\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"1544\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1543\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 127&#45;&gt;128 -->\n<g id=\"edge128\" class=\"edge\">\n<title>127&#45;&gt;128</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1583.5,-816.88C1583.5,-808.78 1583.5,-799.98 1583.5,-791.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1587,-791.3 1583.5,-781.3 1580,-791.3 1587,-791.3\"/>\n</g>\n<!-- 131 -->\n<g id=\"node132\" class=\"node\">\n<title>131</title>\n<path fill=\"#f6d5bd\" stroke=\"black\" d=\"M1743.5,-781C1743.5,-781 1665.5,-781 1665.5,-781 1659.5,-781 1653.5,-775 1653.5,-769 1653.5,-769 1653.5,-725 1653.5,-725 1653.5,-719 1659.5,-713 1665.5,-713 1665.5,-713 1743.5,-713 1743.5,-713 1749.5,-713 1755.5,-719 1755.5,-725 1755.5,-725 1755.5,-769 1755.5,-769 1755.5,-775 1749.5,-781 1743.5,-781\"/>\n<text text-anchor=\"start\" x=\"1661.5\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.433</text>\n<text text-anchor=\"start\" x=\"1671\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n<text text-anchor=\"start\" x=\"1665\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"1664\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 2]</text>\n</g>\n<!-- 127&#45;&gt;131 -->\n<g id=\"edge131\" class=\"edge\">\n<title>127&#45;&gt;131</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1622.79,-816.88C1633.77,-807.62 1645.83,-797.45 1657.23,-787.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1659.61,-790.42 1665,-781.3 1655.1,-785.07 1659.61,-790.42\"/>\n</g>\n<!-- 129 -->\n<g id=\"node130\" class=\"node\">\n<title>129</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1511,-669.5C1511,-669.5 1438,-669.5 1438,-669.5 1432,-669.5 1426,-663.5 1426,-657.5 1426,-657.5 1426,-628.5 1426,-628.5 1426,-622.5 1432,-616.5 1438,-616.5 1438,-616.5 1511,-616.5 1511,-616.5 1517,-616.5 1523,-622.5 1523,-628.5 1523,-628.5 1523,-657.5 1523,-657.5 1523,-663.5 1517,-669.5 1511,-669.5\"/>\n<text text-anchor=\"start\" x=\"1445.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1435\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1434\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 128&#45;&gt;129 -->\n<g id=\"edge129\" class=\"edge\">\n<title>128&#45;&gt;129</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1548.11,-712.88C1535.65,-701.23 1521.67,-688.14 1509.26,-676.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1511.46,-673.8 1501.77,-669.52 1506.68,-678.91 1511.46,-673.8\"/>\n</g>\n<!-- 130 -->\n<g id=\"node131\" class=\"node\">\n<title>130</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1626,-669.5C1626,-669.5 1553,-669.5 1553,-669.5 1547,-669.5 1541,-663.5 1541,-657.5 1541,-657.5 1541,-628.5 1541,-628.5 1541,-622.5 1547,-616.5 1553,-616.5 1553,-616.5 1626,-616.5 1626,-616.5 1632,-616.5 1638,-622.5 1638,-628.5 1638,-628.5 1638,-657.5 1638,-657.5 1638,-663.5 1632,-669.5 1626,-669.5\"/>\n<text text-anchor=\"start\" x=\"1560.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1550\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1549\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 128&#45;&gt;130 -->\n<g id=\"edge130\" class=\"edge\">\n<title>128&#45;&gt;130</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1585.45,-712.88C1586.08,-702.22 1586.77,-690.35 1587.41,-679.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1590.91,-679.71 1588,-669.52 1583.92,-679.3 1590.91,-679.71\"/>\n</g>\n<!-- 132 -->\n<g id=\"node133\" class=\"node\">\n<title>132</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1741,-669.5C1741,-669.5 1668,-669.5 1668,-669.5 1662,-669.5 1656,-663.5 1656,-657.5 1656,-657.5 1656,-628.5 1656,-628.5 1656,-622.5 1662,-616.5 1668,-616.5 1668,-616.5 1741,-616.5 1741,-616.5 1747,-616.5 1753,-622.5 1753,-628.5 1753,-628.5 1753,-657.5 1753,-657.5 1753,-663.5 1747,-669.5 1741,-669.5\"/>\n<text text-anchor=\"start\" x=\"1675.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1665\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1664\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 131&#45;&gt;132 -->\n<g id=\"edge132\" class=\"edge\">\n<title>131&#45;&gt;132</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1704.5,-712.88C1704.5,-702.33 1704.5,-690.6 1704.5,-679.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1708,-679.52 1704.5,-669.52 1701,-679.52 1708,-679.52\"/>\n</g>\n<!-- 133 -->\n<g id=\"node134\" class=\"node\">\n<title>133</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M1856,-677C1856,-677 1783,-677 1783,-677 1777,-677 1771,-671 1771,-665 1771,-665 1771,-621 1771,-621 1771,-615 1777,-609 1783,-609 1783,-609 1856,-609 1856,-609 1862,-609 1868,-615 1868,-621 1868,-621 1868,-665 1868,-665 1868,-671 1862,-677 1856,-677\"/>\n<text text-anchor=\"start\" x=\"1780\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.052</text>\n<text text-anchor=\"start\" x=\"1782\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"1780\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1779\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 131&#45;&gt;133 -->\n<g id=\"edge133\" class=\"edge\">\n<title>131&#45;&gt;133</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1741.84,-712.88C1752.18,-703.71 1763.52,-693.65 1774.26,-684.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1776.8,-686.55 1781.96,-677.3 1772.15,-681.32 1776.8,-686.55\"/>\n</g>\n<!-- 134 -->\n<g id=\"node135\" class=\"node\">\n<title>134</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1798,-565.5C1798,-565.5 1725,-565.5 1725,-565.5 1719,-565.5 1713,-559.5 1713,-553.5 1713,-553.5 1713,-524.5 1713,-524.5 1713,-518.5 1719,-512.5 1725,-512.5 1725,-512.5 1798,-512.5 1798,-512.5 1804,-512.5 1810,-518.5 1810,-524.5 1810,-524.5 1810,-553.5 1810,-553.5 1810,-559.5 1804,-565.5 1798,-565.5\"/>\n<text text-anchor=\"start\" x=\"1732.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1722\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1721\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 133&#45;&gt;134 -->\n<g id=\"edge134\" class=\"edge\">\n<title>133&#45;&gt;134</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1800.67,-608.88C1794.42,-597.89 1787.44,-585.62 1781.13,-574.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1784,-572.48 1776.01,-565.52 1777.91,-575.94 1784,-572.48\"/>\n</g>\n<!-- 135 -->\n<g id=\"node136\" class=\"node\">\n<title>135</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1913,-565.5C1913,-565.5 1840,-565.5 1840,-565.5 1834,-565.5 1828,-559.5 1828,-553.5 1828,-553.5 1828,-524.5 1828,-524.5 1828,-518.5 1834,-512.5 1840,-512.5 1840,-512.5 1913,-512.5 1913,-512.5 1919,-512.5 1925,-518.5 1925,-524.5 1925,-524.5 1925,-553.5 1925,-553.5 1925,-559.5 1919,-565.5 1913,-565.5\"/>\n<text text-anchor=\"start\" x=\"1847.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1837\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1836\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 133&#45;&gt;135 -->\n<g id=\"edge135\" class=\"edge\">\n<title>133&#45;&gt;135</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1838.01,-608.88C1844.15,-597.89 1851.01,-585.62 1857.21,-574.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1860.42,-575.96 1862.24,-565.52 1854.31,-572.54 1860.42,-575.96\"/>\n</g>\n<!-- 139 -->\n<g id=\"node140\" class=\"node\">\n<title>139</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1631,-1293.5C1631,-1293.5 1558,-1293.5 1558,-1293.5 1552,-1293.5 1546,-1287.5 1546,-1281.5 1546,-1281.5 1546,-1252.5 1546,-1252.5 1546,-1246.5 1552,-1240.5 1558,-1240.5 1558,-1240.5 1631,-1240.5 1631,-1240.5 1637,-1240.5 1643,-1246.5 1643,-1252.5 1643,-1252.5 1643,-1281.5 1643,-1281.5 1643,-1287.5 1637,-1293.5 1631,-1293.5\"/>\n<text text-anchor=\"start\" x=\"1565.5\" y=\"-1278.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1555\" y=\"-1263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1554\" y=\"-1248.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 138&#45;&gt;139 -->\n<g id=\"edge139\" class=\"edge\">\n<title>138&#45;&gt;139</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1594.5,-1336.88C1594.5,-1326.33 1594.5,-1314.6 1594.5,-1303.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1598,-1303.52 1594.5,-1293.52 1591,-1303.52 1598,-1303.52\"/>\n</g>\n<!-- 140 -->\n<g id=\"node141\" class=\"node\">\n<title>140</title>\n<path fill=\"#eeab7b\" stroke=\"black\" d=\"M1747,-1301C1747,-1301 1674,-1301 1674,-1301 1668,-1301 1662,-1295 1662,-1289 1662,-1289 1662,-1245 1662,-1245 1662,-1239 1668,-1233 1674,-1233 1674,-1233 1747,-1233 1747,-1233 1753,-1233 1759,-1239 1759,-1245 1759,-1245 1759,-1289 1759,-1289 1759,-1295 1753,-1301 1747,-1301\"/>\n<text text-anchor=\"start\" x=\"1671\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 1.064</text>\n<text text-anchor=\"start\" x=\"1673\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"1671\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"1670\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 2]</text>\n</g>\n<!-- 138&#45;&gt;140 -->\n<g id=\"edge140\" class=\"edge\">\n<title>138&#45;&gt;140</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1632.16,-1336.88C1642.6,-1327.71 1654.04,-1317.65 1664.87,-1308.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1667.43,-1310.53 1672.63,-1301.3 1662.81,-1305.27 1667.43,-1310.53\"/>\n</g>\n<!-- 141 -->\n<g id=\"node142\" class=\"node\">\n<title>141</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1747,-1189.5C1747,-1189.5 1674,-1189.5 1674,-1189.5 1668,-1189.5 1662,-1183.5 1662,-1177.5 1662,-1177.5 1662,-1148.5 1662,-1148.5 1662,-1142.5 1668,-1136.5 1674,-1136.5 1674,-1136.5 1747,-1136.5 1747,-1136.5 1753,-1136.5 1759,-1142.5 1759,-1148.5 1759,-1148.5 1759,-1177.5 1759,-1177.5 1759,-1183.5 1753,-1189.5 1747,-1189.5\"/>\n<text text-anchor=\"start\" x=\"1681.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1671\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1670\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 140&#45;&gt;141 -->\n<g id=\"edge141\" class=\"edge\">\n<title>140&#45;&gt;141</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1710.5,-1232.88C1710.5,-1222.33 1710.5,-1210.6 1710.5,-1199.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1714,-1199.52 1710.5,-1189.52 1707,-1199.52 1714,-1199.52\"/>\n</g>\n<!-- 142 -->\n<g id=\"node143\" class=\"node\">\n<title>142</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M1862,-1197C1862,-1197 1789,-1197 1789,-1197 1783,-1197 1777,-1191 1777,-1185 1777,-1185 1777,-1141 1777,-1141 1777,-1135 1783,-1129 1789,-1129 1789,-1129 1862,-1129 1862,-1129 1868,-1129 1874,-1135 1874,-1141 1874,-1141 1874,-1185 1874,-1185 1874,-1191 1868,-1197 1862,-1197\"/>\n<text text-anchor=\"start\" x=\"1789\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1788\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"1786\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"1785\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 2]</text>\n</g>\n<!-- 140&#45;&gt;142 -->\n<g id=\"edge142\" class=\"edge\">\n<title>140&#45;&gt;142</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1747.84,-1232.88C1758.18,-1223.71 1769.52,-1213.65 1780.26,-1204.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1782.8,-1206.55 1787.96,-1197.3 1778.15,-1201.32 1782.8,-1206.55\"/>\n</g>\n<!-- 143 -->\n<g id=\"node144\" class=\"node\">\n<title>143</title>\n<path fill=\"#f6d5bd\" stroke=\"black\" d=\"M1756.5,-1093C1756.5,-1093 1678.5,-1093 1678.5,-1093 1672.5,-1093 1666.5,-1087 1666.5,-1081 1666.5,-1081 1666.5,-1037 1666.5,-1037 1666.5,-1031 1672.5,-1025 1678.5,-1025 1678.5,-1025 1756.5,-1025 1756.5,-1025 1762.5,-1025 1768.5,-1031 1768.5,-1037 1768.5,-1037 1768.5,-1081 1768.5,-1081 1768.5,-1087 1762.5,-1093 1756.5,-1093\"/>\n<text text-anchor=\"start\" x=\"1674.5\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.854</text>\n<text text-anchor=\"start\" x=\"1684\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n<text text-anchor=\"start\" x=\"1678\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"1677\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 2]</text>\n</g>\n<!-- 142&#45;&gt;143 -->\n<g id=\"edge143\" class=\"edge\">\n<title>142&#45;&gt;143</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1790.44,-1128.88C1780.82,-1119.8 1770.28,-1109.85 1760.28,-1100.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1762.43,-1097.62 1752.76,-1093.3 1757.63,-1102.71 1762.43,-1097.62\"/>\n</g>\n<!-- 150 -->\n<g id=\"node151\" class=\"node\">\n<title>150</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1872,-1085.5C1872,-1085.5 1799,-1085.5 1799,-1085.5 1793,-1085.5 1787,-1079.5 1787,-1073.5 1787,-1073.5 1787,-1044.5 1787,-1044.5 1787,-1038.5 1793,-1032.5 1799,-1032.5 1799,-1032.5 1872,-1032.5 1872,-1032.5 1878,-1032.5 1884,-1038.5 1884,-1044.5 1884,-1044.5 1884,-1073.5 1884,-1073.5 1884,-1079.5 1878,-1085.5 1872,-1085.5\"/>\n<text text-anchor=\"start\" x=\"1806.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1796\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1795\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 142&#45;&gt;150 -->\n<g id=\"edge150\" class=\"edge\">\n<title>142&#45;&gt;150</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1828.75,-1128.88C1829.79,-1118.22 1830.96,-1106.35 1832.02,-1095.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1835.51,-1095.81 1833,-1085.52 1828.54,-1095.13 1835.51,-1095.81\"/>\n</g>\n<!-- 144 -->\n<g id=\"node145\" class=\"node\">\n<title>144</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1754,-981.5C1754,-981.5 1681,-981.5 1681,-981.5 1675,-981.5 1669,-975.5 1669,-969.5 1669,-969.5 1669,-940.5 1669,-940.5 1669,-934.5 1675,-928.5 1681,-928.5 1681,-928.5 1754,-928.5 1754,-928.5 1760,-928.5 1766,-934.5 1766,-940.5 1766,-940.5 1766,-969.5 1766,-969.5 1766,-975.5 1760,-981.5 1754,-981.5\"/>\n<text text-anchor=\"start\" x=\"1688.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1678\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1677\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 143&#45;&gt;144 -->\n<g id=\"edge144\" class=\"edge\">\n<title>143&#45;&gt;144</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1717.5,-1024.88C1717.5,-1014.33 1717.5,-1002.6 1717.5,-991.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1721,-991.52 1717.5,-981.52 1714,-991.52 1721,-991.52\"/>\n</g>\n<!-- 145 -->\n<g id=\"node146\" class=\"node\">\n<title>145</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M1869,-989C1869,-989 1796,-989 1796,-989 1790,-989 1784,-983 1784,-977 1784,-977 1784,-933 1784,-933 1784,-927 1790,-921 1796,-921 1796,-921 1869,-921 1869,-921 1875,-921 1881,-927 1881,-933 1881,-933 1881,-977 1881,-977 1881,-983 1875,-989 1869,-989\"/>\n<text text-anchor=\"start\" x=\"1793\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 1.141</text>\n<text text-anchor=\"start\" x=\"1803.5\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"1793\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"1792\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 2]</text>\n</g>\n<!-- 143&#45;&gt;145 -->\n<g id=\"edge145\" class=\"edge\">\n<title>143&#45;&gt;145</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1754.84,-1024.88C1765.18,-1015.71 1776.52,-1005.65 1787.26,-996.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1789.8,-998.55 1794.96,-989.3 1785.15,-993.32 1789.8,-998.55\"/>\n</g>\n<!-- 146 -->\n<g id=\"node147\" class=\"node\">\n<title>146</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M1866.5,-885C1866.5,-885 1788.5,-885 1788.5,-885 1782.5,-885 1776.5,-879 1776.5,-873 1776.5,-873 1776.5,-829 1776.5,-829 1776.5,-823 1782.5,-817 1788.5,-817 1788.5,-817 1866.5,-817 1866.5,-817 1872.5,-817 1878.5,-823 1878.5,-829 1878.5,-829 1878.5,-873 1878.5,-873 1878.5,-879 1872.5,-885 1866.5,-885\"/>\n<text text-anchor=\"start\" x=\"1784.5\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.789</text>\n<text text-anchor=\"start\" x=\"1790\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"1788\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1787\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 1]</text>\n</g>\n<!-- 145&#45;&gt;146 -->\n<g id=\"edge146\" class=\"edge\">\n<title>145&#45;&gt;146</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1830.88,-920.88C1830.48,-912.78 1830.05,-903.98 1829.63,-895.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1833.12,-895.12 1829.13,-885.3 1826.13,-895.46 1833.12,-895.12\"/>\n</g>\n<!-- 149 -->\n<g id=\"node150\" class=\"node\">\n<title>149</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1982,-877.5C1982,-877.5 1909,-877.5 1909,-877.5 1903,-877.5 1897,-871.5 1897,-865.5 1897,-865.5 1897,-836.5 1897,-836.5 1897,-830.5 1903,-824.5 1909,-824.5 1909,-824.5 1982,-824.5 1982,-824.5 1988,-824.5 1994,-830.5 1994,-836.5 1994,-836.5 1994,-865.5 1994,-865.5 1994,-871.5 1988,-877.5 1982,-877.5\"/>\n<text text-anchor=\"start\" x=\"1916.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1906\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1905\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 145&#45;&gt;149 -->\n<g id=\"edge149\" class=\"edge\">\n<title>145&#45;&gt;149</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1869.19,-920.88C1882.1,-909.23 1896.6,-896.14 1909.46,-884.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1912.15,-886.82 1917.23,-877.52 1907.46,-881.62 1912.15,-886.82\"/>\n</g>\n<!-- 147 -->\n<g id=\"node148\" class=\"node\">\n<title>147</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1861,-773.5C1861,-773.5 1788,-773.5 1788,-773.5 1782,-773.5 1776,-767.5 1776,-761.5 1776,-761.5 1776,-732.5 1776,-732.5 1776,-726.5 1782,-720.5 1788,-720.5 1788,-720.5 1861,-720.5 1861,-720.5 1867,-720.5 1873,-726.5 1873,-732.5 1873,-732.5 1873,-761.5 1873,-761.5 1873,-767.5 1867,-773.5 1861,-773.5\"/>\n<text text-anchor=\"start\" x=\"1795.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1785\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1784\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 146&#45;&gt;147 -->\n<g id=\"edge147\" class=\"edge\">\n<title>146&#45;&gt;147</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1826.53,-816.88C1826.21,-806.22 1825.86,-794.35 1825.54,-783.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1829.04,-783.41 1825.25,-773.52 1822.05,-783.62 1829.04,-783.41\"/>\n</g>\n<!-- 148 -->\n<g id=\"node149\" class=\"node\">\n<title>148</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1976,-773.5C1976,-773.5 1903,-773.5 1903,-773.5 1897,-773.5 1891,-767.5 1891,-761.5 1891,-761.5 1891,-732.5 1891,-732.5 1891,-726.5 1897,-720.5 1903,-720.5 1903,-720.5 1976,-720.5 1976,-720.5 1982,-720.5 1988,-726.5 1988,-732.5 1988,-732.5 1988,-761.5 1988,-761.5 1988,-767.5 1982,-773.5 1976,-773.5\"/>\n<text text-anchor=\"start\" x=\"1910.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1900\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1899\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 146&#45;&gt;148 -->\n<g id=\"edge148\" class=\"edge\">\n<title>146&#45;&gt;148</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1863.86,-816.88C1876.66,-805.23 1891.03,-792.14 1903.78,-780.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1906.44,-782.84 1911.48,-773.52 1901.73,-777.67 1906.44,-782.84\"/>\n</g>\n<!-- 153 -->\n<g id=\"node154\" class=\"node\">\n<title>153</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M1752,-1509C1752,-1509 1679,-1509 1679,-1509 1673,-1509 1667,-1503 1667,-1497 1667,-1497 1667,-1453 1667,-1453 1667,-1447 1673,-1441 1679,-1441 1679,-1441 1752,-1441 1752,-1441 1758,-1441 1764,-1447 1764,-1453 1764,-1453 1764,-1497 1764,-1497 1764,-1503 1758,-1509 1752,-1509\"/>\n<text text-anchor=\"start\" x=\"1676\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 1.604</text>\n<text text-anchor=\"start\" x=\"1678\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"1676\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1675\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 152&#45;&gt;153 -->\n<g id=\"edge153\" class=\"edge\">\n<title>152&#45;&gt;153</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1787.76,-1544.88C1778.23,-1535.8 1767.79,-1525.85 1757.88,-1516.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1760.08,-1513.67 1750.43,-1509.3 1755.25,-1518.73 1760.08,-1513.67\"/>\n</g>\n<!-- 156 -->\n<g id=\"node157\" class=\"node\">\n<title>156</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1867,-1501.5C1867,-1501.5 1794,-1501.5 1794,-1501.5 1788,-1501.5 1782,-1495.5 1782,-1489.5 1782,-1489.5 1782,-1460.5 1782,-1460.5 1782,-1454.5 1788,-1448.5 1794,-1448.5 1794,-1448.5 1867,-1448.5 1867,-1448.5 1873,-1448.5 1879,-1454.5 1879,-1460.5 1879,-1460.5 1879,-1489.5 1879,-1489.5 1879,-1495.5 1873,-1501.5 1867,-1501.5\"/>\n<text text-anchor=\"start\" x=\"1801.5\" y=\"-1486.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1791\" y=\"-1471.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1790\" y=\"-1456.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 152&#45;&gt;156 -->\n<g id=\"edge156\" class=\"edge\">\n<title>152&#45;&gt;156</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1825.1,-1544.88C1825.93,-1534.22 1826.86,-1522.35 1827.71,-1511.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1831.21,-1511.76 1828.5,-1501.52 1824.23,-1511.22 1831.21,-1511.76\"/>\n</g>\n<!-- 154 -->\n<g id=\"node155\" class=\"node\">\n<title>154</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1749,-1397.5C1749,-1397.5 1676,-1397.5 1676,-1397.5 1670,-1397.5 1664,-1391.5 1664,-1385.5 1664,-1385.5 1664,-1356.5 1664,-1356.5 1664,-1350.5 1670,-1344.5 1676,-1344.5 1676,-1344.5 1749,-1344.5 1749,-1344.5 1755,-1344.5 1761,-1350.5 1761,-1356.5 1761,-1356.5 1761,-1385.5 1761,-1385.5 1761,-1391.5 1755,-1397.5 1749,-1397.5\"/>\n<text text-anchor=\"start\" x=\"1683.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1673\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1672\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 153&#45;&gt;154 -->\n<g id=\"edge154\" class=\"edge\">\n<title>153&#45;&gt;154</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1714.53,-1440.88C1714.21,-1430.22 1713.86,-1418.35 1713.54,-1407.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1717.04,-1407.41 1713.25,-1397.52 1710.05,-1407.62 1717.04,-1407.41\"/>\n</g>\n<!-- 155 -->\n<g id=\"node156\" class=\"node\">\n<title>155</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1864,-1397.5C1864,-1397.5 1791,-1397.5 1791,-1397.5 1785,-1397.5 1779,-1391.5 1779,-1385.5 1779,-1385.5 1779,-1356.5 1779,-1356.5 1779,-1350.5 1785,-1344.5 1791,-1344.5 1791,-1344.5 1864,-1344.5 1864,-1344.5 1870,-1344.5 1876,-1350.5 1876,-1356.5 1876,-1356.5 1876,-1385.5 1876,-1385.5 1876,-1391.5 1870,-1397.5 1864,-1397.5\"/>\n<text text-anchor=\"start\" x=\"1798.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1788\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1787\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 153&#45;&gt;155 -->\n<g id=\"edge155\" class=\"edge\">\n<title>153&#45;&gt;155</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1751.86,-1440.88C1764.66,-1429.23 1779.03,-1416.14 1791.78,-1404.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1794.44,-1406.84 1799.48,-1397.52 1789.73,-1401.67 1794.44,-1406.84\"/>\n</g>\n<!-- 158 -->\n<g id=\"node159\" class=\"node\">\n<title>158</title>\n<path fill=\"#e99355\" stroke=\"black\" d=\"M1983,-1613C1983,-1613 1910,-1613 1910,-1613 1904,-1613 1898,-1607 1898,-1601 1898,-1601 1898,-1557 1898,-1557 1898,-1551 1904,-1545 1910,-1545 1910,-1545 1983,-1545 1983,-1545 1989,-1545 1995,-1551 1995,-1557 1995,-1557 1995,-1601 1995,-1601 1995,-1607 1989,-1613 1983,-1613\"/>\n<text text-anchor=\"start\" x=\"1909\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.67</text>\n<text text-anchor=\"start\" x=\"1909\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.219</text>\n<text text-anchor=\"start\" x=\"1907\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"1906\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 1]</text>\n</g>\n<!-- 157&#45;&gt;158 -->\n<g id=\"edge158\" class=\"edge\">\n<title>157&#45;&gt;158</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1951.9,-1648.88C1951.27,-1640.78 1950.58,-1631.98 1949.91,-1623.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1953.38,-1623 1949.11,-1613.3 1946.4,-1623.54 1953.38,-1623\"/>\n</g>\n<!-- 163 -->\n<g id=\"node164\" class=\"node\">\n<title>163</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2106,-1605.5C2106,-1605.5 2025,-1605.5 2025,-1605.5 2019,-1605.5 2013,-1599.5 2013,-1593.5 2013,-1593.5 2013,-1564.5 2013,-1564.5 2013,-1558.5 2019,-1552.5 2025,-1552.5 2025,-1552.5 2106,-1552.5 2106,-1552.5 2112,-1552.5 2118,-1558.5 2118,-1564.5 2118,-1564.5 2118,-1593.5 2118,-1593.5 2118,-1599.5 2112,-1605.5 2106,-1605.5\"/>\n<text text-anchor=\"start\" x=\"2036.5\" y=\"-1590.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2022\" y=\"-1575.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 40</text>\n<text text-anchor=\"start\" x=\"2021\" y=\"-1560.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [40, 0]</text>\n</g>\n<!-- 157&#45;&gt;163 -->\n<g id=\"edge163\" class=\"edge\">\n<title>157&#45;&gt;163</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1990.54,-1648.88C2003.22,-1637.23 2017.46,-1624.14 2030.1,-1612.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2032.73,-1614.86 2037.73,-1605.52 2028,-1609.71 2032.73,-1614.86\"/>\n</g>\n<!-- 159 -->\n<g id=\"node160\" class=\"node\">\n<title>159</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M1987.5,-1509C1987.5,-1509 1909.5,-1509 1909.5,-1509 1903.5,-1509 1897.5,-1503 1897.5,-1497 1897.5,-1497 1897.5,-1453 1897.5,-1453 1897.5,-1447 1903.5,-1441 1909.5,-1441 1909.5,-1441 1987.5,-1441 1987.5,-1441 1993.5,-1441 1999.5,-1447 1999.5,-1453 1999.5,-1453 1999.5,-1497 1999.5,-1497 1999.5,-1503 1993.5,-1509 1987.5,-1509\"/>\n<text text-anchor=\"start\" x=\"1905.5\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.849</text>\n<text text-anchor=\"start\" x=\"1919.5\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"1909\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1908\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 158&#45;&gt;159 -->\n<g id=\"edge159\" class=\"edge\">\n<title>158&#45;&gt;159</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1947.15,-1544.88C1947.31,-1536.78 1947.48,-1527.98 1947.65,-1519.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1951.15,-1519.37 1947.85,-1509.3 1944.15,-1519.23 1951.15,-1519.37\"/>\n</g>\n<!-- 162 -->\n<g id=\"node163\" class=\"node\">\n<title>162</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2103,-1501.5C2103,-1501.5 2030,-1501.5 2030,-1501.5 2024,-1501.5 2018,-1495.5 2018,-1489.5 2018,-1489.5 2018,-1460.5 2018,-1460.5 2018,-1454.5 2024,-1448.5 2030,-1448.5 2030,-1448.5 2103,-1448.5 2103,-1448.5 2109,-1448.5 2115,-1454.5 2115,-1460.5 2115,-1460.5 2115,-1489.5 2115,-1489.5 2115,-1495.5 2109,-1501.5 2103,-1501.5\"/>\n<text text-anchor=\"start\" x=\"2037.5\" y=\"-1486.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2027\" y=\"-1471.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"2026\" y=\"-1456.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 0]</text>\n</g>\n<!-- 158&#45;&gt;162 -->\n<g id=\"edge162\" class=\"edge\">\n<title>158&#45;&gt;162</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1985.46,-1544.88C1999.3,-1533.12 2014.86,-1519.89 2028.61,-1508.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2031.12,-1510.66 2036.48,-1501.52 2026.59,-1505.33 2031.12,-1510.66\"/>\n</g>\n<!-- 160 -->\n<g id=\"node161\" class=\"node\">\n<title>160</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1982,-1397.5C1982,-1397.5 1909,-1397.5 1909,-1397.5 1903,-1397.5 1897,-1391.5 1897,-1385.5 1897,-1385.5 1897,-1356.5 1897,-1356.5 1897,-1350.5 1903,-1344.5 1909,-1344.5 1909,-1344.5 1982,-1344.5 1982,-1344.5 1988,-1344.5 1994,-1350.5 1994,-1356.5 1994,-1356.5 1994,-1385.5 1994,-1385.5 1994,-1391.5 1988,-1397.5 1982,-1397.5\"/>\n<text text-anchor=\"start\" x=\"1916.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1906\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1905\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 159&#45;&gt;160 -->\n<g id=\"edge160\" class=\"edge\">\n<title>159&#45;&gt;160</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1947.53,-1440.88C1947.21,-1430.22 1946.86,-1418.35 1946.54,-1407.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1950.04,-1407.41 1946.25,-1397.52 1943.05,-1407.62 1950.04,-1407.41\"/>\n</g>\n<!-- 161 -->\n<g id=\"node162\" class=\"node\">\n<title>161</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2097,-1397.5C2097,-1397.5 2024,-1397.5 2024,-1397.5 2018,-1397.5 2012,-1391.5 2012,-1385.5 2012,-1385.5 2012,-1356.5 2012,-1356.5 2012,-1350.5 2018,-1344.5 2024,-1344.5 2024,-1344.5 2097,-1344.5 2097,-1344.5 2103,-1344.5 2109,-1350.5 2109,-1356.5 2109,-1356.5 2109,-1385.5 2109,-1385.5 2109,-1391.5 2103,-1397.5 2097,-1397.5\"/>\n<text text-anchor=\"start\" x=\"2031.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2021\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2020\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 159&#45;&gt;161 -->\n<g id=\"edge161\" class=\"edge\">\n<title>159&#45;&gt;161</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1984.86,-1440.88C1997.66,-1429.23 2012.03,-1416.14 2024.78,-1404.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2027.44,-1406.84 2032.48,-1397.52 2022.73,-1401.67 2027.44,-1406.84\"/>\n</g>\n<!-- 165 -->\n<g id=\"node166\" class=\"node\">\n<title>165</title>\n<path fill=\"#bddef6\" stroke=\"black\" d=\"M2392,-1821C2392,-1821 2319,-1821 2319,-1821 2313,-1821 2307,-1815 2307,-1809 2307,-1809 2307,-1765 2307,-1765 2307,-1759 2313,-1753 2319,-1753 2319,-1753 2392,-1753 2392,-1753 2398,-1753 2404,-1759 2404,-1765 2404,-1765 2404,-1809 2404,-1809 2404,-1815 2398,-1821 2392,-1821\"/>\n<text text-anchor=\"start\" x=\"2318\" y=\"-1805.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.94</text>\n<text text-anchor=\"start\" x=\"2322\" y=\"-1790.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n<text text-anchor=\"start\" x=\"2316\" y=\"-1775.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"2315\" y=\"-1760.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 3]</text>\n</g>\n<!-- 164&#45;&gt;165 -->\n<g id=\"edge165\" class=\"edge\">\n<title>164&#45;&gt;165</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2355.5,-1856.88C2355.5,-1848.78 2355.5,-1839.98 2355.5,-1831.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2359,-1831.3 2355.5,-1821.3 2352,-1831.3 2359,-1831.3\"/>\n</g>\n<!-- 172 -->\n<g id=\"node173\" class=\"node\">\n<title>172</title>\n<path fill=\"#ea9b62\" stroke=\"black\" d=\"M2516,-1821C2516,-1821 2435,-1821 2435,-1821 2429,-1821 2423,-1815 2423,-1809 2423,-1809 2423,-1765 2423,-1765 2423,-1759 2429,-1753 2435,-1753 2435,-1753 2516,-1753 2516,-1753 2522,-1753 2528,-1759 2528,-1765 2528,-1765 2528,-1809 2528,-1809 2528,-1815 2522,-1821 2516,-1821\"/>\n<text text-anchor=\"start\" x=\"2439\" y=\"-1805.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"2438\" y=\"-1790.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.284</text>\n<text text-anchor=\"start\" x=\"2432\" y=\"-1775.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 35</text>\n<text text-anchor=\"start\" x=\"2431\" y=\"-1760.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [29, 6]</text>\n</g>\n<!-- 164&#45;&gt;172 -->\n<g id=\"edge172\" class=\"edge\">\n<title>164&#45;&gt;172</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2394.46,-1856.88C2405.36,-1847.62 2417.32,-1837.45 2428.62,-1827.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2430.97,-1830.44 2436.32,-1821.3 2426.44,-1825.11 2430.97,-1830.44\"/>\n</g>\n<!-- 166 -->\n<g id=\"node167\" class=\"node\">\n<title>166</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M2277.5,-1717C2277.5,-1717 2199.5,-1717 2199.5,-1717 2193.5,-1717 2187.5,-1711 2187.5,-1705 2187.5,-1705 2187.5,-1661 2187.5,-1661 2187.5,-1655 2193.5,-1649 2199.5,-1649 2199.5,-1649 2277.5,-1649 2277.5,-1649 2283.5,-1649 2289.5,-1655 2289.5,-1661 2289.5,-1661 2289.5,-1705 2289.5,-1705 2289.5,-1711 2283.5,-1717 2277.5,-1717\"/>\n<text text-anchor=\"start\" x=\"2195.5\" y=\"-1701.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.675</text>\n<text text-anchor=\"start\" x=\"2201\" y=\"-1686.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"2199\" y=\"-1671.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2198\" y=\"-1656.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 1]</text>\n</g>\n<!-- 165&#45;&gt;166 -->\n<g id=\"edge166\" class=\"edge\">\n<title>165&#45;&gt;166</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2317.51,-1752.88C2306.99,-1743.71 2295.45,-1733.65 2284.52,-1724.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2286.53,-1721.23 2276.7,-1717.3 2281.93,-1726.51 2286.53,-1721.23\"/>\n</g>\n<!-- 171 -->\n<g id=\"node172\" class=\"node\">\n<title>171</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2393,-1709.5C2393,-1709.5 2320,-1709.5 2320,-1709.5 2314,-1709.5 2308,-1703.5 2308,-1697.5 2308,-1697.5 2308,-1668.5 2308,-1668.5 2308,-1662.5 2314,-1656.5 2320,-1656.5 2320,-1656.5 2393,-1656.5 2393,-1656.5 2399,-1656.5 2405,-1662.5 2405,-1668.5 2405,-1668.5 2405,-1697.5 2405,-1697.5 2405,-1703.5 2399,-1709.5 2393,-1709.5\"/>\n<text text-anchor=\"start\" x=\"2327.5\" y=\"-1694.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2317\" y=\"-1679.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2316\" y=\"-1664.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 165&#45;&gt;171 -->\n<g id=\"edge171\" class=\"edge\">\n<title>165&#45;&gt;171</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2355.82,-1752.88C2355.93,-1742.33 2356.04,-1730.6 2356.15,-1719.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2359.65,-1719.55 2356.25,-1709.52 2352.65,-1719.49 2359.65,-1719.55\"/>\n</g>\n<!-- 167 -->\n<g id=\"node168\" class=\"node\">\n<title>167</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2221,-1605.5C2221,-1605.5 2148,-1605.5 2148,-1605.5 2142,-1605.5 2136,-1599.5 2136,-1593.5 2136,-1593.5 2136,-1564.5 2136,-1564.5 2136,-1558.5 2142,-1552.5 2148,-1552.5 2148,-1552.5 2221,-1552.5 2221,-1552.5 2227,-1552.5 2233,-1558.5 2233,-1564.5 2233,-1564.5 2233,-1593.5 2233,-1593.5 2233,-1599.5 2227,-1605.5 2221,-1605.5\"/>\n<text text-anchor=\"start\" x=\"2155.5\" y=\"-1590.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2145\" y=\"-1575.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2144\" y=\"-1560.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 166&#45;&gt;167 -->\n<g id=\"edge167\" class=\"edge\">\n<title>166&#45;&gt;167</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2220.97,-1648.88C2215.15,-1637.89 2208.65,-1625.62 2202.77,-1614.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2205.78,-1612.72 2198.01,-1605.52 2199.6,-1616 2205.78,-1612.72\"/>\n</g>\n<!-- 168 -->\n<g id=\"node169\" class=\"node\">\n<title>168</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M2338,-1613C2338,-1613 2263,-1613 2263,-1613 2257,-1613 2251,-1607 2251,-1601 2251,-1601 2251,-1557 2251,-1557 2251,-1551 2257,-1545 2263,-1545 2263,-1545 2338,-1545 2338,-1545 2344,-1545 2350,-1551 2350,-1557 2350,-1557 2350,-1601 2350,-1601 2350,-1607 2344,-1613 2338,-1613\"/>\n<text text-anchor=\"start\" x=\"2259\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;1.402</text>\n<text text-anchor=\"start\" x=\"2271.5\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"2261\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2260\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 166&#45;&gt;168 -->\n<g id=\"edge168\" class=\"edge\">\n<title>166&#45;&gt;168</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2258.63,-1648.88C2263.83,-1640.33 2269.49,-1631.01 2274.93,-1622.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2278.06,-1623.66 2280.26,-1613.3 2272.07,-1620.03 2278.06,-1623.66\"/>\n</g>\n<!-- 169 -->\n<g id=\"node170\" class=\"node\">\n<title>169</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2221,-1501.5C2221,-1501.5 2148,-1501.5 2148,-1501.5 2142,-1501.5 2136,-1495.5 2136,-1489.5 2136,-1489.5 2136,-1460.5 2136,-1460.5 2136,-1454.5 2142,-1448.5 2148,-1448.5 2148,-1448.5 2221,-1448.5 2221,-1448.5 2227,-1448.5 2233,-1454.5 2233,-1460.5 2233,-1460.5 2233,-1489.5 2233,-1489.5 2233,-1495.5 2227,-1501.5 2221,-1501.5\"/>\n<text text-anchor=\"start\" x=\"2155.5\" y=\"-1486.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2145\" y=\"-1471.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2144\" y=\"-1456.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 168&#45;&gt;169 -->\n<g id=\"edge169\" class=\"edge\">\n<title>168&#45;&gt;169</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2262.84,-1544.88C2249.46,-1533.12 2234.42,-1519.89 2221.12,-1508.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2223.34,-1505.49 2213.52,-1501.52 2218.72,-1510.75 2223.34,-1505.49\"/>\n</g>\n<!-- 170 -->\n<g id=\"node171\" class=\"node\">\n<title>170</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2336,-1501.5C2336,-1501.5 2263,-1501.5 2263,-1501.5 2257,-1501.5 2251,-1495.5 2251,-1489.5 2251,-1489.5 2251,-1460.5 2251,-1460.5 2251,-1454.5 2257,-1448.5 2263,-1448.5 2263,-1448.5 2336,-1448.5 2336,-1448.5 2342,-1448.5 2348,-1454.5 2348,-1460.5 2348,-1460.5 2348,-1489.5 2348,-1489.5 2348,-1495.5 2342,-1501.5 2336,-1501.5\"/>\n<text text-anchor=\"start\" x=\"2270.5\" y=\"-1486.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2260\" y=\"-1471.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2259\" y=\"-1456.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 168&#45;&gt;170 -->\n<g id=\"edge170\" class=\"edge\">\n<title>168&#45;&gt;170</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2300.18,-1544.88C2300.07,-1534.33 2299.96,-1522.6 2299.85,-1511.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2303.35,-1511.49 2299.75,-1501.52 2296.35,-1511.55 2303.35,-1511.49\"/>\n</g>\n<!-- 173 -->\n<g id=\"node174\" class=\"node\">\n<title>173</title>\n<path fill=\"#e99355\" stroke=\"black\" d=\"M2516,-1717C2516,-1717 2435,-1717 2435,-1717 2429,-1717 2423,-1711 2423,-1705 2423,-1705 2423,-1661 2423,-1661 2423,-1655 2429,-1649 2435,-1649 2435,-1649 2516,-1649 2516,-1649 2522,-1649 2528,-1655 2528,-1661 2528,-1661 2528,-1705 2528,-1705 2528,-1711 2522,-1717 2516,-1717\"/>\n<text text-anchor=\"start\" x=\"2434\" y=\"-1701.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.015</text>\n<text text-anchor=\"start\" x=\"2438\" y=\"-1686.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.219</text>\n<text text-anchor=\"start\" x=\"2432\" y=\"-1671.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 32</text>\n<text text-anchor=\"start\" x=\"2431\" y=\"-1656.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [28, 4]</text>\n</g>\n<!-- 172&#45;&gt;173 -->\n<g id=\"edge173\" class=\"edge\">\n<title>172&#45;&gt;173</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2475.5,-1752.88C2475.5,-1744.78 2475.5,-1735.98 2475.5,-1727.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2479,-1727.3 2475.5,-1717.3 2472,-1727.3 2479,-1727.3\"/>\n</g>\n<!-- 194 -->\n<g id=\"node195\" class=\"node\">\n<title>194</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M2639,-1717C2639,-1717 2566,-1717 2566,-1717 2560,-1717 2554,-1711 2554,-1705 2554,-1705 2554,-1661 2554,-1661 2554,-1655 2560,-1649 2566,-1649 2566,-1649 2639,-1649 2639,-1649 2645,-1649 2651,-1655 2651,-1661 2651,-1661 2651,-1705 2651,-1705 2651,-1711 2645,-1717 2639,-1717\"/>\n<text text-anchor=\"start\" x=\"2566\" y=\"-1701.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 1.5</text>\n<text text-anchor=\"start\" x=\"2565\" y=\"-1686.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"2563\" y=\"-1671.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2562\" y=\"-1656.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 172&#45;&gt;194 -->\n<g id=\"edge194\" class=\"edge\">\n<title>172&#45;&gt;194</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2516.73,-1752.88C2528.38,-1743.53 2541.17,-1733.26 2553.23,-1723.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2555.43,-1726.29 2561.04,-1717.3 2551.05,-1720.83 2555.43,-1726.29\"/>\n</g>\n<!-- 174 -->\n<g id=\"node175\" class=\"node\">\n<title>174</title>\n<path fill=\"#efb388\" stroke=\"black\" d=\"M2484,-1613C2484,-1613 2409,-1613 2409,-1613 2403,-1613 2397,-1607 2397,-1601 2397,-1601 2397,-1557 2397,-1557 2397,-1551 2403,-1545 2409,-1545 2409,-1545 2484,-1545 2484,-1545 2490,-1545 2496,-1551 2496,-1557 2496,-1557 2496,-1601 2496,-1601 2496,-1607 2490,-1613 2484,-1613\"/>\n<text text-anchor=\"start\" x=\"2405\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.381</text>\n<text text-anchor=\"start\" x=\"2409\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.408</text>\n<text text-anchor=\"start\" x=\"2407\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"2406\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 2]</text>\n</g>\n<!-- 173&#45;&gt;174 -->\n<g id=\"edge174\" class=\"edge\">\n<title>173&#45;&gt;174</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2466.08,-1648.88C2463.75,-1640.69 2461.22,-1631.79 2458.78,-1623.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2462.07,-1621.96 2455.97,-1613.3 2455.34,-1623.88 2462.07,-1621.96\"/>\n</g>\n<!-- 181 -->\n<g id=\"node182\" class=\"node\">\n<title>181</title>\n<path fill=\"#e78c4a\" stroke=\"black\" d=\"M2607,-1613C2607,-1613 2526,-1613 2526,-1613 2520,-1613 2514,-1607 2514,-1601 2514,-1601 2514,-1557 2514,-1557 2514,-1551 2520,-1545 2526,-1545 2526,-1545 2607,-1545 2607,-1545 2613,-1545 2619,-1551 2619,-1557 2619,-1557 2619,-1601 2619,-1601 2619,-1607 2613,-1613 2607,-1613\"/>\n<text text-anchor=\"start\" x=\"2527\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.148</text>\n<text text-anchor=\"start\" x=\"2529\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.147</text>\n<text text-anchor=\"start\" x=\"2523\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 25</text>\n<text text-anchor=\"start\" x=\"2522\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [23, 2]</text>\n</g>\n<!-- 173&#45;&gt;181 -->\n<g id=\"edge181\" class=\"edge\">\n<title>173&#45;&gt;181</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2505.05,-1648.88C2512.99,-1639.98 2521.68,-1630.24 2529.96,-1620.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2532.75,-1623.09 2536.79,-1613.3 2527.52,-1618.43 2532.75,-1623.09\"/>\n</g>\n<!-- 175 -->\n<g id=\"node176\" class=\"node\">\n<title>175</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2451,-1501.5C2451,-1501.5 2378,-1501.5 2378,-1501.5 2372,-1501.5 2366,-1495.5 2366,-1489.5 2366,-1489.5 2366,-1460.5 2366,-1460.5 2366,-1454.5 2372,-1448.5 2378,-1448.5 2378,-1448.5 2451,-1448.5 2451,-1448.5 2457,-1448.5 2463,-1454.5 2463,-1460.5 2463,-1460.5 2463,-1489.5 2463,-1489.5 2463,-1495.5 2457,-1501.5 2451,-1501.5\"/>\n<text text-anchor=\"start\" x=\"2385.5\" y=\"-1486.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2375\" y=\"-1471.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2374\" y=\"-1456.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 174&#45;&gt;175 -->\n<g id=\"edge175\" class=\"edge\">\n<title>174&#45;&gt;175</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2436.11,-1544.88C2432.73,-1534.11 2428.97,-1522.11 2425.54,-1511.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2428.84,-1510.01 2422.51,-1501.52 2422.16,-1512.11 2428.84,-1510.01\"/>\n</g>\n<!-- 176 -->\n<g id=\"node177\" class=\"node\">\n<title>176</title>\n<path fill=\"#f6d5bd\" stroke=\"black\" d=\"M2566,-1509C2566,-1509 2493,-1509 2493,-1509 2487,-1509 2481,-1503 2481,-1497 2481,-1497 2481,-1453 2481,-1453 2481,-1447 2487,-1441 2493,-1441 2493,-1441 2566,-1441 2566,-1441 2572,-1441 2578,-1447 2578,-1453 2578,-1453 2578,-1497 2578,-1497 2578,-1503 2572,-1509 2566,-1509\"/>\n<text text-anchor=\"start\" x=\"2492\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"2496\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n<text text-anchor=\"start\" x=\"2490\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"2489\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 2]</text>\n</g>\n<!-- 174&#45;&gt;176 -->\n<g id=\"edge176\" class=\"edge\">\n<title>174&#45;&gt;176</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2473.45,-1544.88C2480.62,-1536.07 2488.46,-1526.43 2495.95,-1517.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2498.81,-1519.26 2502.4,-1509.3 2493.38,-1514.85 2498.81,-1519.26\"/>\n</g>\n<!-- 177 -->\n<g id=\"node178\" class=\"node\">\n<title>177</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M2451,-1405C2451,-1405 2378,-1405 2378,-1405 2372,-1405 2366,-1399 2366,-1393 2366,-1393 2366,-1349 2366,-1349 2366,-1343 2372,-1337 2378,-1337 2378,-1337 2451,-1337 2451,-1337 2457,-1337 2463,-1343 2463,-1349 2463,-1349 2463,-1393 2463,-1393 2463,-1399 2457,-1405 2451,-1405\"/>\n<text text-anchor=\"start\" x=\"2375.5\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.84</text>\n<text text-anchor=\"start\" x=\"2377\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"2375\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2374\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 176&#45;&gt;177 -->\n<g id=\"edge177\" class=\"edge\">\n<title>176&#45;&gt;177</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2492.16,-1440.88C2481.82,-1431.71 2470.48,-1421.65 2459.74,-1412.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2461.85,-1409.32 2452.04,-1405.3 2457.2,-1414.55 2461.85,-1409.32\"/>\n</g>\n<!-- 180 -->\n<g id=\"node181\" class=\"node\">\n<title>180</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2566,-1397.5C2566,-1397.5 2493,-1397.5 2493,-1397.5 2487,-1397.5 2481,-1391.5 2481,-1385.5 2481,-1385.5 2481,-1356.5 2481,-1356.5 2481,-1350.5 2487,-1344.5 2493,-1344.5 2493,-1344.5 2566,-1344.5 2566,-1344.5 2572,-1344.5 2578,-1350.5 2578,-1356.5 2578,-1356.5 2578,-1385.5 2578,-1385.5 2578,-1391.5 2572,-1397.5 2566,-1397.5\"/>\n<text text-anchor=\"start\" x=\"2500.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2490\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2489\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 176&#45;&gt;180 -->\n<g id=\"edge180\" class=\"edge\">\n<title>176&#45;&gt;180</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2529.5,-1440.88C2529.5,-1430.33 2529.5,-1418.6 2529.5,-1407.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2533,-1407.52 2529.5,-1397.52 2526,-1407.52 2533,-1407.52\"/>\n</g>\n<!-- 178 -->\n<g id=\"node179\" class=\"node\">\n<title>178</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2337,-1293.5C2337,-1293.5 2264,-1293.5 2264,-1293.5 2258,-1293.5 2252,-1287.5 2252,-1281.5 2252,-1281.5 2252,-1252.5 2252,-1252.5 2252,-1246.5 2258,-1240.5 2264,-1240.5 2264,-1240.5 2337,-1240.5 2337,-1240.5 2343,-1240.5 2349,-1246.5 2349,-1252.5 2349,-1252.5 2349,-1281.5 2349,-1281.5 2349,-1287.5 2343,-1293.5 2337,-1293.5\"/>\n<text text-anchor=\"start\" x=\"2271.5\" y=\"-1278.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2261\" y=\"-1263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2260\" y=\"-1248.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 177&#45;&gt;178 -->\n<g id=\"edge178\" class=\"edge\">\n<title>177&#45;&gt;178</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2377.49,-1336.88C2364.34,-1325.12 2349.56,-1311.89 2336.49,-1300.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2338.81,-1297.58 2329.02,-1293.52 2334.14,-1302.8 2338.81,-1297.58\"/>\n</g>\n<!-- 179 -->\n<g id=\"node180\" class=\"node\">\n<title>179</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2452,-1293.5C2452,-1293.5 2379,-1293.5 2379,-1293.5 2373,-1293.5 2367,-1287.5 2367,-1281.5 2367,-1281.5 2367,-1252.5 2367,-1252.5 2367,-1246.5 2373,-1240.5 2379,-1240.5 2379,-1240.5 2452,-1240.5 2452,-1240.5 2458,-1240.5 2464,-1246.5 2464,-1252.5 2464,-1252.5 2464,-1281.5 2464,-1281.5 2464,-1287.5 2458,-1293.5 2452,-1293.5\"/>\n<text text-anchor=\"start\" x=\"2386.5\" y=\"-1278.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2376\" y=\"-1263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2375\" y=\"-1248.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 177&#45;&gt;179 -->\n<g id=\"edge179\" class=\"edge\">\n<title>177&#45;&gt;179</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2414.82,-1336.88C2414.93,-1326.33 2415.04,-1314.6 2415.15,-1303.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2418.65,-1303.55 2415.25,-1293.52 2411.65,-1303.49 2418.65,-1303.55\"/>\n</g>\n<!-- 182 -->\n<g id=\"node183\" class=\"node\">\n<title>182</title>\n<path fill=\"#e89253\" stroke=\"black\" d=\"M2689,-1509C2689,-1509 2608,-1509 2608,-1509 2602,-1509 2596,-1503 2596,-1497 2596,-1497 2596,-1453 2596,-1453 2596,-1447 2602,-1441 2608,-1441 2608,-1441 2689,-1441 2689,-1441 2695,-1441 2701,-1447 2701,-1453 2701,-1453 2701,-1497 2701,-1497 2701,-1503 2695,-1509 2689,-1509\"/>\n<text text-anchor=\"start\" x=\"2609\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pclass ≤ 2.5</text>\n<text text-anchor=\"start\" x=\"2611\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.208</text>\n<text text-anchor=\"start\" x=\"2605\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\n<text text-anchor=\"start\" x=\"2604\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [15, 2]</text>\n</g>\n<!-- 181&#45;&gt;182 -->\n<g id=\"edge182\" class=\"edge\">\n<title>181&#45;&gt;182</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2593.12,-1544.88C2600.21,-1536.07 2607.96,-1526.43 2615.35,-1517.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2618.19,-1519.29 2621.73,-1509.3 2612.74,-1514.9 2618.19,-1519.29\"/>\n</g>\n<!-- 193 -->\n<g id=\"node194\" class=\"node\">\n<title>193</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2804,-1501.5C2804,-1501.5 2731,-1501.5 2731,-1501.5 2725,-1501.5 2719,-1495.5 2719,-1489.5 2719,-1489.5 2719,-1460.5 2719,-1460.5 2719,-1454.5 2725,-1448.5 2731,-1448.5 2731,-1448.5 2804,-1448.5 2804,-1448.5 2810,-1448.5 2816,-1454.5 2816,-1460.5 2816,-1460.5 2816,-1489.5 2816,-1489.5 2816,-1495.5 2810,-1501.5 2804,-1501.5\"/>\n<text text-anchor=\"start\" x=\"2738.5\" y=\"-1486.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2728\" y=\"-1471.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"2727\" y=\"-1456.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 0]</text>\n</g>\n<!-- 181&#45;&gt;193 -->\n<g id=\"edge193\" class=\"edge\">\n<title>181&#45;&gt;193</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2619.26,-1549.11C2622.04,-1547.7 2624.8,-1546.32 2627.5,-1545 2663.26,-1527.52 2673.93,-1526.87 2709.5,-1509 2711.25,-1508.12 2713.02,-1507.22 2714.8,-1506.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2716.56,-1509.32 2723.74,-1501.53 2713.27,-1503.14 2716.56,-1509.32\"/>\n</g>\n<!-- 183 -->\n<g id=\"node184\" class=\"node\">\n<title>183</title>\n<path fill=\"#eeab7b\" stroke=\"black\" d=\"M2686.5,-1405C2686.5,-1405 2608.5,-1405 2608.5,-1405 2602.5,-1405 2596.5,-1399 2596.5,-1393 2596.5,-1393 2596.5,-1349 2596.5,-1349 2596.5,-1343 2602.5,-1337 2608.5,-1337 2608.5,-1337 2686.5,-1337 2686.5,-1337 2692.5,-1337 2698.5,-1343 2698.5,-1349 2698.5,-1349 2698.5,-1393 2698.5,-1393 2698.5,-1399 2692.5,-1405 2686.5,-1405\"/>\n<text text-anchor=\"start\" x=\"2604.5\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.229</text>\n<text text-anchor=\"start\" x=\"2610\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"2608\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"2607\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 1]</text>\n</g>\n<!-- 182&#45;&gt;183 -->\n<g id=\"edge183\" class=\"edge\">\n<title>182&#45;&gt;183</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2648.18,-1440.88C2648.1,-1432.78 2648.01,-1423.98 2647.93,-1415.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2651.42,-1415.26 2647.83,-1405.3 2644.42,-1415.33 2651.42,-1415.26\"/>\n</g>\n<!-- 186 -->\n<g id=\"node187\" class=\"node\">\n<title>186</title>\n<path fill=\"#e78c49\" stroke=\"black\" d=\"M2810,-1405C2810,-1405 2729,-1405 2729,-1405 2723,-1405 2717,-1399 2717,-1393 2717,-1393 2717,-1349 2717,-1349 2717,-1343 2723,-1337 2729,-1337 2729,-1337 2810,-1337 2810,-1337 2816,-1337 2822,-1343 2822,-1349 2822,-1349 2822,-1393 2822,-1393 2822,-1399 2816,-1405 2810,-1405\"/>\n<text text-anchor=\"start\" x=\"2730.5\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.88</text>\n<text text-anchor=\"start\" x=\"2732\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.142</text>\n<text text-anchor=\"start\" x=\"2726\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13</text>\n<text text-anchor=\"start\" x=\"2725\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [12, 1]</text>\n</g>\n<!-- 182&#45;&gt;186 -->\n<g id=\"edge186\" class=\"edge\">\n<title>182&#45;&gt;186</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2687.79,-1440.88C2698.77,-1431.62 2710.83,-1421.45 2722.23,-1411.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2724.61,-1414.42 2730,-1405.3 2720.1,-1409.07 2724.61,-1414.42\"/>\n</g>\n<!-- 184 -->\n<g id=\"node185\" class=\"node\">\n<title>184</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2571,-1293.5C2571,-1293.5 2498,-1293.5 2498,-1293.5 2492,-1293.5 2486,-1287.5 2486,-1281.5 2486,-1281.5 2486,-1252.5 2486,-1252.5 2486,-1246.5 2492,-1240.5 2498,-1240.5 2498,-1240.5 2571,-1240.5 2571,-1240.5 2577,-1240.5 2583,-1246.5 2583,-1252.5 2583,-1252.5 2583,-1281.5 2583,-1281.5 2583,-1287.5 2577,-1293.5 2571,-1293.5\"/>\n<text text-anchor=\"start\" x=\"2505.5\" y=\"-1278.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2495\" y=\"-1263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2494\" y=\"-1248.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 183&#45;&gt;184 -->\n<g id=\"edge184\" class=\"edge\">\n<title>183&#45;&gt;184</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2610.81,-1336.88C2597.9,-1325.23 2583.4,-1312.14 2570.54,-1300.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2572.54,-1297.62 2562.77,-1293.52 2567.85,-1302.82 2572.54,-1297.62\"/>\n</g>\n<!-- 185 -->\n<g id=\"node186\" class=\"node\">\n<title>185</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2686,-1293.5C2686,-1293.5 2613,-1293.5 2613,-1293.5 2607,-1293.5 2601,-1287.5 2601,-1281.5 2601,-1281.5 2601,-1252.5 2601,-1252.5 2601,-1246.5 2607,-1240.5 2613,-1240.5 2613,-1240.5 2686,-1240.5 2686,-1240.5 2692,-1240.5 2698,-1246.5 2698,-1252.5 2698,-1252.5 2698,-1281.5 2698,-1281.5 2698,-1287.5 2692,-1293.5 2686,-1293.5\"/>\n<text text-anchor=\"start\" x=\"2620.5\" y=\"-1278.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2610\" y=\"-1263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2609\" y=\"-1248.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 183&#45;&gt;185 -->\n<g id=\"edge185\" class=\"edge\">\n<title>183&#45;&gt;185</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2648.15,-1336.88C2648.36,-1326.22 2648.59,-1314.35 2648.8,-1303.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2652.3,-1303.59 2649,-1293.52 2645.3,-1303.45 2652.3,-1303.59\"/>\n</g>\n<!-- 187 -->\n<g id=\"node188\" class=\"node\">\n<title>187</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2804,-1293.5C2804,-1293.5 2731,-1293.5 2731,-1293.5 2725,-1293.5 2719,-1287.5 2719,-1281.5 2719,-1281.5 2719,-1252.5 2719,-1252.5 2719,-1246.5 2725,-1240.5 2731,-1240.5 2731,-1240.5 2804,-1240.5 2804,-1240.5 2810,-1240.5 2816,-1246.5 2816,-1252.5 2816,-1252.5 2816,-1281.5 2816,-1281.5 2816,-1287.5 2810,-1293.5 2804,-1293.5\"/>\n<text text-anchor=\"start\" x=\"2738.5\" y=\"-1278.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2728\" y=\"-1263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"2727\" y=\"-1248.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 0]</text>\n</g>\n<!-- 186&#45;&gt;187 -->\n<g id=\"edge187\" class=\"edge\">\n<title>186&#45;&gt;187</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2768.85,-1336.88C2768.64,-1326.22 2768.41,-1314.35 2768.2,-1303.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2771.7,-1303.45 2768,-1293.52 2764.7,-1303.59 2771.7,-1303.45\"/>\n</g>\n<!-- 188 -->\n<g id=\"node189\" class=\"node\">\n<title>188</title>\n<path fill=\"#e89152\" stroke=\"black\" d=\"M2919,-1301C2919,-1301 2846,-1301 2846,-1301 2840,-1301 2834,-1295 2834,-1289 2834,-1289 2834,-1245 2834,-1245 2834,-1239 2840,-1233 2846,-1233 2846,-1233 2919,-1233 2919,-1233 2925,-1233 2931,-1239 2931,-1245 2931,-1245 2931,-1289 2931,-1289 2931,-1295 2925,-1301 2919,-1301\"/>\n<text text-anchor=\"start\" x=\"2843.5\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.84</text>\n<text text-anchor=\"start\" x=\"2845\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.198</text>\n<text text-anchor=\"start\" x=\"2843\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"2842\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 1]</text>\n</g>\n<!-- 186&#45;&gt;188 -->\n<g id=\"edge188\" class=\"edge\">\n<title>186&#45;&gt;188</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2806.19,-1336.88C2816.35,-1327.71 2827.5,-1317.65 2838.05,-1308.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2840.53,-1310.6 2845.61,-1301.3 2835.84,-1305.4 2840.53,-1310.6\"/>\n</g>\n<!-- 189 -->\n<g id=\"node190\" class=\"node\">\n<title>189</title>\n<path fill=\"#ea9a61\" stroke=\"black\" d=\"M2861,-1197C2861,-1197 2788,-1197 2788,-1197 2782,-1197 2776,-1191 2776,-1185 2776,-1185 2776,-1141 2776,-1141 2776,-1135 2782,-1129 2788,-1129 2788,-1129 2861,-1129 2861,-1129 2867,-1129 2873,-1135 2873,-1141 2873,-1141 2873,-1185 2873,-1185 2873,-1191 2867,-1197 2861,-1197\"/>\n<text text-anchor=\"start\" x=\"2785\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.052</text>\n<text text-anchor=\"start\" x=\"2787\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.278</text>\n<text text-anchor=\"start\" x=\"2785\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"2784\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 1]</text>\n</g>\n<!-- 188&#45;&gt;189 -->\n<g id=\"edge189\" class=\"edge\">\n<title>188&#45;&gt;189</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2863.67,-1232.88C2858.81,-1224.33 2853.51,-1215.01 2848.42,-1206.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2851.42,-1204.26 2843.43,-1197.3 2845.34,-1207.72 2851.42,-1204.26\"/>\n</g>\n<!-- 192 -->\n<g id=\"node193\" class=\"node\">\n<title>192</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2976,-1189.5C2976,-1189.5 2903,-1189.5 2903,-1189.5 2897,-1189.5 2891,-1183.5 2891,-1177.5 2891,-1177.5 2891,-1148.5 2891,-1148.5 2891,-1142.5 2897,-1136.5 2903,-1136.5 2903,-1136.5 2976,-1136.5 2976,-1136.5 2982,-1136.5 2988,-1142.5 2988,-1148.5 2988,-1148.5 2988,-1177.5 2988,-1177.5 2988,-1183.5 2982,-1189.5 2976,-1189.5\"/>\n<text text-anchor=\"start\" x=\"2910.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2900\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2899\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 188&#45;&gt;192 -->\n<g id=\"edge192\" class=\"edge\">\n<title>188&#45;&gt;192</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2901.01,-1232.88C2907.15,-1221.89 2914.01,-1209.62 2920.21,-1198.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2923.42,-1199.96 2925.24,-1189.52 2917.31,-1196.54 2923.42,-1199.96\"/>\n</g>\n<!-- 190 -->\n<g id=\"node191\" class=\"node\">\n<title>190</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2803,-1085.5C2803,-1085.5 2730,-1085.5 2730,-1085.5 2724,-1085.5 2718,-1079.5 2718,-1073.5 2718,-1073.5 2718,-1044.5 2718,-1044.5 2718,-1038.5 2724,-1032.5 2730,-1032.5 2730,-1032.5 2803,-1032.5 2803,-1032.5 2809,-1032.5 2815,-1038.5 2815,-1044.5 2815,-1044.5 2815,-1073.5 2815,-1073.5 2815,-1079.5 2809,-1085.5 2803,-1085.5\"/>\n<text text-anchor=\"start\" x=\"2737.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2727\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2726\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 189&#45;&gt;190 -->\n<g id=\"edge190\" class=\"edge\">\n<title>189&#45;&gt;190</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2805.67,-1128.88C2799.42,-1117.89 2792.44,-1105.62 2786.13,-1094.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2789,-1092.48 2781.01,-1085.52 2782.91,-1095.94 2789,-1092.48\"/>\n</g>\n<!-- 191 -->\n<g id=\"node192\" class=\"node\">\n<title>191</title>\n<path fill=\"#eca06a\" stroke=\"black\" d=\"M2918,-1085.5C2918,-1085.5 2845,-1085.5 2845,-1085.5 2839,-1085.5 2833,-1079.5 2833,-1073.5 2833,-1073.5 2833,-1044.5 2833,-1044.5 2833,-1038.5 2839,-1032.5 2845,-1032.5 2845,-1032.5 2918,-1032.5 2918,-1032.5 2924,-1032.5 2930,-1038.5 2930,-1044.5 2930,-1044.5 2930,-1073.5 2930,-1073.5 2930,-1079.5 2924,-1085.5 2918,-1085.5\"/>\n<text text-anchor=\"start\" x=\"2848\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"2842\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"2841\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 1]</text>\n</g>\n<!-- 189&#45;&gt;191 -->\n<g id=\"edge191\" class=\"edge\">\n<title>189&#45;&gt;191</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2843.01,-1128.88C2849.15,-1117.89 2856.01,-1105.62 2862.21,-1094.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2865.42,-1095.96 2867.24,-1085.52 2859.31,-1092.54 2865.42,-1095.96\"/>\n</g>\n<!-- 195 -->\n<g id=\"node196\" class=\"node\">\n<title>195</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2722,-1605.5C2722,-1605.5 2649,-1605.5 2649,-1605.5 2643,-1605.5 2637,-1599.5 2637,-1593.5 2637,-1593.5 2637,-1564.5 2637,-1564.5 2637,-1558.5 2643,-1552.5 2649,-1552.5 2649,-1552.5 2722,-1552.5 2722,-1552.5 2728,-1552.5 2734,-1558.5 2734,-1564.5 2734,-1564.5 2734,-1593.5 2734,-1593.5 2734,-1599.5 2728,-1605.5 2722,-1605.5\"/>\n<text text-anchor=\"start\" x=\"2656.5\" y=\"-1590.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2646\" y=\"-1575.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2645\" y=\"-1560.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 194&#45;&gt;195 -->\n<g id=\"edge195\" class=\"edge\">\n<title>194&#45;&gt;195</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2629.45,-1648.88C2638.67,-1637.56 2648.98,-1624.88 2658.22,-1613.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2661.14,-1615.49 2664.73,-1605.52 2655.71,-1611.07 2661.14,-1615.49\"/>\n</g>\n<!-- 196 -->\n<g id=\"node197\" class=\"node\">\n<title>196</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2837,-1605.5C2837,-1605.5 2764,-1605.5 2764,-1605.5 2758,-1605.5 2752,-1599.5 2752,-1593.5 2752,-1593.5 2752,-1564.5 2752,-1564.5 2752,-1558.5 2758,-1552.5 2764,-1552.5 2764,-1552.5 2837,-1552.5 2837,-1552.5 2843,-1552.5 2849,-1558.5 2849,-1564.5 2849,-1564.5 2849,-1593.5 2849,-1593.5 2849,-1599.5 2843,-1605.5 2837,-1605.5\"/>\n<text text-anchor=\"start\" x=\"2771.5\" y=\"-1590.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2761\" y=\"-1575.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2760\" y=\"-1560.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 194&#45;&gt;196 -->\n<g id=\"edge196\" class=\"edge\">\n<title>194&#45;&gt;196</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2651.11,-1653.36C2653.93,-1651.85 2656.74,-1650.39 2659.5,-1649 2695.4,-1630.9 2706.53,-1630.97 2742.5,-1613 2744.25,-1612.13 2746.02,-1611.22 2747.8,-1610.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2749.56,-1613.33 2756.75,-1605.55 2746.28,-1607.15 2749.56,-1613.33\"/>\n</g>\n<!-- 198 -->\n<g id=\"node199\" class=\"node\">\n<title>198</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2528,-1917.5C2528,-1917.5 2455,-1917.5 2455,-1917.5 2449,-1917.5 2443,-1911.5 2443,-1905.5 2443,-1905.5 2443,-1876.5 2443,-1876.5 2443,-1870.5 2449,-1864.5 2455,-1864.5 2455,-1864.5 2528,-1864.5 2528,-1864.5 2534,-1864.5 2540,-1870.5 2540,-1876.5 2540,-1876.5 2540,-1905.5 2540,-1905.5 2540,-1911.5 2534,-1917.5 2528,-1917.5\"/>\n<text text-anchor=\"start\" x=\"2462.5\" y=\"-1902.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2452\" y=\"-1887.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"2451\" y=\"-1872.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 5]</text>\n</g>\n<!-- 197&#45;&gt;198 -->\n<g id=\"edge198\" class=\"edge\">\n<title>197&#45;&gt;198</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2492.18,-1960.88C2492.07,-1950.33 2491.96,-1938.6 2491.85,-1927.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2495.35,-1927.49 2491.75,-1917.52 2488.35,-1927.55 2495.35,-1927.49\"/>\n</g>\n<!-- 199 -->\n<g id=\"node200\" class=\"node\">\n<title>199</title>\n<path fill=\"#e78c4b\" stroke=\"black\" d=\"M2651,-1925C2651,-1925 2570,-1925 2570,-1925 2564,-1925 2558,-1919 2558,-1913 2558,-1913 2558,-1869 2558,-1869 2558,-1863 2564,-1857 2570,-1857 2570,-1857 2651,-1857 2651,-1857 2657,-1857 2663,-1863 2663,-1869 2663,-1869 2663,-1913 2663,-1913 2663,-1919 2657,-1925 2651,-1925\"/>\n<text text-anchor=\"start\" x=\"2571\" y=\"-1909.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.823</text>\n<text text-anchor=\"start\" x=\"2573\" y=\"-1894.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.153</text>\n<text text-anchor=\"start\" x=\"2567\" y=\"-1879.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\n<text text-anchor=\"start\" x=\"2566\" y=\"-1864.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 1]</text>\n</g>\n<!-- 197&#45;&gt;199 -->\n<g id=\"edge199\" class=\"edge\">\n<title>197&#45;&gt;199</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2530.81,-1960.88C2541.53,-1951.62 2553.29,-1941.45 2564.4,-1931.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2566.7,-1934.49 2571.98,-1925.3 2562.12,-1929.19 2566.7,-1934.49\"/>\n</g>\n<!-- 200 -->\n<g id=\"node201\" class=\"node\">\n<title>200</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2647,-1813.5C2647,-1813.5 2566,-1813.5 2566,-1813.5 2560,-1813.5 2554,-1807.5 2554,-1801.5 2554,-1801.5 2554,-1772.5 2554,-1772.5 2554,-1766.5 2560,-1760.5 2566,-1760.5 2566,-1760.5 2647,-1760.5 2647,-1760.5 2653,-1760.5 2659,-1766.5 2659,-1772.5 2659,-1772.5 2659,-1801.5 2659,-1801.5 2659,-1807.5 2653,-1813.5 2647,-1813.5\"/>\n<text text-anchor=\"start\" x=\"2577.5\" y=\"-1798.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2563\" y=\"-1783.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"2562\" y=\"-1768.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [10, 0]</text>\n</g>\n<!-- 199&#45;&gt;200 -->\n<g id=\"edge200\" class=\"edge\">\n<title>199&#45;&gt;200</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2609.2,-1856.88C2608.78,-1846.22 2608.32,-1834.35 2607.89,-1823.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2611.39,-1823.38 2607.5,-1813.52 2604.4,-1823.65 2611.39,-1823.38\"/>\n</g>\n<!-- 201 -->\n<g id=\"node202\" class=\"node\">\n<title>201</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M2763.5,-1821C2763.5,-1821 2689.5,-1821 2689.5,-1821 2683.5,-1821 2677.5,-1815 2677.5,-1809 2677.5,-1809 2677.5,-1765 2677.5,-1765 2677.5,-1759 2683.5,-1753 2689.5,-1753 2689.5,-1753 2763.5,-1753 2763.5,-1753 2769.5,-1753 2775.5,-1759 2775.5,-1765 2775.5,-1765 2775.5,-1809 2775.5,-1809 2775.5,-1815 2769.5,-1821 2763.5,-1821\"/>\n<text text-anchor=\"start\" x=\"2685.5\" y=\"-1805.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 1.612</text>\n<text text-anchor=\"start\" x=\"2697.5\" y=\"-1790.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"2687\" y=\"-1775.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2686\" y=\"-1760.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 199&#45;&gt;201 -->\n<g id=\"edge201\" class=\"edge\">\n<title>199&#45;&gt;201</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2648.16,-1856.88C2658.6,-1847.71 2670.04,-1837.65 2680.87,-1828.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2683.43,-1830.53 2688.63,-1821.3 2678.81,-1825.27 2683.43,-1830.53\"/>\n</g>\n<!-- 202 -->\n<g id=\"node203\" class=\"node\">\n<title>202</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2754,-1709.5C2754,-1709.5 2681,-1709.5 2681,-1709.5 2675,-1709.5 2669,-1703.5 2669,-1697.5 2669,-1697.5 2669,-1668.5 2669,-1668.5 2669,-1662.5 2675,-1656.5 2681,-1656.5 2681,-1656.5 2754,-1656.5 2754,-1656.5 2760,-1656.5 2766,-1662.5 2766,-1668.5 2766,-1668.5 2766,-1697.5 2766,-1697.5 2766,-1703.5 2760,-1709.5 2754,-1709.5\"/>\n<text text-anchor=\"start\" x=\"2688.5\" y=\"-1694.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2678\" y=\"-1679.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2677\" y=\"-1664.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 201&#45;&gt;202 -->\n<g id=\"edge202\" class=\"edge\">\n<title>201&#45;&gt;202</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2723.58,-1752.88C2722.64,-1742.22 2721.59,-1730.35 2720.63,-1719.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2724.12,-1719.17 2719.75,-1709.52 2717.14,-1719.79 2724.12,-1719.17\"/>\n</g>\n<!-- 203 -->\n<g id=\"node204\" class=\"node\">\n<title>203</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2869,-1709.5C2869,-1709.5 2796,-1709.5 2796,-1709.5 2790,-1709.5 2784,-1703.5 2784,-1697.5 2784,-1697.5 2784,-1668.5 2784,-1668.5 2784,-1662.5 2790,-1656.5 2796,-1656.5 2796,-1656.5 2869,-1656.5 2869,-1656.5 2875,-1656.5 2881,-1662.5 2881,-1668.5 2881,-1668.5 2881,-1697.5 2881,-1697.5 2881,-1703.5 2875,-1709.5 2869,-1709.5\"/>\n<text text-anchor=\"start\" x=\"2803.5\" y=\"-1694.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2793\" y=\"-1679.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2792\" y=\"-1664.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 201&#45;&gt;203 -->\n<g id=\"edge203\" class=\"edge\">\n<title>201&#45;&gt;203</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2760.92,-1752.88C2773.03,-1741.23 2786.63,-1728.14 2798.69,-1716.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2801.2,-1718.98 2805.98,-1709.52 2796.35,-1713.93 2801.2,-1718.98\"/>\n</g>\n<!-- 205 -->\n<g id=\"node206\" class=\"node\">\n<title>205</title>\n<path fill=\"#42a1e6\" stroke=\"black\" d=\"M3404,-2237C3404,-2237 3315,-2237 3315,-2237 3309,-2237 3303,-2231 3303,-2225 3303,-2225 3303,-2181 3303,-2181 3303,-2175 3309,-2169 3315,-2169 3315,-2169 3404,-2169 3404,-2169 3410,-2169 3416,-2175 3416,-2181 3416,-2181 3416,-2225 3416,-2225 3416,-2231 3410,-2237 3404,-2237\"/>\n<text text-anchor=\"start\" x=\"3318.5\" y=\"-2221.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.452</text>\n<text text-anchor=\"start\" x=\"3322\" y=\"-2206.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.083</text>\n<text text-anchor=\"start\" x=\"3312\" y=\"-2191.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 115</text>\n<text text-anchor=\"start\" x=\"3311\" y=\"-2176.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 110]</text>\n</g>\n<!-- 204&#45;&gt;205 -->\n<g id=\"edge205\" class=\"edge\">\n<title>204&#45;&gt;205</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3359.5,-2272.88C3359.5,-2264.78 3359.5,-2255.98 3359.5,-2247.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3363,-2247.3 3359.5,-2237.3 3356,-2247.3 3363,-2247.3\"/>\n</g>\n<!-- 230 -->\n<g id=\"node231\" class=\"node\">\n<title>230</title>\n<path fill=\"#fbfdfe\" stroke=\"black\" d=\"M3637,-2237C3637,-2237 3526,-2237 3526,-2237 3520,-2237 3514,-2231 3514,-2225 3514,-2225 3514,-2181 3514,-2181 3514,-2175 3520,-2169 3526,-2169 3526,-2169 3637,-2169 3637,-2169 3643,-2169 3649,-2175 3649,-2181 3649,-2181 3649,-2225 3649,-2225 3649,-2231 3643,-2237 3637,-2237\"/>\n<text text-anchor=\"start\" x=\"3522\" y=\"-2221.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Embarked_S ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"3552.5\" y=\"-2206.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"3538\" y=\"-2191.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 97</text>\n<text text-anchor=\"start\" x=\"3533\" y=\"-2176.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [48, 49]</text>\n</g>\n<!-- 204&#45;&gt;230 -->\n<g id=\"edge230\" class=\"edge\">\n<title>204&#45;&gt;230</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3420.75,-2277.86C3446.69,-2265.94 3477.21,-2251.92 3504.64,-2239.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3506.19,-2242.45 3513.82,-2235.1 3503.27,-2236.09 3506.19,-2242.45\"/>\n</g>\n<!-- 206 -->\n<g id=\"node207\" class=\"node\">\n<title>206</title>\n<path fill=\"#4fa8e8\" stroke=\"black\" d=\"M3348,-2133C3348,-2133 3267,-2133 3267,-2133 3261,-2133 3255,-2127 3255,-2121 3255,-2121 3255,-2077 3255,-2077 3255,-2071 3261,-2065 3267,-2065 3267,-2065 3348,-2065 3348,-2065 3354,-2065 3360,-2071 3360,-2077 3360,-2077 3360,-2121 3360,-2121 3360,-2127 3354,-2133 3348,-2133\"/>\n<text text-anchor=\"start\" x=\"3271\" y=\"-2117.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.43</text>\n<text text-anchor=\"start\" x=\"3274\" y=\"-2102.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.18</text>\n<text text-anchor=\"start\" x=\"3264\" y=\"-2087.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 50</text>\n<text text-anchor=\"start\" x=\"3263\" y=\"-2072.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 45]</text>\n</g>\n<!-- 205&#45;&gt;206 -->\n<g id=\"edge206\" class=\"edge\">\n<title>205&#45;&gt;206</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3342.62,-2168.88C3338.3,-2160.42 3333.61,-2151.21 3329.09,-2142.35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3332.14,-2140.62 3324.48,-2133.3 3325.9,-2143.8 3332.14,-2140.62\"/>\n</g>\n<!-- 229 -->\n<g id=\"node230\" class=\"node\">\n<title>229</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3471,-2125.5C3471,-2125.5 3390,-2125.5 3390,-2125.5 3384,-2125.5 3378,-2119.5 3378,-2113.5 3378,-2113.5 3378,-2084.5 3378,-2084.5 3378,-2078.5 3384,-2072.5 3390,-2072.5 3390,-2072.5 3471,-2072.5 3471,-2072.5 3477,-2072.5 3483,-2078.5 3483,-2084.5 3483,-2084.5 3483,-2113.5 3483,-2113.5 3483,-2119.5 3477,-2125.5 3471,-2125.5\"/>\n<text text-anchor=\"start\" x=\"3401.5\" y=\"-2110.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3387\" y=\"-2095.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 65</text>\n<text text-anchor=\"start\" x=\"3386\" y=\"-2080.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 65]</text>\n</g>\n<!-- 205&#45;&gt;229 -->\n<g id=\"edge229\" class=\"edge\">\n<title>205&#45;&gt;229</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3382.55,-2168.88C3390.36,-2157.67 3399.09,-2145.13 3406.94,-2133.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3409.9,-2135.73 3412.74,-2125.52 3404.15,-2131.73 3409.9,-2135.73\"/>\n</g>\n<!-- 207 -->\n<g id=\"node208\" class=\"node\">\n<title>207</title>\n<path fill=\"#4ba6e7\" stroke=\"black\" d=\"M3293,-2029C3293,-2029 3212,-2029 3212,-2029 3206,-2029 3200,-2023 3200,-2017 3200,-2017 3200,-1973 3200,-1973 3200,-1967 3206,-1961 3212,-1961 3212,-1961 3293,-1961 3293,-1961 3299,-1961 3305,-1967 3305,-1973 3305,-1973 3305,-2017 3305,-2017 3305,-2023 3299,-2029 3293,-2029\"/>\n<text text-anchor=\"start\" x=\"3213\" y=\"-2013.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 2.028</text>\n<text text-anchor=\"start\" x=\"3219\" y=\"-1998.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.15</text>\n<text text-anchor=\"start\" x=\"3209\" y=\"-1983.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 49</text>\n<text text-anchor=\"start\" x=\"3208\" y=\"-1968.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 45]</text>\n</g>\n<!-- 206&#45;&gt;207 -->\n<g id=\"edge207\" class=\"edge\">\n<title>206&#45;&gt;207</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3289.64,-2064.88C3285.08,-2056.42 3280.11,-2047.21 3275.34,-2038.35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3278.28,-2036.44 3270.46,-2029.3 3272.12,-2039.76 3278.28,-2036.44\"/>\n</g>\n<!-- 228 -->\n<g id=\"node229\" class=\"node\">\n<title>228</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3408,-2021.5C3408,-2021.5 3335,-2021.5 3335,-2021.5 3329,-2021.5 3323,-2015.5 3323,-2009.5 3323,-2009.5 3323,-1980.5 3323,-1980.5 3323,-1974.5 3329,-1968.5 3335,-1968.5 3335,-1968.5 3408,-1968.5 3408,-1968.5 3414,-1968.5 3420,-1974.5 3420,-1980.5 3420,-1980.5 3420,-2009.5 3420,-2009.5 3420,-2015.5 3414,-2021.5 3408,-2021.5\"/>\n<text text-anchor=\"start\" x=\"3342.5\" y=\"-2006.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3332\" y=\"-1991.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3331\" y=\"-1976.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 206&#45;&gt;228 -->\n<g id=\"edge228\" class=\"edge\">\n<title>206&#45;&gt;228</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3328.28,-2064.88C3335.25,-2053.78 3343.03,-2041.37 3350.05,-2030.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3353.14,-2031.85 3355.49,-2021.52 3347.21,-2028.13 3353.14,-2031.85\"/>\n</g>\n<!-- 208 -->\n<g id=\"node209\" class=\"node\">\n<title>208</title>\n<path fill=\"#46a4e7\" stroke=\"black\" d=\"M3236,-1925C3236,-1925 3155,-1925 3155,-1925 3149,-1925 3143,-1919 3143,-1913 3143,-1913 3143,-1869 3143,-1869 3143,-1863 3149,-1857 3155,-1857 3155,-1857 3236,-1857 3236,-1857 3242,-1857 3248,-1863 3248,-1869 3248,-1869 3248,-1913 3248,-1913 3248,-1919 3242,-1925 3236,-1925\"/>\n<text text-anchor=\"start\" x=\"3156\" y=\"-1909.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.563</text>\n<text text-anchor=\"start\" x=\"3162\" y=\"-1894.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.12</text>\n<text text-anchor=\"start\" x=\"3152\" y=\"-1879.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 47</text>\n<text text-anchor=\"start\" x=\"3151\" y=\"-1864.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 44]</text>\n</g>\n<!-- 207&#45;&gt;208 -->\n<g id=\"edge208\" class=\"edge\">\n<title>207&#45;&gt;208</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3233.99,-1960.88C3229.22,-1952.33 3224.01,-1943.01 3219.01,-1934.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3222.04,-1932.32 3214.11,-1925.3 3215.93,-1935.74 3222.04,-1932.32\"/>\n</g>\n<!-- 225 -->\n<g id=\"node226\" class=\"node\">\n<title>225</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M3351,-1925C3351,-1925 3278,-1925 3278,-1925 3272,-1925 3266,-1919 3266,-1913 3266,-1913 3266,-1869 3266,-1869 3266,-1863 3272,-1857 3278,-1857 3278,-1857 3351,-1857 3351,-1857 3357,-1857 3363,-1863 3363,-1869 3363,-1869 3363,-1913 3363,-1913 3363,-1919 3357,-1925 3351,-1925\"/>\n<text text-anchor=\"start\" x=\"3275\" y=\"-1909.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pclass ≤ 1.5</text>\n<text text-anchor=\"start\" x=\"3285.5\" y=\"-1894.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"3275\" y=\"-1879.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"3274\" y=\"-1864.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 207&#45;&gt;225 -->\n<g id=\"edge225\" class=\"edge\">\n<title>207&#45;&gt;225</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3272.63,-1960.88C3277.83,-1952.33 3283.49,-1943.01 3288.93,-1934.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3292.06,-1935.66 3294.26,-1925.3 3286.07,-1932.03 3292.06,-1935.66\"/>\n</g>\n<!-- 209 -->\n<g id=\"node210\" class=\"node\">\n<title>209</title>\n<path fill=\"#3fa0e6\" stroke=\"black\" d=\"M3113,-1821C3113,-1821 3032,-1821 3032,-1821 3026,-1821 3020,-1815 3020,-1809 3020,-1809 3020,-1765 3020,-1765 3020,-1759 3026,-1753 3032,-1753 3032,-1753 3113,-1753 3113,-1753 3119,-1753 3125,-1759 3125,-1765 3125,-1765 3125,-1809 3125,-1809 3125,-1815 3119,-1821 3113,-1821\"/>\n<text text-anchor=\"start\" x=\"3035\" y=\"-1805.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"3035\" y=\"-1790.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.061</text>\n<text text-anchor=\"start\" x=\"3029\" y=\"-1775.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 32</text>\n<text text-anchor=\"start\" x=\"3028\" y=\"-1760.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 31]</text>\n</g>\n<!-- 208&#45;&gt;209 -->\n<g id=\"edge209\" class=\"edge\">\n<title>208&#45;&gt;209</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3155.57,-1856.88C3144.39,-1847.62 3132.14,-1837.45 3120.55,-1827.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3122.59,-1824.99 3112.66,-1821.3 3118.12,-1830.38 3122.59,-1824.99\"/>\n</g>\n<!-- 218 -->\n<g id=\"node219\" class=\"node\">\n<title>218</title>\n<path fill=\"#57ace9\" stroke=\"black\" d=\"M3236,-1821C3236,-1821 3155,-1821 3155,-1821 3149,-1821 3143,-1815 3143,-1809 3143,-1809 3143,-1765 3143,-1765 3143,-1759 3149,-1753 3155,-1753 3155,-1753 3236,-1753 3236,-1753 3242,-1753 3248,-1759 3248,-1765 3248,-1765 3248,-1809 3248,-1809 3248,-1815 3242,-1821 3236,-1821\"/>\n<text text-anchor=\"start\" x=\"3156\" y=\"-1805.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.718</text>\n<text text-anchor=\"start\" x=\"3158\" y=\"-1790.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.231</text>\n<text text-anchor=\"start\" x=\"3152\" y=\"-1775.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\n<text text-anchor=\"start\" x=\"3151\" y=\"-1760.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 13]</text>\n</g>\n<!-- 208&#45;&gt;218 -->\n<g id=\"edge218\" class=\"edge\">\n<title>208&#45;&gt;218</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3195.5,-1856.88C3195.5,-1848.78 3195.5,-1839.98 3195.5,-1831.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3199,-1831.3 3195.5,-1821.3 3192,-1831.3 3199,-1831.3\"/>\n</g>\n<!-- 210 -->\n<g id=\"node211\" class=\"node\">\n<title>210</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2992,-1709.5C2992,-1709.5 2911,-1709.5 2911,-1709.5 2905,-1709.5 2899,-1703.5 2899,-1697.5 2899,-1697.5 2899,-1668.5 2899,-1668.5 2899,-1662.5 2905,-1656.5 2911,-1656.5 2911,-1656.5 2992,-1656.5 2992,-1656.5 2998,-1656.5 3004,-1662.5 3004,-1668.5 3004,-1668.5 3004,-1697.5 3004,-1697.5 3004,-1703.5 2998,-1709.5 2992,-1709.5\"/>\n<text text-anchor=\"start\" x=\"2922.5\" y=\"-1694.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2908\" y=\"-1679.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\n<text text-anchor=\"start\" x=\"2907\" y=\"-1664.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 17]</text>\n</g>\n<!-- 209&#45;&gt;210 -->\n<g id=\"edge210\" class=\"edge\">\n<title>209&#45;&gt;210</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3033.21,-1752.88C3019.26,-1741.12 3003.57,-1727.89 2989.7,-1716.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2991.68,-1713.29 2981.77,-1709.52 2987.16,-1718.64 2991.68,-1713.29\"/>\n</g>\n<!-- 211 -->\n<g id=\"node212\" class=\"node\">\n<title>211</title>\n<path fill=\"#47a4e7\" stroke=\"black\" d=\"M3115,-1717C3115,-1717 3034,-1717 3034,-1717 3028,-1717 3022,-1711 3022,-1705 3022,-1705 3022,-1661 3022,-1661 3022,-1655 3028,-1649 3034,-1649 3034,-1649 3115,-1649 3115,-1649 3121,-1649 3127,-1655 3127,-1661 3127,-1661 3127,-1705 3127,-1705 3127,-1711 3121,-1717 3115,-1717\"/>\n<text text-anchor=\"start\" x=\"3033.5\" y=\"-1701.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.181</text>\n<text text-anchor=\"start\" x=\"3037\" y=\"-1686.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.124</text>\n<text text-anchor=\"start\" x=\"3031\" y=\"-1671.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\n<text text-anchor=\"start\" x=\"3030\" y=\"-1656.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 14]</text>\n</g>\n<!-- 209&#45;&gt;211 -->\n<g id=\"edge211\" class=\"edge\">\n<title>209&#45;&gt;211</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3073.15,-1752.88C3073.31,-1744.78 3073.48,-1735.98 3073.65,-1727.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3077.15,-1727.37 3073.85,-1717.3 3070.15,-1727.23 3077.15,-1727.37\"/>\n</g>\n<!-- 212 -->\n<g id=\"node213\" class=\"node\">\n<title>212</title>\n<path fill=\"#7bbeee\" stroke=\"black\" d=\"M2991.5,-1613C2991.5,-1613 2917.5,-1613 2917.5,-1613 2911.5,-1613 2905.5,-1607 2905.5,-1601 2905.5,-1601 2905.5,-1557 2905.5,-1557 2905.5,-1551 2911.5,-1545 2917.5,-1545 2917.5,-1545 2991.5,-1545 2991.5,-1545 2997.5,-1545 3003.5,-1551 3003.5,-1557 3003.5,-1557 3003.5,-1601 3003.5,-1601 3003.5,-1607 2997.5,-1613 2991.5,-1613\"/>\n<text text-anchor=\"start\" x=\"2913.5\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.081</text>\n<text text-anchor=\"start\" x=\"2917\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"2915\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"2914\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 3]</text>\n</g>\n<!-- 211&#45;&gt;212 -->\n<g id=\"edge212\" class=\"edge\">\n<title>211&#45;&gt;212</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3035.54,-1648.88C3024.64,-1639.62 3012.68,-1629.45 3001.38,-1619.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3003.56,-1617.11 2993.68,-1613.3 2999.03,-1622.44 3003.56,-1617.11\"/>\n</g>\n<!-- 217 -->\n<g id=\"node218\" class=\"node\">\n<title>217</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3115,-1605.5C3115,-1605.5 3034,-1605.5 3034,-1605.5 3028,-1605.5 3022,-1599.5 3022,-1593.5 3022,-1593.5 3022,-1564.5 3022,-1564.5 3022,-1558.5 3028,-1552.5 3034,-1552.5 3034,-1552.5 3115,-1552.5 3115,-1552.5 3121,-1552.5 3127,-1558.5 3127,-1564.5 3127,-1564.5 3127,-1593.5 3127,-1593.5 3127,-1599.5 3121,-1605.5 3115,-1605.5\"/>\n<text text-anchor=\"start\" x=\"3045.5\" y=\"-1590.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3031\" y=\"-1575.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"start\" x=\"3030\" y=\"-1560.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 11]</text>\n</g>\n<!-- 211&#45;&gt;217 -->\n<g id=\"edge217\" class=\"edge\">\n<title>211&#45;&gt;217</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3074.5,-1648.88C3074.5,-1638.33 3074.5,-1626.6 3074.5,-1615.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3078,-1615.52 3074.5,-1605.52 3071,-1615.52 3078,-1615.52\"/>\n</g>\n<!-- 213 -->\n<g id=\"node214\" class=\"node\">\n<title>213</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2929,-1501.5C2929,-1501.5 2856,-1501.5 2856,-1501.5 2850,-1501.5 2844,-1495.5 2844,-1489.5 2844,-1489.5 2844,-1460.5 2844,-1460.5 2844,-1454.5 2850,-1448.5 2856,-1448.5 2856,-1448.5 2929,-1448.5 2929,-1448.5 2935,-1448.5 2941,-1454.5 2941,-1460.5 2941,-1460.5 2941,-1489.5 2941,-1489.5 2941,-1495.5 2935,-1501.5 2929,-1501.5\"/>\n<text text-anchor=\"start\" x=\"2863.5\" y=\"-1486.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2853\" y=\"-1471.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2852\" y=\"-1456.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 212&#45;&gt;213 -->\n<g id=\"edge213\" class=\"edge\">\n<title>212&#45;&gt;213</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2934.37,-1544.88C2927.62,-1533.78 2920.08,-1521.37 2913.28,-1510.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2916.2,-1508.25 2908.01,-1501.52 2910.22,-1511.88 2916.2,-1508.25\"/>\n</g>\n<!-- 214 -->\n<g id=\"node215\" class=\"node\">\n<title>214</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M3046,-1509C3046,-1509 2971,-1509 2971,-1509 2965,-1509 2959,-1503 2959,-1497 2959,-1497 2959,-1453 2959,-1453 2959,-1447 2965,-1441 2971,-1441 2971,-1441 3046,-1441 3046,-1441 3052,-1441 3058,-1447 3058,-1453 3058,-1453 3058,-1497 3058,-1497 3058,-1503 3052,-1509 3046,-1509\"/>\n<text text-anchor=\"start\" x=\"2967\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.092</text>\n<text text-anchor=\"start\" x=\"2979.5\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"2969\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2968\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 212&#45;&gt;214 -->\n<g id=\"edge214\" class=\"edge\">\n<title>212&#45;&gt;214</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2972.03,-1544.88C2976.51,-1536.42 2981.39,-1527.21 2986.08,-1518.35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2989.29,-1519.77 2990.87,-1509.3 2983.1,-1516.5 2989.29,-1519.77\"/>\n</g>\n<!-- 215 -->\n<g id=\"node216\" class=\"node\">\n<title>215</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2932,-1397.5C2932,-1397.5 2859,-1397.5 2859,-1397.5 2853,-1397.5 2847,-1391.5 2847,-1385.5 2847,-1385.5 2847,-1356.5 2847,-1356.5 2847,-1350.5 2853,-1344.5 2859,-1344.5 2859,-1344.5 2932,-1344.5 2932,-1344.5 2938,-1344.5 2944,-1350.5 2944,-1356.5 2944,-1356.5 2944,-1385.5 2944,-1385.5 2944,-1391.5 2938,-1397.5 2932,-1397.5\"/>\n<text text-anchor=\"start\" x=\"2866.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2856\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2855\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 214&#45;&gt;215 -->\n<g id=\"edge215\" class=\"edge\">\n<title>214&#45;&gt;215</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2971.81,-1440.88C2958.9,-1429.23 2944.4,-1416.14 2931.54,-1404.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2933.54,-1401.62 2923.77,-1397.52 2928.85,-1406.82 2933.54,-1401.62\"/>\n</g>\n<!-- 216 -->\n<g id=\"node217\" class=\"node\">\n<title>216</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3047,-1397.5C3047,-1397.5 2974,-1397.5 2974,-1397.5 2968,-1397.5 2962,-1391.5 2962,-1385.5 2962,-1385.5 2962,-1356.5 2962,-1356.5 2962,-1350.5 2968,-1344.5 2974,-1344.5 2974,-1344.5 3047,-1344.5 3047,-1344.5 3053,-1344.5 3059,-1350.5 3059,-1356.5 3059,-1356.5 3059,-1385.5 3059,-1385.5 3059,-1391.5 3053,-1397.5 3047,-1397.5\"/>\n<text text-anchor=\"start\" x=\"2981.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2971\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2970\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 214&#45;&gt;216 -->\n<g id=\"edge216\" class=\"edge\">\n<title>214&#45;&gt;216</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3009.15,-1440.88C3009.36,-1430.22 3009.59,-1418.35 3009.8,-1407.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3013.3,-1407.59 3010,-1397.52 3006.3,-1407.45 3013.3,-1407.59\"/>\n</g>\n<!-- 219 -->\n<g id=\"node220\" class=\"node\">\n<title>219</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3231,-1709.5C3231,-1709.5 3158,-1709.5 3158,-1709.5 3152,-1709.5 3146,-1703.5 3146,-1697.5 3146,-1697.5 3146,-1668.5 3146,-1668.5 3146,-1662.5 3152,-1656.5 3158,-1656.5 3158,-1656.5 3231,-1656.5 3231,-1656.5 3237,-1656.5 3243,-1662.5 3243,-1668.5 3243,-1668.5 3243,-1697.5 3243,-1697.5 3243,-1703.5 3237,-1709.5 3231,-1709.5\"/>\n<text text-anchor=\"start\" x=\"3165.5\" y=\"-1694.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3155\" y=\"-1679.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3154\" y=\"-1664.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 218&#45;&gt;219 -->\n<g id=\"edge219\" class=\"edge\">\n<title>218&#45;&gt;219</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3195.18,-1752.88C3195.07,-1742.33 3194.96,-1730.6 3194.85,-1719.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3198.35,-1719.49 3194.75,-1709.52 3191.35,-1719.55 3198.35,-1719.49\"/>\n</g>\n<!-- 220 -->\n<g id=\"node221\" class=\"node\">\n<title>220</title>\n<path fill=\"#48a5e7\" stroke=\"black\" d=\"M3354,-1717C3354,-1717 3273,-1717 3273,-1717 3267,-1717 3261,-1711 3261,-1705 3261,-1705 3261,-1661 3261,-1661 3261,-1655 3267,-1649 3273,-1649 3273,-1649 3354,-1649 3354,-1649 3360,-1649 3366,-1655 3366,-1661 3366,-1661 3366,-1705 3366,-1705 3366,-1711 3360,-1717 3354,-1717\"/>\n<text text-anchor=\"start\" x=\"3276\" y=\"-1701.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"3276\" y=\"-1686.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.133</text>\n<text text-anchor=\"start\" x=\"3270\" y=\"-1671.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14</text>\n<text text-anchor=\"start\" x=\"3269\" y=\"-1656.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 13]</text>\n</g>\n<!-- 218&#45;&gt;220 -->\n<g id=\"edge220\" class=\"edge\">\n<title>218&#45;&gt;220</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3233.81,-1752.88C3244.53,-1743.62 3256.29,-1733.45 3267.4,-1723.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3269.7,-1726.49 3274.98,-1717.3 3265.12,-1721.19 3269.7,-1726.49\"/>\n</g>\n<!-- 221 -->\n<g id=\"node222\" class=\"node\">\n<title>221</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3238,-1605.5C3238,-1605.5 3157,-1605.5 3157,-1605.5 3151,-1605.5 3145,-1599.5 3145,-1593.5 3145,-1593.5 3145,-1564.5 3145,-1564.5 3145,-1558.5 3151,-1552.5 3157,-1552.5 3157,-1552.5 3238,-1552.5 3238,-1552.5 3244,-1552.5 3250,-1558.5 3250,-1564.5 3250,-1564.5 3250,-1593.5 3250,-1593.5 3250,-1599.5 3244,-1605.5 3238,-1605.5\"/>\n<text text-anchor=\"start\" x=\"3168.5\" y=\"-1590.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3154\" y=\"-1575.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"start\" x=\"3153\" y=\"-1560.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 11]</text>\n</g>\n<!-- 220&#45;&gt;221 -->\n<g id=\"edge221\" class=\"edge\">\n<title>220&#45;&gt;221</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3275.84,-1648.88C3262.46,-1637.12 3247.42,-1623.89 3234.12,-1612.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3236.34,-1609.49 3226.52,-1605.52 3231.72,-1614.75 3236.34,-1609.49\"/>\n</g>\n<!-- 222 -->\n<g id=\"node223\" class=\"node\">\n<title>222</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M3353,-1613C3353,-1613 3280,-1613 3280,-1613 3274,-1613 3268,-1607 3268,-1601 3268,-1601 3268,-1557 3268,-1557 3268,-1551 3274,-1545 3280,-1545 3280,-1545 3353,-1545 3353,-1545 3359,-1545 3365,-1551 3365,-1557 3365,-1557 3365,-1601 3365,-1601 3365,-1607 3359,-1613 3353,-1613\"/>\n<text text-anchor=\"start\" x=\"3280\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"3279\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"3277\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"3276\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 220&#45;&gt;222 -->\n<g id=\"edge222\" class=\"edge\">\n<title>220&#45;&gt;222</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3314.47,-1648.88C3314.71,-1640.78 3314.97,-1631.98 3315.22,-1623.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3318.73,-1623.4 3315.52,-1613.3 3311.73,-1623.19 3318.73,-1623.4\"/>\n</g>\n<!-- 223 -->\n<g id=\"node224\" class=\"node\">\n<title>223</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3238,-1501.5C3238,-1501.5 3165,-1501.5 3165,-1501.5 3159,-1501.5 3153,-1495.5 3153,-1489.5 3153,-1489.5 3153,-1460.5 3153,-1460.5 3153,-1454.5 3159,-1448.5 3165,-1448.5 3165,-1448.5 3238,-1448.5 3238,-1448.5 3244,-1448.5 3250,-1454.5 3250,-1460.5 3250,-1460.5 3250,-1489.5 3250,-1489.5 3250,-1495.5 3244,-1501.5 3238,-1501.5\"/>\n<text text-anchor=\"start\" x=\"3172.5\" y=\"-1486.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3162\" y=\"-1471.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3161\" y=\"-1456.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 222&#45;&gt;223 -->\n<g id=\"edge223\" class=\"edge\">\n<title>222&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3279.16,-1544.88C3265.9,-1533.12 3250.99,-1519.89 3237.81,-1508.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3240.08,-1505.54 3230.27,-1501.52 3235.43,-1510.77 3240.08,-1505.54\"/>\n</g>\n<!-- 224 -->\n<g id=\"node225\" class=\"node\">\n<title>224</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3353,-1501.5C3353,-1501.5 3280,-1501.5 3280,-1501.5 3274,-1501.5 3268,-1495.5 3268,-1489.5 3268,-1489.5 3268,-1460.5 3268,-1460.5 3268,-1454.5 3274,-1448.5 3280,-1448.5 3280,-1448.5 3353,-1448.5 3353,-1448.5 3359,-1448.5 3365,-1454.5 3365,-1460.5 3365,-1460.5 3365,-1489.5 3365,-1489.5 3365,-1495.5 3359,-1501.5 3353,-1501.5\"/>\n<text text-anchor=\"start\" x=\"3287.5\" y=\"-1486.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3277\" y=\"-1471.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"3276\" y=\"-1456.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 222&#45;&gt;224 -->\n<g id=\"edge224\" class=\"edge\">\n<title>222&#45;&gt;224</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3316.5,-1544.88C3316.5,-1534.33 3316.5,-1522.6 3316.5,-1511.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3320,-1511.52 3316.5,-1501.52 3313,-1511.52 3320,-1511.52\"/>\n</g>\n<!-- 226 -->\n<g id=\"node227\" class=\"node\">\n<title>226</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3351,-1813.5C3351,-1813.5 3278,-1813.5 3278,-1813.5 3272,-1813.5 3266,-1807.5 3266,-1801.5 3266,-1801.5 3266,-1772.5 3266,-1772.5 3266,-1766.5 3272,-1760.5 3278,-1760.5 3278,-1760.5 3351,-1760.5 3351,-1760.5 3357,-1760.5 3363,-1766.5 3363,-1772.5 3363,-1772.5 3363,-1801.5 3363,-1801.5 3363,-1807.5 3357,-1813.5 3351,-1813.5\"/>\n<text text-anchor=\"start\" x=\"3285.5\" y=\"-1798.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3275\" y=\"-1783.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3274\" y=\"-1768.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 225&#45;&gt;226 -->\n<g id=\"edge226\" class=\"edge\">\n<title>225&#45;&gt;226</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3314.5,-1856.88C3314.5,-1846.33 3314.5,-1834.6 3314.5,-1823.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3318,-1823.52 3314.5,-1813.52 3311,-1823.52 3318,-1823.52\"/>\n</g>\n<!-- 227 -->\n<g id=\"node228\" class=\"node\">\n<title>227</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3466,-1813.5C3466,-1813.5 3393,-1813.5 3393,-1813.5 3387,-1813.5 3381,-1807.5 3381,-1801.5 3381,-1801.5 3381,-1772.5 3381,-1772.5 3381,-1766.5 3387,-1760.5 3393,-1760.5 3393,-1760.5 3466,-1760.5 3466,-1760.5 3472,-1760.5 3478,-1766.5 3478,-1772.5 3478,-1772.5 3478,-1801.5 3478,-1801.5 3478,-1807.5 3472,-1813.5 3466,-1813.5\"/>\n<text text-anchor=\"start\" x=\"3400.5\" y=\"-1798.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3390\" y=\"-1783.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3389\" y=\"-1768.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 225&#45;&gt;227 -->\n<g id=\"edge227\" class=\"edge\">\n<title>225&#45;&gt;227</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3351.84,-1856.88C3365.1,-1845.12 3380.01,-1831.89 3393.19,-1820.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3395.57,-1822.77 3400.73,-1813.52 3390.92,-1817.54 3395.57,-1822.77\"/>\n</g>\n<!-- 231 -->\n<g id=\"node232\" class=\"node\">\n<title>231</title>\n<path fill=\"#79bced\" stroke=\"black\" d=\"M3622,-2133C3622,-2133 3541,-2133 3541,-2133 3535,-2133 3529,-2127 3529,-2121 3529,-2121 3529,-2077 3529,-2077 3529,-2071 3535,-2065 3541,-2065 3541,-2065 3622,-2065 3622,-2065 3628,-2065 3634,-2071 3634,-2077 3634,-2077 3634,-2121 3634,-2121 3634,-2127 3628,-2133 3622,-2133\"/>\n<text text-anchor=\"start\" x=\"3540\" y=\"-2117.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.037</text>\n<text text-anchor=\"start\" x=\"3544\" y=\"-2102.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.368</text>\n<text text-anchor=\"start\" x=\"3538\" y=\"-2087.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 37</text>\n<text text-anchor=\"start\" x=\"3537\" y=\"-2072.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 28]</text>\n</g>\n<!-- 230&#45;&gt;231 -->\n<g id=\"edge231\" class=\"edge\">\n<title>230&#45;&gt;231</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3581.5,-2168.88C3581.5,-2160.78 3581.5,-2151.98 3581.5,-2143.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3585,-2143.3 3581.5,-2133.3 3578,-2143.3 3585,-2143.3\"/>\n</g>\n<!-- 252 -->\n<g id=\"node253\" class=\"node\">\n<title>252</title>\n<path fill=\"#f3c5a4\" stroke=\"black\" d=\"M4063,-2133C4063,-2133 3974,-2133 3974,-2133 3968,-2133 3962,-2127 3962,-2121 3962,-2121 3962,-2077 3962,-2077 3962,-2071 3968,-2065 3974,-2065 3974,-2065 4063,-2065 4063,-2065 4069,-2065 4075,-2071 4075,-2077 4075,-2077 4075,-2121 4075,-2121 4075,-2127 4069,-2133 4063,-2133\"/>\n<text text-anchor=\"start\" x=\"3977.5\" y=\"-2117.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.127</text>\n<text text-anchor=\"start\" x=\"3981\" y=\"-2102.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.455</text>\n<text text-anchor=\"start\" x=\"3975\" y=\"-2087.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 60</text>\n<text text-anchor=\"start\" x=\"3970\" y=\"-2072.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [39, 21]</text>\n</g>\n<!-- 230&#45;&gt;252 -->\n<g id=\"edge252\" class=\"edge\">\n<title>230&#45;&gt;252</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3649.3,-2186.17C3731.69,-2166.94 3869.82,-2134.7 3951.73,-2115.58\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3952.74,-2118.94 3961.68,-2113.26 3951.15,-2112.13 3952.74,-2118.94\"/>\n</g>\n<!-- 232 -->\n<g id=\"node233\" class=\"node\">\n<title>232</title>\n<path fill=\"#6ab6ec\" stroke=\"black\" d=\"M3575,-2029C3575,-2029 3494,-2029 3494,-2029 3488,-2029 3482,-2023 3482,-2017 3482,-2017 3482,-1973 3482,-1973 3482,-1967 3488,-1961 3494,-1961 3494,-1961 3575,-1961 3575,-1961 3581,-1961 3587,-1967 3587,-1973 3587,-1973 3587,-2017 3587,-2017 3587,-2023 3581,-2029 3575,-2029\"/>\n<text text-anchor=\"start\" x=\"3491.5\" y=\"-2013.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.911</text>\n<text text-anchor=\"start\" x=\"3501\" y=\"-1998.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"3491\" y=\"-1983.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 35</text>\n<text text-anchor=\"start\" x=\"3490\" y=\"-1968.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 28]</text>\n</g>\n<!-- 231&#45;&gt;232 -->\n<g id=\"edge232\" class=\"edge\">\n<title>231&#45;&gt;232</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3566.24,-2064.88C3562.38,-2056.51 3558.18,-2047.4 3554.14,-2038.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3557.21,-2036.92 3549.84,-2029.3 3550.85,-2039.85 3557.21,-2036.92\"/>\n</g>\n<!-- 251 -->\n<g id=\"node252\" class=\"node\">\n<title>251</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3690,-2021.5C3690,-2021.5 3617,-2021.5 3617,-2021.5 3611,-2021.5 3605,-2015.5 3605,-2009.5 3605,-2009.5 3605,-1980.5 3605,-1980.5 3605,-1974.5 3611,-1968.5 3617,-1968.5 3617,-1968.5 3690,-1968.5 3690,-1968.5 3696,-1968.5 3702,-1974.5 3702,-1980.5 3702,-1980.5 3702,-2009.5 3702,-2009.5 3702,-2015.5 3696,-2021.5 3690,-2021.5\"/>\n<text text-anchor=\"start\" x=\"3624.5\" y=\"-2006.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3614\" y=\"-1991.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"3613\" y=\"-1976.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 231&#45;&gt;251 -->\n<g id=\"edge251\" class=\"edge\">\n<title>231&#45;&gt;251</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3604.88,-2064.88C3612.79,-2053.67 3621.65,-2041.13 3629.6,-2029.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3632.58,-2031.71 3635.49,-2021.52 3626.86,-2027.67 3632.58,-2031.71\"/>\n</g>\n<!-- 233 -->\n<g id=\"node234\" class=\"node\">\n<title>233</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3496,-1917.5C3496,-1917.5 3423,-1917.5 3423,-1917.5 3417,-1917.5 3411,-1911.5 3411,-1905.5 3411,-1905.5 3411,-1876.5 3411,-1876.5 3411,-1870.5 3417,-1864.5 3423,-1864.5 3423,-1864.5 3496,-1864.5 3496,-1864.5 3502,-1864.5 3508,-1870.5 3508,-1876.5 3508,-1876.5 3508,-1905.5 3508,-1905.5 3508,-1911.5 3502,-1917.5 3496,-1917.5\"/>\n<text text-anchor=\"start\" x=\"3430.5\" y=\"-1902.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3420\" y=\"-1887.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3419\" y=\"-1872.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 232&#45;&gt;233 -->\n<g id=\"edge233\" class=\"edge\">\n<title>232&#45;&gt;233</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3510.15,-1960.88C3501.9,-1949.67 3492.68,-1937.13 3484.39,-1925.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3487.01,-1923.5 3478.26,-1917.52 3481.37,-1927.65 3487.01,-1923.5\"/>\n</g>\n<!-- 234 -->\n<g id=\"node235\" class=\"node\">\n<title>234</title>\n<path fill=\"#63b2eb\" stroke=\"black\" d=\"M3619,-1925C3619,-1925 3538,-1925 3538,-1925 3532,-1925 3526,-1919 3526,-1913 3526,-1913 3526,-1869 3526,-1869 3526,-1863 3532,-1857 3538,-1857 3538,-1857 3619,-1857 3619,-1857 3625,-1857 3631,-1863 3631,-1869 3631,-1869 3631,-1913 3631,-1913 3631,-1919 3625,-1925 3619,-1925\"/>\n<text text-anchor=\"start\" x=\"3535.5\" y=\"-1909.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.195</text>\n<text text-anchor=\"start\" x=\"3541\" y=\"-1894.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.291</text>\n<text text-anchor=\"start\" x=\"3535\" y=\"-1879.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 34</text>\n<text text-anchor=\"start\" x=\"3534\" y=\"-1864.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 28]</text>\n</g>\n<!-- 232&#45;&gt;234 -->\n<g id=\"edge234\" class=\"edge\">\n<title>232&#45;&gt;234</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3548.79,-1960.88C3552.4,-1952.51 3556.33,-1943.4 3560.11,-1934.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3563.39,-1935.87 3564.14,-1925.3 3556.96,-1933.1 3563.39,-1935.87\"/>\n</g>\n<!-- 235 -->\n<g id=\"node236\" class=\"node\">\n<title>235</title>\n<path fill=\"#7fc0ee\" stroke=\"black\" d=\"M3589,-1821C3589,-1821 3508,-1821 3508,-1821 3502,-1821 3496,-1815 3496,-1809 3496,-1809 3496,-1765 3496,-1765 3496,-1759 3502,-1753 3508,-1753 3508,-1753 3589,-1753 3589,-1753 3595,-1753 3601,-1759 3601,-1765 3601,-1765 3601,-1809 3601,-1809 3601,-1815 3595,-1821 3589,-1821\"/>\n<text text-anchor=\"start\" x=\"3505.5\" y=\"-1805.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.265</text>\n<text text-anchor=\"start\" x=\"3511\" y=\"-1790.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.386</text>\n<text text-anchor=\"start\" x=\"3505\" y=\"-1775.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 23</text>\n<text text-anchor=\"start\" x=\"3504\" y=\"-1760.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 17]</text>\n</g>\n<!-- 234&#45;&gt;235 -->\n<g id=\"edge235\" class=\"edge\">\n<title>234&#45;&gt;235</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3568.76,-1856.88C3566.32,-1848.6 3563.68,-1839.6 3561.12,-1830.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3564.47,-1829.91 3558.29,-1821.3 3557.76,-1831.88 3564.47,-1829.91\"/>\n</g>\n<!-- 250 -->\n<g id=\"node251\" class=\"node\">\n<title>250</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3712,-1813.5C3712,-1813.5 3631,-1813.5 3631,-1813.5 3625,-1813.5 3619,-1807.5 3619,-1801.5 3619,-1801.5 3619,-1772.5 3619,-1772.5 3619,-1766.5 3625,-1760.5 3631,-1760.5 3631,-1760.5 3712,-1760.5 3712,-1760.5 3718,-1760.5 3724,-1766.5 3724,-1772.5 3724,-1772.5 3724,-1801.5 3724,-1801.5 3724,-1807.5 3718,-1813.5 3712,-1813.5\"/>\n<text text-anchor=\"start\" x=\"3642.5\" y=\"-1798.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3628\" y=\"-1783.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"start\" x=\"3627\" y=\"-1768.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 11]</text>\n</g>\n<!-- 234&#45;&gt;250 -->\n<g id=\"edge250\" class=\"edge\">\n<title>234&#45;&gt;250</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3608.69,-1856.88C3619.12,-1845.45 3630.8,-1832.63 3641.24,-1821.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3644.08,-1823.27 3648.23,-1813.52 3638.91,-1818.55 3644.08,-1823.27\"/>\n</g>\n<!-- 236 -->\n<g id=\"node237\" class=\"node\">\n<title>236</title>\n<path fill=\"#5caeea\" stroke=\"black\" d=\"M3520,-1717C3520,-1717 3439,-1717 3439,-1717 3433,-1717 3427,-1711 3427,-1705 3427,-1705 3427,-1661 3427,-1661 3427,-1655 3433,-1649 3439,-1649 3439,-1649 3520,-1649 3520,-1649 3526,-1649 3532,-1655 3532,-1661 3532,-1661 3532,-1705 3532,-1705 3532,-1711 3526,-1717 3520,-1717\"/>\n<text text-anchor=\"start\" x=\"3443\" y=\"-1701.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 1.5</text>\n<text text-anchor=\"start\" x=\"3442\" y=\"-1686.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.255</text>\n<text text-anchor=\"start\" x=\"3436\" y=\"-1671.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 20</text>\n<text text-anchor=\"start\" x=\"3435\" y=\"-1656.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 17]</text>\n</g>\n<!-- 235&#45;&gt;236 -->\n<g id=\"edge236\" class=\"edge\">\n<title>235&#45;&gt;236</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3526.1,-1752.88C3520.25,-1744.24 3513.88,-1734.82 3507.77,-1725.79\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3510.53,-1723.62 3502.03,-1717.3 3504.73,-1727.54 3510.53,-1723.62\"/>\n</g>\n<!-- 249 -->\n<g id=\"node250\" class=\"node\">\n<title>249</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3635,-1709.5C3635,-1709.5 3562,-1709.5 3562,-1709.5 3556,-1709.5 3550,-1703.5 3550,-1697.5 3550,-1697.5 3550,-1668.5 3550,-1668.5 3550,-1662.5 3556,-1656.5 3562,-1656.5 3562,-1656.5 3635,-1656.5 3635,-1656.5 3641,-1656.5 3647,-1662.5 3647,-1668.5 3647,-1668.5 3647,-1697.5 3647,-1697.5 3647,-1703.5 3641,-1709.5 3635,-1709.5\"/>\n<text text-anchor=\"start\" x=\"3569.5\" y=\"-1694.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3559\" y=\"-1679.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"3558\" y=\"-1664.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 235&#45;&gt;249 -->\n<g id=\"edge249\" class=\"edge\">\n<title>235&#45;&gt;249</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3564.73,-1752.88C3570.12,-1741.89 3576.14,-1729.62 3581.58,-1718.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3584.73,-1720.04 3585.99,-1709.52 3578.45,-1716.96 3584.73,-1720.04\"/>\n</g>\n<!-- 237 -->\n<g id=\"node238\" class=\"node\">\n<title>237</title>\n<path fill=\"#50a9e8\" stroke=\"black\" d=\"M3491,-1613C3491,-1613 3410,-1613 3410,-1613 3404,-1613 3398,-1607 3398,-1601 3398,-1601 3398,-1557 3398,-1557 3398,-1551 3404,-1545 3410,-1545 3410,-1545 3491,-1545 3491,-1545 3497,-1545 3503,-1551 3503,-1557 3503,-1557 3503,-1601 3503,-1601 3503,-1607 3497,-1613 3491,-1613\"/>\n<text text-anchor=\"start\" x=\"3407.5\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.778</text>\n<text text-anchor=\"start\" x=\"3413\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.188</text>\n<text text-anchor=\"start\" x=\"3407\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\n<text text-anchor=\"start\" x=\"3406\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 17]</text>\n</g>\n<!-- 236&#45;&gt;237 -->\n<g id=\"edge237\" class=\"edge\">\n<title>236&#45;&gt;237</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3470.08,-1648.88C3467.75,-1640.69 3465.22,-1631.79 3462.78,-1623.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3466.07,-1621.96 3459.97,-1613.3 3459.34,-1623.88 3466.07,-1621.96\"/>\n</g>\n<!-- 248 -->\n<g id=\"node249\" class=\"node\">\n<title>248</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3606,-1605.5C3606,-1605.5 3533,-1605.5 3533,-1605.5 3527,-1605.5 3521,-1599.5 3521,-1593.5 3521,-1593.5 3521,-1564.5 3521,-1564.5 3521,-1558.5 3527,-1552.5 3533,-1552.5 3533,-1552.5 3606,-1552.5 3606,-1552.5 3612,-1552.5 3618,-1558.5 3618,-1564.5 3618,-1564.5 3618,-1593.5 3618,-1593.5 3618,-1599.5 3612,-1605.5 3606,-1605.5\"/>\n<text text-anchor=\"start\" x=\"3540.5\" y=\"-1590.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3530\" y=\"-1575.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3529\" y=\"-1560.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 236&#45;&gt;248 -->\n<g id=\"edge248\" class=\"edge\">\n<title>236&#45;&gt;248</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3508.72,-1648.88C3518.81,-1637.45 3530.12,-1624.63 3540.21,-1613.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3542.99,-1615.33 3546.98,-1605.52 3537.74,-1610.7 3542.99,-1615.33\"/>\n</g>\n<!-- 238 -->\n<g id=\"node239\" class=\"node\">\n<title>238</title>\n<path fill=\"#45a3e7\" stroke=\"black\" d=\"M3476,-1509C3476,-1509 3395,-1509 3395,-1509 3389,-1509 3383,-1503 3383,-1497 3383,-1497 3383,-1453 3383,-1453 3383,-1447 3389,-1441 3395,-1441 3395,-1441 3476,-1441 3476,-1441 3482,-1441 3488,-1447 3488,-1453 3488,-1453 3488,-1497 3488,-1497 3488,-1503 3482,-1509 3476,-1509\"/>\n<text text-anchor=\"start\" x=\"3392.5\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.817</text>\n<text text-anchor=\"start\" x=\"3398\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.111</text>\n<text text-anchor=\"start\" x=\"3392\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\n<text text-anchor=\"start\" x=\"3391\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 16]</text>\n</g>\n<!-- 237&#45;&gt;238 -->\n<g id=\"edge238\" class=\"edge\">\n<title>237&#45;&gt;238</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3445.63,-1544.88C3444.44,-1536.78 3443.14,-1527.98 3441.89,-1519.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3445.31,-1518.68 3440.4,-1509.3 3438.39,-1519.7 3445.31,-1518.68\"/>\n</g>\n<!-- 245 -->\n<g id=\"node246\" class=\"node\">\n<title>245</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M3631,-1509C3631,-1509 3518,-1509 3518,-1509 3512,-1509 3506,-1503 3506,-1497 3506,-1497 3506,-1453 3506,-1453 3506,-1447 3512,-1441 3518,-1441 3518,-1441 3631,-1441 3631,-1441 3637,-1441 3643,-1447 3643,-1453 3643,-1453 3643,-1497 3643,-1497 3643,-1503 3637,-1509 3631,-1509\"/>\n<text text-anchor=\"start\" x=\"3514\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Embarked_Q ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"3545.5\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"3535\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"3534\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 237&#45;&gt;245 -->\n<g id=\"edge245\" class=\"edge\">\n<title>237&#45;&gt;245</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3490.76,-1544.88C3502.02,-1535.62 3514.38,-1525.45 3526.06,-1515.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3528.52,-1518.36 3534.02,-1509.3 3524.07,-1512.95 3528.52,-1518.36\"/>\n</g>\n<!-- 239 -->\n<g id=\"node240\" class=\"node\">\n<title>239</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3353,-1397.5C3353,-1397.5 3280,-1397.5 3280,-1397.5 3274,-1397.5 3268,-1391.5 3268,-1385.5 3268,-1385.5 3268,-1356.5 3268,-1356.5 3268,-1350.5 3274,-1344.5 3280,-1344.5 3280,-1344.5 3353,-1344.5 3353,-1344.5 3359,-1344.5 3365,-1350.5 3365,-1356.5 3365,-1356.5 3365,-1385.5 3365,-1385.5 3365,-1391.5 3359,-1397.5 3353,-1397.5\"/>\n<text text-anchor=\"start\" x=\"3287.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3277\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"3276\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 5]</text>\n</g>\n<!-- 238&#45;&gt;239 -->\n<g id=\"edge239\" class=\"edge\">\n<title>238&#45;&gt;239</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3396.86,-1440.88C3383.14,-1429.12 3367.71,-1415.89 3354.07,-1404.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3356.14,-1401.37 3346.27,-1397.52 3351.59,-1406.69 3356.14,-1401.37\"/>\n</g>\n<!-- 240 -->\n<g id=\"node241\" class=\"node\">\n<title>240</title>\n<path fill=\"#4ba6e7\" stroke=\"black\" d=\"M3476,-1405C3476,-1405 3395,-1405 3395,-1405 3389,-1405 3383,-1399 3383,-1393 3383,-1393 3383,-1349 3383,-1349 3383,-1343 3389,-1337 3395,-1337 3395,-1337 3476,-1337 3476,-1337 3482,-1337 3488,-1343 3488,-1349 3488,-1349 3488,-1393 3488,-1393 3488,-1399 3482,-1405 3476,-1405\"/>\n<text text-anchor=\"start\" x=\"3392.5\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.809</text>\n<text text-anchor=\"start\" x=\"3398\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.153</text>\n<text text-anchor=\"start\" x=\"3392\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\n<text text-anchor=\"start\" x=\"3391\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 11]</text>\n</g>\n<!-- 238&#45;&gt;240 -->\n<g id=\"edge240\" class=\"edge\">\n<title>238&#45;&gt;240</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3435.5,-1440.88C3435.5,-1432.78 3435.5,-1423.98 3435.5,-1415.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3439,-1415.3 3435.5,-1405.3 3432,-1415.3 3439,-1415.3\"/>\n</g>\n<!-- 241 -->\n<g id=\"node242\" class=\"node\">\n<title>241</title>\n<path fill=\"#55abe9\" stroke=\"black\" d=\"M3415,-1301C3415,-1301 3340,-1301 3340,-1301 3334,-1301 3328,-1295 3328,-1289 3328,-1289 3328,-1245 3328,-1245 3328,-1239 3334,-1233 3340,-1233 3340,-1233 3415,-1233 3415,-1233 3421,-1233 3427,-1239 3427,-1245 3427,-1245 3427,-1289 3427,-1289 3427,-1295 3421,-1301 3415,-1301\"/>\n<text text-anchor=\"start\" x=\"3336\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.365</text>\n<text text-anchor=\"start\" x=\"3340\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.219</text>\n<text text-anchor=\"start\" x=\"3338\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"3337\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 7]</text>\n</g>\n<!-- 240&#45;&gt;241 -->\n<g id=\"edge241\" class=\"edge\">\n<title>240&#45;&gt;241</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3416.67,-1336.88C3411.81,-1328.33 3406.51,-1319.01 3401.42,-1310.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3404.42,-1308.26 3396.43,-1301.3 3398.34,-1311.72 3404.42,-1308.26\"/>\n</g>\n<!-- 244 -->\n<g id=\"node245\" class=\"node\">\n<title>244</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3530,-1293.5C3530,-1293.5 3457,-1293.5 3457,-1293.5 3451,-1293.5 3445,-1287.5 3445,-1281.5 3445,-1281.5 3445,-1252.5 3445,-1252.5 3445,-1246.5 3451,-1240.5 3457,-1240.5 3457,-1240.5 3530,-1240.5 3530,-1240.5 3536,-1240.5 3542,-1246.5 3542,-1252.5 3542,-1252.5 3542,-1281.5 3542,-1281.5 3542,-1287.5 3536,-1293.5 3530,-1293.5\"/>\n<text text-anchor=\"start\" x=\"3464.5\" y=\"-1278.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3454\" y=\"-1263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"3453\" y=\"-1248.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4]</text>\n</g>\n<!-- 240&#45;&gt;244 -->\n<g id=\"edge244\" class=\"edge\">\n<title>240&#45;&gt;244</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3454.33,-1336.88C3460.58,-1325.89 3467.56,-1313.62 3473.87,-1302.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3477.09,-1303.94 3478.99,-1293.52 3471,-1300.48 3477.09,-1303.94\"/>\n</g>\n<!-- 242 -->\n<g id=\"node243\" class=\"node\">\n<title>242</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3356,-1189.5C3356,-1189.5 3283,-1189.5 3283,-1189.5 3277,-1189.5 3271,-1183.5 3271,-1177.5 3271,-1177.5 3271,-1148.5 3271,-1148.5 3271,-1142.5 3277,-1136.5 3283,-1136.5 3283,-1136.5 3356,-1136.5 3356,-1136.5 3362,-1136.5 3368,-1142.5 3368,-1148.5 3368,-1148.5 3368,-1177.5 3368,-1177.5 3368,-1183.5 3362,-1189.5 3356,-1189.5\"/>\n<text text-anchor=\"start\" x=\"3290.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3280\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"3279\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 241&#45;&gt;242 -->\n<g id=\"edge242\" class=\"edge\">\n<title>241&#45;&gt;242</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3358.67,-1232.88C3352.42,-1221.89 3345.44,-1209.62 3339.13,-1198.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3342,-1196.48 3334.01,-1189.52 3335.91,-1199.94 3342,-1196.48\"/>\n</g>\n<!-- 243 -->\n<g id=\"node244\" class=\"node\">\n<title>243</title>\n<path fill=\"#61b1ea\" stroke=\"black\" d=\"M3471,-1189.5C3471,-1189.5 3398,-1189.5 3398,-1189.5 3392,-1189.5 3386,-1183.5 3386,-1177.5 3386,-1177.5 3386,-1148.5 3386,-1148.5 3386,-1142.5 3392,-1136.5 3398,-1136.5 3398,-1136.5 3471,-1136.5 3471,-1136.5 3477,-1136.5 3483,-1142.5 3483,-1148.5 3483,-1148.5 3483,-1177.5 3483,-1177.5 3483,-1183.5 3477,-1189.5 3471,-1189.5\"/>\n<text text-anchor=\"start\" x=\"3397\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.278</text>\n<text text-anchor=\"start\" x=\"3395\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"3394\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 5]</text>\n</g>\n<!-- 241&#45;&gt;243 -->\n<g id=\"edge243\" class=\"edge\">\n<title>241&#45;&gt;243</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3396.01,-1232.88C3402.15,-1221.89 3409.01,-1209.62 3415.21,-1198.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3418.42,-1199.96 3420.24,-1189.52 3412.31,-1196.54 3418.42,-1199.96\"/>\n</g>\n<!-- 246 -->\n<g id=\"node247\" class=\"node\">\n<title>246</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3591,-1397.5C3591,-1397.5 3518,-1397.5 3518,-1397.5 3512,-1397.5 3506,-1391.5 3506,-1385.5 3506,-1385.5 3506,-1356.5 3506,-1356.5 3506,-1350.5 3512,-1344.5 3518,-1344.5 3518,-1344.5 3591,-1344.5 3591,-1344.5 3597,-1344.5 3603,-1350.5 3603,-1356.5 3603,-1356.5 3603,-1385.5 3603,-1385.5 3603,-1391.5 3597,-1397.5 3591,-1397.5\"/>\n<text text-anchor=\"start\" x=\"3525.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3515\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3514\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 245&#45;&gt;246 -->\n<g id=\"edge246\" class=\"edge\">\n<title>245&#45;&gt;246</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3568.01,-1440.88C3565.91,-1430.22 3563.59,-1418.35 3561.46,-1407.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3564.86,-1406.66 3559.5,-1397.52 3557.99,-1408.01 3564.86,-1406.66\"/>\n</g>\n<!-- 247 -->\n<g id=\"node248\" class=\"node\">\n<title>247</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3706,-1397.5C3706,-1397.5 3633,-1397.5 3633,-1397.5 3627,-1397.5 3621,-1391.5 3621,-1385.5 3621,-1385.5 3621,-1356.5 3621,-1356.5 3621,-1350.5 3627,-1344.5 3633,-1344.5 3633,-1344.5 3706,-1344.5 3706,-1344.5 3712,-1344.5 3718,-1350.5 3718,-1356.5 3718,-1356.5 3718,-1385.5 3718,-1385.5 3718,-1391.5 3712,-1397.5 3706,-1397.5\"/>\n<text text-anchor=\"start\" x=\"3640.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3630\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3629\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 245&#45;&gt;247 -->\n<g id=\"edge247\" class=\"edge\">\n<title>245&#45;&gt;247</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3605.34,-1440.88C3616.1,-1429.34 3628.16,-1416.39 3638.89,-1404.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3641.48,-1407.22 3645.73,-1397.52 3636.35,-1402.45 3641.48,-1407.22\"/>\n</g>\n<!-- 253 -->\n<g id=\"node254\" class=\"node\">\n<title>253</title>\n<path fill=\"#fef9f5\" stroke=\"black\" d=\"M4063,-2029C4063,-2029 3974,-2029 3974,-2029 3968,-2029 3962,-2023 3962,-2017 3962,-2017 3962,-1973 3962,-1973 3962,-1967 3968,-1961 3974,-1961 3974,-1961 4063,-1961 4063,-1961 4069,-1961 4075,-1967 4075,-1973 4075,-1973 4075,-2017 4075,-2017 4075,-2023 4069,-2029 4063,-2029\"/>\n<text text-anchor=\"start\" x=\"3982\" y=\"-2013.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"3989.5\" y=\"-1998.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"3975\" y=\"-1983.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 39</text>\n<text text-anchor=\"start\" x=\"3970\" y=\"-1968.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [20, 19]</text>\n</g>\n<!-- 252&#45;&gt;253 -->\n<g id=\"edge253\" class=\"edge\">\n<title>252&#45;&gt;253</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4018.5,-2064.88C4018.5,-2056.78 4018.5,-2047.98 4018.5,-2039.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4022,-2039.3 4018.5,-2029.3 4015,-2039.3 4022,-2039.3\"/>\n</g>\n<!-- 286 -->\n<g id=\"node287\" class=\"node\">\n<title>286</title>\n<path fill=\"#e88e4e\" stroke=\"black\" d=\"M4349,-2029C4349,-2029 4268,-2029 4268,-2029 4262,-2029 4256,-2023 4256,-2017 4256,-2017 4256,-1973 4256,-1973 4256,-1967 4262,-1961 4268,-1961 4268,-1961 4349,-1961 4349,-1961 4355,-1961 4361,-1967 4361,-1973 4361,-1973 4361,-2017 4361,-2017 4361,-2023 4355,-2029 4349,-2029\"/>\n<text text-anchor=\"start\" x=\"4267\" y=\"-2013.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;1.787</text>\n<text text-anchor=\"start\" x=\"4271\" y=\"-1998.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.172</text>\n<text text-anchor=\"start\" x=\"4265\" y=\"-1983.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 21</text>\n<text text-anchor=\"start\" x=\"4264\" y=\"-1968.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [19, 2]</text>\n</g>\n<!-- 252&#45;&gt;286 -->\n<g id=\"edge286\" class=\"edge\">\n<title>252&#45;&gt;286</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4075.1,-2078.09C4124.35,-2060.77 4195.59,-2035.71 4246.39,-2017.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4247.67,-2021.11 4255.94,-2014.49 4245.35,-2014.5 4247.67,-2021.11\"/>\n</g>\n<!-- 254 -->\n<g id=\"node255\" class=\"node\">\n<title>254</title>\n<path fill=\"#f4caac\" stroke=\"black\" d=\"M4002,-1925C4002,-1925 3913,-1925 3913,-1925 3907,-1925 3901,-1919 3901,-1913 3901,-1913 3901,-1869 3901,-1869 3901,-1863 3907,-1857 3913,-1857 3913,-1857 4002,-1857 4002,-1857 4008,-1857 4014,-1863 4014,-1869 4014,-1869 4014,-1913 4014,-1913 4014,-1919 4008,-1925 4002,-1925\"/>\n<text text-anchor=\"start\" x=\"3914.5\" y=\"-1909.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.815</text>\n<text text-anchor=\"start\" x=\"3920\" y=\"-1894.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.464</text>\n<text text-anchor=\"start\" x=\"3914\" y=\"-1879.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30</text>\n<text text-anchor=\"start\" x=\"3909\" y=\"-1864.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [19, 11]</text>\n</g>\n<!-- 253&#45;&gt;254 -->\n<g id=\"edge254\" class=\"edge\">\n<title>253&#45;&gt;254</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3998.7,-1960.88C3993.58,-1952.33 3988.01,-1943.01 3982.66,-1934.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3985.55,-1932.09 3977.41,-1925.3 3979.54,-1935.68 3985.55,-1932.09\"/>\n</g>\n<!-- 283 -->\n<g id=\"node284\" class=\"node\">\n<title>283</title>\n<path fill=\"#52a9e8\" stroke=\"black\" d=\"M4117,-1925C4117,-1925 4044,-1925 4044,-1925 4038,-1925 4032,-1919 4032,-1913 4032,-1913 4032,-1869 4032,-1869 4032,-1863 4038,-1857 4044,-1857 4044,-1857 4117,-1857 4117,-1857 4123,-1857 4129,-1863 4129,-1869 4129,-1869 4129,-1913 4129,-1913 4129,-1919 4123,-1925 4117,-1925\"/>\n<text text-anchor=\"start\" x=\"4045.5\" y=\"-1909.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.64</text>\n<text text-anchor=\"start\" x=\"4043\" y=\"-1894.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.198</text>\n<text text-anchor=\"start\" x=\"4041\" y=\"-1879.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"4040\" y=\"-1864.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 8]</text>\n</g>\n<!-- 253&#45;&gt;283 -->\n<g id=\"edge283\" class=\"edge\">\n<title>253&#45;&gt;283</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4038.63,-1960.88C4043.83,-1952.33 4049.49,-1943.01 4054.93,-1934.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4058.06,-1935.66 4060.26,-1925.3 4052.07,-1932.03 4058.06,-1935.66\"/>\n</g>\n<!-- 255 -->\n<g id=\"node256\" class=\"node\">\n<title>255</title>\n<path fill=\"#6ab6ec\" stroke=\"black\" d=\"M3877,-1821C3877,-1821 3802,-1821 3802,-1821 3796,-1821 3790,-1815 3790,-1809 3790,-1809 3790,-1765 3790,-1765 3790,-1759 3796,-1753 3802,-1753 3802,-1753 3877,-1753 3877,-1753 3883,-1753 3889,-1759 3889,-1765 3889,-1765 3889,-1809 3889,-1809 3889,-1815 3883,-1821 3877,-1821\"/>\n<text text-anchor=\"start\" x=\"3798\" y=\"-1805.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.326</text>\n<text text-anchor=\"start\" x=\"3806\" y=\"-1790.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"3800\" y=\"-1775.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"3799\" y=\"-1760.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 4]</text>\n</g>\n<!-- 254&#45;&gt;255 -->\n<g id=\"edge255\" class=\"edge\">\n<title>254&#45;&gt;255</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3919.19,-1856.88C3908.47,-1847.62 3896.71,-1837.45 3885.6,-1827.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3887.88,-1825.19 3878.02,-1821.3 3883.3,-1830.49 3887.88,-1825.19\"/>\n</g>\n<!-- 258 -->\n<g id=\"node259\" class=\"node\">\n<title>258</title>\n<path fill=\"#efb286\" stroke=\"black\" d=\"M4000,-1821C4000,-1821 3919,-1821 3919,-1821 3913,-1821 3907,-1815 3907,-1809 3907,-1809 3907,-1765 3907,-1765 3907,-1759 3913,-1753 3919,-1753 3919,-1753 4000,-1753 4000,-1753 4006,-1753 4012,-1759 4012,-1765 4012,-1765 4012,-1809 4012,-1809 4012,-1815 4006,-1821 4000,-1821\"/>\n<text text-anchor=\"start\" x=\"3918\" y=\"-1805.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.785</text>\n<text text-anchor=\"start\" x=\"3922\" y=\"-1790.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.403</text>\n<text text-anchor=\"start\" x=\"3916\" y=\"-1775.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 25</text>\n<text text-anchor=\"start\" x=\"3915\" y=\"-1760.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [18, 7]</text>\n</g>\n<!-- 254&#45;&gt;258 -->\n<g id=\"edge258\" class=\"edge\">\n<title>254&#45;&gt;258</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3958.15,-1856.88C3958.31,-1848.78 3958.48,-1839.98 3958.65,-1831.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3962.15,-1831.37 3958.85,-1821.3 3955.15,-1831.23 3962.15,-1831.37\"/>\n</g>\n<!-- 256 -->\n<g id=\"node257\" class=\"node\">\n<title>256</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3764,-1709.5C3764,-1709.5 3691,-1709.5 3691,-1709.5 3685,-1709.5 3679,-1703.5 3679,-1697.5 3679,-1697.5 3679,-1668.5 3679,-1668.5 3679,-1662.5 3685,-1656.5 3691,-1656.5 3691,-1656.5 3764,-1656.5 3764,-1656.5 3770,-1656.5 3776,-1662.5 3776,-1668.5 3776,-1668.5 3776,-1697.5 3776,-1697.5 3776,-1703.5 3770,-1709.5 3764,-1709.5\"/>\n<text text-anchor=\"start\" x=\"3698.5\" y=\"-1694.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3688\" y=\"-1679.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"3687\" y=\"-1664.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4]</text>\n</g>\n<!-- 255&#45;&gt;256 -->\n<g id=\"edge256\" class=\"edge\">\n<title>255&#45;&gt;256</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3803.14,-1752.88C3790.34,-1741.23 3775.97,-1728.14 3763.22,-1716.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3765.27,-1713.67 3755.52,-1709.52 3760.56,-1718.84 3765.27,-1713.67\"/>\n</g>\n<!-- 257 -->\n<g id=\"node258\" class=\"node\">\n<title>257</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3879,-1709.5C3879,-1709.5 3806,-1709.5 3806,-1709.5 3800,-1709.5 3794,-1703.5 3794,-1697.5 3794,-1697.5 3794,-1668.5 3794,-1668.5 3794,-1662.5 3800,-1656.5 3806,-1656.5 3806,-1656.5 3879,-1656.5 3879,-1656.5 3885,-1656.5 3891,-1662.5 3891,-1668.5 3891,-1668.5 3891,-1697.5 3891,-1697.5 3891,-1703.5 3885,-1709.5 3879,-1709.5\"/>\n<text text-anchor=\"start\" x=\"3813.5\" y=\"-1694.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3803\" y=\"-1679.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3802\" y=\"-1664.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 255&#45;&gt;257 -->\n<g id=\"edge257\" class=\"edge\">\n<title>255&#45;&gt;257</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3840.47,-1752.88C3840.79,-1742.22 3841.14,-1730.35 3841.46,-1719.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3844.95,-1719.62 3841.75,-1709.52 3837.96,-1719.41 3844.95,-1719.62\"/>\n</g>\n<!-- 259 -->\n<g id=\"node260\" class=\"node\">\n<title>259</title>\n<path fill=\"#bddef6\" stroke=\"black\" d=\"M3996,-1717C3996,-1717 3923,-1717 3923,-1717 3917,-1717 3911,-1711 3911,-1705 3911,-1705 3911,-1661 3911,-1661 3911,-1655 3917,-1649 3923,-1649 3923,-1649 3996,-1649 3996,-1649 4002,-1649 4008,-1655 4008,-1661 4008,-1661 4008,-1705 4008,-1705 4008,-1711 4002,-1717 3996,-1717\"/>\n<text text-anchor=\"start\" x=\"3922\" y=\"-1701.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 1.5</text>\n<text text-anchor=\"start\" x=\"3926\" y=\"-1686.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n<text text-anchor=\"start\" x=\"3920\" y=\"-1671.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"3919\" y=\"-1656.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 3]</text>\n</g>\n<!-- 258&#45;&gt;259 -->\n<g id=\"edge259\" class=\"edge\">\n<title>258&#45;&gt;259</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3959.5,-1752.88C3959.5,-1744.78 3959.5,-1735.98 3959.5,-1727.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3963,-1727.3 3959.5,-1717.3 3956,-1727.3 3963,-1727.3\"/>\n</g>\n<!-- 266 -->\n<g id=\"node267\" class=\"node\">\n<title>266</title>\n<path fill=\"#eca06a\" stroke=\"black\" d=\"M4228,-1717C4228,-1717 4147,-1717 4147,-1717 4141,-1717 4135,-1711 4135,-1705 4135,-1705 4135,-1661 4135,-1661 4135,-1655 4141,-1649 4147,-1649 4147,-1649 4228,-1649 4228,-1649 4234,-1649 4240,-1655 4240,-1661 4240,-1661 4240,-1705 4240,-1705 4240,-1711 4234,-1717 4228,-1717\"/>\n<text text-anchor=\"start\" x=\"4144.5\" y=\"-1701.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.175</text>\n<text text-anchor=\"start\" x=\"4154\" y=\"-1686.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"4144\" y=\"-1671.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 20</text>\n<text text-anchor=\"start\" x=\"4143\" y=\"-1656.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [16, 4]</text>\n</g>\n<!-- 258&#45;&gt;266 -->\n<g id=\"edge266\" class=\"edge\">\n<title>258&#45;&gt;266</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4012.23,-1757.04C4015.01,-1755.65 4017.78,-1754.29 4020.5,-1753 4054.65,-1736.76 4093.66,-1720.52 4125.39,-1707.88\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4126.98,-1711.01 4134.99,-1704.07 4124.4,-1704.5 4126.98,-1711.01\"/>\n</g>\n<!-- 260 -->\n<g id=\"node261\" class=\"node\">\n<title>260</title>\n<path fill=\"#7bbeee\" stroke=\"black\" d=\"M3905,-1613C3905,-1613 3830,-1613 3830,-1613 3824,-1613 3818,-1607 3818,-1601 3818,-1601 3818,-1557 3818,-1557 3818,-1551 3824,-1545 3830,-1545 3830,-1545 3905,-1545 3905,-1545 3911,-1545 3917,-1551 3917,-1557 3917,-1557 3917,-1601 3917,-1601 3917,-1607 3911,-1613 3905,-1613\"/>\n<text text-anchor=\"start\" x=\"3826\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;1.055</text>\n<text text-anchor=\"start\" x=\"3830\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"3828\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"3827\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 3]</text>\n</g>\n<!-- 259&#45;&gt;260 -->\n<g id=\"edge260\" class=\"edge\">\n<title>259&#45;&gt;260</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3929.63,-1648.88C3921.6,-1639.98 3912.81,-1630.24 3904.44,-1620.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3906.83,-1618.38 3897.53,-1613.3 3901.63,-1623.07 3906.83,-1618.38\"/>\n</g>\n<!-- 265 -->\n<g id=\"node266\" class=\"node\">\n<title>265</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4020,-1605.5C4020,-1605.5 3947,-1605.5 3947,-1605.5 3941,-1605.5 3935,-1599.5 3935,-1593.5 3935,-1593.5 3935,-1564.5 3935,-1564.5 3935,-1558.5 3941,-1552.5 3947,-1552.5 3947,-1552.5 4020,-1552.5 4020,-1552.5 4026,-1552.5 4032,-1558.5 4032,-1564.5 4032,-1564.5 4032,-1593.5 4032,-1593.5 4032,-1599.5 4026,-1605.5 4020,-1605.5\"/>\n<text text-anchor=\"start\" x=\"3954.5\" y=\"-1590.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3944\" y=\"-1575.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3943\" y=\"-1560.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 259&#45;&gt;265 -->\n<g id=\"edge265\" class=\"edge\">\n<title>259&#45;&gt;265</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3967.29,-1648.88C3969.8,-1638.22 3972.59,-1626.35 3975.14,-1615.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3978.61,-1616.06 3977.5,-1605.52 3971.8,-1614.45 3978.61,-1616.06\"/>\n</g>\n<!-- 261 -->\n<g id=\"node262\" class=\"node\">\n<title>261</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M3864,-1509C3864,-1509 3789,-1509 3789,-1509 3783,-1509 3777,-1503 3777,-1497 3777,-1497 3777,-1453 3777,-1453 3777,-1447 3783,-1441 3789,-1441 3789,-1441 3864,-1441 3864,-1441 3870,-1441 3876,-1447 3876,-1453 3876,-1453 3876,-1497 3876,-1497 3876,-1503 3870,-1509 3864,-1509\"/>\n<text text-anchor=\"start\" x=\"3785\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;1.556</text>\n<text text-anchor=\"start\" x=\"3797.5\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"3787\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"3786\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 260&#45;&gt;261 -->\n<g id=\"edge261\" class=\"edge\">\n<title>260&#45;&gt;261</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3854.19,-1544.88C3850.82,-1536.51 3847.16,-1527.4 3843.64,-1518.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3846.86,-1517.27 3839.89,-1509.3 3840.37,-1519.88 3846.86,-1517.27\"/>\n</g>\n<!-- 264 -->\n<g id=\"node265\" class=\"node\">\n<title>264</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3979,-1501.5C3979,-1501.5 3906,-1501.5 3906,-1501.5 3900,-1501.5 3894,-1495.5 3894,-1489.5 3894,-1489.5 3894,-1460.5 3894,-1460.5 3894,-1454.5 3900,-1448.5 3906,-1448.5 3906,-1448.5 3979,-1448.5 3979,-1448.5 3985,-1448.5 3991,-1454.5 3991,-1460.5 3991,-1460.5 3991,-1489.5 3991,-1489.5 3991,-1495.5 3985,-1501.5 3979,-1501.5\"/>\n<text text-anchor=\"start\" x=\"3913.5\" y=\"-1486.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3903\" y=\"-1471.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"3902\" y=\"-1456.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 260&#45;&gt;264 -->\n<g id=\"edge264\" class=\"edge\">\n<title>260&#45;&gt;264</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3891.85,-1544.88C3900.1,-1533.67 3909.32,-1521.13 3917.61,-1509.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3920.63,-1511.65 3923.74,-1501.52 3914.99,-1507.5 3920.63,-1511.65\"/>\n</g>\n<!-- 262 -->\n<g id=\"node263\" class=\"node\">\n<title>262</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3821,-1397.5C3821,-1397.5 3748,-1397.5 3748,-1397.5 3742,-1397.5 3736,-1391.5 3736,-1385.5 3736,-1385.5 3736,-1356.5 3736,-1356.5 3736,-1350.5 3742,-1344.5 3748,-1344.5 3748,-1344.5 3821,-1344.5 3821,-1344.5 3827,-1344.5 3833,-1350.5 3833,-1356.5 3833,-1356.5 3833,-1385.5 3833,-1385.5 3833,-1391.5 3827,-1397.5 3821,-1397.5\"/>\n<text text-anchor=\"start\" x=\"3755.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3745\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3744\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 261&#45;&gt;262 -->\n<g id=\"edge262\" class=\"edge\">\n<title>261&#45;&gt;262</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3812.86,-1440.88C3808.38,-1430 3803.38,-1417.86 3798.85,-1406.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3802.05,-1405.43 3795.01,-1397.52 3795.58,-1408.1 3802.05,-1405.43\"/>\n</g>\n<!-- 263 -->\n<g id=\"node264\" class=\"node\">\n<title>263</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3936,-1397.5C3936,-1397.5 3863,-1397.5 3863,-1397.5 3857,-1397.5 3851,-1391.5 3851,-1385.5 3851,-1385.5 3851,-1356.5 3851,-1356.5 3851,-1350.5 3857,-1344.5 3863,-1344.5 3863,-1344.5 3936,-1344.5 3936,-1344.5 3942,-1344.5 3948,-1350.5 3948,-1356.5 3948,-1356.5 3948,-1385.5 3948,-1385.5 3948,-1391.5 3942,-1397.5 3936,-1397.5\"/>\n<text text-anchor=\"start\" x=\"3870.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3860\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3859\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 261&#45;&gt;263 -->\n<g id=\"edge263\" class=\"edge\">\n<title>261&#45;&gt;263</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3850.2,-1440.88C3858.23,-1429.67 3867.2,-1417.13 3875.27,-1405.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3878.26,-1407.69 3881.24,-1397.52 3872.57,-1403.61 3878.26,-1407.69\"/>\n</g>\n<!-- 267 -->\n<g id=\"node268\" class=\"node\">\n<title>267</title>\n<path fill=\"#e99355\" stroke=\"black\" d=\"M4228,-1613C4228,-1613 4147,-1613 4147,-1613 4141,-1613 4135,-1607 4135,-1601 4135,-1601 4135,-1557 4135,-1557 4135,-1551 4141,-1545 4147,-1545 4147,-1545 4228,-1545 4228,-1545 4234,-1545 4240,-1551 4240,-1557 4240,-1557 4240,-1601 4240,-1601 4240,-1607 4234,-1613 4228,-1613\"/>\n<text text-anchor=\"start\" x=\"4144.5\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.809</text>\n<text text-anchor=\"start\" x=\"4150\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.219</text>\n<text text-anchor=\"start\" x=\"4144\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"start\" x=\"4143\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [14, 2]</text>\n</g>\n<!-- 266&#45;&gt;267 -->\n<g id=\"edge267\" class=\"edge\">\n<title>266&#45;&gt;267</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4187.5,-1648.88C4187.5,-1640.78 4187.5,-1631.98 4187.5,-1623.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4191,-1623.3 4187.5,-1613.3 4184,-1623.3 4191,-1623.3\"/>\n</g>\n<!-- 278 -->\n<g id=\"node279\" class=\"node\">\n<title>278</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M4517,-1613C4517,-1613 4444,-1613 4444,-1613 4438,-1613 4432,-1607 4432,-1601 4432,-1601 4432,-1557 4432,-1557 4432,-1551 4438,-1545 4444,-1545 4444,-1545 4517,-1545 4517,-1545 4523,-1545 4529,-1551 4529,-1557 4529,-1557 4529,-1601 4529,-1601 4529,-1607 4523,-1613 4517,-1613\"/>\n<text text-anchor=\"start\" x=\"4441.5\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.07</text>\n<text text-anchor=\"start\" x=\"4451.5\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"4441\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"4440\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 2]</text>\n</g>\n<!-- 266&#45;&gt;278 -->\n<g id=\"edge278\" class=\"edge\">\n<title>266&#45;&gt;278</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4240.22,-1663.65C4291.41,-1645.83 4368.94,-1618.84 4422,-1600.37\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4423.32,-1603.61 4431.61,-1597.02 4421.02,-1597 4423.32,-1603.61\"/>\n</g>\n<!-- 268 -->\n<g id=\"node269\" class=\"node\">\n<title>268</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M4165,-1509C4165,-1509 4090,-1509 4090,-1509 4084,-1509 4078,-1503 4078,-1497 4078,-1497 4078,-1453 4078,-1453 4078,-1447 4084,-1441 4090,-1441 4090,-1441 4165,-1441 4165,-1441 4171,-1441 4177,-1447 4177,-1453 4177,-1453 4177,-1497 4177,-1497 4177,-1503 4171,-1509 4165,-1509\"/>\n<text text-anchor=\"start\" x=\"4086\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.477</text>\n<text text-anchor=\"start\" x=\"4098.5\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"4088\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"4087\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 267&#45;&gt;268 -->\n<g id=\"edge268\" class=\"edge\">\n<title>267&#45;&gt;268</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4168.02,-1544.88C4162.99,-1536.33 4157.51,-1527.01 4152.25,-1518.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4155.17,-1516.14 4147.09,-1509.3 4149.14,-1519.69 4155.17,-1516.14\"/>\n</g>\n<!-- 271 -->\n<g id=\"node272\" class=\"node\">\n<title>271</title>\n<path fill=\"#e78b48\" stroke=\"black\" d=\"M4288,-1509C4288,-1509 4207,-1509 4207,-1509 4201,-1509 4195,-1503 4195,-1497 4195,-1497 4195,-1453 4195,-1453 4195,-1447 4201,-1441 4207,-1441 4207,-1441 4288,-1441 4288,-1441 4294,-1441 4300,-1447 4300,-1453 4300,-1453 4300,-1497 4300,-1497 4300,-1503 4294,-1509 4288,-1509\"/>\n<text text-anchor=\"start\" x=\"4206\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.015</text>\n<text text-anchor=\"start\" x=\"4210\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.133</text>\n<text text-anchor=\"start\" x=\"4204\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14</text>\n<text text-anchor=\"start\" x=\"4203\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 1]</text>\n</g>\n<!-- 267&#45;&gt;271 -->\n<g id=\"edge271\" class=\"edge\">\n<title>267&#45;&gt;271</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4206.98,-1544.88C4212.01,-1536.33 4217.49,-1527.01 4222.75,-1518.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4225.86,-1519.69 4227.91,-1509.3 4219.83,-1516.14 4225.86,-1519.69\"/>\n</g>\n<!-- 269 -->\n<g id=\"node270\" class=\"node\">\n<title>269</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4051,-1397.5C4051,-1397.5 3978,-1397.5 3978,-1397.5 3972,-1397.5 3966,-1391.5 3966,-1385.5 3966,-1385.5 3966,-1356.5 3966,-1356.5 3966,-1350.5 3972,-1344.5 3978,-1344.5 3978,-1344.5 4051,-1344.5 4051,-1344.5 4057,-1344.5 4063,-1350.5 4063,-1356.5 4063,-1356.5 4063,-1385.5 4063,-1385.5 4063,-1391.5 4057,-1397.5 4051,-1397.5\"/>\n<text text-anchor=\"start\" x=\"3985.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3975\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3974\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 268&#45;&gt;269 -->\n<g id=\"edge269\" class=\"edge\">\n<title>268&#45;&gt;269</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4090.81,-1440.88C4077.9,-1429.23 4063.4,-1416.14 4050.54,-1404.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4052.54,-1401.62 4042.77,-1397.52 4047.85,-1406.82 4052.54,-1401.62\"/>\n</g>\n<!-- 270 -->\n<g id=\"node271\" class=\"node\">\n<title>270</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4166,-1397.5C4166,-1397.5 4093,-1397.5 4093,-1397.5 4087,-1397.5 4081,-1391.5 4081,-1385.5 4081,-1385.5 4081,-1356.5 4081,-1356.5 4081,-1350.5 4087,-1344.5 4093,-1344.5 4093,-1344.5 4166,-1344.5 4166,-1344.5 4172,-1344.5 4178,-1350.5 4178,-1356.5 4178,-1356.5 4178,-1385.5 4178,-1385.5 4178,-1391.5 4172,-1397.5 4166,-1397.5\"/>\n<text text-anchor=\"start\" x=\"4100.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4090\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"4089\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 268&#45;&gt;270 -->\n<g id=\"edge270\" class=\"edge\">\n<title>268&#45;&gt;270</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4128.15,-1440.88C4128.36,-1430.22 4128.59,-1418.35 4128.8,-1407.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4132.3,-1407.59 4129,-1397.52 4125.3,-1407.45 4132.3,-1407.59\"/>\n</g>\n<!-- 272 -->\n<g id=\"node273\" class=\"node\">\n<title>272</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4281,-1397.5C4281,-1397.5 4208,-1397.5 4208,-1397.5 4202,-1397.5 4196,-1391.5 4196,-1385.5 4196,-1385.5 4196,-1356.5 4196,-1356.5 4196,-1350.5 4202,-1344.5 4208,-1344.5 4208,-1344.5 4281,-1344.5 4281,-1344.5 4287,-1344.5 4293,-1350.5 4293,-1356.5 4293,-1356.5 4293,-1385.5 4293,-1385.5 4293,-1391.5 4287,-1397.5 4281,-1397.5\"/>\n<text text-anchor=\"start\" x=\"4215.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4205\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"4204\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 0]</text>\n</g>\n<!-- 271&#45;&gt;272 -->\n<g id=\"edge272\" class=\"edge\">\n<title>271&#45;&gt;272</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4246.53,-1440.88C4246.21,-1430.22 4245.86,-1418.35 4245.54,-1407.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4249.04,-1407.41 4245.25,-1397.52 4242.05,-1407.62 4249.04,-1407.41\"/>\n</g>\n<!-- 273 -->\n<g id=\"node274\" class=\"node\">\n<title>273</title>\n<path fill=\"#eca06a\" stroke=\"black\" d=\"M4401.5,-1405C4401.5,-1405 4323.5,-1405 4323.5,-1405 4317.5,-1405 4311.5,-1399 4311.5,-1393 4311.5,-1393 4311.5,-1349 4311.5,-1349 4311.5,-1343 4317.5,-1337 4323.5,-1337 4323.5,-1337 4401.5,-1337 4401.5,-1337 4407.5,-1337 4413.5,-1343 4413.5,-1349 4413.5,-1349 4413.5,-1393 4413.5,-1393 4413.5,-1399 4407.5,-1405 4401.5,-1405\"/>\n<text text-anchor=\"start\" x=\"4319.5\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.671</text>\n<text text-anchor=\"start\" x=\"4329\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"4323\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"4322\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 1]</text>\n</g>\n<!-- 271&#45;&gt;273 -->\n<g id=\"edge273\" class=\"edge\">\n<title>271&#45;&gt;273</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4284.84,-1440.88C4295.18,-1431.71 4306.52,-1421.65 4317.26,-1412.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4319.8,-1414.55 4324.96,-1405.3 4315.15,-1409.32 4319.8,-1414.55\"/>\n</g>\n<!-- 274 -->\n<g id=\"node275\" class=\"node\">\n<title>274</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M4342.5,-1301C4342.5,-1301 4264.5,-1301 4264.5,-1301 4258.5,-1301 4252.5,-1295 4252.5,-1289 4252.5,-1289 4252.5,-1245 4252.5,-1245 4252.5,-1239 4258.5,-1233 4264.5,-1233 4264.5,-1233 4342.5,-1233 4342.5,-1233 4348.5,-1233 4354.5,-1239 4354.5,-1245 4354.5,-1245 4354.5,-1289 4354.5,-1289 4354.5,-1295 4348.5,-1301 4342.5,-1301\"/>\n<text text-anchor=\"start\" x=\"4260.5\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.758</text>\n<text text-anchor=\"start\" x=\"4274.5\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"4264\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"4263\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 273&#45;&gt;274 -->\n<g id=\"edge274\" class=\"edge\">\n<title>273&#45;&gt;274</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4343.34,-1336.88C4338.4,-1328.33 4333.01,-1319.01 4327.84,-1310.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4330.8,-1308.2 4322.76,-1301.3 4324.74,-1311.71 4330.8,-1308.2\"/>\n</g>\n<!-- 277 -->\n<g id=\"node278\" class=\"node\">\n<title>277</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4458,-1293.5C4458,-1293.5 4385,-1293.5 4385,-1293.5 4379,-1293.5 4373,-1287.5 4373,-1281.5 4373,-1281.5 4373,-1252.5 4373,-1252.5 4373,-1246.5 4379,-1240.5 4385,-1240.5 4385,-1240.5 4458,-1240.5 4458,-1240.5 4464,-1240.5 4470,-1246.5 4470,-1252.5 4470,-1252.5 4470,-1281.5 4470,-1281.5 4470,-1287.5 4464,-1293.5 4458,-1293.5\"/>\n<text text-anchor=\"start\" x=\"4392.5\" y=\"-1278.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4382\" y=\"-1263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"4381\" y=\"-1248.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 273&#45;&gt;277 -->\n<g id=\"edge277\" class=\"edge\">\n<title>273&#45;&gt;277</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4381.66,-1336.88C4388.08,-1325.78 4395.26,-1313.37 4401.73,-1302.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4404.76,-1303.93 4406.74,-1293.52 4398.7,-1300.42 4404.76,-1303.93\"/>\n</g>\n<!-- 275 -->\n<g id=\"node276\" class=\"node\">\n<title>275</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4282,-1189.5C4282,-1189.5 4209,-1189.5 4209,-1189.5 4203,-1189.5 4197,-1183.5 4197,-1177.5 4197,-1177.5 4197,-1148.5 4197,-1148.5 4197,-1142.5 4203,-1136.5 4209,-1136.5 4209,-1136.5 4282,-1136.5 4282,-1136.5 4288,-1136.5 4294,-1142.5 4294,-1148.5 4294,-1148.5 4294,-1177.5 4294,-1177.5 4294,-1183.5 4288,-1189.5 4282,-1189.5\"/>\n<text text-anchor=\"start\" x=\"4216.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4206\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"4205\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 274&#45;&gt;275 -->\n<g id=\"edge275\" class=\"edge\">\n<title>274&#45;&gt;275</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4284.67,-1232.88C4278.42,-1221.89 4271.44,-1209.62 4265.13,-1198.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4268,-1196.48 4260.01,-1189.52 4261.91,-1199.94 4268,-1196.48\"/>\n</g>\n<!-- 276 -->\n<g id=\"node277\" class=\"node\">\n<title>276</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4397,-1189.5C4397,-1189.5 4324,-1189.5 4324,-1189.5 4318,-1189.5 4312,-1183.5 4312,-1177.5 4312,-1177.5 4312,-1148.5 4312,-1148.5 4312,-1142.5 4318,-1136.5 4324,-1136.5 4324,-1136.5 4397,-1136.5 4397,-1136.5 4403,-1136.5 4409,-1142.5 4409,-1148.5 4409,-1148.5 4409,-1177.5 4409,-1177.5 4409,-1183.5 4403,-1189.5 4397,-1189.5\"/>\n<text text-anchor=\"start\" x=\"4331.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4321\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"4320\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 274&#45;&gt;276 -->\n<g id=\"edge276\" class=\"edge\">\n<title>274&#45;&gt;276</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4322.01,-1232.88C4328.15,-1221.89 4335.01,-1209.62 4341.21,-1198.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4344.42,-1199.96 4346.24,-1189.52 4338.31,-1196.54 4344.42,-1199.96\"/>\n</g>\n<!-- 279 -->\n<g id=\"node280\" class=\"node\">\n<title>279</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M4518,-1509C4518,-1509 4443,-1509 4443,-1509 4437,-1509 4431,-1503 4431,-1497 4431,-1497 4431,-1453 4431,-1453 4431,-1447 4437,-1441 4443,-1441 4443,-1441 4518,-1441 4518,-1441 4524,-1441 4530,-1447 4530,-1453 4530,-1453 4530,-1497 4530,-1497 4530,-1503 4524,-1509 4518,-1509\"/>\n<text text-anchor=\"start\" x=\"4439\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.211</text>\n<text text-anchor=\"start\" x=\"4443\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"4441\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"4440\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 278&#45;&gt;279 -->\n<g id=\"edge279\" class=\"edge\">\n<title>278&#45;&gt;279</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4480.5,-1544.88C4480.5,-1536.78 4480.5,-1527.98 4480.5,-1519.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4484,-1519.3 4480.5,-1509.3 4477,-1519.3 4484,-1519.3\"/>\n</g>\n<!-- 282 -->\n<g id=\"node283\" class=\"node\">\n<title>282</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4633,-1501.5C4633,-1501.5 4560,-1501.5 4560,-1501.5 4554,-1501.5 4548,-1495.5 4548,-1489.5 4548,-1489.5 4548,-1460.5 4548,-1460.5 4548,-1454.5 4554,-1448.5 4560,-1448.5 4560,-1448.5 4633,-1448.5 4633,-1448.5 4639,-1448.5 4645,-1454.5 4645,-1460.5 4645,-1460.5 4645,-1489.5 4645,-1489.5 4645,-1495.5 4639,-1501.5 4633,-1501.5\"/>\n<text text-anchor=\"start\" x=\"4567.5\" y=\"-1486.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4557\" y=\"-1471.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"4556\" y=\"-1456.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 278&#45;&gt;282 -->\n<g id=\"edge282\" class=\"edge\">\n<title>278&#45;&gt;282</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4518.16,-1544.88C4531.54,-1533.12 4546.58,-1519.89 4559.88,-1508.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4562.28,-1510.75 4567.48,-1501.52 4557.66,-1505.49 4562.28,-1510.75\"/>\n</g>\n<!-- 280 -->\n<g id=\"node281\" class=\"node\">\n<title>280</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4517,-1397.5C4517,-1397.5 4444,-1397.5 4444,-1397.5 4438,-1397.5 4432,-1391.5 4432,-1385.5 4432,-1385.5 4432,-1356.5 4432,-1356.5 4432,-1350.5 4438,-1344.5 4444,-1344.5 4444,-1344.5 4517,-1344.5 4517,-1344.5 4523,-1344.5 4529,-1350.5 4529,-1356.5 4529,-1356.5 4529,-1385.5 4529,-1385.5 4529,-1391.5 4523,-1397.5 4517,-1397.5\"/>\n<text text-anchor=\"start\" x=\"4451.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4441\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"4440\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 279&#45;&gt;280 -->\n<g id=\"edge280\" class=\"edge\">\n<title>279&#45;&gt;280</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4480.5,-1440.88C4480.5,-1430.33 4480.5,-1418.6 4480.5,-1407.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4484,-1407.52 4480.5,-1397.52 4477,-1407.52 4484,-1407.52\"/>\n</g>\n<!-- 281 -->\n<g id=\"node282\" class=\"node\">\n<title>281</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4632,-1397.5C4632,-1397.5 4559,-1397.5 4559,-1397.5 4553,-1397.5 4547,-1391.5 4547,-1385.5 4547,-1385.5 4547,-1356.5 4547,-1356.5 4547,-1350.5 4553,-1344.5 4559,-1344.5 4559,-1344.5 4632,-1344.5 4632,-1344.5 4638,-1344.5 4644,-1350.5 4644,-1356.5 4644,-1356.5 4644,-1385.5 4644,-1385.5 4644,-1391.5 4638,-1397.5 4632,-1397.5\"/>\n<text text-anchor=\"start\" x=\"4566.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4556\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"4555\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 279&#45;&gt;281 -->\n<g id=\"edge281\" class=\"edge\">\n<title>279&#45;&gt;281</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4517.84,-1440.88C4531.1,-1429.12 4546.01,-1415.89 4559.19,-1404.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4561.57,-1406.77 4566.73,-1397.52 4556.92,-1401.54 4561.57,-1406.77\"/>\n</g>\n<!-- 284 -->\n<g id=\"node285\" class=\"node\">\n<title>284</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4115,-1813.5C4115,-1813.5 4042,-1813.5 4042,-1813.5 4036,-1813.5 4030,-1807.5 4030,-1801.5 4030,-1801.5 4030,-1772.5 4030,-1772.5 4030,-1766.5 4036,-1760.5 4042,-1760.5 4042,-1760.5 4115,-1760.5 4115,-1760.5 4121,-1760.5 4127,-1766.5 4127,-1772.5 4127,-1772.5 4127,-1801.5 4127,-1801.5 4127,-1807.5 4121,-1813.5 4115,-1813.5\"/>\n<text text-anchor=\"start\" x=\"4049.5\" y=\"-1798.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4039\" y=\"-1783.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"4038\" y=\"-1768.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 8]</text>\n</g>\n<!-- 283&#45;&gt;284 -->\n<g id=\"edge284\" class=\"edge\">\n<title>283&#45;&gt;284</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4079.85,-1856.88C4079.64,-1846.22 4079.41,-1834.35 4079.2,-1823.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4082.7,-1823.45 4079,-1813.52 4075.7,-1823.59 4082.7,-1823.45\"/>\n</g>\n<!-- 285 -->\n<g id=\"node286\" class=\"node\">\n<title>285</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4230,-1813.5C4230,-1813.5 4157,-1813.5 4157,-1813.5 4151,-1813.5 4145,-1807.5 4145,-1801.5 4145,-1801.5 4145,-1772.5 4145,-1772.5 4145,-1766.5 4151,-1760.5 4157,-1760.5 4157,-1760.5 4230,-1760.5 4230,-1760.5 4236,-1760.5 4242,-1766.5 4242,-1772.5 4242,-1772.5 4242,-1801.5 4242,-1801.5 4242,-1807.5 4236,-1813.5 4230,-1813.5\"/>\n<text text-anchor=\"start\" x=\"4164.5\" y=\"-1798.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4154\" y=\"-1783.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"4153\" y=\"-1768.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 283&#45;&gt;285 -->\n<g id=\"edge285\" class=\"edge\">\n<title>283&#45;&gt;285</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4117.19,-1856.88C4130.1,-1845.23 4144.6,-1832.14 4157.46,-1820.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4160.15,-1822.82 4165.23,-1813.52 4155.46,-1817.62 4160.15,-1822.82\"/>\n</g>\n<!-- 287 -->\n<g id=\"node288\" class=\"node\">\n<title>287</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M4346,-1925C4346,-1925 4271,-1925 4271,-1925 4265,-1925 4259,-1919 4259,-1913 4259,-1913 4259,-1869 4259,-1869 4259,-1863 4265,-1857 4271,-1857 4271,-1857 4346,-1857 4346,-1857 4352,-1857 4358,-1863 4358,-1869 4358,-1869 4358,-1913 4358,-1913 4358,-1919 4352,-1925 4346,-1925\"/>\n<text text-anchor=\"start\" x=\"4267\" y=\"-1909.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;2.019</text>\n<text text-anchor=\"start\" x=\"4279.5\" y=\"-1894.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"4269\" y=\"-1879.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"4268\" y=\"-1864.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 2]</text>\n</g>\n<!-- 286&#45;&gt;287 -->\n<g id=\"edge287\" class=\"edge\">\n<title>286&#45;&gt;287</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4308.5,-1960.88C4308.5,-1952.78 4308.5,-1943.98 4308.5,-1935.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4312,-1935.3 4308.5,-1925.3 4305,-1935.3 4312,-1935.3\"/>\n</g>\n<!-- 290 -->\n<g id=\"node291\" class=\"node\">\n<title>290</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4469,-1917.5C4469,-1917.5 4388,-1917.5 4388,-1917.5 4382,-1917.5 4376,-1911.5 4376,-1905.5 4376,-1905.5 4376,-1876.5 4376,-1876.5 4376,-1870.5 4382,-1864.5 4388,-1864.5 4388,-1864.5 4469,-1864.5 4469,-1864.5 4475,-1864.5 4481,-1870.5 4481,-1876.5 4481,-1876.5 4481,-1905.5 4481,-1905.5 4481,-1911.5 4475,-1917.5 4469,-1917.5\"/>\n<text text-anchor=\"start\" x=\"4399.5\" y=\"-1902.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4385\" y=\"-1887.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\n<text text-anchor=\"start\" x=\"4384\" y=\"-1872.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 0]</text>\n</g>\n<!-- 286&#45;&gt;290 -->\n<g id=\"edge290\" class=\"edge\">\n<title>286&#45;&gt;290</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4347.46,-1960.88C4361.3,-1949.12 4376.86,-1935.89 4390.61,-1924.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4393.12,-1926.66 4398.48,-1917.52 4388.59,-1921.33 4393.12,-1926.66\"/>\n</g>\n<!-- 288 -->\n<g id=\"node289\" class=\"node\">\n<title>288</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4345,-1813.5C4345,-1813.5 4272,-1813.5 4272,-1813.5 4266,-1813.5 4260,-1807.5 4260,-1801.5 4260,-1801.5 4260,-1772.5 4260,-1772.5 4260,-1766.5 4266,-1760.5 4272,-1760.5 4272,-1760.5 4345,-1760.5 4345,-1760.5 4351,-1760.5 4357,-1766.5 4357,-1772.5 4357,-1772.5 4357,-1801.5 4357,-1801.5 4357,-1807.5 4351,-1813.5 4345,-1813.5\"/>\n<text text-anchor=\"start\" x=\"4279.5\" y=\"-1798.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4269\" y=\"-1783.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"4268\" y=\"-1768.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 287&#45;&gt;288 -->\n<g id=\"edge288\" class=\"edge\">\n<title>287&#45;&gt;288</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4308.5,-1856.88C4308.5,-1846.33 4308.5,-1834.6 4308.5,-1823.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4312,-1823.52 4308.5,-1813.52 4305,-1823.52 4312,-1823.52\"/>\n</g>\n<!-- 289 -->\n<g id=\"node290\" class=\"node\">\n<title>289</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4460,-1813.5C4460,-1813.5 4387,-1813.5 4387,-1813.5 4381,-1813.5 4375,-1807.5 4375,-1801.5 4375,-1801.5 4375,-1772.5 4375,-1772.5 4375,-1766.5 4381,-1760.5 4387,-1760.5 4387,-1760.5 4460,-1760.5 4460,-1760.5 4466,-1760.5 4472,-1766.5 4472,-1772.5 4472,-1772.5 4472,-1801.5 4472,-1801.5 4472,-1807.5 4466,-1813.5 4460,-1813.5\"/>\n<text text-anchor=\"start\" x=\"4394.5\" y=\"-1798.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4384\" y=\"-1783.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"4383\" y=\"-1768.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 287&#45;&gt;289 -->\n<g id=\"edge289\" class=\"edge\">\n<title>287&#45;&gt;289</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4345.84,-1856.88C4359.1,-1845.12 4374.01,-1831.89 4387.19,-1820.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4389.57,-1822.77 4394.73,-1813.52 4384.92,-1817.54 4389.57,-1822.77\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": "<graphviz.sources.Source at 0x1ce5e4f7a60>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(dt, out_file=None,\n",
    "                      feature_names=X_train.loc[:, X_train.columns != 'PassengerId'].columns,\n",
    "                      filled=True, rounded=True,\n",
    "                      special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, the complexity of the tree is very large. Perhaps this is also why it is not good at modeling data and making good predictions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### K Nearest Neighbor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.824      0.832      0.83064516 0.7983871  0.83870968]\n",
      "0.8247483870967741\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "cv = cross_val_score(knn,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I wasn't expecting good accuracies like this. In fact, I believed that the algorithm would have made it difficult to define which were the closest points. In fact, having a 38-dimensional space, I didn't think it was easy to define the distance between points in space."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.824      0.856      0.87903226 0.80645161 0.82258065]\n",
      "0.8376129032258064\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state = 1)\n",
    "cv = cross_val_score(rf,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7677902621722846"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(y_pred, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Support vector machine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.832      0.832      0.7983871  0.83064516 0.80645161]\n",
      "0.8198967741935483\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(probability=True)\n",
    "cv = cross_val_score(svc,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8164794007490637"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svc.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(y_pred, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### XGboost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.808      0.792      0.84677419 0.85483871 0.83870968]\n",
      "0.8280645161290323\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "cv = cross_val_score(xgb,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Voting classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(estimators = [('lr',lr),('knn',knn),('rf',rf),('gnb',gnb),('svm',svc),('xgb',xgb)], voting = 'soft')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cv = cross_val_score(voting_clf,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84       0.864      0.84677419 0.82258065 0.82258065]\n",
      "0.8391870967741936\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This method consists in having the various models vote. I expected it to be the best because different models can and are able to capture information other than data. I compensate each other for the shortcomings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8014981273408239"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "p_v = voting_clf.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(p_v, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we try it with the test data, perhaps we see that this voting model goes into overfitting a bit."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### GridSearch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "from utils import clf_performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "param_grid_lr = {'max_iter' : [2000],\n",
    "              'penalty' : ['l1', 'l2'],\n",
    "              'C' : np.logspace(-4, 4, 20),\n",
    "              'solver' : ['liblinear']}\n",
    "\n",
    "param_grid_knn = {'n_neighbors' : [3,5,7,9],\n",
    "              'weights' : ['uniform', 'distance'],\n",
    "              'algorithm' : ['auto', 'ball_tree','kd_tree'],\n",
    "              'p' : [1,2]}\n",
    "\n",
    "param_grid_svc = tuned_parameters = [{'kernel': ['rbf'], 'gamma': [.1,.5,1,2,5,10],\n",
    "                                  'C': [.1, 1, 10, 100, 1000]},\n",
    "                                 {'kernel': ['linear'], 'C': [.1, 1, 10, 100, 1000]},\n",
    "                                 {'kernel': ['poly'], 'degree' : [2,3,4,5], 'C': [.1, 1, 10, 100, 1000]}]\n",
    "\n",
    "param_grid_rf =  {'n_estimators': [100,500,1000],\n",
    "                                  'bootstrap': [True,False],\n",
    "                                  'max_depth': [3,5,10,20,50,75,100,None],\n",
    "                                  'max_features': ['auto','sqrt'],\n",
    "                                  'min_samples_leaf': [1,2,4,10],\n",
    "                                  'min_samples_split': [2,5,10]}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [20, 50, 100, 250, 500,1000],\n",
    "    'colsample_bytree': [0.2, 0.5, 0.7, 0.8, 1],\n",
    "    'max_depth': [2, 5, 10, 15, 20, 25, None],\n",
    "    'reg_alpha': [0, 0.5, 1],\n",
    "    'reg_lambda': [1, 1.5, 2],\n",
    "    'subsample': [0.5,0.6,0.7, 0.8, 0.9],\n",
    "    'learning_rate':[.01,0.1,0.2,0.3,0.5, 0.7, 0.9],\n",
    "    'gamma':[0,.01,.1,1,10,100],\n",
    "    'min_child_weight':[0,.01,0.1,1,10,100],\n",
    "    'sampling_method': ['uniform', 'gradient_based']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "lr_g = LogisticRegression()\n",
    "knn_g = KNeighborsClassifier()\n",
    "svc_g = SVC(probability = True)\n",
    "rf_g = RandomForestClassifier(random_state = 1)\n",
    "xgb_g = XGBClassifier(random_state = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Logistic Regression\n",
      "Best Score: 0.7973548387096774\n",
      "Best Parameters: {'C': 4.281332398719396, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "clf_lr = GridSearchCV(lr_g, param_grid = param_grid_lr, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_lr = clf_lr.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_lr,'Logistic Regression')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "KNN\n",
      "Best Score: 0.8552645161290323\n",
      "Best Parameters: {'algorithm': 'auto', 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "clf_knn = GridSearchCV(knn_g, param_grid = param_grid_knn, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_knn = clf_knn.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_knn,'KNN')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7827715355805244"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_best = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 5, p= 1, weights= 'uniform')\n",
    "knn_best.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "\n",
    "y_pred_best_knn = knn_best.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(y_pred_best_knn, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "SVC\n",
      "Best Score: 0.8472645161290323\n",
      "Best Parameters: {'C': 1, 'gamma': 0.5, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "clf_svc = GridSearchCV(svc_g, param_grid = param_grid_svc, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_svc = clf_svc.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_svc,'SVC')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7827715355805244"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_best = SVC(C= 1, gamma= 0.5, kernel= 'rbf')\n",
    "svc_best.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "\n",
    "y_pred_best = svc_best.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(y_pred_best, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Random Forest\n",
      "Best Score: 0.8681290322580646\n",
      "Best Parameters: {'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 50, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "clf_rf_rnd = RandomizedSearchCV(rf_g, param_distributions = param_grid_rf, n_iter = 100, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_rf_rnd = clf_rf_rnd.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_rf_rnd,'Random Forest')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1152 candidates, totalling 5760 fits\n",
      "Random Forest\n",
      "Best Score: 0.868141935483871\n",
      "Best Parameters: {'bootstrap': False, 'max_depth': 50, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "clf_rf = GridSearchCV(rf_g, param_grid = param_grid_rf, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_rf = clf_rf.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_rf,'Random Forest')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "0.797752808988764"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_best = RandomForestClassifier(bootstrap= False, max_depth= 50, max_features= 'auto', min_samples_leaf= 2, min_samples_split= 10, n_estimators= 500)\n",
    "rf_best.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "pred_rf_best = rf_best.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(pred_rf_best, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(rf_best.feature_importances_, index=X_train.loc[:, X_train.columns != 'PassengerId'].columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n",
      "XGB\n",
      "Best Score: 0.860116129032258\n",
      "Best Parameters: {'subsample': 0.8, 'sampling_method': 'uniform', 'reg_lambda': 1, 'reg_alpha': 0, 'n_estimators': 20, 'min_child_weight': 0.01, 'max_depth': 25, 'learning_rate': 0.3, 'gamma': 1, 'colsample_bytree': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2460 fits failed out of a total of 5000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:44] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:45] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:46] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:48] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:49] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:50] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "55 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:51] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "11 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:53] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:52] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:58] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:54] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:56] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "17 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:00] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "36 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:01] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:03] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:57] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:59] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "23 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:12] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:02] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:04] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:05] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:06] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:07] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:09] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:11] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:14] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:17] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:15] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:18] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "23 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:19] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:20] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "41 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:21] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:26] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:23] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:22] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "34 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:24] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "17 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:28] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:25] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:29] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:30] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:32] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "19 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:33] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "26 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:34] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:35] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "17 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:38] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:36] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:37] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:39] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:40] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:57] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:41] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:42] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "19 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:05] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:44] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:45] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:46] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:48] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "23 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:49] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:50] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:51] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:54] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:59] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:00] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:02] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:04] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "29 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:09] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "19 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:07] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:12] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:10] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:11] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:13] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:14] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:15] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:17] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:18] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:20] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:19] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:21] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:22] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:23] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:24] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:25] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:26] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:28] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:29] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:31] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:32] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:33] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:35] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:36] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:37] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:38] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:40] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:41] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:43] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:44] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:45] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:46] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:47] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:49] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:48] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:50] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:51] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:53] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "29 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:54] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:56] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:58] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:59] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:00] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:02] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "36 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:03] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:04] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:07] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:05] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:08] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:09] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:10] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:11] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:12] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:13] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:14] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:15] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:18] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:21] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:19] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:20] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:22] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:24] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:25] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:26] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:29] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:30] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "11 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:31] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:32] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:33] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:34] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "64 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:35] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:36] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "26 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:37] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:38] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:39] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:40] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:46] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:41] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:44] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:45] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:47] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:48] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:49] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:50] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:52] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:53] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:54] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:55] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:56] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:57] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:59] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:00] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:01] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "26 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:02] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:03] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:04] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:05] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:06] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:07] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:14] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:16] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:17] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:18] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:19] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:24] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:20] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:22] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:23] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "11 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:25] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:28] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:27] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:29] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:32] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:33] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:34] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:35] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:36] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:37] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:38] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:39] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:40] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.61414194        nan 0.78616774        nan 0.8424129  0.8215871\n",
      " 0.61414194 0.80864516        nan        nan 0.82323871 0.81190968\n",
      " 0.61414194        nan 0.71544516        nan 0.85206452 0.79256774\n",
      "        nan 0.8263871         nan 0.82962581 0.83443871        nan\n",
      " 0.81825806        nan        nan 0.84729032        nan 0.61414194\n",
      "        nan 0.82802581        nan        nan        nan        nan\n",
      "        nan        nan 0.68027097        nan 0.81996129        nan\n",
      "        nan        nan        nan        nan 0.8248129         nan\n",
      " 0.82477419 0.61414194        nan 0.81349677        nan 0.85370323\n",
      "        nan        nan 0.8280129         nan        nan        nan\n",
      " 0.84566452        nan 0.61414194        nan        nan 0.83443871\n",
      "        nan        nan 0.81192258        nan        nan 0.61414194\n",
      "        nan 0.61414194        nan        nan        nan 0.83446452\n",
      "        nan 0.85212903 0.82309677        nan        nan        nan\n",
      "        nan 0.61414194 0.8296     0.81836129        nan 0.84723871\n",
      "        nan        nan 0.61414194 0.80704516 0.84563871        nan\n",
      "        nan 0.81027097        nan        nan 0.81665806        nan\n",
      " 0.8136     0.84087742 0.61414194        nan        nan        nan\n",
      " 0.84729032        nan 0.85852903        nan 0.83437419 0.61414194\n",
      " 0.61414194        nan        nan 0.83762581 0.61414194 0.8263871\n",
      "        nan 0.79096774        nan        nan        nan 0.78778065\n",
      "        nan        nan 0.61414194 0.80869677 0.83597419        nan\n",
      " 0.84889032 0.61414194        nan 0.80060645 0.82323871 0.8376\n",
      "        nan 0.82962581        nan        nan        nan        nan\n",
      " 0.81514839 0.61414194 0.82308387 0.80379355 0.84562581        nan\n",
      " 0.80864516        nan 0.81343226 0.83277419        nan        nan\n",
      "        nan        nan 0.61414194 0.61414194 0.8408129         nan\n",
      " 0.82634839        nan        nan 0.80864516        nan        nan\n",
      "        nan 0.84406452 0.78932903        nan        nan 0.84403871\n",
      " 0.82962581        nan 0.82323871 0.82642581        nan 0.81670968\n",
      " 0.83929032        nan 0.84083871 0.85369032        nan 0.81989677\n",
      " 0.84243871        nan        nan        nan        nan 0.83117419\n",
      " 0.61414194        nan 0.80865806        nan        nan 0.83443871\n",
      " 0.82802581        nan        nan 0.61414194 0.61414194 0.85531613\n",
      " 0.84249032 0.81988387 0.82794839        nan        nan        nan\n",
      " 0.8311871         nan 0.82963871        nan 0.83442581 0.82474839\n",
      " 0.81353548        nan        nan 0.61414194 0.83285161        nan\n",
      "        nan 0.82152258 0.80545806 0.80219355 0.83763871 0.6480129\n",
      "        nan        nan 0.77661935        nan        nan        nan\n",
      "        nan        nan 0.80705806 0.81833548        nan        nan\n",
      "        nan 0.82803871        nan 0.83765161 0.78616774 0.83930323\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.61414194        nan 0.82156129\n",
      " 0.82633548 0.83116129 0.61414194        nan        nan        nan\n",
      "        nan        nan 0.61414194 0.85046452 0.61414194        nan\n",
      "        nan        nan        nan        nan 0.81664516 0.78616774\n",
      "        nan        nan 0.82314839 0.61414194        nan 0.81836129\n",
      " 0.83762581        nan 0.61414194        nan        nan        nan\n",
      " 0.61414194        nan 0.83765161        nan 0.8375871  0.8424\n",
      "        nan 0.61414194        nan        nan        nan        nan\n",
      "        nan 0.80550968 0.80381935        nan        nan 0.82803871\n",
      " 0.81505806 0.61414194 0.84889032 0.84087742        nan 0.8295871\n",
      " 0.81509677 0.84089032        nan 0.83766452 0.81027097 0.61414194\n",
      "        nan        nan 0.82802581        nan        nan 0.84886452\n",
      "        nan 0.80876129        nan 0.82802581 0.8296            nan\n",
      "        nan        nan 0.82962581 0.83286452 0.61414194        nan\n",
      " 0.78287742        nan        nan        nan        nan 0.61414194\n",
      "        nan 0.83603871        nan 0.81989677        nan 0.81834839\n",
      "        nan 0.61414194        nan 0.61414194 0.61414194 0.84249032\n",
      "        nan 0.82473548        nan        nan 0.81343226        nan\n",
      " 0.83442581        nan        nan        nan 0.8472129         nan\n",
      " 0.8376129         nan        nan 0.79411613 0.80864516        nan\n",
      " 0.82956129 0.61414194 0.84567742 0.83756129 0.79579355        nan\n",
      " 0.8264            nan        nan        nan        nan 0.81667097\n",
      " 0.82153548 0.84727742        nan        nan        nan 0.61414194\n",
      "        nan 0.80383226        nan        nan        nan        nan\n",
      " 0.61414194        nan 0.83283871        nan 0.61414194 0.61414194\n",
      "        nan        nan        nan        nan 0.8280129         nan\n",
      "        nan 0.79096774 0.78294194        nan 0.81829677 0.61414194\n",
      "        nan 0.68294194        nan 0.82474839        nan 0.81188387\n",
      "        nan 0.78294194        nan 0.8328129  0.61414194 0.61414194\n",
      "        nan        nan 0.82003871        nan 0.82153548        nan\n",
      " 0.84887742 0.61414194 0.81033548 0.78616774        nan        nan\n",
      "        nan        nan 0.61414194 0.8247871  0.8247871  0.61414194\n",
      "        nan        nan 0.61414194        nan        nan        nan\n",
      "        nan        nan 0.8264     0.83445161        nan        nan\n",
      " 0.61414194 0.61414194        nan 0.8247871  0.8247871         nan\n",
      "        nan        nan        nan        nan 0.83282581 0.85371613\n",
      "        nan        nan 0.8215871         nan        nan 0.83285161\n",
      "        nan        nan        nan 0.81507097 0.8232     0.82317419\n",
      "        nan 0.86011613        nan        nan 0.79416774 0.84411613\n",
      " 0.82954839        nan        nan 0.82314839 0.84249032 0.79096774\n",
      " 0.81997419        nan 0.84249032 0.78616774 0.83443871        nan\n",
      "        nan 0.61414194 0.81187097 0.85211613 0.61414194        nan\n",
      "        nan        nan 0.81984516        nan 0.81023226 0.61414194\n",
      "        nan        nan        nan 0.84566452        nan 0.85210323\n",
      " 0.81025806        nan 0.85690323 0.8264129         nan        nan\n",
      "        nan 0.84729032        nan 0.83122581 0.61414194        nan\n",
      " 0.79418065 0.84247742 0.61414194 0.81357419        nan 0.82312258\n",
      " 0.61414194        nan        nan        nan 0.8184            nan\n",
      "        nan        nan 0.61414194 0.8279871         nan        nan\n",
      "        nan        nan 0.84725161 0.79415484 0.8440129  0.80060645\n",
      "        nan        nan        nan 0.84406452 0.8247871  0.8344\n",
      "        nan        nan 0.81343226 0.84406452 0.83926452 0.81505806\n",
      " 0.81505806 0.83766452        nan        nan        nan        nan\n",
      "        nan 0.83286452        nan 0.79735484        nan        nan\n",
      "        nan        nan        nan 0.84245161 0.85527742 0.82472258\n",
      "        nan 0.61414194        nan 0.84245161 0.81989677        nan\n",
      "        nan 0.79736774 0.83926452 0.81664516        nan 0.61414194\n",
      "        nan        nan 0.61414194        nan 0.81352258        nan\n",
      " 0.81348387        nan 0.75256774 0.81507097 0.82953548 0.85371613\n",
      " 0.61414194        nan 0.83603871 0.8328            nan 0.82152258\n",
      "        nan        nan 0.74584516        nan 0.82642581        nan\n",
      "        nan 0.82157419        nan        nan        nan 0.84249032\n",
      "        nan 0.82154839 0.61414194        nan 0.84407742 0.80221935\n",
      " 0.82632258 0.85049032        nan        nan        nan 0.82805161\n",
      " 0.61414194        nan 0.85049032 0.65254194        nan        nan\n",
      "        nan 0.61414194 0.81513548 0.84729032 0.61414194        nan\n",
      "        nan 0.61414194 0.82645161 0.61414194        nan 0.61414194\n",
      " 0.61414194 0.8312     0.83925161        nan 0.61414194 0.81988387\n",
      "        nan 0.61414194        nan 0.82634839 0.82645161        nan\n",
      " 0.83110968        nan 0.82314839 0.84891613 0.84725161 0.79578065\n",
      "        nan 0.84567742 0.83765161 0.6480129  0.61414194        nan\n",
      "        nan 0.79739355 0.82634839        nan        nan 0.61414194\n",
      "        nan        nan        nan 0.82314839 0.83923871 0.79418065\n",
      " 0.61414194        nan 0.81512258        nan        nan        nan\n",
      "        nan 0.81837419        nan 0.81665806        nan        nan\n",
      "        nan        nan        nan        nan 0.83446452        nan\n",
      "        nan        nan        nan        nan 0.8344            nan\n",
      "        nan 0.8328129  0.84569032        nan        nan        nan\n",
      "        nan 0.78775484 0.81837419        nan 0.61414194        nan\n",
      " 0.61414194 0.82633548        nan        nan 0.79259355        nan\n",
      "        nan 0.61414194 0.61414194        nan 0.78612903 0.61414194\n",
      " 0.61414194        nan        nan        nan        nan 0.82157419\n",
      "        nan        nan 0.79579355 0.81989677        nan 0.82310968\n",
      "        nan        nan 0.61414194        nan 0.79579355        nan\n",
      " 0.81507097        nan        nan 0.83437419 0.8263871         nan\n",
      " 0.83283871        nan 0.79899355        nan        nan 0.85529032\n",
      "        nan        nan 0.8344     0.61414194 0.84407742        nan\n",
      "        nan 0.81668387 0.82153548        nan 0.83282581 0.81023226\n",
      " 0.61414194        nan 0.61414194        nan 0.82156129        nan\n",
      "        nan 0.61414194 0.61414194        nan        nan 0.61414194\n",
      " 0.85689032        nan        nan 0.61414194        nan        nan\n",
      "        nan        nan 0.85210323 0.81837419 0.84087742 0.79096774\n",
      " 0.82476129 0.61414194        nan 0.84409032 0.61414194 0.61414194\n",
      " 0.82794839 0.61414194        nan        nan        nan        nan\n",
      " 0.78616774 0.61414194 0.78938065 0.82803871        nan 0.82312258\n",
      "        nan        nan        nan        nan        nan 0.8279871\n",
      "        nan        nan        nan 0.61414194 0.82482581        nan\n",
      " 0.84730323 0.82150968        nan 0.61414194        nan        nan\n",
      " 0.82952258        nan        nan        nan 0.78616774 0.78294194\n",
      "        nan        nan        nan        nan 0.61414194 0.78616774\n",
      "        nan 0.81994839        nan        nan 0.8520129  0.81828387\n",
      "        nan        nan 0.84727742        nan        nan 0.82953548\n",
      " 0.82797419 0.85527742 0.83606452        nan 0.78610323        nan\n",
      "        nan 0.61414194 0.82153548 0.6783871  0.81192258 0.84885161\n",
      " 0.78616774 0.78616774 0.83274839 0.83925161 0.61414194        nan\n",
      " 0.84082581        nan 0.61414194 0.61414194 0.61414194 0.83445161\n",
      "        nan 0.81992258 0.828             nan 0.64934194        nan\n",
      " 0.61414194 0.81832258        nan 0.83122581        nan        nan\n",
      "        nan 0.61414194        nan 0.78616774        nan 0.61414194\n",
      " 0.8295871         nan        nan        nan 0.85210323 0.8456\n",
      " 0.61414194        nan        nan        nan        nan        nan\n",
      " 0.78294194 0.61414194 0.82637419        nan        nan        nan\n",
      "        nan 0.61414194 0.81025806        nan 0.8376            nan\n",
      " 0.80383226 0.82154839 0.81510968 0.61414194 0.8232129         nan\n",
      " 0.80383226 0.74584516        nan 0.61414194 0.8392     0.82152258\n",
      "        nan 0.61414194 0.71064516 0.84892903 0.61414194 0.84077419\n",
      " 0.85529032 0.84083871        nan        nan        nan 0.81030968\n",
      "        nan        nan 0.81185806        nan 0.61414194 0.8296\n",
      "        nan 0.6447871  0.78932903 0.61414194 0.82953548        nan\n",
      " 0.84889032 0.82472258        nan 0.8168            nan 0.8392129\n",
      " 0.79096774 0.80704516        nan 0.61414194 0.84727742        nan\n",
      " 0.8184     0.84731613 0.85372903        nan        nan 0.79256774\n",
      " 0.61414194 0.61414194        nan        nan        nan 0.61414194\n",
      "        nan        nan        nan        nan 0.61414194 0.84410323\n",
      " 0.61414194 0.61414194 0.77487742 0.8183871 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf_xgb_rnd = RandomizedSearchCV(xgb_g, param_distributions = param_grid_xgb, n_iter = 1000, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_xgb_rnd = clf_xgb_rnd.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_xgb_rnd,'XGB')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "XGB\n",
      "Best Score: 0.8537161290322581\n",
      "Best Parameters: {'colsample_bytree': 0.85, 'gamma': 1, 'learning_rate': 0.5, 'max_depth': None, 'min_child_weight': 0.01, 'n_estimators': 550, 'reg_alpha': 1, 'reg_lambda': 10, 'sampling_method': 'uniform', 'subsample': 0.65}\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state = 1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [450,500,550],\n",
    "    'colsample_bytree': [0.75,0.8,0.85],\n",
    "    'max_depth': [None],\n",
    "    'reg_alpha': [1],\n",
    "    'reg_lambda': [2, 5, 10],\n",
    "    'subsample': [0.55, 0.6, .65],\n",
    "    'learning_rate':[0.5],\n",
    "    'gamma':[.5,1,2],\n",
    "    'min_child_weight':[0.01],\n",
    "    'sampling_method': ['uniform']\n",
    "}\n",
    "\n",
    "clf_xgb = GridSearchCV(xgb, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_xgb = clf_xgb.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_xgb,'XGB')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:47:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytre\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8277153558052435"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_best = XGBClassifier(colsample_bytre= 0.75, gamma= 1, learning_rate= 0.5, max_depth= None, min_child_weight= 0.01, n_estimators= 450, reg_alpha= 1, reg_lambda= 5, sampling_method= 'uniform', subsample= 0.6)\n",
    "xgb_best.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "\n",
    "y_pred_best_xgb = xgb_best.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(y_pred_best_xgb, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "\"clf_xgb = GridSearchCV(xgb_g, param_grid = param_grid_xgb, cv = 5, verbose = True, n_jobs = -1)\\nbest_clf_xgb = clf_xgb.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\\nclf_performance(best_clf_xgb,'XGB')\""
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"clf_xgb = GridSearchCV(xgb_g, param_grid = param_grid_xgb, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_xgb = clf_xgb.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_xgb,'XGB')\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_clf_lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [45]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m best_lr \u001B[38;5;241m=\u001B[39m \u001B[43mbest_clf_lr\u001B[49m\u001B[38;5;241m.\u001B[39mbest_estimator_\n\u001B[0;32m      2\u001B[0m best_knn \u001B[38;5;241m=\u001B[39m best_clf_knn\u001B[38;5;241m.\u001B[39mbest_estimator_\n\u001B[0;32m      3\u001B[0m best_svc \u001B[38;5;241m=\u001B[39m best_clf_svc\u001B[38;5;241m.\u001B[39mbest_estimator_\n",
      "\u001B[1;31mNameError\u001B[0m: name 'best_clf_lr' is not defined"
     ]
    }
   ],
   "source": [
    "best_lr = best_clf_lr.best_estimator_\n",
    "best_knn = best_clf_knn.best_estimator_\n",
    "best_svc = best_clf_svc.best_estimator_\n",
    "best_rf = best_clf_rf.best_estimator_\n",
    "best_xgb = best_clf_xgb_rnd.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "voting_clf_hard = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc)], voting = 'hard')\n",
    "voting_clf_soft = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc)], voting = 'soft')\n",
    "voting_clf_all = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc), ('lr', best_lr)], voting = 'soft')\n",
    "voting_clf_xgb = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc), ('xgb', best_xgb),('lr', best_lr)], voting = 'soft')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting_clf_hard : [0.72       0.688      0.75       0.68548387 0.72580645]\n",
      "voting_clf_hard mean : 0.7138580645161291\n",
      "voting_clf_soft : [0.816      0.808      0.7983871  0.75       0.79032258]\n",
      "voting_clf_soft mean : 0.7893419354838709\n",
      "voting_clf_all : [0.832      0.856      0.83870968 0.83064516 0.7983871 ]\n",
      "voting_clf_all mean : 0.8311483870967742\n",
      "voting_clf_xgb : [0.848      0.856      0.84677419 0.85483871 0.84677419]\n",
      "voting_clf_xgb mean : 0.8504774193548388\n"
     ]
    }
   ],
   "source": [
    "print('voting_clf_hard :',cross_val_score(voting_clf_hard,X_train,y_train,cv=5))\n",
    "print('voting_clf_hard mean :',cross_val_score(voting_clf_hard,X_train,y_train,cv=5).mean())\n",
    "\n",
    "print('voting_clf_soft :',cross_val_score(voting_clf_soft,X_train,y_train,cv=5))\n",
    "print('voting_clf_soft mean :',cross_val_score(voting_clf_soft,X_train,y_train,cv=5).mean())\n",
    "\n",
    "print('voting_clf_all :',cross_val_score(voting_clf_all,X_train,y_train,cv=5))\n",
    "print('voting_clf_all mean :',cross_val_score(voting_clf_all,X_train,y_train,cv=5).mean())\n",
    "\n",
    "print('voting_clf_xgb :',cross_val_score(voting_clf_xgb,X_train,y_train,cv=5))\n",
    "print('voting_clf_xgb mean :',cross_val_score(voting_clf_xgb,X_train,y_train,cv=5).mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "params_voting = {'weights' : [[1,1,1,1,1],[1,1,1,1,2],[1,1,1,2,2],[1,1,2,2,2],[1,2,2,2,2],\n",
    "                              [3,4,2,3,1]]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "VC Weights\n",
      "Best Score: 0.8552774193548387\n",
      "Best Parameters: {'weights': [3, 4, 2, 3, 1]}\n"
     ]
    }
   ],
   "source": [
    "vote_weight = GridSearchCV(voting_clf_xgb, param_grid = params_voting, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_weight = vote_weight.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_weight,'VC Weights')\n",
    "voting_clf_sub = best_clf_weight.best_estimator_.predict(X_test.loc[:, X_test.columns != 'PassengerId'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_knn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [47]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m voting_clf_best \u001B[38;5;241m=\u001B[39m VotingClassifier(estimators \u001B[38;5;241m=\u001B[39m [(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mknn\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[43mbest_knn\u001B[49m),(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrf\u001B[39m\u001B[38;5;124m'\u001B[39m,best_rf),(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msvc\u001B[39m\u001B[38;5;124m'\u001B[39m,best_svc), (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mxgb\u001B[39m\u001B[38;5;124m'\u001B[39m, best_xgb),(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m'\u001B[39m, best_lr)], voting \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msoft\u001B[39m\u001B[38;5;124m'\u001B[39m, weights\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m4\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m      2\u001B[0m voting_clf_best\u001B[38;5;241m.\u001B[39mfit(X_train\u001B[38;5;241m.\u001B[39mloc[:, X_train\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPassengerId\u001B[39m\u001B[38;5;124m'\u001B[39m],y_train)\n\u001B[0;32m      3\u001B[0m p_v_best \u001B[38;5;241m=\u001B[39m voting_clf_best\u001B[38;5;241m.\u001B[39mpredict(X_test\u001B[38;5;241m.\u001B[39mloc[:, X_test\u001B[38;5;241m.\u001B[39mcolumns \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPassengerId\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[1;31mNameError\u001B[0m: name 'best_knn' is not defined"
     ]
    }
   ],
   "source": [
    "voting_clf_best = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc), ('xgb', best_xgb),('lr', best_lr)], voting = 'soft', weights=[3,4,2,3,1])\n",
    "voting_clf_best.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "p_v_best = voting_clf_best.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(p_v_best, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The weights chosen as the best are the ones I entered by hand. In fact, looking at the performance of the various models from the cells above, I gave a greater weight to the best models and a lesser weight to the models that had earlier had lower accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### At the end the best model is the xgb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deep learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section I try to implement some simple neural networks in keras. I don't expect good performance because neural networks are too complex for this task and will likely overfit the model right away. In any case it is necessary to do some tests."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "keras_classifier = Sequential()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "keras_classifier.add(Dense(16, input_dim=X_train.shape[1]-1, kernel_initializer='uniform', activation='relu'))\n",
    "keras_classifier.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "keras_classifier.add(Dense(4, kernel_initializer='uniform', activation='relu'))\n",
    "keras_classifier.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "keras_classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 751us/step - loss: 0.6923 - accuracy: 0.5981\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.6141\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.6141\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 843us/step - loss: 0.6873 - accuracy: 0.6141\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 783us/step - loss: 0.6857 - accuracy: 0.6141\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x28d2144e500>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_classifier.fit(X_train.loc[:, X_train.columns != 'PassengerId'], y_train, epochs = 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "#keras_prediction = keras_classifier.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "#k_pred = np.rint(keras_prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "#accuracy_score(k_pred, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.6255\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.6841917037963867, 0.6254681944847107]"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_classifier.evaluate(X_test.loc[:, X_test.columns != 'PassengerId'], y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### keras 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "20/20 [==============================] - 0s 554us/step - loss: 0.6923 - accuracy: 0.5852\n",
      "Epoch 2/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.6141\n",
      "Epoch 3/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6806 - accuracy: 0.6158\n",
      "Epoch 4/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6594 - accuracy: 0.6511\n",
      "Epoch 5/25\n",
      "20/20 [==============================] - 0s 985us/step - loss: 0.6190 - accuracy: 0.7122\n",
      "Epoch 6/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7219\n",
      "Epoch 7/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5234 - accuracy: 0.7717\n",
      "Epoch 8/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.8023\n",
      "Epoch 9/25\n",
      "20/20 [==============================] - 0s 385us/step - loss: 0.4622 - accuracy: 0.8039\n",
      "Epoch 10/25\n",
      "20/20 [==============================] - 0s 648us/step - loss: 0.4454 - accuracy: 0.7990\n",
      "Epoch 11/25\n",
      "20/20 [==============================] - 0s 825us/step - loss: 0.4340 - accuracy: 0.8023\n",
      "Epoch 12/25\n",
      "20/20 [==============================] - 0s 862us/step - loss: 0.4251 - accuracy: 0.8039\n",
      "Epoch 13/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4196 - accuracy: 0.8103\n",
      "Epoch 14/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8167\n",
      "Epoch 15/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4121 - accuracy: 0.8167\n",
      "Epoch 16/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8264\n",
      "Epoch 17/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4054 - accuracy: 0.8264\n",
      "Epoch 18/25\n",
      "20/20 [==============================] - 0s 836us/step - loss: 0.4022 - accuracy: 0.8296\n",
      "Epoch 19/25\n",
      "20/20 [==============================] - 0s 835us/step - loss: 0.4017 - accuracy: 0.8296\n",
      "Epoch 20/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4005 - accuracy: 0.8264\n",
      "Epoch 21/25\n",
      "20/20 [==============================] - 0s 732us/step - loss: 0.3982 - accuracy: 0.8312\n",
      "Epoch 22/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8328\n",
      "Epoch 23/25\n",
      "20/20 [==============================] - 0s 836us/step - loss: 0.3986 - accuracy: 0.8296\n",
      "Epoch 24/25\n",
      "20/20 [==============================] - 0s 858us/step - loss: 0.3950 - accuracy: 0.8360\n",
      "Epoch 25/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3955 - accuracy: 0.8312\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x28d2272f370>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_classifier2 = Sequential()\n",
    "\n",
    "keras_classifier2.add(Dense(16, input_dim=X_train.shape[1]-1, kernel_initializer='uniform', activation='relu'))\n",
    "keras_classifier2.add(Dense(6, kernel_initializer='uniform', activation='relu'))\n",
    "keras_classifier2.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "keras_classifier2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "keras_classifier2.fit(X_train.loc[:, X_train.columns != 'PassengerId'], y_train, epochs =25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 0s/step - loss: 0.4442 - accuracy: 0.8052\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.44424349069595337, 0.8052434325218201]"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_classifier2.evaluate(X_test.loc[:, X_test.columns != 'PassengerId'], y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### keras 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.6141\n",
      "Epoch 2/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7476\n",
      "Epoch 3/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7974\n",
      "Epoch 4/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8215\n",
      "Epoch 5/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8280\n",
      "Epoch 6/25\n",
      "20/20 [==============================] - 0s 874us/step - loss: 0.4048 - accuracy: 0.8312\n",
      "Epoch 7/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8392\n",
      "Epoch 8/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8424\n",
      "Epoch 9/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3921 - accuracy: 0.8376\n",
      "Epoch 10/25\n",
      "20/20 [==============================] - 0s 823us/step - loss: 0.4016 - accuracy: 0.8392\n",
      "Epoch 11/25\n",
      "20/20 [==============================] - 0s 828us/step - loss: 0.4009 - accuracy: 0.8376\n",
      "Epoch 12/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3945 - accuracy: 0.8360\n",
      "Epoch 13/25\n",
      "20/20 [==============================] - 0s 917us/step - loss: 0.3926 - accuracy: 0.8376\n",
      "Epoch 14/25\n",
      "20/20 [==============================] - 0s 864us/step - loss: 0.3917 - accuracy: 0.8408\n",
      "Epoch 15/25\n",
      "20/20 [==============================] - 0s 826us/step - loss: 0.3901 - accuracy: 0.8408\n",
      "Epoch 16/25\n",
      "20/20 [==============================] - 0s 756us/step - loss: 0.3874 - accuracy: 0.8376\n",
      "Epoch 17/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3885 - accuracy: 0.8328\n",
      "Epoch 18/25\n",
      "20/20 [==============================] - 0s 881us/step - loss: 0.3901 - accuracy: 0.8360\n",
      "Epoch 19/25\n",
      "20/20 [==============================] - 0s 823us/step - loss: 0.3896 - accuracy: 0.8457\n",
      "Epoch 20/25\n",
      "20/20 [==============================] - 0s 701us/step - loss: 0.3841 - accuracy: 0.8424\n",
      "Epoch 21/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8408\n",
      "Epoch 22/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8376\n",
      "Epoch 23/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3814 - accuracy: 0.8457\n",
      "Epoch 24/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3839 - accuracy: 0.8392\n",
      "Epoch 25/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8376\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x28d23846890>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_classifier3 = Sequential()\n",
    "\n",
    "keras_classifier3.add(Dense(10, input_dim=X_train.shape[1]-1, kernel_initializer='uniform', activation='relu'))\n",
    "keras_classifier3.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "keras_classifier3.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "keras_classifier3.fit(X_train.loc[:, X_train.columns != 'PassengerId'], y_train, epochs =25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 0s/step - loss: 0.4636 - accuracy: 0.8127\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.4636099636554718, 0.812734067440033]"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_classifier3.evaluate(X_test.loc[:, X_test.columns != 'PassengerId'], y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Among the deep learning classifiers the best classifier is the keras_classifier2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 10)                280       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 291\n",
      "Trainable params: 291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_classifier3.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save best models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "utils.save_obj('./save_best_model/pickle_best_models', first = svc_best, second = xgb_best, third = voting_clf_best)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./save_best_model_pickle/keras_classifier3\\assets\n"
     ]
    }
   ],
   "source": [
    "keras_classifier2.save(\"./save_best_model_pickle/keras_classifier3\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}