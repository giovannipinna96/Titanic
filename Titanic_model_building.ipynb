{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Titanic model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import warnings\n",
    "\n",
    "import utils\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=SettingWithCopyWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from loadDataUtils import loadDataUtils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "path_train = r'C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\data\\train.csv'\n",
    "path_test = r'C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\data\\test.csv'\n",
    "data = loadDataUtils(path_train, path_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_train, df_test = data.get_train_and_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clean data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from titanicPreprocessing import preprocess"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "p = preprocess(df_train.copy(), df_test.copy())\n",
    "p.do_preprocess()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train, test = p.get_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 889 entries, 0 to 890\n",
      "Data columns (total 29 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   PassengerId        889 non-null    int64  \n",
      " 1   Survived           889 non-null    int64  \n",
      " 2   Pclass             889 non-null    int64  \n",
      " 3   Age                889 non-null    float64\n",
      " 4   SibSp              889 non-null    int64  \n",
      " 5   Parch              889 non-null    int64  \n",
      " 6   Fare               889 non-null    float64\n",
      " 7   cabin_multiple     889 non-null    int64  \n",
      " 8   Sex_female         889 non-null    uint8  \n",
      " 9   Sex_male           889 non-null    uint8  \n",
      " 10  Embarked_C         889 non-null    uint8  \n",
      " 11  Embarked_Q         889 non-null    uint8  \n",
      " 12  Embarked_S         889 non-null    uint8  \n",
      " 13  cabin_letter_0     889 non-null    uint8  \n",
      " 14  cabin_letter_A     889 non-null    uint8  \n",
      " 15  cabin_letter_B     889 non-null    uint8  \n",
      " 16  cabin_letter_C     889 non-null    uint8  \n",
      " 17  cabin_letter_D     889 non-null    uint8  \n",
      " 18  cabin_letter_E     889 non-null    uint8  \n",
      " 19  cabin_letter_F     889 non-null    uint8  \n",
      " 20  cabin_letter_G     889 non-null    uint8  \n",
      " 21  cabin_letter_T     889 non-null    uint8  \n",
      " 22  name_title_Dr      889 non-null    uint8  \n",
      " 23  name_title_Master  889 non-null    uint8  \n",
      " 24  name_title_Miss    889 non-null    uint8  \n",
      " 25  name_title_Mr      889 non-null    uint8  \n",
      " 26  name_title_Mrs     889 non-null    uint8  \n",
      " 27  name_title_Rare    889 non-null    uint8  \n",
      " 28  name_title_Rev     889 non-null    uint8  \n",
      "dtypes: float64(2), int64(6), uint8(21)\n",
      "memory usage: 113.0 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_target = train['Survived']\n",
    "train.drop(columns=['Survived'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, train_target, test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model building"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Baseline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "the gender submission provided by kaggle could be our baseline. In fact, this dataset is characterized by the fact that they assumed that all women would have survived, so we expect an accuracy of about 50%."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "baseline = pd.read_csv(r'C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\data\\gender_submission.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   PassengerId  418 non-null    int64\n",
      " 1   Survived     418 non-null    int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 6.7 KB\n"
     ]
    }
   ],
   "source": [
    "baseline.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "0.49760765550239233"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "baseline_acc = accuracy_score(baseline['Survived'], y_train[0:418])\n",
    "baseline_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "we put the value of 418 in the y_train to make a comparison. When we divided the dataset our trainset had more than 418 observations, so we put the limit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Gaussian Naive Bayes (GaussianNB)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76       0.424      0.7983871  0.77419355 0.71774194]\n",
      "0.6948645161290322\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#I usually use Naive Bayes as a baseline for my classification tasks\n",
    "gnb = GaussianNB()\n",
    "cv = cross_val_score(gnb,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nlr = LogisticRegression(max_iter = 20000)\\ncv = cross_val_score(lr,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\\nprint(cv)\\nprint(cv.mean())\\n\""
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\"\"\"\n",
    "lr = LogisticRegression(max_iter = 20000)\n",
    "cv = cross_val_score(lr,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87301587 0.79365079 0.83870968 0.85483871 0.87096774 0.79032258\n",
      " 0.87096774 0.80645161 0.79032258 0.79032258]\n",
      "0.8279569892473118\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter = 2000)\n",
    "cv = cross_val_score(lr,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=10)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "we can already observe that with the logistic regression we get almost 10% more accuracy than the GaussianNB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Deciosion tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.688      0.816      0.7983871  0.7983871  0.83064516]\n",
      "0.7862838709677419\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(random_state = 1)\n",
    "cv = cross_val_score(dt,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7752808988764045"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "dt.score(X_test.loc[:, X_test.columns != 'PassengerId'],y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "'Titanic_decision_tree.pdf'"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "dot_data = tree.export_graphviz(dt, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"Titanic_decision_tree\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"4941pt\" height=\"1725pt\"\n viewBox=\"0.00 0.00 4941.00 1725.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 1721)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-1721 4937,-1721 4937,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#f5d0b5\" stroke=\"black\" d=\"M2424,-1717C2424,-1717 2307,-1717 2307,-1717 2301,-1717 2295,-1711 2295,-1705 2295,-1705 2295,-1661 2295,-1661 2295,-1655 2301,-1649 2307,-1649 2307,-1649 2424,-1649 2424,-1649 2430,-1649 2436,-1655 2436,-1661 2436,-1661 2436,-1705 2436,-1705 2436,-1711 2430,-1717 2424,-1717\"/>\n<text text-anchor=\"start\" x=\"2303\" y=\"-1701.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">name_title_Mr ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"2328\" y=\"-1686.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.474</text>\n<text text-anchor=\"start\" x=\"2318\" y=\"-1671.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 622</text>\n<text text-anchor=\"start\" x=\"2308.5\" y=\"-1656.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [382, 240]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#8ac5f0\" stroke=\"black\" d=\"M1218.5,-1613C1218.5,-1613 1120.5,-1613 1120.5,-1613 1114.5,-1613 1108.5,-1607 1108.5,-1601 1108.5,-1601 1108.5,-1557 1108.5,-1557 1108.5,-1551 1114.5,-1545 1120.5,-1545 1120.5,-1545 1218.5,-1545 1218.5,-1545 1224.5,-1545 1230.5,-1551 1230.5,-1557 1230.5,-1557 1230.5,-1601 1230.5,-1601 1230.5,-1607 1224.5,-1613 1218.5,-1613\"/>\n<text text-anchor=\"start\" x=\"1130\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pclass ≤ 2.5</text>\n<text text-anchor=\"start\" x=\"1132\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.412</text>\n<text text-anchor=\"start\" x=\"1122\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 255</text>\n<text text-anchor=\"start\" x=\"1116.5\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [74, 181]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2294.71,-1675.96C2082.53,-1657.87 1453.41,-1604.21 1240.7,-1586.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1240.85,-1582.57 1230.59,-1585.21 1240.25,-1589.55 1240.85,-1582.57\"/>\n<text text-anchor=\"middle\" x=\"1246.7\" y=\"-1600.63\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 98 -->\n<g id=\"node99\" class=\"node\">\n<title>98</title>\n<path fill=\"#ea995f\" stroke=\"black\" d=\"M3603.5,-1613C3603.5,-1613 3505.5,-1613 3505.5,-1613 3499.5,-1613 3493.5,-1607 3493.5,-1601 3493.5,-1601 3493.5,-1557 3493.5,-1557 3493.5,-1551 3499.5,-1545 3505.5,-1545 3505.5,-1545 3603.5,-1545 3603.5,-1545 3609.5,-1545 3615.5,-1551 3615.5,-1557 3615.5,-1557 3615.5,-1601 3615.5,-1601 3615.5,-1607 3609.5,-1613 3603.5,-1613\"/>\n<text text-anchor=\"start\" x=\"3513.5\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.358</text>\n<text text-anchor=\"start\" x=\"3521\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.27</text>\n<text text-anchor=\"start\" x=\"3507\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 367</text>\n<text text-anchor=\"start\" x=\"3501.5\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [308, 59]</text>\n</g>\n<!-- 0&#45;&gt;98 -->\n<g id=\"edge98\" class=\"edge\">\n<title>0&#45;&gt;98</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2436.32,-1675.92C2647.58,-1657.8 3271.82,-1604.25 3483.42,-1586.1\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3483.82,-1589.58 3493.48,-1585.23 3483.22,-1582.6 3483.82,-1589.58\"/>\n<text text-anchor=\"middle\" x=\"3477.38\" y=\"-1600.66\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#4ba6e7\" stroke=\"black\" d=\"M1033,-1509C1033,-1509 906,-1509 906,-1509 900,-1509 894,-1503 894,-1497 894,-1497 894,-1453 894,-1453 894,-1447 900,-1441 906,-1441 906,-1441 1033,-1441 1033,-1441 1039,-1441 1045,-1447 1045,-1453 1045,-1453 1045,-1497 1045,-1497 1045,-1503 1039,-1509 1033,-1509\"/>\n<text text-anchor=\"start\" x=\"902\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">name_title_Rev ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"932\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.151</text>\n<text text-anchor=\"start\" x=\"922\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 134</text>\n<text text-anchor=\"start\" x=\"916.5\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 123]</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1108.41,-1546.84C1087.9,-1536.38 1064.81,-1524.61 1043.43,-1513.7\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1044.88,-1510.52 1034.38,-1509.09 1041.7,-1516.75 1044.88,-1510.52\"/>\n</g>\n<!-- 33 -->\n<g id=\"node34\" class=\"node\">\n<title>33</title>\n<path fill=\"#fdf5ef\" stroke=\"black\" d=\"M1214,-1509C1214,-1509 1125,-1509 1125,-1509 1119,-1509 1113,-1503 1113,-1497 1113,-1497 1113,-1453 1113,-1453 1113,-1447 1119,-1441 1125,-1441 1125,-1441 1214,-1441 1214,-1441 1220,-1441 1226,-1447 1226,-1453 1226,-1453 1226,-1497 1226,-1497 1226,-1503 1220,-1509 1214,-1509\"/>\n<text text-anchor=\"start\" x=\"1128.5\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.241</text>\n<text text-anchor=\"start\" x=\"1132\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.499</text>\n<text text-anchor=\"start\" x=\"1122\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 121</text>\n<text text-anchor=\"start\" x=\"1121\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [63, 58]</text>\n</g>\n<!-- 1&#45;&gt;33 -->\n<g id=\"edge33\" class=\"edge\">\n<title>1&#45;&gt;33</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1169.5,-1544.88C1169.5,-1536.78 1169.5,-1527.98 1169.5,-1519.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1173,-1519.3 1169.5,-1509.3 1166,-1519.3 1173,-1519.3\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#46a3e7\" stroke=\"black\" d=\"M765,-1405C765,-1405 676,-1405 676,-1405 670,-1405 664,-1399 664,-1393 664,-1393 664,-1349 664,-1349 664,-1343 670,-1337 676,-1337 676,-1337 765,-1337 765,-1337 771,-1337 777,-1343 777,-1349 777,-1349 777,-1393 777,-1393 777,-1399 771,-1405 765,-1405\"/>\n<text text-anchor=\"start\" x=\"677.5\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.471</text>\n<text text-anchor=\"start\" x=\"683\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.115</text>\n<text text-anchor=\"start\" x=\"673\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 131</text>\n<text text-anchor=\"start\" x=\"672\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 123]</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M893.78,-1442.98C859.66,-1429 819.73,-1412.65 786.81,-1399.16\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"787.86,-1395.81 777.28,-1395.26 785.21,-1402.29 787.86,-1395.81\"/>\n</g>\n<!-- 32 -->\n<g id=\"node33\" class=\"node\">\n<title>32</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1006,-1397.5C1006,-1397.5 933,-1397.5 933,-1397.5 927,-1397.5 921,-1391.5 921,-1385.5 921,-1385.5 921,-1356.5 921,-1356.5 921,-1350.5 927,-1344.5 933,-1344.5 933,-1344.5 1006,-1344.5 1006,-1344.5 1012,-1344.5 1018,-1350.5 1018,-1356.5 1018,-1356.5 1018,-1385.5 1018,-1385.5 1018,-1391.5 1012,-1397.5 1006,-1397.5\"/>\n<text text-anchor=\"start\" x=\"940.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"930\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"929\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 2&#45;&gt;32 -->\n<g id=\"edge32\" class=\"edge\">\n<title>2&#45;&gt;32</title>\n<path fill=\"none\" stroke=\"black\" d=\"M969.5,-1440.88C969.5,-1430.33 969.5,-1418.6 969.5,-1407.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"973,-1407.52 969.5,-1397.52 966,-1407.52 973,-1407.52\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#cee6f8\" stroke=\"black\" d=\"M596,-1301C596,-1301 465,-1301 465,-1301 459,-1301 453,-1295 453,-1289 453,-1289 453,-1245 453,-1245 453,-1239 459,-1233 465,-1233 465,-1233 596,-1233 596,-1233 602,-1233 608,-1239 608,-1245 608,-1245 608,-1289 608,-1289 608,-1295 602,-1301 596,-1301\"/>\n<text text-anchor=\"start\" x=\"461\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">name_title_Miss ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"497\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.49</text>\n<text text-anchor=\"start\" x=\"491\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"490\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 4]</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M663.75,-1339.53C644.13,-1329 621.89,-1317.06 601.29,-1306\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"602.72,-1302.8 592.26,-1301.15 599.41,-1308.97 602.72,-1302.8\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#41a1e6\" stroke=\"black\" d=\"M765,-1301C765,-1301 676,-1301 676,-1301 670,-1301 664,-1295 664,-1289 664,-1289 664,-1245 664,-1245 664,-1239 670,-1233 676,-1233 676,-1233 765,-1233 765,-1233 771,-1233 777,-1239 777,-1245 777,-1245 777,-1289 777,-1289 777,-1295 771,-1301 765,-1301\"/>\n<text text-anchor=\"start\" x=\"679.5\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.452</text>\n<text text-anchor=\"start\" x=\"683\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.077</text>\n<text text-anchor=\"start\" x=\"673\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 124</text>\n<text text-anchor=\"start\" x=\"672\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 119]</text>\n</g>\n<!-- 3&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>3&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M720.5,-1336.88C720.5,-1328.78 720.5,-1319.98 720.5,-1311.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"724,-1311.3 720.5,-1301.3 717,-1311.3 724,-1311.3\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#eeab7b\" stroke=\"black\" d=\"M436,-1197C436,-1197 317,-1197 317,-1197 311,-1197 305,-1191 305,-1185 305,-1185 305,-1141 305,-1141 305,-1135 311,-1129 317,-1129 317,-1129 436,-1129 436,-1129 442,-1129 448,-1135 448,-1141 448,-1141 448,-1185 448,-1185 448,-1191 442,-1197 436,-1197\"/>\n<text text-anchor=\"start\" x=\"313\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_F ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"339\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"337\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"336\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 1]</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M480.5,-1232.88C466.04,-1223.3 450.12,-1212.76 435.18,-1202.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"436.78,-1199.73 426.51,-1197.12 432.92,-1205.56 436.78,-1199.73\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M567,-1189.5C567,-1189.5 494,-1189.5 494,-1189.5 488,-1189.5 482,-1183.5 482,-1177.5 482,-1177.5 482,-1148.5 482,-1148.5 482,-1142.5 488,-1136.5 494,-1136.5 494,-1136.5 567,-1136.5 567,-1136.5 573,-1136.5 579,-1142.5 579,-1148.5 579,-1148.5 579,-1177.5 579,-1177.5 579,-1183.5 573,-1189.5 567,-1189.5\"/>\n<text text-anchor=\"start\" x=\"501.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"491\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"490\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\n</g>\n<!-- 4&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>4&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M530.5,-1232.88C530.5,-1222.33 530.5,-1210.6 530.5,-1199.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"534,-1199.52 530.5,-1189.52 527,-1199.52 534,-1199.52\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M298,-1085.5C298,-1085.5 225,-1085.5 225,-1085.5 219,-1085.5 213,-1079.5 213,-1073.5 213,-1073.5 213,-1044.5 213,-1044.5 213,-1038.5 219,-1032.5 225,-1032.5 225,-1032.5 298,-1032.5 298,-1032.5 304,-1032.5 310,-1038.5 310,-1044.5 310,-1044.5 310,-1073.5 310,-1073.5 310,-1079.5 304,-1085.5 298,-1085.5\"/>\n<text text-anchor=\"start\" x=\"232.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"222\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"221\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M339.16,-1128.88C325.9,-1117.12 310.99,-1103.89 297.81,-1092.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"300.08,-1089.54 290.27,-1085.52 295.43,-1094.77 300.08,-1089.54\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M413,-1085.5C413,-1085.5 340,-1085.5 340,-1085.5 334,-1085.5 328,-1079.5 328,-1073.5 328,-1073.5 328,-1044.5 328,-1044.5 328,-1038.5 334,-1032.5 340,-1032.5 340,-1032.5 413,-1032.5 413,-1032.5 419,-1032.5 425,-1038.5 425,-1044.5 425,-1044.5 425,-1073.5 425,-1073.5 425,-1079.5 419,-1085.5 413,-1085.5\"/>\n<text text-anchor=\"start\" x=\"347.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"337\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"336\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M376.5,-1128.88C376.5,-1118.33 376.5,-1106.6 376.5,-1095.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"380,-1095.52 376.5,-1085.52 373,-1095.52 380,-1095.52\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#4fa8e8\" stroke=\"black\" d=\"M699,-1197C699,-1197 618,-1197 618,-1197 612,-1197 606,-1191 606,-1185 606,-1185 606,-1141 606,-1141 606,-1135 612,-1129 618,-1129 618,-1129 699,-1129 699,-1129 705,-1129 711,-1135 711,-1141 711,-1141 711,-1185 711,-1185 711,-1191 705,-1197 699,-1197\"/>\n<text text-anchor=\"start\" x=\"622\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.43</text>\n<text text-anchor=\"start\" x=\"625\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.18</text>\n<text text-anchor=\"start\" x=\"615\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 50</text>\n<text text-anchor=\"start\" x=\"614\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 45]</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M700.37,-1232.88C695.17,-1224.33 689.51,-1215.01 684.07,-1206.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"686.93,-1204.03 678.74,-1197.3 680.94,-1207.66 686.93,-1204.03\"/>\n</g>\n<!-- 31 -->\n<g id=\"node32\" class=\"node\">\n<title>31</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M822,-1189.5C822,-1189.5 741,-1189.5 741,-1189.5 735,-1189.5 729,-1183.5 729,-1177.5 729,-1177.5 729,-1148.5 729,-1148.5 729,-1142.5 735,-1136.5 741,-1136.5 741,-1136.5 822,-1136.5 822,-1136.5 828,-1136.5 834,-1142.5 834,-1148.5 834,-1148.5 834,-1177.5 834,-1177.5 834,-1183.5 828,-1189.5 822,-1189.5\"/>\n<text text-anchor=\"start\" x=\"752.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"738\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 74</text>\n<text text-anchor=\"start\" x=\"737\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 74]</text>\n</g>\n<!-- 9&#45;&gt;31 -->\n<g id=\"edge31\" class=\"edge\">\n<title>9&#45;&gt;31</title>\n<path fill=\"none\" stroke=\"black\" d=\"M740.3,-1232.88C746.95,-1221.78 754.37,-1209.37 761.06,-1198.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"764.11,-1199.9 766.24,-1189.52 758.1,-1196.31 764.11,-1199.9\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<path fill=\"#4ba6e7\" stroke=\"black\" d=\"M587.5,-1093C587.5,-1093 455.5,-1093 455.5,-1093 449.5,-1093 443.5,-1087 443.5,-1081 443.5,-1081 443.5,-1037 443.5,-1037 443.5,-1031 449.5,-1025 455.5,-1025 455.5,-1025 587.5,-1025 587.5,-1025 593.5,-1025 599.5,-1031 599.5,-1037 599.5,-1037 599.5,-1081 599.5,-1081 599.5,-1087 593.5,-1093 587.5,-1093\"/>\n<text text-anchor=\"start\" x=\"451.5\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">name_title_Rare ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"488\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.15</text>\n<text text-anchor=\"start\" x=\"478\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 49</text>\n<text text-anchor=\"start\" x=\"477\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 45]</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M614.02,-1128.88C601.34,-1119.44 587.4,-1109.06 574.27,-1099.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"576.34,-1096.46 566.23,-1093.3 572.16,-1102.08 576.34,-1096.46\"/>\n</g>\n<!-- 30 -->\n<g id=\"node31\" class=\"node\">\n<title>30</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M703,-1085.5C703,-1085.5 630,-1085.5 630,-1085.5 624,-1085.5 618,-1079.5 618,-1073.5 618,-1073.5 618,-1044.5 618,-1044.5 618,-1038.5 624,-1032.5 630,-1032.5 630,-1032.5 703,-1032.5 703,-1032.5 709,-1032.5 715,-1038.5 715,-1044.5 715,-1044.5 715,-1073.5 715,-1073.5 715,-1079.5 709,-1085.5 703,-1085.5\"/>\n<text text-anchor=\"start\" x=\"637.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"627\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"626\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 10&#45;&gt;30 -->\n<g id=\"edge30\" class=\"edge\">\n<title>10&#45;&gt;30</title>\n<path fill=\"none\" stroke=\"black\" d=\"M661.1,-1128.88C661.93,-1118.22 662.86,-1106.35 663.71,-1095.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"667.21,-1095.76 664.5,-1085.52 660.23,-1095.22 667.21,-1095.76\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<path fill=\"#46a4e7\" stroke=\"black\" d=\"M443,-989C443,-989 362,-989 362,-989 356,-989 350,-983 350,-977 350,-977 350,-933 350,-933 350,-927 356,-921 362,-921 362,-921 443,-921 443,-921 449,-921 455,-927 455,-933 455,-933 455,-977 455,-977 455,-983 449,-989 443,-989\"/>\n<text text-anchor=\"start\" x=\"366\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"365\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.117</text>\n<text text-anchor=\"start\" x=\"359\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 48</text>\n<text text-anchor=\"start\" x=\"358\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 45]</text>\n</g>\n<!-- 11&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>11&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M482.86,-1024.88C472.06,-1015.62 460.2,-1005.45 448.99,-995.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"451.22,-993.15 441.35,-989.3 446.66,-998.46 451.22,-993.15\"/>\n</g>\n<!-- 29 -->\n<g id=\"node30\" class=\"node\">\n<title>29</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M558,-981.5C558,-981.5 485,-981.5 485,-981.5 479,-981.5 473,-975.5 473,-969.5 473,-969.5 473,-940.5 473,-940.5 473,-934.5 479,-928.5 485,-928.5 485,-928.5 558,-928.5 558,-928.5 564,-928.5 570,-934.5 570,-940.5 570,-940.5 570,-969.5 570,-969.5 570,-975.5 564,-981.5 558,-981.5\"/>\n<text text-anchor=\"start\" x=\"492.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"482\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"481\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 11&#45;&gt;29 -->\n<g id=\"edge29\" class=\"edge\">\n<title>11&#45;&gt;29</title>\n<path fill=\"none\" stroke=\"black\" d=\"M521.5,-1024.88C521.5,-1014.33 521.5,-1002.6 521.5,-991.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"525,-991.52 521.5,-981.52 518,-991.52 525,-991.52\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<path fill=\"#50a8e8\" stroke=\"black\" d=\"M329,-885C329,-885 248,-885 248,-885 242,-885 236,-879 236,-873 236,-873 236,-829 236,-829 236,-823 242,-817 248,-817 248,-817 329,-817 329,-817 335,-817 341,-823 341,-829 341,-829 341,-873 341,-873 341,-879 335,-885 329,-885\"/>\n<text text-anchor=\"start\" x=\"251\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"251\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.185</text>\n<text text-anchor=\"start\" x=\"245\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 29</text>\n<text text-anchor=\"start\" x=\"244\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 26]</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M365.49,-920.88C355.23,-911.71 343.99,-901.65 333.34,-892.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"335.5,-889.36 325.72,-885.3 330.84,-894.58 335.5,-889.36\"/>\n</g>\n<!-- 28 -->\n<g id=\"node29\" class=\"node\">\n<title>28</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M452,-877.5C452,-877.5 371,-877.5 371,-877.5 365,-877.5 359,-871.5 359,-865.5 359,-865.5 359,-836.5 359,-836.5 359,-830.5 365,-824.5 371,-824.5 371,-824.5 452,-824.5 452,-824.5 458,-824.5 464,-830.5 464,-836.5 464,-836.5 464,-865.5 464,-865.5 464,-871.5 458,-877.5 452,-877.5\"/>\n<text text-anchor=\"start\" x=\"382.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"368\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\n<text text-anchor=\"start\" x=\"367\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 19]</text>\n</g>\n<!-- 12&#45;&gt;28 -->\n<g id=\"edge28\" class=\"edge\">\n<title>12&#45;&gt;28</title>\n<path fill=\"none\" stroke=\"black\" d=\"M405.42,-920.88C406.36,-910.22 407.41,-898.35 408.37,-887.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"411.86,-887.79 409.25,-877.52 404.88,-887.17 411.86,-887.79\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<path fill=\"#44a2e6\" stroke=\"black\" d=\"M207,-781C207,-781 126,-781 126,-781 120,-781 114,-775 114,-769 114,-769 114,-725 114,-725 114,-719 120,-713 126,-713 126,-713 207,-713 207,-713 213,-713 219,-719 219,-725 219,-725 219,-769 219,-769 219,-775 213,-781 207,-781\"/>\n<text text-anchor=\"start\" x=\"127\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.551</text>\n<text text-anchor=\"start\" x=\"137.5\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.1</text>\n<text text-anchor=\"start\" x=\"123\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\n<text text-anchor=\"start\" x=\"122\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 18]</text>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M248.89,-816.88C237.81,-807.62 225.65,-797.45 214.16,-787.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"216.25,-785.03 206.33,-781.3 211.76,-790.4 216.25,-785.03\"/>\n</g>\n<!-- 19 -->\n<g id=\"node20\" class=\"node\">\n<title>19</title>\n<path fill=\"#6ab6ec\" stroke=\"black\" d=\"M341,-781C341,-781 262,-781 262,-781 256,-781 250,-775 250,-769 250,-769 250,-725 250,-725 250,-719 256,-713 262,-713 262,-713 341,-713 341,-713 347,-713 353,-719 353,-725 353,-725 353,-769 353,-769 353,-775 347,-781 341,-781\"/>\n<text text-anchor=\"start\" x=\"262\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.777</text>\n<text text-anchor=\"start\" x=\"268\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"258\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"261\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 8]</text>\n</g>\n<!-- 13&#45;&gt;19 -->\n<g id=\"edge19\" class=\"edge\">\n<title>13&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"black\" d=\"M292.72,-816.88C293.75,-808.78 294.87,-799.98 295.96,-791.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"299.46,-791.66 297.26,-781.3 292.52,-790.78 299.46,-791.66\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M85,-669.5C85,-669.5 12,-669.5 12,-669.5 6,-669.5 0,-663.5 0,-657.5 0,-657.5 0,-628.5 0,-628.5 0,-622.5 6,-616.5 12,-616.5 12,-616.5 85,-616.5 85,-616.5 91,-616.5 97,-622.5 97,-628.5 97,-628.5 97,-657.5 97,-657.5 97,-663.5 91,-669.5 85,-669.5\"/>\n<text text-anchor=\"start\" x=\"19.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"9\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 9]</text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M128.19,-712.88C114.58,-701.12 99.28,-687.89 85.75,-676.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"87.88,-673.41 78.02,-669.52 83.3,-678.71 87.88,-673.41\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<path fill=\"#4fa8e8\" stroke=\"black\" d=\"M206,-677C206,-677 127,-677 127,-677 121,-677 115,-671 115,-665 115,-665 115,-621 115,-621 115,-615 121,-609 127,-609 127,-609 206,-609 206,-609 212,-609 218,-615 218,-621 218,-621 218,-665 218,-665 218,-671 212,-677 206,-677\"/>\n<text text-anchor=\"start\" x=\"127\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.702</text>\n<text text-anchor=\"start\" x=\"133\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.18</text>\n<text text-anchor=\"start\" x=\"123\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"126\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 9]</text>\n</g>\n<!-- 14&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>14&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M166.5,-712.88C166.5,-704.78 166.5,-695.98 166.5,-687.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"170,-687.3 166.5,-677.3 163,-687.3 170,-687.3\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M88,-565.5C88,-565.5 15,-565.5 15,-565.5 9,-565.5 3,-559.5 3,-553.5 3,-553.5 3,-524.5 3,-524.5 3,-518.5 9,-512.5 15,-512.5 15,-512.5 88,-512.5 88,-512.5 94,-512.5 100,-518.5 100,-524.5 100,-524.5 100,-553.5 100,-553.5 100,-559.5 94,-565.5 88,-565.5\"/>\n<text text-anchor=\"start\" x=\"22.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"12\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"11\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 16&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>16&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"black\" d=\"M129.16,-608.88C115.9,-597.12 100.99,-583.89 87.81,-572.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"90.08,-569.54 80.27,-565.52 85.43,-574.77 90.08,-569.54\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M203,-565.5C203,-565.5 130,-565.5 130,-565.5 124,-565.5 118,-559.5 118,-553.5 118,-553.5 118,-524.5 118,-524.5 118,-518.5 124,-512.5 130,-512.5 130,-512.5 203,-512.5 203,-512.5 209,-512.5 215,-518.5 215,-524.5 215,-524.5 215,-553.5 215,-553.5 215,-559.5 209,-565.5 203,-565.5\"/>\n<text text-anchor=\"start\" x=\"137.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"127\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"126\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 9]</text>\n</g>\n<!-- 16&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>16&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"black\" d=\"M166.5,-608.88C166.5,-598.33 166.5,-586.6 166.5,-575.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"170,-575.52 166.5,-565.52 163,-575.52 170,-575.52\"/>\n</g>\n<!-- 20 -->\n<g id=\"node21\" class=\"node\">\n<title>20</title>\n<path fill=\"#52a9e8\" stroke=\"black\" d=\"M338.5,-677C338.5,-677 264.5,-677 264.5,-677 258.5,-677 252.5,-671 252.5,-665 252.5,-665 252.5,-621 252.5,-621 252.5,-615 258.5,-609 264.5,-609 264.5,-609 338.5,-609 338.5,-609 344.5,-609 350.5,-615 350.5,-621 350.5,-621 350.5,-665 350.5,-665 350.5,-671 344.5,-677 338.5,-677\"/>\n<text text-anchor=\"start\" x=\"260.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.203</text>\n<text text-anchor=\"start\" x=\"264\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.198</text>\n<text text-anchor=\"start\" x=\"262\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"261\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 8]</text>\n</g>\n<!-- 19&#45;&gt;20 -->\n<g id=\"edge20\" class=\"edge\">\n<title>19&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"black\" d=\"M301.5,-712.88C301.5,-704.78 301.5,-695.98 301.5,-687.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"305,-687.3 301.5,-677.3 298,-687.3 305,-687.3\"/>\n</g>\n<!-- 27 -->\n<g id=\"node28\" class=\"node\">\n<title>27</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M454,-669.5C454,-669.5 381,-669.5 381,-669.5 375,-669.5 369,-663.5 369,-657.5 369,-657.5 369,-628.5 369,-628.5 369,-622.5 375,-616.5 381,-616.5 381,-616.5 454,-616.5 454,-616.5 460,-616.5 466,-622.5 466,-628.5 466,-628.5 466,-657.5 466,-657.5 466,-663.5 460,-669.5 454,-669.5\"/>\n<text text-anchor=\"start\" x=\"388.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"378\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"377\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 19&#45;&gt;27 -->\n<g id=\"edge27\" class=\"edge\">\n<title>19&#45;&gt;27</title>\n<path fill=\"none\" stroke=\"black\" d=\"M339.16,-712.88C352.54,-701.12 367.58,-687.89 380.88,-676.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"383.28,-678.75 388.48,-669.52 378.66,-673.49 383.28,-678.75\"/>\n</g>\n<!-- 21 -->\n<g id=\"node22\" class=\"node\">\n<title>21</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M357.5,-573C357.5,-573 245.5,-573 245.5,-573 239.5,-573 233.5,-567 233.5,-561 233.5,-561 233.5,-517 233.5,-517 233.5,-511 239.5,-505 245.5,-505 245.5,-505 357.5,-505 357.5,-505 363.5,-505 369.5,-511 369.5,-517 369.5,-517 369.5,-561 369.5,-561 369.5,-567 363.5,-573 357.5,-573\"/>\n<text text-anchor=\"start\" x=\"241.5\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Embarked_C ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"264\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"262\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"261\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 20&#45;&gt;21 -->\n<g id=\"edge21\" class=\"edge\">\n<title>20&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"black\" d=\"M301.5,-608.88C301.5,-600.78 301.5,-591.98 301.5,-583.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"305,-583.3 301.5,-573.3 298,-583.3 305,-583.3\"/>\n</g>\n<!-- 26 -->\n<g id=\"node27\" class=\"node\">\n<title>26</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M473,-565.5C473,-565.5 400,-565.5 400,-565.5 394,-565.5 388,-559.5 388,-553.5 388,-553.5 388,-524.5 388,-524.5 388,-518.5 394,-512.5 400,-512.5 400,-512.5 473,-512.5 473,-512.5 479,-512.5 485,-518.5 485,-524.5 485,-524.5 485,-553.5 485,-553.5 485,-559.5 479,-565.5 473,-565.5\"/>\n<text text-anchor=\"start\" x=\"407.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"397\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"396\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 6]</text>\n</g>\n<!-- 20&#45;&gt;26 -->\n<g id=\"edge26\" class=\"edge\">\n<title>20&#45;&gt;26</title>\n<path fill=\"none\" stroke=\"black\" d=\"M345.33,-608.88C361.2,-596.9 379.06,-583.4 394.74,-571.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"396.85,-574.34 402.72,-565.52 392.63,-568.76 396.85,-574.34\"/>\n</g>\n<!-- 22 -->\n<g id=\"node23\" class=\"node\">\n<title>22</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M280,-469C280,-469 207,-469 207,-469 201,-469 195,-463 195,-457 195,-457 195,-413 195,-413 195,-407 201,-401 207,-401 207,-401 280,-401 280,-401 286,-401 292,-407 292,-413 292,-413 292,-457 292,-457 292,-463 286,-469 280,-469\"/>\n<text text-anchor=\"start\" x=\"206\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 2.0</text>\n<text text-anchor=\"start\" x=\"214.5\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"204\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"203\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 21&#45;&gt;22 -->\n<g id=\"edge22\" class=\"edge\">\n<title>21&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"black\" d=\"M282.67,-504.88C277.81,-496.33 272.51,-487.01 267.42,-478.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"270.42,-476.26 262.43,-469.3 264.34,-479.72 270.42,-476.26\"/>\n</g>\n<!-- 25 -->\n<g id=\"node26\" class=\"node\">\n<title>25</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M395,-461.5C395,-461.5 322,-461.5 322,-461.5 316,-461.5 310,-455.5 310,-449.5 310,-449.5 310,-420.5 310,-420.5 310,-414.5 316,-408.5 322,-408.5 322,-408.5 395,-408.5 395,-408.5 401,-408.5 407,-414.5 407,-420.5 407,-420.5 407,-449.5 407,-449.5 407,-455.5 401,-461.5 395,-461.5\"/>\n<text text-anchor=\"start\" x=\"329.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"319\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"318\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 21&#45;&gt;25 -->\n<g id=\"edge25\" class=\"edge\">\n<title>21&#45;&gt;25</title>\n<path fill=\"none\" stroke=\"black\" d=\"M320.01,-504.88C326.15,-493.89 333.01,-481.62 339.21,-470.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"342.42,-471.96 344.24,-461.52 336.31,-468.54 342.42,-471.96\"/>\n</g>\n<!-- 23 -->\n<g id=\"node24\" class=\"node\">\n<title>23</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M223,-357.5C223,-357.5 150,-357.5 150,-357.5 144,-357.5 138,-351.5 138,-345.5 138,-345.5 138,-316.5 138,-316.5 138,-310.5 144,-304.5 150,-304.5 150,-304.5 223,-304.5 223,-304.5 229,-304.5 235,-310.5 235,-316.5 235,-316.5 235,-345.5 235,-345.5 235,-351.5 229,-357.5 223,-357.5\"/>\n<text text-anchor=\"start\" x=\"157.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"147\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"146\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 22&#45;&gt;23 -->\n<g id=\"edge23\" class=\"edge\">\n<title>22&#45;&gt;23</title>\n<path fill=\"none\" stroke=\"black\" d=\"M224.99,-400.88C218.85,-389.89 211.99,-377.62 205.79,-366.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"208.69,-364.54 200.76,-357.52 202.58,-367.96 208.69,-364.54\"/>\n</g>\n<!-- 24 -->\n<g id=\"node25\" class=\"node\">\n<title>24</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M338,-357.5C338,-357.5 265,-357.5 265,-357.5 259,-357.5 253,-351.5 253,-345.5 253,-345.5 253,-316.5 253,-316.5 253,-310.5 259,-304.5 265,-304.5 265,-304.5 338,-304.5 338,-304.5 344,-304.5 350,-310.5 350,-316.5 350,-316.5 350,-345.5 350,-345.5 350,-351.5 344,-357.5 338,-357.5\"/>\n<text text-anchor=\"start\" x=\"272.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"262\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"261\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 22&#45;&gt;24 -->\n<g id=\"edge24\" class=\"edge\">\n<title>22&#45;&gt;24</title>\n<path fill=\"none\" stroke=\"black\" d=\"M262.33,-400.88C268.58,-389.89 275.56,-377.62 281.87,-366.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"285.09,-367.94 286.99,-357.52 279,-364.48 285.09,-367.94\"/>\n</g>\n<!-- 34 -->\n<g id=\"node35\" class=\"node\">\n<title>34</title>\n<path fill=\"#aad5f4\" stroke=\"black\" d=\"M1175,-1405C1175,-1405 1086,-1405 1086,-1405 1080,-1405 1074,-1399 1074,-1393 1074,-1393 1074,-1349 1074,-1349 1074,-1343 1080,-1337 1086,-1337 1086,-1337 1175,-1337 1175,-1337 1181,-1337 1187,-1343 1187,-1349 1187,-1349 1187,-1393 1187,-1393 1187,-1399 1181,-1405 1175,-1405\"/>\n<text text-anchor=\"start\" x=\"1091\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.509</text>\n<text text-anchor=\"start\" x=\"1093\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.463</text>\n<text text-anchor=\"start\" x=\"1087\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 88</text>\n<text text-anchor=\"start\" x=\"1082\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [32, 56]</text>\n</g>\n<!-- 33&#45;&gt;34 -->\n<g id=\"edge34\" class=\"edge\">\n<title>33&#45;&gt;34</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1156.84,-1440.88C1153.67,-1432.6 1150.23,-1423.6 1146.91,-1414.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1150.07,-1413.39 1143.23,-1405.3 1143.53,-1415.89 1150.07,-1413.39\"/>\n</g>\n<!-- 91 -->\n<g id=\"node92\" class=\"node\">\n<title>91</title>\n<path fill=\"#e78946\" stroke=\"black\" d=\"M1298,-1405C1298,-1405 1217,-1405 1217,-1405 1211,-1405 1205,-1399 1205,-1393 1205,-1393 1205,-1349 1205,-1349 1205,-1343 1211,-1337 1217,-1337 1217,-1337 1298,-1337 1298,-1337 1304,-1337 1310,-1343 1310,-1349 1310,-1349 1310,-1393 1310,-1393 1310,-1399 1304,-1405 1298,-1405\"/>\n<text text-anchor=\"start\" x=\"1221\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1220\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.114</text>\n<text text-anchor=\"start\" x=\"1214\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 33</text>\n<text text-anchor=\"start\" x=\"1213\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 2]</text>\n</g>\n<!-- 33&#45;&gt;91 -->\n<g id=\"edge91\" class=\"edge\">\n<title>33&#45;&gt;91</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1198.07,-1440.88C1205.76,-1431.98 1214.16,-1422.24 1222.16,-1412.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1224.89,-1415.16 1228.77,-1405.3 1219.59,-1410.58 1224.89,-1415.16\"/>\n</g>\n<!-- 35 -->\n<g id=\"node36\" class=\"node\">\n<title>35</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M1058,-1301C1058,-1301 969,-1301 969,-1301 963,-1301 957,-1295 957,-1289 957,-1289 957,-1245 957,-1245 957,-1239 963,-1233 969,-1233 969,-1233 1058,-1233 1058,-1233 1064,-1233 1070,-1239 1070,-1245 1070,-1245 1070,-1289 1070,-1289 1070,-1295 1064,-1301 1058,-1301\"/>\n<text text-anchor=\"start\" x=\"972\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.998</text>\n<text text-anchor=\"start\" x=\"976\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"970\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 84</text>\n<text text-anchor=\"start\" x=\"965\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [28, 56]</text>\n</g>\n<!-- 34&#45;&gt;35 -->\n<g id=\"edge35\" class=\"edge\">\n<title>34&#45;&gt;35</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1092.51,-1336.88C1081.99,-1327.71 1070.45,-1317.65 1059.52,-1308.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1061.53,-1305.23 1051.7,-1301.3 1056.93,-1310.51 1061.53,-1305.23\"/>\n</g>\n<!-- 90 -->\n<g id=\"node91\" class=\"node\">\n<title>90</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1173,-1293.5C1173,-1293.5 1100,-1293.5 1100,-1293.5 1094,-1293.5 1088,-1287.5 1088,-1281.5 1088,-1281.5 1088,-1252.5 1088,-1252.5 1088,-1246.5 1094,-1240.5 1100,-1240.5 1100,-1240.5 1173,-1240.5 1173,-1240.5 1179,-1240.5 1185,-1246.5 1185,-1252.5 1185,-1252.5 1185,-1281.5 1185,-1281.5 1185,-1287.5 1179,-1293.5 1173,-1293.5\"/>\n<text text-anchor=\"start\" x=\"1107.5\" y=\"-1278.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1097\" y=\"-1263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"1096\" y=\"-1248.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 0]</text>\n</g>\n<!-- 34&#45;&gt;90 -->\n<g id=\"edge90\" class=\"edge\">\n<title>34&#45;&gt;90</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1132.45,-1336.88C1133.08,-1326.22 1133.77,-1314.35 1134.41,-1303.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1137.91,-1303.71 1135,-1293.52 1130.92,-1303.3 1137.91,-1303.71\"/>\n</g>\n<!-- 36 -->\n<g id=\"node37\" class=\"node\">\n<title>36</title>\n<path fill=\"#57ace9\" stroke=\"black\" d=\"M959,-1197C959,-1197 878,-1197 878,-1197 872,-1197 866,-1191 866,-1185 866,-1185 866,-1141 866,-1141 866,-1135 872,-1129 878,-1129 878,-1129 959,-1129 959,-1129 965,-1129 971,-1135 971,-1141 971,-1141 971,-1185 971,-1185 971,-1191 965,-1197 959,-1197\"/>\n<text text-anchor=\"start\" x=\"881\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 2.5</text>\n<text text-anchor=\"start\" x=\"881\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.227</text>\n<text text-anchor=\"start\" x=\"875\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 23</text>\n<text text-anchor=\"start\" x=\"874\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 20]</text>\n</g>\n<!-- 35&#45;&gt;36 -->\n<g id=\"edge36\" class=\"edge\">\n<title>35&#45;&gt;36</title>\n<path fill=\"none\" stroke=\"black\" d=\"M982.66,-1232.88C974.28,-1223.89 965.11,-1214.04 956.39,-1204.68\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"958.89,-1202.23 949.51,-1197.3 953.77,-1207 958.89,-1202.23\"/>\n</g>\n<!-- 43 -->\n<g id=\"node44\" class=\"node\">\n<title>43</title>\n<path fill=\"#c2e1f7\" stroke=\"black\" d=\"M1102,-1197C1102,-1197 1013,-1197 1013,-1197 1007,-1197 1001,-1191 1001,-1185 1001,-1185 1001,-1141 1001,-1141 1001,-1135 1007,-1129 1013,-1129 1013,-1129 1102,-1129 1102,-1129 1108,-1129 1114,-1135 1114,-1141 1114,-1141 1114,-1185 1114,-1185 1114,-1191 1108,-1197 1102,-1197\"/>\n<text text-anchor=\"start\" x=\"1014.5\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.801</text>\n<text text-anchor=\"start\" x=\"1020\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.484</text>\n<text text-anchor=\"start\" x=\"1014\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 61</text>\n<text text-anchor=\"start\" x=\"1009\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [25, 36]</text>\n</g>\n<!-- 35&#45;&gt;43 -->\n<g id=\"edge43\" class=\"edge\">\n<title>35&#45;&gt;43</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1027.79,-1232.88C1031.4,-1224.51 1035.33,-1215.4 1039.11,-1206.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1042.39,-1207.87 1043.14,-1197.3 1035.96,-1205.1 1042.39,-1207.87\"/>\n</g>\n<!-- 37 -->\n<g id=\"node38\" class=\"node\">\n<title>37</title>\n<path fill=\"#43a2e6\" stroke=\"black\" d=\"M834,-1093C834,-1093 753,-1093 753,-1093 747,-1093 741,-1087 741,-1081 741,-1081 741,-1037 741,-1037 741,-1031 747,-1025 753,-1025 753,-1025 834,-1025 834,-1025 840,-1025 846,-1031 846,-1037 846,-1037 846,-1081 846,-1081 846,-1087 840,-1093 834,-1093\"/>\n<text text-anchor=\"start\" x=\"750.5\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.794</text>\n<text text-anchor=\"start\" x=\"756\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.091</text>\n<text text-anchor=\"start\" x=\"750\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 21</text>\n<text text-anchor=\"start\" x=\"749\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 20]</text>\n</g>\n<!-- 36&#45;&gt;37 -->\n<g id=\"edge37\" class=\"edge\">\n<title>36&#45;&gt;37</title>\n<path fill=\"none\" stroke=\"black\" d=\"M877.92,-1128.88C866.56,-1119.62 854.11,-1109.45 842.33,-1099.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"844.27,-1096.91 834.31,-1093.3 839.84,-1102.33 844.27,-1096.91\"/>\n</g>\n<!-- 42 -->\n<g id=\"node43\" class=\"node\">\n<title>42</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M955,-1085.5C955,-1085.5 882,-1085.5 882,-1085.5 876,-1085.5 870,-1079.5 870,-1073.5 870,-1073.5 870,-1044.5 870,-1044.5 870,-1038.5 876,-1032.5 882,-1032.5 882,-1032.5 955,-1032.5 955,-1032.5 961,-1032.5 967,-1038.5 967,-1044.5 967,-1044.5 967,-1073.5 967,-1073.5 967,-1079.5 961,-1085.5 955,-1085.5\"/>\n<text text-anchor=\"start\" x=\"889.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"879\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"878\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 36&#45;&gt;42 -->\n<g id=\"edge42\" class=\"edge\">\n<title>36&#45;&gt;42</title>\n<path fill=\"none\" stroke=\"black\" d=\"M918.5,-1128.88C918.5,-1118.33 918.5,-1106.6 918.5,-1095.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"922,-1095.52 918.5,-1085.52 915,-1095.52 922,-1095.52\"/>\n</g>\n<!-- 38 -->\n<g id=\"node39\" class=\"node\">\n<title>38</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M711,-989C711,-989 600,-989 600,-989 594,-989 588,-983 588,-977 588,-977 588,-933 588,-933 588,-927 594,-921 600,-921 600,-921 711,-921 711,-921 717,-921 723,-927 723,-933 723,-933 723,-977 723,-977 723,-983 717,-989 711,-989\"/>\n<text text-anchor=\"start\" x=\"596\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Embarked_S ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"618\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"616\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"615\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 37&#45;&gt;38 -->\n<g id=\"edge38\" class=\"edge\">\n<title>37&#45;&gt;38</title>\n<path fill=\"none\" stroke=\"black\" d=\"M748.7,-1024.88C735.92,-1015.44 721.88,-1005.06 708.66,-995.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"710.67,-992.43 700.55,-989.3 706.51,-998.06 710.67,-992.43\"/>\n</g>\n<!-- 41 -->\n<g id=\"node42\" class=\"node\">\n<title>41</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M834,-981.5C834,-981.5 753,-981.5 753,-981.5 747,-981.5 741,-975.5 741,-969.5 741,-969.5 741,-940.5 741,-940.5 741,-934.5 747,-928.5 753,-928.5 753,-928.5 834,-928.5 834,-928.5 840,-928.5 846,-934.5 846,-940.5 846,-940.5 846,-969.5 846,-969.5 846,-975.5 840,-981.5 834,-981.5\"/>\n<text text-anchor=\"start\" x=\"764.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"750\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n<text text-anchor=\"start\" x=\"749\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 18]</text>\n</g>\n<!-- 37&#45;&gt;41 -->\n<g id=\"edge41\" class=\"edge\">\n<title>37&#45;&gt;41</title>\n<path fill=\"none\" stroke=\"black\" d=\"M793.5,-1024.88C793.5,-1014.33 793.5,-1002.6 793.5,-991.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"797,-991.52 793.5,-981.52 790,-991.52 797,-991.52\"/>\n</g>\n<!-- 39 -->\n<g id=\"node40\" class=\"node\">\n<title>39</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M588,-877.5C588,-877.5 515,-877.5 515,-877.5 509,-877.5 503,-871.5 503,-865.5 503,-865.5 503,-836.5 503,-836.5 503,-830.5 509,-824.5 515,-824.5 515,-824.5 588,-824.5 588,-824.5 594,-824.5 600,-830.5 600,-836.5 600,-836.5 600,-865.5 600,-865.5 600,-871.5 594,-877.5 588,-877.5\"/>\n<text text-anchor=\"start\" x=\"522.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"512\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"511\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 38&#45;&gt;39 -->\n<g id=\"edge39\" class=\"edge\">\n<title>38&#45;&gt;39</title>\n<path fill=\"none\" stroke=\"black\" d=\"M621.73,-920.88C609.85,-909.23 596.51,-896.14 584.67,-884.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"587.11,-882.02 577.52,-877.52 582.21,-887.02 587.11,-882.02\"/>\n</g>\n<!-- 40 -->\n<g id=\"node41\" class=\"node\">\n<title>40</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M703,-877.5C703,-877.5 630,-877.5 630,-877.5 624,-877.5 618,-871.5 618,-865.5 618,-865.5 618,-836.5 618,-836.5 618,-830.5 624,-824.5 630,-824.5 630,-824.5 703,-824.5 703,-824.5 709,-824.5 715,-830.5 715,-836.5 715,-836.5 715,-865.5 715,-865.5 715,-871.5 709,-877.5 703,-877.5\"/>\n<text text-anchor=\"start\" x=\"637.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"627\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"626\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 38&#45;&gt;40 -->\n<g id=\"edge40\" class=\"edge\">\n<title>38&#45;&gt;40</title>\n<path fill=\"none\" stroke=\"black\" d=\"M659.07,-920.88C660.22,-910.22 661.5,-898.35 662.67,-887.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"666.16,-887.84 663.75,-877.52 659.2,-887.09 666.16,-887.84\"/>\n</g>\n<!-- 44 -->\n<g id=\"node45\" class=\"node\">\n<title>44</title>\n<path fill=\"#82c1ef\" stroke=\"black\" d=\"M1098,-1093C1098,-1093 1017,-1093 1017,-1093 1011,-1093 1005,-1087 1005,-1081 1005,-1081 1005,-1037 1005,-1037 1005,-1031 1011,-1025 1017,-1025 1017,-1025 1098,-1025 1098,-1025 1104,-1025 1110,-1031 1110,-1037 1110,-1037 1110,-1081 1110,-1081 1110,-1087 1104,-1093 1098,-1093\"/>\n<text text-anchor=\"start\" x=\"1016\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.431</text>\n<text text-anchor=\"start\" x=\"1020\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.393</text>\n<text text-anchor=\"start\" x=\"1014\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 26</text>\n<text text-anchor=\"start\" x=\"1013\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 19]</text>\n</g>\n<!-- 43&#45;&gt;44 -->\n<g id=\"edge44\" class=\"edge\">\n<title>43&#45;&gt;44</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1057.5,-1128.88C1057.5,-1120.78 1057.5,-1111.98 1057.5,-1103.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1061,-1103.3 1057.5,-1093.3 1054,-1103.3 1061,-1103.3\"/>\n</g>\n<!-- 65 -->\n<g id=\"node66\" class=\"node\">\n<title>65</title>\n<path fill=\"#fef8f4\" stroke=\"black\" d=\"M1253,-1093C1253,-1093 1164,-1093 1164,-1093 1158,-1093 1152,-1087 1152,-1081 1152,-1081 1152,-1037 1152,-1037 1152,-1031 1158,-1025 1164,-1025 1164,-1025 1253,-1025 1253,-1025 1259,-1025 1265,-1031 1265,-1037 1265,-1037 1265,-1081 1265,-1081 1265,-1087 1259,-1093 1253,-1093\"/>\n<text text-anchor=\"start\" x=\"1165.5\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.713</text>\n<text text-anchor=\"start\" x=\"1179.5\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"1165\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 35</text>\n<text text-anchor=\"start\" x=\"1160\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [18, 17]</text>\n</g>\n<!-- 43&#45;&gt;65 -->\n<g id=\"edge65\" class=\"edge\">\n<title>43&#45;&gt;65</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1106.53,-1128.88C1120.71,-1119.3 1136.32,-1108.76 1150.97,-1098.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1153.13,-1101.62 1159.46,-1093.12 1149.22,-1095.82 1153.13,-1101.62\"/>\n</g>\n<!-- 45 -->\n<g id=\"node46\" class=\"node\">\n<title>45</title>\n<path fill=\"#68b4eb\" stroke=\"black\" d=\"M957,-989C957,-989 876,-989 876,-989 870,-989 864,-983 864,-977 864,-977 864,-933 864,-933 864,-927 870,-921 876,-921 876,-921 957,-921 957,-921 963,-921 969,-927 969,-933 969,-933 969,-977 969,-977 969,-983 963,-989 957,-989\"/>\n<text text-anchor=\"start\" x=\"880\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 1.0</text>\n<text text-anchor=\"start\" x=\"879\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.308</text>\n<text text-anchor=\"start\" x=\"873\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 21</text>\n<text text-anchor=\"start\" x=\"872\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 17]</text>\n</g>\n<!-- 44&#45;&gt;45 -->\n<g id=\"edge45\" class=\"edge\">\n<title>44&#45;&gt;45</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1011.72,-1024.88C998.67,-1015.44 984.32,-1005.06 970.81,-995.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"972.69,-992.32 962.53,-989.3 968.58,-998 972.69,-992.32\"/>\n</g>\n<!-- 62 -->\n<g id=\"node63\" class=\"node\">\n<title>62</title>\n<path fill=\"#f6d5bd\" stroke=\"black\" d=\"M1130,-989C1130,-989 999,-989 999,-989 993,-989 987,-983 987,-977 987,-977 987,-933 987,-933 987,-927 993,-921 999,-921 999,-921 1130,-921 1130,-921 1136,-921 1142,-927 1142,-933 1142,-933 1142,-977 1142,-977 1142,-983 1136,-989 1130,-989\"/>\n<text text-anchor=\"start\" x=\"995\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">name_title_Miss ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1031\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n<text text-anchor=\"start\" x=\"1025\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"1024\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 2]</text>\n</g>\n<!-- 44&#45;&gt;62 -->\n<g id=\"edge62\" class=\"edge\">\n<title>44&#45;&gt;62</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1059.77,-1024.88C1060.33,-1016.78 1060.93,-1007.98 1061.52,-999.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1065.02,-999.52 1062.21,-989.3 1058.04,-999.04 1065.02,-999.52\"/>\n</g>\n<!-- 46 -->\n<g id=\"node47\" class=\"node\">\n<title>46</title>\n<path fill=\"#5caeea\" stroke=\"black\" d=\"M838,-885C838,-885 757,-885 757,-885 751,-885 745,-879 745,-873 745,-873 745,-829 745,-829 745,-823 751,-817 757,-817 757,-817 838,-817 838,-817 844,-817 850,-823 850,-829 850,-829 850,-873 850,-873 850,-879 844,-885 838,-885\"/>\n<text text-anchor=\"start\" x=\"754.5\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.895</text>\n<text text-anchor=\"start\" x=\"760\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.255</text>\n<text text-anchor=\"start\" x=\"754\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 20</text>\n<text text-anchor=\"start\" x=\"753\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 17]</text>\n</g>\n<!-- 45&#45;&gt;46 -->\n<g id=\"edge46\" class=\"edge\">\n<title>45&#45;&gt;46</title>\n<path fill=\"none\" stroke=\"black\" d=\"M877.86,-920.88C867.06,-911.62 855.2,-901.45 843.99,-891.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"846.22,-889.15 836.35,-885.3 841.66,-894.46 846.22,-889.15\"/>\n</g>\n<!-- 61 -->\n<g id=\"node62\" class=\"node\">\n<title>61</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M953,-877.5C953,-877.5 880,-877.5 880,-877.5 874,-877.5 868,-871.5 868,-865.5 868,-865.5 868,-836.5 868,-836.5 868,-830.5 874,-824.5 880,-824.5 880,-824.5 953,-824.5 953,-824.5 959,-824.5 965,-830.5 965,-836.5 965,-836.5 965,-865.5 965,-865.5 965,-871.5 959,-877.5 953,-877.5\"/>\n<text text-anchor=\"start\" x=\"887.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"877\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"876\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 45&#45;&gt;61 -->\n<g id=\"edge61\" class=\"edge\">\n<title>45&#45;&gt;61</title>\n<path fill=\"none\" stroke=\"black\" d=\"M916.5,-920.88C916.5,-910.33 916.5,-898.6 916.5,-887.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"920,-887.52 916.5,-877.52 913,-887.52 920,-887.52\"/>\n</g>\n<!-- 47 -->\n<g id=\"node48\" class=\"node\">\n<title>47</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M730,-773.5C730,-773.5 657,-773.5 657,-773.5 651,-773.5 645,-767.5 645,-761.5 645,-761.5 645,-732.5 645,-732.5 645,-726.5 651,-720.5 657,-720.5 657,-720.5 730,-720.5 730,-720.5 736,-720.5 742,-726.5 742,-732.5 742,-732.5 742,-761.5 742,-761.5 742,-767.5 736,-773.5 730,-773.5\"/>\n<text text-anchor=\"start\" x=\"664.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"654\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"653\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 46&#45;&gt;47 -->\n<g id=\"edge47\" class=\"edge\">\n<title>46&#45;&gt;47</title>\n<path fill=\"none\" stroke=\"black\" d=\"M763.73,-816.88C751.85,-805.23 738.51,-792.14 726.67,-780.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"729.11,-778.02 719.52,-773.52 724.21,-783.02 729.11,-778.02\"/>\n</g>\n<!-- 48 -->\n<g id=\"node49\" class=\"node\">\n<title>48</title>\n<path fill=\"#50a9e8\" stroke=\"black\" d=\"M853,-781C853,-781 772,-781 772,-781 766,-781 760,-775 760,-769 760,-769 760,-725 760,-725 760,-719 766,-713 772,-713 772,-713 853,-713 853,-713 859,-713 865,-719 865,-725 865,-725 865,-769 865,-769 865,-775 859,-781 853,-781\"/>\n<text text-anchor=\"start\" x=\"769.5\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.835</text>\n<text text-anchor=\"start\" x=\"775\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.188</text>\n<text text-anchor=\"start\" x=\"769\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\n<text text-anchor=\"start\" x=\"768\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 17]</text>\n</g>\n<!-- 46&#45;&gt;48 -->\n<g id=\"edge48\" class=\"edge\">\n<title>46&#45;&gt;48</title>\n<path fill=\"none\" stroke=\"black\" d=\"M802.37,-816.88C803.56,-808.78 804.86,-799.98 806.11,-791.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"809.61,-791.7 807.6,-781.3 802.69,-790.68 809.61,-791.7\"/>\n</g>\n<!-- 49 -->\n<g id=\"node50\" class=\"node\">\n<title>49</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M731.5,-677C731.5,-677 653.5,-677 653.5,-677 647.5,-677 641.5,-671 641.5,-665 641.5,-665 641.5,-621 641.5,-621 641.5,-615 647.5,-609 653.5,-609 653.5,-609 731.5,-609 731.5,-609 737.5,-609 743.5,-615 743.5,-621 743.5,-621 743.5,-665 743.5,-665 743.5,-671 737.5,-677 731.5,-677\"/>\n<text text-anchor=\"start\" x=\"649.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.844</text>\n<text text-anchor=\"start\" x=\"655\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"653\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"652\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 48&#45;&gt;49 -->\n<g id=\"edge49\" class=\"edge\">\n<title>48&#45;&gt;49</title>\n<path fill=\"none\" stroke=\"black\" d=\"M773.54,-712.88C762.64,-703.62 750.68,-693.45 739.38,-683.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"741.56,-681.11 731.68,-677.3 737.03,-686.44 741.56,-681.11\"/>\n</g>\n<!-- 54 -->\n<g id=\"node55\" class=\"node\">\n<title>54</title>\n<path fill=\"#46a4e7\" stroke=\"black\" d=\"M855,-677C855,-677 774,-677 774,-677 768,-677 762,-671 762,-665 762,-665 762,-621 762,-621 762,-615 768,-609 774,-609 774,-609 855,-609 855,-609 861,-609 867,-615 867,-621 867,-621 867,-665 867,-665 867,-671 861,-677 855,-677\"/>\n<text text-anchor=\"start\" x=\"771.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.815</text>\n<text text-anchor=\"start\" x=\"777\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.117</text>\n<text text-anchor=\"start\" x=\"771\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"start\" x=\"770\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 15]</text>\n</g>\n<!-- 48&#45;&gt;54 -->\n<g id=\"edge54\" class=\"edge\">\n<title>48&#45;&gt;54</title>\n<path fill=\"none\" stroke=\"black\" d=\"M813.15,-712.88C813.31,-704.78 813.48,-695.98 813.65,-687.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"817.15,-687.37 813.85,-677.3 810.15,-687.23 817.15,-687.37\"/>\n</g>\n<!-- 50 -->\n<g id=\"node51\" class=\"node\">\n<title>50</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M613,-565.5C613,-565.5 540,-565.5 540,-565.5 534,-565.5 528,-559.5 528,-553.5 528,-553.5 528,-524.5 528,-524.5 528,-518.5 534,-512.5 540,-512.5 540,-512.5 613,-512.5 613,-512.5 619,-512.5 625,-518.5 625,-524.5 625,-524.5 625,-553.5 625,-553.5 625,-559.5 619,-565.5 613,-565.5\"/>\n<text text-anchor=\"start\" x=\"547.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"537\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"536\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 49&#45;&gt;50 -->\n<g id=\"edge50\" class=\"edge\">\n<title>49&#45;&gt;50</title>\n<path fill=\"none\" stroke=\"black\" d=\"M654.84,-608.88C641.46,-597.12 626.42,-583.89 613.12,-572.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"615.34,-569.49 605.52,-565.52 610.72,-574.75 615.34,-569.49\"/>\n</g>\n<!-- 51 -->\n<g id=\"node52\" class=\"node\">\n<title>51</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M730,-573C730,-573 655,-573 655,-573 649,-573 643,-567 643,-561 643,-561 643,-517 643,-517 643,-511 649,-505 655,-505 655,-505 730,-505 730,-505 736,-505 742,-511 742,-517 742,-517 742,-561 742,-561 742,-567 736,-573 730,-573\"/>\n<text text-anchor=\"start\" x=\"651\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.553</text>\n<text text-anchor=\"start\" x=\"663.5\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"653\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"652\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 49&#45;&gt;51 -->\n<g id=\"edge51\" class=\"edge\">\n<title>49&#45;&gt;51</title>\n<path fill=\"none\" stroke=\"black\" d=\"M692.5,-608.88C692.5,-600.78 692.5,-591.98 692.5,-583.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"696,-583.3 692.5,-573.3 689,-583.3 696,-583.3\"/>\n</g>\n<!-- 52 -->\n<g id=\"node53\" class=\"node\">\n<title>52</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M616,-461.5C616,-461.5 543,-461.5 543,-461.5 537,-461.5 531,-455.5 531,-449.5 531,-449.5 531,-420.5 531,-420.5 531,-414.5 537,-408.5 543,-408.5 543,-408.5 616,-408.5 616,-408.5 622,-408.5 628,-414.5 628,-420.5 628,-420.5 628,-449.5 628,-449.5 628,-455.5 622,-461.5 616,-461.5\"/>\n<text text-anchor=\"start\" x=\"550.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"540\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"539\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 51&#45;&gt;52 -->\n<g id=\"edge52\" class=\"edge\">\n<title>51&#45;&gt;52</title>\n<path fill=\"none\" stroke=\"black\" d=\"M655.81,-504.88C642.9,-493.23 628.4,-480.14 615.54,-468.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"617.54,-465.62 607.77,-461.52 612.85,-470.82 617.54,-465.62\"/>\n</g>\n<!-- 53 -->\n<g id=\"node54\" class=\"node\">\n<title>53</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M731,-461.5C731,-461.5 658,-461.5 658,-461.5 652,-461.5 646,-455.5 646,-449.5 646,-449.5 646,-420.5 646,-420.5 646,-414.5 652,-408.5 658,-408.5 658,-408.5 731,-408.5 731,-408.5 737,-408.5 743,-414.5 743,-420.5 743,-420.5 743,-449.5 743,-449.5 743,-455.5 737,-461.5 731,-461.5\"/>\n<text text-anchor=\"start\" x=\"665.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"655\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"654\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 51&#45;&gt;53 -->\n<g id=\"edge53\" class=\"edge\">\n<title>51&#45;&gt;53</title>\n<path fill=\"none\" stroke=\"black\" d=\"M693.15,-504.88C693.36,-494.22 693.59,-482.35 693.8,-471.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"697.3,-471.59 694,-461.52 690.3,-471.45 697.3,-471.59\"/>\n</g>\n<!-- 55 -->\n<g id=\"node56\" class=\"node\">\n<title>55</title>\n<path fill=\"#4da7e8\" stroke=\"black\" d=\"M854,-573C854,-573 773,-573 773,-573 767,-573 761,-567 761,-561 761,-561 761,-517 761,-517 761,-511 767,-505 773,-505 773,-505 854,-505 854,-505 860,-505 866,-511 866,-517 866,-517 866,-561 866,-561 866,-567 860,-573 854,-573\"/>\n<text text-anchor=\"start\" x=\"770.5\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.817</text>\n<text text-anchor=\"start\" x=\"776\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.165</text>\n<text text-anchor=\"start\" x=\"770\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"start\" x=\"769\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 10]</text>\n</g>\n<!-- 54&#45;&gt;55 -->\n<g id=\"edge55\" class=\"edge\">\n<title>54&#45;&gt;55</title>\n<path fill=\"none\" stroke=\"black\" d=\"M814.18,-608.88C814.1,-600.78 814.01,-591.98 813.93,-583.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"817.42,-583.26 813.83,-573.3 810.42,-583.33 817.42,-583.26\"/>\n</g>\n<!-- 60 -->\n<g id=\"node61\" class=\"node\">\n<title>60</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M969,-565.5C969,-565.5 896,-565.5 896,-565.5 890,-565.5 884,-559.5 884,-553.5 884,-553.5 884,-524.5 884,-524.5 884,-518.5 890,-512.5 896,-512.5 896,-512.5 969,-512.5 969,-512.5 975,-512.5 981,-518.5 981,-524.5 981,-524.5 981,-553.5 981,-553.5 981,-559.5 975,-565.5 969,-565.5\"/>\n<text text-anchor=\"start\" x=\"903.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"893\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"892\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 5]</text>\n</g>\n<!-- 54&#45;&gt;60 -->\n<g id=\"edge60\" class=\"edge\">\n<title>54&#45;&gt;60</title>\n<path fill=\"none\" stroke=\"black\" d=\"M852.81,-608.88C866.42,-597.12 881.72,-583.89 895.25,-572.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"897.7,-574.71 902.98,-565.52 893.12,-569.41 897.7,-574.71\"/>\n</g>\n<!-- 56 -->\n<g id=\"node57\" class=\"node\">\n<title>56</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M848,-461.5C848,-461.5 775,-461.5 775,-461.5 769,-461.5 763,-455.5 763,-449.5 763,-449.5 763,-420.5 763,-420.5 763,-414.5 769,-408.5 775,-408.5 775,-408.5 848,-408.5 848,-408.5 854,-408.5 860,-414.5 860,-420.5 860,-420.5 860,-449.5 860,-449.5 860,-455.5 854,-461.5 848,-461.5\"/>\n<text text-anchor=\"start\" x=\"782.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"772\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"771\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\n</g>\n<!-- 55&#45;&gt;56 -->\n<g id=\"edge56\" class=\"edge\">\n<title>55&#45;&gt;56</title>\n<path fill=\"none\" stroke=\"black\" d=\"M812.85,-504.88C812.64,-494.22 812.41,-482.35 812.2,-471.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"815.7,-471.45 812,-461.52 808.7,-471.59 815.7,-471.45\"/>\n</g>\n<!-- 57 -->\n<g id=\"node58\" class=\"node\">\n<title>57</title>\n<path fill=\"#55abe9\" stroke=\"black\" d=\"M965,-469C965,-469 890,-469 890,-469 884,-469 878,-463 878,-457 878,-457 878,-413 878,-413 878,-407 884,-401 890,-401 890,-401 965,-401 965,-401 971,-401 977,-407 977,-413 977,-413 977,-457 977,-457 977,-463 971,-469 965,-469\"/>\n<text text-anchor=\"start\" x=\"886\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.591</text>\n<text text-anchor=\"start\" x=\"890\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.219</text>\n<text text-anchor=\"start\" x=\"888\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"887\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 7]</text>\n</g>\n<!-- 55&#45;&gt;57 -->\n<g id=\"edge57\" class=\"edge\">\n<title>55&#45;&gt;57</title>\n<path fill=\"none\" stroke=\"black\" d=\"M850.51,-504.88C860.77,-495.71 872.01,-485.65 882.66,-476.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"885.16,-478.58 890.28,-469.3 880.5,-473.36 885.16,-478.58\"/>\n</g>\n<!-- 58 -->\n<g id=\"node59\" class=\"node\">\n<title>58</title>\n<path fill=\"#61b1ea\" stroke=\"black\" d=\"M907,-357.5C907,-357.5 834,-357.5 834,-357.5 828,-357.5 822,-351.5 822,-345.5 822,-345.5 822,-316.5 822,-316.5 822,-310.5 828,-304.5 834,-304.5 834,-304.5 907,-304.5 907,-304.5 913,-304.5 919,-310.5 919,-316.5 919,-316.5 919,-345.5 919,-345.5 919,-351.5 913,-357.5 907,-357.5\"/>\n<text text-anchor=\"start\" x=\"833\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.278</text>\n<text text-anchor=\"start\" x=\"831\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"830\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 5]</text>\n</g>\n<!-- 57&#45;&gt;58 -->\n<g id=\"edge58\" class=\"edge\">\n<title>57&#45;&gt;58</title>\n<path fill=\"none\" stroke=\"black\" d=\"M908.99,-400.88C902.85,-389.89 895.99,-377.62 889.79,-366.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"892.69,-364.54 884.76,-357.52 886.58,-367.96 892.69,-364.54\"/>\n</g>\n<!-- 59 -->\n<g id=\"node60\" class=\"node\">\n<title>59</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1022,-357.5C1022,-357.5 949,-357.5 949,-357.5 943,-357.5 937,-351.5 937,-345.5 937,-345.5 937,-316.5 937,-316.5 937,-310.5 943,-304.5 949,-304.5 949,-304.5 1022,-304.5 1022,-304.5 1028,-304.5 1034,-310.5 1034,-316.5 1034,-316.5 1034,-345.5 1034,-345.5 1034,-351.5 1028,-357.5 1022,-357.5\"/>\n<text text-anchor=\"start\" x=\"956.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"946\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"945\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 57&#45;&gt;59 -->\n<g id=\"edge59\" class=\"edge\">\n<title>57&#45;&gt;59</title>\n<path fill=\"none\" stroke=\"black\" d=\"M946.33,-400.88C952.58,-389.89 959.56,-377.62 965.87,-366.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"969.09,-367.94 970.99,-357.52 963,-364.48 969.09,-367.94\"/>\n</g>\n<!-- 63 -->\n<g id=\"node64\" class=\"node\">\n<title>63</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1068,-877.5C1068,-877.5 995,-877.5 995,-877.5 989,-877.5 983,-871.5 983,-865.5 983,-865.5 983,-836.5 983,-836.5 983,-830.5 989,-824.5 995,-824.5 995,-824.5 1068,-824.5 1068,-824.5 1074,-824.5 1080,-830.5 1080,-836.5 1080,-836.5 1080,-865.5 1080,-865.5 1080,-871.5 1074,-877.5 1068,-877.5\"/>\n<text text-anchor=\"start\" x=\"1002.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"992\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"991\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 62&#45;&gt;63 -->\n<g id=\"edge63\" class=\"edge\">\n<title>62&#45;&gt;63</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1053.79,-920.88C1050.3,-910.11 1046.42,-898.11 1042.88,-887.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1046.16,-885.96 1039.76,-877.52 1039.5,-888.11 1046.16,-885.96\"/>\n</g>\n<!-- 64 -->\n<g id=\"node65\" class=\"node\">\n<title>64</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1183,-877.5C1183,-877.5 1110,-877.5 1110,-877.5 1104,-877.5 1098,-871.5 1098,-865.5 1098,-865.5 1098,-836.5 1098,-836.5 1098,-830.5 1104,-824.5 1110,-824.5 1110,-824.5 1183,-824.5 1183,-824.5 1189,-824.5 1195,-830.5 1195,-836.5 1195,-836.5 1195,-865.5 1195,-865.5 1195,-871.5 1189,-877.5 1183,-877.5\"/>\n<text text-anchor=\"start\" x=\"1117.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1107\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1106\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 62&#45;&gt;64 -->\n<g id=\"edge64\" class=\"edge\">\n<title>62&#45;&gt;64</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1091.12,-920.88C1100.23,-909.56 1110.42,-896.88 1119.55,-885.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1122.45,-887.51 1125.98,-877.52 1116.99,-883.12 1122.45,-887.51\"/>\n</g>\n<!-- 66 -->\n<g id=\"node67\" class=\"node\">\n<title>66</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1245,-981.5C1245,-981.5 1172,-981.5 1172,-981.5 1166,-981.5 1160,-975.5 1160,-969.5 1160,-969.5 1160,-940.5 1160,-940.5 1160,-934.5 1166,-928.5 1172,-928.5 1172,-928.5 1245,-928.5 1245,-928.5 1251,-928.5 1257,-934.5 1257,-940.5 1257,-940.5 1257,-969.5 1257,-969.5 1257,-975.5 1251,-981.5 1245,-981.5\"/>\n<text text-anchor=\"start\" x=\"1179.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1169\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"1168\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 0]</text>\n</g>\n<!-- 65&#45;&gt;66 -->\n<g id=\"edge66\" class=\"edge\">\n<title>65&#45;&gt;66</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1208.5,-1024.88C1208.5,-1014.33 1208.5,-1002.6 1208.5,-991.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1212,-991.52 1208.5,-981.52 1205,-991.52 1212,-991.52\"/>\n</g>\n<!-- 67 -->\n<g id=\"node68\" class=\"node\">\n<title>67</title>\n<path fill=\"#c5e2f7\" stroke=\"black\" d=\"M1376,-989C1376,-989 1287,-989 1287,-989 1281,-989 1275,-983 1275,-977 1275,-977 1275,-933 1275,-933 1275,-927 1281,-921 1287,-921 1287,-921 1376,-921 1376,-921 1382,-921 1388,-927 1388,-933 1388,-933 1388,-977 1388,-977 1388,-983 1382,-989 1376,-989\"/>\n<text text-anchor=\"start\" x=\"1290\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.629</text>\n<text text-anchor=\"start\" x=\"1294\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.485</text>\n<text text-anchor=\"start\" x=\"1288\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 29</text>\n<text text-anchor=\"start\" x=\"1283\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [12, 17]</text>\n</g>\n<!-- 65&#45;&gt;67 -->\n<g id=\"edge67\" class=\"edge\">\n<title>65&#45;&gt;67</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1248.43,-1024.88C1259.61,-1015.62 1271.86,-1005.45 1283.45,-995.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1285.88,-998.38 1291.34,-989.3 1281.41,-992.99 1285.88,-998.38\"/>\n</g>\n<!-- 68 -->\n<g id=\"node69\" class=\"node\">\n<title>68</title>\n<path fill=\"#efb388\" stroke=\"black\" d=\"M1298,-885C1298,-885 1225,-885 1225,-885 1219,-885 1213,-879 1213,-873 1213,-873 1213,-829 1213,-829 1213,-823 1219,-817 1225,-817 1225,-817 1298,-817 1298,-817 1304,-817 1310,-823 1310,-829 1310,-829 1310,-873 1310,-873 1310,-879 1304,-885 1298,-885\"/>\n<text text-anchor=\"start\" x=\"1222.5\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.62</text>\n<text text-anchor=\"start\" x=\"1224\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.408</text>\n<text text-anchor=\"start\" x=\"1222\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"1221\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 2]</text>\n</g>\n<!-- 67&#45;&gt;68 -->\n<g id=\"edge68\" class=\"edge\">\n<title>67&#45;&gt;68</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1308.77,-920.88C1302.84,-912.24 1296.38,-902.82 1290.18,-893.79\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1292.9,-891.56 1284.35,-885.3 1287.13,-895.52 1292.9,-891.56\"/>\n</g>\n<!-- 75 -->\n<g id=\"node76\" class=\"node\">\n<title>75</title>\n<path fill=\"#95cbf1\" stroke=\"black\" d=\"M1421,-885C1421,-885 1340,-885 1340,-885 1334,-885 1328,-879 1328,-873 1328,-873 1328,-829 1328,-829 1328,-823 1334,-817 1340,-817 1340,-817 1421,-817 1421,-817 1427,-817 1433,-823 1433,-829 1433,-829 1433,-873 1433,-873 1433,-879 1427,-885 1421,-885\"/>\n<text text-anchor=\"start\" x=\"1339\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.591</text>\n<text text-anchor=\"start\" x=\"1343\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.434</text>\n<text text-anchor=\"start\" x=\"1337\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 22</text>\n<text text-anchor=\"start\" x=\"1336\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 15]</text>\n</g>\n<!-- 67&#45;&gt;75 -->\n<g id=\"edge75\" class=\"edge\">\n<title>67&#45;&gt;75</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1347.41,-920.88C1351.47,-912.42 1355.9,-903.21 1360.15,-894.35\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1363.33,-895.83 1364.5,-885.3 1357.02,-892.8 1363.33,-895.83\"/>\n</g>\n<!-- 69 -->\n<g id=\"node70\" class=\"node\">\n<title>69</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1180,-773.5C1180,-773.5 1107,-773.5 1107,-773.5 1101,-773.5 1095,-767.5 1095,-761.5 1095,-761.5 1095,-732.5 1095,-732.5 1095,-726.5 1101,-720.5 1107,-720.5 1107,-720.5 1180,-720.5 1180,-720.5 1186,-720.5 1192,-726.5 1192,-732.5 1192,-732.5 1192,-761.5 1192,-761.5 1192,-767.5 1186,-773.5 1180,-773.5\"/>\n<text text-anchor=\"start\" x=\"1114.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1104\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1103\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 68&#45;&gt;69 -->\n<g id=\"edge69\" class=\"edge\">\n<title>68&#45;&gt;69</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1223.19,-816.88C1209.58,-805.12 1194.28,-791.89 1180.75,-780.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1182.88,-777.41 1173.02,-773.52 1178.3,-782.71 1182.88,-777.41\"/>\n</g>\n<!-- 70 -->\n<g id=\"node71\" class=\"node\">\n<title>70</title>\n<path fill=\"#ea9a61\" stroke=\"black\" d=\"M1300.5,-781C1300.5,-781 1222.5,-781 1222.5,-781 1216.5,-781 1210.5,-775 1210.5,-769 1210.5,-769 1210.5,-725 1210.5,-725 1210.5,-719 1216.5,-713 1222.5,-713 1222.5,-713 1300.5,-713 1300.5,-713 1306.5,-713 1312.5,-719 1312.5,-725 1312.5,-725 1312.5,-769 1312.5,-769 1312.5,-775 1306.5,-781 1300.5,-781\"/>\n<text text-anchor=\"start\" x=\"1218.5\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.412</text>\n<text text-anchor=\"start\" x=\"1224\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.278</text>\n<text text-anchor=\"start\" x=\"1222\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"1221\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 1]</text>\n</g>\n<!-- 68&#45;&gt;70 -->\n<g id=\"edge70\" class=\"edge\">\n<title>68&#45;&gt;70</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1261.5,-816.88C1261.5,-808.78 1261.5,-799.98 1261.5,-791.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1265,-791.3 1261.5,-781.3 1258,-791.3 1265,-791.3\"/>\n</g>\n<!-- 71 -->\n<g id=\"node72\" class=\"node\">\n<title>71</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M1195,-677C1195,-677 1122,-677 1122,-677 1116,-677 1110,-671 1110,-665 1110,-665 1110,-621 1110,-621 1110,-615 1116,-609 1122,-609 1122,-609 1195,-609 1195,-609 1201,-609 1207,-615 1207,-621 1207,-621 1207,-665 1207,-665 1207,-671 1201,-677 1195,-677\"/>\n<text text-anchor=\"start\" x=\"1121\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1121\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"1119\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1118\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 1]</text>\n</g>\n<!-- 70&#45;&gt;71 -->\n<g id=\"edge71\" class=\"edge\">\n<title>70&#45;&gt;71</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1228.06,-712.88C1218.88,-703.8 1208.83,-693.85 1199.3,-684.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1201.69,-681.85 1192.13,-677.3 1196.77,-686.82 1201.69,-681.85\"/>\n</g>\n<!-- 74 -->\n<g id=\"node75\" class=\"node\">\n<title>74</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1310,-669.5C1310,-669.5 1237,-669.5 1237,-669.5 1231,-669.5 1225,-663.5 1225,-657.5 1225,-657.5 1225,-628.5 1225,-628.5 1225,-622.5 1231,-616.5 1237,-616.5 1237,-616.5 1310,-616.5 1310,-616.5 1316,-616.5 1322,-622.5 1322,-628.5 1322,-628.5 1322,-657.5 1322,-657.5 1322,-663.5 1316,-669.5 1310,-669.5\"/>\n<text text-anchor=\"start\" x=\"1244.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1234\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1233\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 70&#45;&gt;74 -->\n<g id=\"edge74\" class=\"edge\">\n<title>70&#45;&gt;74</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1265.4,-712.88C1266.65,-702.22 1268.05,-690.35 1269.32,-679.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1272.81,-679.86 1270.5,-669.52 1265.85,-679.04 1272.81,-679.86\"/>\n</g>\n<!-- 72 -->\n<g id=\"node73\" class=\"node\">\n<title>72</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1089,-565.5C1089,-565.5 1016,-565.5 1016,-565.5 1010,-565.5 1004,-559.5 1004,-553.5 1004,-553.5 1004,-524.5 1004,-524.5 1004,-518.5 1010,-512.5 1016,-512.5 1016,-512.5 1089,-512.5 1089,-512.5 1095,-512.5 1101,-518.5 1101,-524.5 1101,-524.5 1101,-553.5 1101,-553.5 1101,-559.5 1095,-565.5 1089,-565.5\"/>\n<text text-anchor=\"start\" x=\"1023.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1013\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1012\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 71&#45;&gt;72 -->\n<g id=\"edge72\" class=\"edge\">\n<title>71&#45;&gt;72</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1124.08,-608.88C1111.97,-597.23 1098.37,-584.14 1086.31,-572.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1088.65,-569.93 1079.02,-565.52 1083.8,-574.98 1088.65,-569.93\"/>\n</g>\n<!-- 73 -->\n<g id=\"node74\" class=\"node\">\n<title>73</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1204,-565.5C1204,-565.5 1131,-565.5 1131,-565.5 1125,-565.5 1119,-559.5 1119,-553.5 1119,-553.5 1119,-524.5 1119,-524.5 1119,-518.5 1125,-512.5 1131,-512.5 1131,-512.5 1204,-512.5 1204,-512.5 1210,-512.5 1216,-518.5 1216,-524.5 1216,-524.5 1216,-553.5 1216,-553.5 1216,-559.5 1210,-565.5 1204,-565.5\"/>\n<text text-anchor=\"start\" x=\"1138.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1128\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1127\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 71&#45;&gt;73 -->\n<g id=\"edge73\" class=\"edge\">\n<title>71&#45;&gt;73</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1161.42,-608.88C1162.36,-598.22 1163.41,-586.35 1164.37,-575.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1167.86,-575.79 1165.25,-565.52 1160.88,-575.17 1167.86,-575.79\"/>\n</g>\n<!-- 76 -->\n<g id=\"node77\" class=\"node\">\n<title>76</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1416,-773.5C1416,-773.5 1343,-773.5 1343,-773.5 1337,-773.5 1331,-767.5 1331,-761.5 1331,-761.5 1331,-732.5 1331,-732.5 1331,-726.5 1337,-720.5 1343,-720.5 1343,-720.5 1416,-720.5 1416,-720.5 1422,-720.5 1428,-726.5 1428,-732.5 1428,-732.5 1428,-761.5 1428,-761.5 1428,-767.5 1422,-773.5 1416,-773.5\"/>\n<text text-anchor=\"start\" x=\"1350.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1340\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"1339\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4]</text>\n</g>\n<!-- 75&#45;&gt;76 -->\n<g id=\"edge76\" class=\"edge\">\n<title>75&#45;&gt;76</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1380.18,-816.88C1380.07,-806.33 1379.96,-794.6 1379.85,-783.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1383.35,-783.49 1379.75,-773.52 1376.35,-783.55 1383.35,-783.49\"/>\n</g>\n<!-- 77 -->\n<g id=\"node78\" class=\"node\">\n<title>77</title>\n<path fill=\"#b7dbf6\" stroke=\"black\" d=\"M1583,-781C1583,-781 1458,-781 1458,-781 1452,-781 1446,-775 1446,-769 1446,-769 1446,-725 1446,-725 1446,-719 1452,-713 1458,-713 1458,-713 1583,-713 1583,-713 1589,-713 1595,-719 1595,-725 1595,-725 1595,-769 1595,-769 1595,-775 1589,-781 1583,-781\"/>\n<text text-anchor=\"start\" x=\"1454\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">name_title_Mrs ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1483\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.475</text>\n<text text-anchor=\"start\" x=\"1477\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n<text text-anchor=\"start\" x=\"1476\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 11]</text>\n</g>\n<!-- 75&#45;&gt;77 -->\n<g id=\"edge77\" class=\"edge\">\n<title>75&#45;&gt;77</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1425.95,-816.88C1438.91,-807.44 1453.16,-797.06 1466.57,-787.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1468.77,-790.02 1474.79,-781.3 1464.65,-784.36 1468.77,-790.02\"/>\n</g>\n<!-- 78 -->\n<g id=\"node79\" class=\"node\">\n<title>78</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1438,-669.5C1438,-669.5 1365,-669.5 1365,-669.5 1359,-669.5 1353,-663.5 1353,-657.5 1353,-657.5 1353,-628.5 1353,-628.5 1353,-622.5 1359,-616.5 1365,-616.5 1365,-616.5 1438,-616.5 1438,-616.5 1444,-616.5 1450,-622.5 1450,-628.5 1450,-628.5 1450,-657.5 1450,-657.5 1450,-663.5 1444,-669.5 1438,-669.5\"/>\n<text text-anchor=\"start\" x=\"1372.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1362\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1361\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 77&#45;&gt;78 -->\n<g id=\"edge78\" class=\"edge\">\n<title>77&#45;&gt;78</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1481.86,-712.88C1468.14,-701.12 1452.71,-687.89 1439.07,-676.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1441.14,-673.37 1431.27,-669.52 1436.59,-678.69 1441.14,-673.37\"/>\n</g>\n<!-- 79 -->\n<g id=\"node80\" class=\"node\">\n<title>79</title>\n<path fill=\"#93caf1\" stroke=\"black\" d=\"M1561,-677C1561,-677 1480,-677 1480,-677 1474,-677 1468,-671 1468,-665 1468,-665 1468,-621 1468,-621 1468,-615 1474,-609 1480,-609 1480,-609 1561,-609 1561,-609 1567,-609 1573,-615 1573,-621 1573,-621 1573,-665 1573,-665 1573,-671 1567,-677 1561,-677\"/>\n<text text-anchor=\"start\" x=\"1484\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 3.5</text>\n<text text-anchor=\"start\" x=\"1487\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.43</text>\n<text text-anchor=\"start\" x=\"1477\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"start\" x=\"1476\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 11]</text>\n</g>\n<!-- 77&#45;&gt;79 -->\n<g id=\"edge79\" class=\"edge\">\n<title>77&#45;&gt;79</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1520.5,-712.88C1520.5,-704.78 1520.5,-695.98 1520.5,-687.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1524,-687.3 1520.5,-677.3 1517,-687.3 1524,-687.3\"/>\n</g>\n<!-- 80 -->\n<g id=\"node81\" class=\"node\">\n<title>80</title>\n<path fill=\"#81c1ee\" stroke=\"black\" d=\"M1332,-573C1332,-573 1251,-573 1251,-573 1245,-573 1239,-567 1239,-561 1239,-561 1239,-517 1239,-517 1239,-511 1245,-505 1251,-505 1251,-505 1332,-505 1332,-505 1338,-505 1344,-511 1344,-517 1344,-517 1344,-561 1344,-561 1344,-567 1338,-573 1332,-573\"/>\n<text text-anchor=\"start\" x=\"1254\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1254\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.391</text>\n<text text-anchor=\"start\" x=\"1248\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\n<text text-anchor=\"start\" x=\"1247\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 11]</text>\n</g>\n<!-- 79&#45;&gt;80 -->\n<g id=\"edge80\" class=\"edge\">\n<title>79&#45;&gt;80</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1467.91,-613.56C1464.74,-611.99 1461.59,-610.46 1458.5,-609 1424.43,-592.94 1385.58,-576.76 1353.93,-564.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1354.93,-560.75 1344.35,-560.31 1352.35,-567.26 1354.93,-560.75\"/>\n</g>\n<!-- 89 -->\n<g id=\"node90\" class=\"node\">\n<title>89</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1557,-565.5C1557,-565.5 1484,-565.5 1484,-565.5 1478,-565.5 1472,-559.5 1472,-553.5 1472,-553.5 1472,-524.5 1472,-524.5 1472,-518.5 1478,-512.5 1484,-512.5 1484,-512.5 1557,-512.5 1557,-512.5 1563,-512.5 1569,-518.5 1569,-524.5 1569,-524.5 1569,-553.5 1569,-553.5 1569,-559.5 1563,-565.5 1557,-565.5\"/>\n<text text-anchor=\"start\" x=\"1491.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1481\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1480\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 79&#45;&gt;89 -->\n<g id=\"edge89\" class=\"edge\">\n<title>79&#45;&gt;89</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1520.5,-608.88C1520.5,-598.33 1520.5,-586.6 1520.5,-575.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1524,-575.52 1520.5,-565.52 1517,-575.52 1524,-575.52\"/>\n</g>\n<!-- 81 -->\n<g id=\"node82\" class=\"node\">\n<title>81</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1213,-461.5C1213,-461.5 1140,-461.5 1140,-461.5 1134,-461.5 1128,-455.5 1128,-449.5 1128,-449.5 1128,-420.5 1128,-420.5 1128,-414.5 1134,-408.5 1140,-408.5 1140,-408.5 1213,-408.5 1213,-408.5 1219,-408.5 1225,-414.5 1225,-420.5 1225,-420.5 1225,-449.5 1225,-449.5 1225,-455.5 1219,-461.5 1213,-461.5\"/>\n<text text-anchor=\"start\" x=\"1147.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1137\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"1136\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 6]</text>\n</g>\n<!-- 80&#45;&gt;81 -->\n<g id=\"edge81\" class=\"edge\">\n<title>80&#45;&gt;81</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1254.16,-504.88C1240.9,-493.12 1225.99,-479.89 1212.81,-468.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1215.08,-465.54 1205.27,-461.52 1210.43,-470.77 1215.08,-465.54\"/>\n</g>\n<!-- 82 -->\n<g id=\"node83\" class=\"node\">\n<title>82</title>\n<path fill=\"#d7ebfa\" stroke=\"black\" d=\"M1328,-469C1328,-469 1255,-469 1255,-469 1249,-469 1243,-463 1243,-457 1243,-457 1243,-413 1243,-413 1243,-407 1249,-401 1255,-401 1255,-401 1328,-401 1328,-401 1334,-401 1340,-407 1340,-413 1340,-413 1340,-457 1340,-457 1340,-463 1334,-469 1328,-469\"/>\n<text text-anchor=\"start\" x=\"1252\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.286</text>\n<text text-anchor=\"start\" x=\"1254\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.494</text>\n<text text-anchor=\"start\" x=\"1252\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"1251\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 5]</text>\n</g>\n<!-- 80&#45;&gt;82 -->\n<g id=\"edge82\" class=\"edge\">\n<title>80&#45;&gt;82</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1291.5,-504.88C1291.5,-496.78 1291.5,-487.98 1291.5,-479.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1295,-479.3 1291.5,-469.3 1288,-479.3 1295,-479.3\"/>\n</g>\n<!-- 83 -->\n<g id=\"node84\" class=\"node\">\n<title>83</title>\n<path fill=\"#eeab7b\" stroke=\"black\" d=\"M1210.5,-365C1210.5,-365 1136.5,-365 1136.5,-365 1130.5,-365 1124.5,-359 1124.5,-353 1124.5,-353 1124.5,-309 1124.5,-309 1124.5,-303 1130.5,-297 1136.5,-297 1136.5,-297 1210.5,-297 1210.5,-297 1216.5,-297 1222.5,-303 1222.5,-309 1222.5,-309 1222.5,-353 1222.5,-353 1222.5,-359 1216.5,-365 1210.5,-365\"/>\n<text text-anchor=\"start\" x=\"1132.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.049</text>\n<text text-anchor=\"start\" x=\"1136\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"1134\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"1133\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 1]</text>\n</g>\n<!-- 82&#45;&gt;83 -->\n<g id=\"edge83\" class=\"edge\">\n<title>82&#45;&gt;83</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1253.19,-400.88C1242.47,-391.62 1230.71,-381.45 1219.6,-371.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1221.88,-369.19 1212.02,-365.3 1217.3,-374.49 1221.88,-369.19\"/>\n</g>\n<!-- 86 -->\n<g id=\"node87\" class=\"node\">\n<title>86</title>\n<path fill=\"#6ab6ec\" stroke=\"black\" d=\"M1330.5,-365C1330.5,-365 1252.5,-365 1252.5,-365 1246.5,-365 1240.5,-359 1240.5,-353 1240.5,-353 1240.5,-309 1240.5,-309 1240.5,-303 1246.5,-297 1252.5,-297 1252.5,-297 1330.5,-297 1330.5,-297 1336.5,-297 1342.5,-303 1342.5,-309 1342.5,-309 1342.5,-353 1342.5,-353 1342.5,-359 1336.5,-365 1330.5,-365\"/>\n<text text-anchor=\"start\" x=\"1248.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.195</text>\n<text text-anchor=\"start\" x=\"1258\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"1252\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"1251\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 4]</text>\n</g>\n<!-- 82&#45;&gt;86 -->\n<g id=\"edge86\" class=\"edge\">\n<title>82&#45;&gt;86</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1291.5,-400.88C1291.5,-392.78 1291.5,-383.98 1291.5,-375.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1295,-375.3 1291.5,-365.3 1288,-375.3 1295,-375.3\"/>\n</g>\n<!-- 84 -->\n<g id=\"node85\" class=\"node\">\n<title>84</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1096,-253.5C1096,-253.5 1023,-253.5 1023,-253.5 1017,-253.5 1011,-247.5 1011,-241.5 1011,-241.5 1011,-212.5 1011,-212.5 1011,-206.5 1017,-200.5 1023,-200.5 1023,-200.5 1096,-200.5 1096,-200.5 1102,-200.5 1108,-206.5 1108,-212.5 1108,-212.5 1108,-241.5 1108,-241.5 1108,-247.5 1102,-253.5 1096,-253.5\"/>\n<text text-anchor=\"start\" x=\"1030.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1020\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1019\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 83&#45;&gt;84 -->\n<g id=\"edge84\" class=\"edge\">\n<title>83&#45;&gt;84</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1136.49,-296.88C1123.34,-285.12 1108.56,-271.89 1095.49,-260.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1097.81,-257.58 1088.02,-253.52 1093.14,-262.8 1097.81,-257.58\"/>\n</g>\n<!-- 85 -->\n<g id=\"node86\" class=\"node\">\n<title>85</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1211,-253.5C1211,-253.5 1138,-253.5 1138,-253.5 1132,-253.5 1126,-247.5 1126,-241.5 1126,-241.5 1126,-212.5 1126,-212.5 1126,-206.5 1132,-200.5 1138,-200.5 1138,-200.5 1211,-200.5 1211,-200.5 1217,-200.5 1223,-206.5 1223,-212.5 1223,-212.5 1223,-241.5 1223,-241.5 1223,-247.5 1217,-253.5 1211,-253.5\"/>\n<text text-anchor=\"start\" x=\"1145.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1135\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1134\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 83&#45;&gt;85 -->\n<g id=\"edge85\" class=\"edge\">\n<title>83&#45;&gt;85</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1173.82,-296.88C1173.93,-286.33 1174.04,-274.6 1174.15,-263.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1177.65,-263.55 1174.25,-253.52 1170.65,-263.49 1177.65,-263.55\"/>\n</g>\n<!-- 87 -->\n<g id=\"node88\" class=\"node\">\n<title>87</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1327,-253.5C1327,-253.5 1254,-253.5 1254,-253.5 1248,-253.5 1242,-247.5 1242,-241.5 1242,-241.5 1242,-212.5 1242,-212.5 1242,-206.5 1248,-200.5 1254,-200.5 1254,-200.5 1327,-200.5 1327,-200.5 1333,-200.5 1339,-206.5 1339,-212.5 1339,-212.5 1339,-241.5 1339,-241.5 1339,-247.5 1333,-253.5 1327,-253.5\"/>\n<text text-anchor=\"start\" x=\"1261.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1251\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1250\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 86&#45;&gt;87 -->\n<g id=\"edge87\" class=\"edge\">\n<title>86&#45;&gt;87</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1291.18,-296.88C1291.07,-286.33 1290.96,-274.6 1290.85,-263.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1294.35,-263.49 1290.75,-253.52 1287.35,-263.55 1294.35,-263.49\"/>\n</g>\n<!-- 88 -->\n<g id=\"node89\" class=\"node\">\n<title>88</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1442,-253.5C1442,-253.5 1369,-253.5 1369,-253.5 1363,-253.5 1357,-247.5 1357,-241.5 1357,-241.5 1357,-212.5 1357,-212.5 1357,-206.5 1363,-200.5 1369,-200.5 1369,-200.5 1442,-200.5 1442,-200.5 1448,-200.5 1454,-206.5 1454,-212.5 1454,-212.5 1454,-241.5 1454,-241.5 1454,-247.5 1448,-253.5 1442,-253.5\"/>\n<text text-anchor=\"start\" x=\"1376.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1366\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"1365\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4]</text>\n</g>\n<!-- 86&#45;&gt;88 -->\n<g id=\"edge88\" class=\"edge\">\n<title>86&#45;&gt;88</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1328.51,-296.88C1341.66,-285.12 1356.44,-271.89 1369.51,-260.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1371.86,-262.8 1376.98,-253.52 1367.19,-257.58 1371.86,-262.8\"/>\n</g>\n<!-- 92 -->\n<g id=\"node93\" class=\"node\">\n<title>92</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1291,-1293.5C1291,-1293.5 1218,-1293.5 1218,-1293.5 1212,-1293.5 1206,-1287.5 1206,-1281.5 1206,-1281.5 1206,-1252.5 1206,-1252.5 1206,-1246.5 1212,-1240.5 1218,-1240.5 1218,-1240.5 1291,-1240.5 1291,-1240.5 1297,-1240.5 1303,-1246.5 1303,-1252.5 1303,-1252.5 1303,-1281.5 1303,-1281.5 1303,-1287.5 1297,-1293.5 1291,-1293.5\"/>\n<text text-anchor=\"start\" x=\"1225.5\" y=\"-1278.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1215\" y=\"-1263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1214\" y=\"-1248.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 91&#45;&gt;92 -->\n<g id=\"edge92\" class=\"edge\">\n<title>91&#45;&gt;92</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1256.53,-1336.88C1256.21,-1326.22 1255.86,-1314.35 1255.54,-1303.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1259.04,-1303.41 1255.25,-1293.52 1252.05,-1303.62 1259.04,-1303.41\"/>\n</g>\n<!-- 93 -->\n<g id=\"node94\" class=\"node\">\n<title>93</title>\n<path fill=\"#e6853f\" stroke=\"black\" d=\"M1414,-1301C1414,-1301 1333,-1301 1333,-1301 1327,-1301 1321,-1295 1321,-1289 1321,-1289 1321,-1245 1321,-1245 1321,-1239 1327,-1233 1333,-1233 1333,-1233 1414,-1233 1414,-1233 1420,-1233 1426,-1239 1426,-1245 1426,-1245 1426,-1289 1426,-1289 1426,-1295 1420,-1301 1414,-1301\"/>\n<text text-anchor=\"start\" x=\"1332\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;1.791</text>\n<text text-anchor=\"start\" x=\"1336\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.061</text>\n<text text-anchor=\"start\" x=\"1330\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 32</text>\n<text text-anchor=\"start\" x=\"1329\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 1]</text>\n</g>\n<!-- 91&#45;&gt;93 -->\n<g id=\"edge93\" class=\"edge\">\n<title>91&#45;&gt;93</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1295.16,-1336.88C1305.6,-1327.71 1317.04,-1317.65 1327.87,-1308.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1330.43,-1310.53 1335.63,-1301.3 1325.81,-1305.27 1330.43,-1310.53\"/>\n</g>\n<!-- 94 -->\n<g id=\"node95\" class=\"node\">\n<title>94</title>\n<path fill=\"#e88f4f\" stroke=\"black\" d=\"M1403,-1197C1403,-1197 1324,-1197 1324,-1197 1318,-1197 1312,-1191 1312,-1185 1312,-1185 1312,-1141 1312,-1141 1312,-1135 1318,-1129 1324,-1129 1324,-1129 1403,-1129 1403,-1129 1409,-1129 1415,-1135 1415,-1141 1415,-1141 1415,-1185 1415,-1185 1415,-1191 1409,-1197 1403,-1197\"/>\n<text text-anchor=\"start\" x=\"1322\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;1.883</text>\n<text text-anchor=\"start\" x=\"1330\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.18</text>\n<text text-anchor=\"start\" x=\"1320\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"1323\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 1]</text>\n</g>\n<!-- 93&#45;&gt;94 -->\n<g id=\"edge94\" class=\"edge\">\n<title>93&#45;&gt;94</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1370.25,-1232.88C1369.46,-1224.78 1368.6,-1215.98 1367.76,-1207.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1371.22,-1206.91 1366.76,-1197.3 1364.26,-1207.59 1371.22,-1206.91\"/>\n</g>\n<!-- 97 -->\n<g id=\"node98\" class=\"node\">\n<title>97</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1526,-1189.5C1526,-1189.5 1445,-1189.5 1445,-1189.5 1439,-1189.5 1433,-1183.5 1433,-1177.5 1433,-1177.5 1433,-1148.5 1433,-1148.5 1433,-1142.5 1439,-1136.5 1445,-1136.5 1445,-1136.5 1526,-1136.5 1526,-1136.5 1532,-1136.5 1538,-1142.5 1538,-1148.5 1538,-1148.5 1538,-1177.5 1538,-1177.5 1538,-1183.5 1532,-1189.5 1526,-1189.5\"/>\n<text text-anchor=\"start\" x=\"1456.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1442\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 22</text>\n<text text-anchor=\"start\" x=\"1441\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [22, 0]</text>\n</g>\n<!-- 93&#45;&gt;97 -->\n<g id=\"edge97\" class=\"edge\">\n<title>93&#45;&gt;97</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1409.86,-1232.88C1422.66,-1221.23 1437.03,-1208.14 1449.78,-1196.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1452.44,-1198.84 1457.48,-1189.52 1447.73,-1193.67 1452.44,-1198.84\"/>\n</g>\n<!-- 95 -->\n<g id=\"node96\" class=\"node\">\n<title>95</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1378,-1085.5C1378,-1085.5 1305,-1085.5 1305,-1085.5 1299,-1085.5 1293,-1079.5 1293,-1073.5 1293,-1073.5 1293,-1044.5 1293,-1044.5 1293,-1038.5 1299,-1032.5 1305,-1032.5 1305,-1032.5 1378,-1032.5 1378,-1032.5 1384,-1032.5 1390,-1038.5 1390,-1044.5 1390,-1044.5 1390,-1073.5 1390,-1073.5 1390,-1079.5 1384,-1085.5 1378,-1085.5\"/>\n<text text-anchor=\"start\" x=\"1312.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1302\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"1301\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 0]</text>\n</g>\n<!-- 94&#45;&gt;95 -->\n<g id=\"edge95\" class=\"edge\">\n<title>94&#45;&gt;95</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1356.36,-1128.88C1354.06,-1118.22 1351.5,-1106.35 1349.16,-1095.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1352.53,-1094.56 1347,-1085.52 1345.69,-1096.03 1352.53,-1094.56\"/>\n</g>\n<!-- 96 -->\n<g id=\"node97\" class=\"node\">\n<title>96</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1493,-1085.5C1493,-1085.5 1420,-1085.5 1420,-1085.5 1414,-1085.5 1408,-1079.5 1408,-1073.5 1408,-1073.5 1408,-1044.5 1408,-1044.5 1408,-1038.5 1414,-1032.5 1420,-1032.5 1420,-1032.5 1493,-1032.5 1493,-1032.5 1499,-1032.5 1505,-1038.5 1505,-1044.5 1505,-1044.5 1505,-1073.5 1505,-1073.5 1505,-1079.5 1499,-1085.5 1493,-1085.5\"/>\n<text text-anchor=\"start\" x=\"1427.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1417\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1416\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 94&#45;&gt;96 -->\n<g id=\"edge96\" class=\"edge\">\n<title>94&#45;&gt;96</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1393.69,-1128.88C1404.12,-1117.45 1415.8,-1104.63 1426.24,-1093.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1429.08,-1095.27 1433.23,-1085.52 1423.91,-1090.55 1429.08,-1095.27\"/>\n</g>\n<!-- 99 -->\n<g id=\"node100\" class=\"node\">\n<title>99</title>\n<path fill=\"#e89050\" stroke=\"black\" d=\"M3614.5,-1509C3614.5,-1509 3494.5,-1509 3494.5,-1509 3488.5,-1509 3482.5,-1503 3482.5,-1497 3482.5,-1497 3482.5,-1453 3482.5,-1453 3482.5,-1447 3488.5,-1441 3494.5,-1441 3494.5,-1441 3614.5,-1441 3614.5,-1441 3620.5,-1441 3626.5,-1447 3626.5,-1453 3626.5,-1453 3626.5,-1497 3626.5,-1497 3626.5,-1503 3620.5,-1509 3614.5,-1509\"/>\n<text text-anchor=\"start\" x=\"3490.5\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_D ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"3517\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.189</text>\n<text text-anchor=\"start\" x=\"3507\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 275</text>\n<text text-anchor=\"start\" x=\"3501.5\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [246, 29]</text>\n</g>\n<!-- 98&#45;&gt;99 -->\n<g id=\"edge99\" class=\"edge\">\n<title>98&#45;&gt;99</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3554.5,-1544.88C3554.5,-1536.78 3554.5,-1527.98 3554.5,-1519.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3558,-1519.3 3554.5,-1509.3 3551,-1519.3 3558,-1519.3\"/>\n</g>\n<!-- 218 -->\n<g id=\"node219\" class=\"node\">\n<title>218</title>\n<path fill=\"#f2be99\" stroke=\"black\" d=\"M3794,-1509C3794,-1509 3705,-1509 3705,-1509 3699,-1509 3693,-1503 3693,-1497 3693,-1497 3693,-1453 3693,-1453 3693,-1447 3699,-1441 3705,-1441 3705,-1441 3794,-1441 3794,-1441 3800,-1441 3806,-1447 3806,-1453 3806,-1453 3806,-1497 3806,-1497 3806,-1503 3800,-1509 3794,-1509\"/>\n<text text-anchor=\"start\" x=\"3708.5\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.366</text>\n<text text-anchor=\"start\" x=\"3716\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.44</text>\n<text text-anchor=\"start\" x=\"3706\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 92</text>\n<text text-anchor=\"start\" x=\"3701\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [62, 30]</text>\n</g>\n<!-- 98&#45;&gt;218 -->\n<g id=\"edge218\" class=\"edge\">\n<title>98&#45;&gt;218</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3615.66,-1546.01C3637.36,-1534.66 3661.86,-1521.84 3683.9,-1510.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3685.63,-1513.36 3692.87,-1505.62 3682.38,-1507.16 3685.63,-1513.36\"/>\n</g>\n<!-- 100 -->\n<g id=\"node101\" class=\"node\">\n<title>100</title>\n<path fill=\"#e88f50\" stroke=\"black\" d=\"M3515.5,-1405C3515.5,-1405 3417.5,-1405 3417.5,-1405 3411.5,-1405 3405.5,-1399 3405.5,-1393 3405.5,-1393 3405.5,-1349 3405.5,-1349 3405.5,-1343 3411.5,-1337 3417.5,-1337 3417.5,-1337 3515.5,-1337 3515.5,-1337 3521.5,-1337 3527.5,-1343 3527.5,-1349 3527.5,-1349 3527.5,-1393 3527.5,-1393 3527.5,-1399 3521.5,-1405 3515.5,-1405\"/>\n<text text-anchor=\"start\" x=\"3427\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.187</text>\n<text text-anchor=\"start\" x=\"3429\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.183</text>\n<text text-anchor=\"start\" x=\"3419\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 274</text>\n<text text-anchor=\"start\" x=\"3413.5\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [246, 28]</text>\n</g>\n<!-- 99&#45;&gt;100 -->\n<g id=\"edge100\" class=\"edge\">\n<title>99&#45;&gt;100</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3525.93,-1440.88C3518.24,-1431.98 3509.84,-1422.24 3501.84,-1412.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3504.41,-1410.58 3495.23,-1405.3 3499.11,-1415.16 3504.41,-1410.58\"/>\n</g>\n<!-- 217 -->\n<g id=\"node218\" class=\"node\">\n<title>217</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3631,-1397.5C3631,-1397.5 3558,-1397.5 3558,-1397.5 3552,-1397.5 3546,-1391.5 3546,-1385.5 3546,-1385.5 3546,-1356.5 3546,-1356.5 3546,-1350.5 3552,-1344.5 3558,-1344.5 3558,-1344.5 3631,-1344.5 3631,-1344.5 3637,-1344.5 3643,-1350.5 3643,-1356.5 3643,-1356.5 3643,-1385.5 3643,-1385.5 3643,-1391.5 3637,-1397.5 3631,-1397.5\"/>\n<text text-anchor=\"start\" x=\"3565.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3555\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3554\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 99&#45;&gt;217 -->\n<g id=\"edge217\" class=\"edge\">\n<title>99&#45;&gt;217</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3567.49,-1440.88C3571.76,-1430 3576.51,-1417.86 3580.83,-1406.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3584.1,-1408.11 3584.49,-1397.52 3577.58,-1405.55 3584.1,-1408.11\"/>\n</g>\n<!-- 101 -->\n<g id=\"node102\" class=\"node\">\n<title>101</title>\n<path fill=\"#e99559\" stroke=\"black\" d=\"M3225,-1301C3225,-1301 3106,-1301 3106,-1301 3100,-1301 3094,-1295 3094,-1289 3094,-1289 3094,-1245 3094,-1245 3094,-1239 3100,-1233 3106,-1233 3106,-1233 3225,-1233 3225,-1233 3231,-1233 3237,-1239 3237,-1245 3237,-1245 3237,-1289 3237,-1289 3237,-1295 3231,-1301 3225,-1301\"/>\n<text text-anchor=\"start\" x=\"3102\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_E ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"3132\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.24</text>\n<text text-anchor=\"start\" x=\"3118\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 136</text>\n<text text-anchor=\"start\" x=\"3112.5\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [117, 19]</text>\n</g>\n<!-- 100&#45;&gt;101 -->\n<g id=\"edge101\" class=\"edge\">\n<title>100&#45;&gt;101</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3405.23,-1349.24C3359.44,-1333.72 3296.43,-1312.37 3246.49,-1295.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3247.6,-1292.13 3237.01,-1292.23 3245.35,-1298.76 3247.6,-1292.13\"/>\n</g>\n<!-- 178 -->\n<g id=\"node179\" class=\"node\">\n<title>178</title>\n<path fill=\"#e78a47\" stroke=\"black\" d=\"M3528,-1301C3528,-1301 3439,-1301 3439,-1301 3433,-1301 3427,-1295 3427,-1289 3427,-1289 3427,-1245 3427,-1245 3427,-1239 3433,-1233 3439,-1233 3439,-1233 3528,-1233 3528,-1233 3534,-1233 3540,-1239 3540,-1245 3540,-1245 3540,-1289 3540,-1289 3540,-1295 3534,-1301 3528,-1301\"/>\n<text text-anchor=\"start\" x=\"3440.5\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.798</text>\n<text text-anchor=\"start\" x=\"3446\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.122</text>\n<text text-anchor=\"start\" x=\"3436\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 138</text>\n<text text-anchor=\"start\" x=\"3435\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [129, 9]</text>\n</g>\n<!-- 100&#45;&gt;178 -->\n<g id=\"edge178\" class=\"edge\">\n<title>100&#45;&gt;178</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3472.02,-1336.88C3473.39,-1328.69 3474.87,-1319.79 3476.3,-1311.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3479.76,-1311.74 3477.95,-1301.3 3472.85,-1310.59 3479.76,-1311.74\"/>\n</g>\n<!-- 102 -->\n<g id=\"node103\" class=\"node\">\n<title>102</title>\n<path fill=\"#e99457\" stroke=\"black\" d=\"M3001.5,-1197C3001.5,-1197 2889.5,-1197 2889.5,-1197 2883.5,-1197 2877.5,-1191 2877.5,-1185 2877.5,-1185 2877.5,-1141 2877.5,-1141 2877.5,-1135 2883.5,-1129 2889.5,-1129 2889.5,-1129 3001.5,-1129 3001.5,-1129 3007.5,-1129 3013.5,-1135 3013.5,-1141 3013.5,-1141 3013.5,-1185 3013.5,-1185 3013.5,-1191 3007.5,-1197 3001.5,-1197\"/>\n<text text-anchor=\"start\" x=\"2885.5\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Embarked_C ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"2908\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.231</text>\n<text text-anchor=\"start\" x=\"2898\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 135</text>\n<text text-anchor=\"start\" x=\"2892.5\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [117, 18]</text>\n</g>\n<!-- 101&#45;&gt;102 -->\n<g id=\"edge102\" class=\"edge\">\n<title>101&#45;&gt;102</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3094.07,-1232.88C3071.26,-1222.3 3045.9,-1210.55 3022.69,-1199.79\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3024.12,-1196.59 3013.58,-1195.56 3021.18,-1202.94 3024.12,-1196.59\"/>\n</g>\n<!-- 177 -->\n<g id=\"node178\" class=\"node\">\n<title>177</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3202,-1189.5C3202,-1189.5 3129,-1189.5 3129,-1189.5 3123,-1189.5 3117,-1183.5 3117,-1177.5 3117,-1177.5 3117,-1148.5 3117,-1148.5 3117,-1142.5 3123,-1136.5 3129,-1136.5 3129,-1136.5 3202,-1136.5 3202,-1136.5 3208,-1136.5 3214,-1142.5 3214,-1148.5 3214,-1148.5 3214,-1177.5 3214,-1177.5 3214,-1183.5 3208,-1189.5 3202,-1189.5\"/>\n<text text-anchor=\"start\" x=\"3136.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3126\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3125\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 101&#45;&gt;177 -->\n<g id=\"edge177\" class=\"edge\">\n<title>101&#45;&gt;177</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3165.5,-1232.88C3165.5,-1222.33 3165.5,-1210.6 3165.5,-1199.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3169,-1199.52 3165.5,-1189.52 3162,-1199.52 3169,-1199.52\"/>\n</g>\n<!-- 103 -->\n<g id=\"node104\" class=\"node\">\n<title>103</title>\n<path fill=\"#e89153\" stroke=\"black\" d=\"M2693.5,-1093C2693.5,-1093 2595.5,-1093 2595.5,-1093 2589.5,-1093 2583.5,-1087 2583.5,-1081 2583.5,-1081 2583.5,-1037 2583.5,-1037 2583.5,-1031 2589.5,-1025 2595.5,-1025 2595.5,-1025 2693.5,-1025 2693.5,-1025 2699.5,-1025 2705.5,-1031 2705.5,-1037 2705.5,-1037 2705.5,-1081 2705.5,-1081 2705.5,-1087 2699.5,-1093 2693.5,-1093\"/>\n<text text-anchor=\"start\" x=\"2601.5\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;2.001</text>\n<text text-anchor=\"start\" x=\"2607\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.203</text>\n<text text-anchor=\"start\" x=\"2597\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 122</text>\n<text text-anchor=\"start\" x=\"2591.5\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [108, 14]</text>\n</g>\n<!-- 102&#45;&gt;103 -->\n<g id=\"edge103\" class=\"edge\">\n<title>102&#45;&gt;103</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2877.2,-1138.85C2828.82,-1122.46 2764.1,-1100.53 2715.19,-1083.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2716.23,-1080.61 2705.63,-1080.72 2713.98,-1087.24 2716.23,-1080.61\"/>\n</g>\n<!-- 166 -->\n<g id=\"node167\" class=\"node\">\n<title>166</title>\n<path fill=\"#f1b991\" stroke=\"black\" d=\"M2985,-1093C2985,-1093 2906,-1093 2906,-1093 2900,-1093 2894,-1087 2894,-1081 2894,-1081 2894,-1037 2894,-1037 2894,-1031 2900,-1025 2906,-1025 2906,-1025 2985,-1025 2985,-1025 2991,-1025 2997,-1031 2997,-1037 2997,-1037 2997,-1081 2997,-1081 2997,-1087 2991,-1093 2985,-1093\"/>\n<text text-anchor=\"start\" x=\"2904\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.016</text>\n<text text-anchor=\"start\" x=\"2908\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.426</text>\n<text text-anchor=\"start\" x=\"2902\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13</text>\n<text text-anchor=\"start\" x=\"2905\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 4]</text>\n</g>\n<!-- 102&#45;&gt;166 -->\n<g id=\"edge166\" class=\"edge\">\n<title>102&#45;&gt;166</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2945.5,-1128.88C2945.5,-1120.78 2945.5,-1111.98 2945.5,-1103.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2949,-1103.3 2945.5,-1093.3 2942,-1103.3 2949,-1103.3\"/>\n</g>\n<!-- 104 -->\n<g id=\"node105\" class=\"node\">\n<title>104</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M2503,-989C2503,-989 2428,-989 2428,-989 2422,-989 2416,-983 2416,-977 2416,-977 2416,-933 2416,-933 2416,-927 2422,-921 2428,-921 2428,-921 2503,-921 2503,-921 2509,-921 2515,-927 2515,-933 2515,-933 2515,-977 2515,-977 2515,-983 2509,-989 2503,-989\"/>\n<text text-anchor=\"start\" x=\"2424\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.582</text>\n<text text-anchor=\"start\" x=\"2436.5\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"2426\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2425\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 103&#45;&gt;104 -->\n<g id=\"edge104\" class=\"edge\">\n<title>103&#45;&gt;104</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2586.38,-1024.88C2566.38,-1013.48 2543.97,-1000.72 2523.94,-989.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2525.64,-986.24 2515.22,-984.33 2522.17,-992.32 2525.64,-986.24\"/>\n</g>\n<!-- 107 -->\n<g id=\"node108\" class=\"node\">\n<title>107</title>\n<path fill=\"#e89051\" stroke=\"black\" d=\"M2693.5,-989C2693.5,-989 2595.5,-989 2595.5,-989 2589.5,-989 2583.5,-983 2583.5,-977 2583.5,-977 2583.5,-933 2583.5,-933 2583.5,-927 2589.5,-921 2595.5,-921 2595.5,-921 2693.5,-921 2693.5,-921 2699.5,-921 2705.5,-927 2705.5,-933 2705.5,-933 2705.5,-977 2705.5,-977 2705.5,-983 2699.5,-989 2693.5,-989\"/>\n<text text-anchor=\"start\" x=\"2603\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.072</text>\n<text text-anchor=\"start\" x=\"2607\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.193</text>\n<text text-anchor=\"start\" x=\"2597\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 120</text>\n<text text-anchor=\"start\" x=\"2591.5\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [107, 13]</text>\n</g>\n<!-- 103&#45;&gt;107 -->\n<g id=\"edge107\" class=\"edge\">\n<title>103&#45;&gt;107</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2644.5,-1024.88C2644.5,-1016.78 2644.5,-1007.98 2644.5,-999.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2648,-999.3 2644.5,-989.3 2641,-999.3 2648,-999.3\"/>\n</g>\n<!-- 105 -->\n<g id=\"node106\" class=\"node\">\n<title>105</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2387,-877.5C2387,-877.5 2314,-877.5 2314,-877.5 2308,-877.5 2302,-871.5 2302,-865.5 2302,-865.5 2302,-836.5 2302,-836.5 2302,-830.5 2308,-824.5 2314,-824.5 2314,-824.5 2387,-824.5 2387,-824.5 2393,-824.5 2399,-830.5 2399,-836.5 2399,-836.5 2399,-865.5 2399,-865.5 2399,-871.5 2393,-877.5 2387,-877.5\"/>\n<text text-anchor=\"start\" x=\"2321.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2311\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2310\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 104&#45;&gt;105 -->\n<g id=\"edge105\" class=\"edge\">\n<title>104&#45;&gt;105</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2428.16,-920.88C2414.9,-909.12 2399.99,-895.89 2386.81,-884.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2389.08,-881.54 2379.27,-877.52 2384.43,-886.77 2389.08,-881.54\"/>\n</g>\n<!-- 106 -->\n<g id=\"node107\" class=\"node\">\n<title>106</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2502,-877.5C2502,-877.5 2429,-877.5 2429,-877.5 2423,-877.5 2417,-871.5 2417,-865.5 2417,-865.5 2417,-836.5 2417,-836.5 2417,-830.5 2423,-824.5 2429,-824.5 2429,-824.5 2502,-824.5 2502,-824.5 2508,-824.5 2514,-830.5 2514,-836.5 2514,-836.5 2514,-865.5 2514,-865.5 2514,-871.5 2508,-877.5 2502,-877.5\"/>\n<text text-anchor=\"start\" x=\"2436.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2426\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2425\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 104&#45;&gt;106 -->\n<g id=\"edge106\" class=\"edge\">\n<title>104&#45;&gt;106</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2465.5,-920.88C2465.5,-910.33 2465.5,-898.6 2465.5,-887.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2469,-887.52 2465.5,-877.52 2462,-887.52 2469,-887.52\"/>\n</g>\n<!-- 108 -->\n<g id=\"node109\" class=\"node\">\n<title>108</title>\n<path fill=\"#e78d4b\" stroke=\"black\" d=\"M2625,-885C2625,-885 2544,-885 2544,-885 2538,-885 2532,-879 2532,-873 2532,-873 2532,-829 2532,-829 2532,-823 2538,-817 2544,-817 2544,-817 2625,-817 2625,-817 2631,-817 2637,-823 2637,-829 2637,-829 2637,-873 2637,-873 2637,-879 2631,-885 2625,-885\"/>\n<text text-anchor=\"start\" x=\"2541.5\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.768</text>\n<text text-anchor=\"start\" x=\"2547\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.154</text>\n<text text-anchor=\"start\" x=\"2541\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 95</text>\n<text text-anchor=\"start\" x=\"2540\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [87, 8]</text>\n</g>\n<!-- 107&#45;&gt;108 -->\n<g id=\"edge108\" class=\"edge\">\n<title>107&#45;&gt;108</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2625.02,-920.88C2619.99,-912.33 2614.51,-903.01 2609.25,-894.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2612.17,-892.14 2604.09,-885.3 2606.14,-895.69 2612.17,-892.14\"/>\n</g>\n<!-- 147 -->\n<g id=\"node148\" class=\"node\">\n<title>147</title>\n<path fill=\"#eca06a\" stroke=\"black\" d=\"M2748,-885C2748,-885 2667,-885 2667,-885 2661,-885 2655,-879 2655,-873 2655,-873 2655,-829 2655,-829 2655,-823 2661,-817 2667,-817 2667,-817 2748,-817 2748,-817 2754,-817 2760,-823 2760,-829 2760,-829 2760,-873 2760,-873 2760,-879 2754,-885 2748,-885\"/>\n<text text-anchor=\"start\" x=\"2670\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"2674\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"2664\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 25</text>\n<text text-anchor=\"start\" x=\"2663\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [20, 5]</text>\n</g>\n<!-- 107&#45;&gt;147 -->\n<g id=\"edge147\" class=\"edge\">\n<title>107&#45;&gt;147</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2664.95,-920.88C2670.24,-912.33 2675.99,-903.01 2681.51,-894.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2684.66,-895.65 2686.93,-885.3 2678.7,-891.97 2684.66,-895.65\"/>\n</g>\n<!-- 109 -->\n<g id=\"node110\" class=\"node\">\n<title>109</title>\n<path fill=\"#e99355\" stroke=\"black\" d=\"M2181,-781C2181,-781 2100,-781 2100,-781 2094,-781 2088,-775 2088,-769 2088,-769 2088,-725 2088,-725 2088,-719 2094,-713 2100,-713 2100,-713 2181,-713 2181,-713 2187,-713 2193,-719 2193,-725 2193,-725 2193,-769 2193,-769 2193,-775 2187,-781 2181,-781\"/>\n<text text-anchor=\"start\" x=\"2097.5\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.798</text>\n<text text-anchor=\"start\" x=\"2103\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.215</text>\n<text text-anchor=\"start\" x=\"2097\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 57</text>\n<text text-anchor=\"start\" x=\"2096\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 7]</text>\n</g>\n<!-- 108&#45;&gt;109 -->\n<g id=\"edge109\" class=\"edge\">\n<title>108&#45;&gt;109</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2531.89,-820.61C2528.75,-819.3 2525.61,-818.08 2522.5,-817 2413.73,-779.27 2280.02,-761.17 2203.09,-753.3\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2203.38,-749.81 2193.08,-752.3 2202.69,-756.78 2203.38,-749.81\"/>\n</g>\n<!-- 140 -->\n<g id=\"node141\" class=\"node\">\n<title>140</title>\n<path fill=\"#e6843e\" stroke=\"black\" d=\"M2625,-781C2625,-781 2544,-781 2544,-781 2538,-781 2532,-775 2532,-769 2532,-769 2532,-725 2532,-725 2532,-719 2538,-713 2544,-713 2544,-713 2625,-713 2625,-713 2631,-713 2637,-719 2637,-725 2637,-725 2637,-769 2637,-769 2637,-775 2631,-781 2625,-781\"/>\n<text text-anchor=\"start\" x=\"2543\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.771</text>\n<text text-anchor=\"start\" x=\"2547\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.051</text>\n<text text-anchor=\"start\" x=\"2541\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 38</text>\n<text text-anchor=\"start\" x=\"2540\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [37, 1]</text>\n</g>\n<!-- 108&#45;&gt;140 -->\n<g id=\"edge140\" class=\"edge\">\n<title>108&#45;&gt;140</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2584.5,-816.88C2584.5,-808.78 2584.5,-799.98 2584.5,-791.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2588,-791.3 2584.5,-781.3 2581,-791.3 2588,-791.3\"/>\n</g>\n<!-- 110 -->\n<g id=\"node111\" class=\"node\">\n<title>110</title>\n<path fill=\"#e78c49\" stroke=\"black\" d=\"M2009,-677C2009,-677 1928,-677 1928,-677 1922,-677 1916,-671 1916,-665 1916,-665 1916,-621 1916,-621 1916,-615 1922,-609 1928,-609 1928,-609 2009,-609 2009,-609 2015,-609 2021,-615 2021,-621 2021,-621 2021,-665 2021,-665 2021,-671 2015,-677 2009,-677\"/>\n<text text-anchor=\"start\" x=\"1927\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.242</text>\n<text text-anchor=\"start\" x=\"1931\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.142</text>\n<text text-anchor=\"start\" x=\"1925\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 39</text>\n<text text-anchor=\"start\" x=\"1924\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [36, 3]</text>\n</g>\n<!-- 109&#45;&gt;110 -->\n<g id=\"edge110\" class=\"edge\">\n<title>109&#45;&gt;110</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2087.96,-714.84C2069.54,-703.92 2048.69,-691.56 2029.63,-680.25\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2031.4,-677.23 2021.01,-675.14 2027.83,-683.25 2031.4,-677.23\"/>\n</g>\n<!-- 129 -->\n<g id=\"node130\" class=\"node\">\n<title>129</title>\n<path fill=\"#eca572\" stroke=\"black\" d=\"M2181,-677C2181,-677 2100,-677 2100,-677 2094,-677 2088,-671 2088,-665 2088,-665 2088,-621 2088,-621 2088,-615 2094,-609 2100,-609 2100,-609 2181,-609 2181,-609 2187,-609 2193,-615 2193,-621 2193,-621 2193,-665 2193,-665 2193,-671 2187,-677 2181,-677\"/>\n<text text-anchor=\"start\" x=\"2099\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.696</text>\n<text text-anchor=\"start\" x=\"2103\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.346</text>\n<text text-anchor=\"start\" x=\"2097\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n<text text-anchor=\"start\" x=\"2096\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [14, 4]</text>\n</g>\n<!-- 109&#45;&gt;129 -->\n<g id=\"edge129\" class=\"edge\">\n<title>109&#45;&gt;129</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2140.5,-712.88C2140.5,-704.78 2140.5,-695.98 2140.5,-687.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2144,-687.3 2140.5,-677.3 2137,-687.3 2144,-687.3\"/>\n</g>\n<!-- 111 -->\n<g id=\"node112\" class=\"node\">\n<title>111</title>\n<path fill=\"#e78945\" stroke=\"black\" d=\"M1736,-573C1736,-573 1655,-573 1655,-573 1649,-573 1643,-567 1643,-561 1643,-561 1643,-517 1643,-517 1643,-511 1649,-505 1655,-505 1655,-505 1736,-505 1736,-505 1742,-505 1748,-511 1748,-517 1748,-517 1748,-561 1748,-561 1748,-567 1742,-573 1736,-573\"/>\n<text text-anchor=\"start\" x=\"1652.5\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.884</text>\n<text text-anchor=\"start\" x=\"1658\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.108</text>\n<text text-anchor=\"start\" x=\"1652\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 35</text>\n<text text-anchor=\"start\" x=\"1651\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [33, 2]</text>\n</g>\n<!-- 110&#45;&gt;111 -->\n<g id=\"edge111\" class=\"edge\">\n<title>110&#45;&gt;111</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1915.86,-622.33C1870.78,-605.49 1805.77,-581.2 1758.05,-563.37\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1759.03,-560 1748.44,-559.78 1756.58,-566.56 1759.03,-560\"/>\n</g>\n<!-- 124 -->\n<g id=\"node125\" class=\"node\">\n<title>124</title>\n<path fill=\"#eeab7b\" stroke=\"black\" d=\"M2007.5,-573C2007.5,-573 1929.5,-573 1929.5,-573 1923.5,-573 1917.5,-567 1917.5,-561 1917.5,-561 1917.5,-517 1917.5,-517 1917.5,-511 1923.5,-505 1929.5,-505 1929.5,-505 2007.5,-505 2007.5,-505 2013.5,-505 2019.5,-511 2019.5,-517 2019.5,-517 2019.5,-561 2019.5,-561 2019.5,-567 2013.5,-573 2007.5,-573\"/>\n<text text-anchor=\"start\" x=\"1925.5\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.806</text>\n<text text-anchor=\"start\" x=\"1931\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"1929\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"1928\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 1]</text>\n</g>\n<!-- 110&#45;&gt;124 -->\n<g id=\"edge124\" class=\"edge\">\n<title>110&#45;&gt;124</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1968.5,-608.88C1968.5,-600.78 1968.5,-591.98 1968.5,-583.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1972,-583.3 1968.5,-573.3 1965,-583.3 1972,-583.3\"/>\n</g>\n<!-- 112 -->\n<g id=\"node113\" class=\"node\">\n<title>112</title>\n<path fill=\"#ea9a61\" stroke=\"black\" d=\"M1563.5,-469C1563.5,-469 1485.5,-469 1485.5,-469 1479.5,-469 1473.5,-463 1473.5,-457 1473.5,-457 1473.5,-413 1473.5,-413 1473.5,-407 1479.5,-401 1485.5,-401 1485.5,-401 1563.5,-401 1563.5,-401 1569.5,-401 1575.5,-407 1575.5,-413 1575.5,-413 1575.5,-457 1575.5,-457 1575.5,-463 1569.5,-469 1563.5,-469\"/>\n<text text-anchor=\"start\" x=\"1481.5\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.892</text>\n<text text-anchor=\"start\" x=\"1487\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.278</text>\n<text text-anchor=\"start\" x=\"1485\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"1484\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 1]</text>\n</g>\n<!-- 111&#45;&gt;112 -->\n<g id=\"edge112\" class=\"edge\">\n<title>111&#45;&gt;112</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1642.8,-506.56C1624.25,-495.5 1603.27,-482.98 1584.18,-471.6\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1585.94,-468.57 1575.56,-466.46 1582.36,-474.59 1585.94,-468.57\"/>\n</g>\n<!-- 115 -->\n<g id=\"node116\" class=\"node\">\n<title>115</title>\n<path fill=\"#e68640\" stroke=\"black\" d=\"M1736,-469C1736,-469 1655,-469 1655,-469 1649,-469 1643,-463 1643,-457 1643,-457 1643,-413 1643,-413 1643,-407 1649,-401 1655,-401 1655,-401 1736,-401 1736,-401 1742,-401 1748,-407 1748,-413 1748,-413 1748,-457 1748,-457 1748,-463 1742,-469 1736,-469\"/>\n<text text-anchor=\"start\" x=\"1652.5\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.813</text>\n<text text-anchor=\"start\" x=\"1658\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.067</text>\n<text text-anchor=\"start\" x=\"1652\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 29</text>\n<text text-anchor=\"start\" x=\"1651\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [28, 1]</text>\n</g>\n<!-- 111&#45;&gt;115 -->\n<g id=\"edge115\" class=\"edge\">\n<title>111&#45;&gt;115</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1695.5,-504.88C1695.5,-496.78 1695.5,-487.98 1695.5,-479.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1699,-479.3 1695.5,-469.3 1692,-479.3 1699,-479.3\"/>\n</g>\n<!-- 113 -->\n<g id=\"node114\" class=\"node\">\n<title>113</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1446,-357.5C1446,-357.5 1373,-357.5 1373,-357.5 1367,-357.5 1361,-351.5 1361,-345.5 1361,-345.5 1361,-316.5 1361,-316.5 1361,-310.5 1367,-304.5 1373,-304.5 1373,-304.5 1446,-304.5 1446,-304.5 1452,-304.5 1458,-310.5 1458,-316.5 1458,-316.5 1458,-345.5 1458,-345.5 1458,-351.5 1452,-357.5 1446,-357.5\"/>\n<text text-anchor=\"start\" x=\"1380.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1370\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"1369\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 0]</text>\n</g>\n<!-- 112&#45;&gt;113 -->\n<g id=\"edge113\" class=\"edge\">\n<title>112&#45;&gt;113</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1487.16,-400.88C1473.9,-389.12 1458.99,-375.89 1445.81,-364.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1448.08,-361.54 1438.27,-357.52 1443.43,-366.77 1448.08,-361.54\"/>\n</g>\n<!-- 114 -->\n<g id=\"node115\" class=\"node\">\n<title>114</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1561,-357.5C1561,-357.5 1488,-357.5 1488,-357.5 1482,-357.5 1476,-351.5 1476,-345.5 1476,-345.5 1476,-316.5 1476,-316.5 1476,-310.5 1482,-304.5 1488,-304.5 1488,-304.5 1561,-304.5 1561,-304.5 1567,-304.5 1573,-310.5 1573,-316.5 1573,-316.5 1573,-345.5 1573,-345.5 1573,-351.5 1567,-357.5 1561,-357.5\"/>\n<text text-anchor=\"start\" x=\"1495.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1485\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1484\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 112&#45;&gt;114 -->\n<g id=\"edge114\" class=\"edge\">\n<title>112&#45;&gt;114</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1524.5,-400.88C1524.5,-390.33 1524.5,-378.6 1524.5,-367.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1528,-367.52 1524.5,-357.52 1521,-367.52 1528,-367.52\"/>\n</g>\n<!-- 116 -->\n<g id=\"node117\" class=\"node\">\n<title>116</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1684,-357.5C1684,-357.5 1603,-357.5 1603,-357.5 1597,-357.5 1591,-351.5 1591,-345.5 1591,-345.5 1591,-316.5 1591,-316.5 1591,-310.5 1597,-304.5 1603,-304.5 1603,-304.5 1684,-304.5 1684,-304.5 1690,-304.5 1696,-310.5 1696,-316.5 1696,-316.5 1696,-345.5 1696,-345.5 1696,-351.5 1690,-357.5 1684,-357.5\"/>\n<text text-anchor=\"start\" x=\"1614.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1600\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14</text>\n<text text-anchor=\"start\" x=\"1599\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [14, 0]</text>\n</g>\n<!-- 115&#45;&gt;116 -->\n<g id=\"edge116\" class=\"edge\">\n<title>115&#45;&gt;116</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1678.62,-400.88C1673.01,-389.89 1666.76,-377.62 1661.1,-366.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1664.17,-364.84 1656.51,-357.52 1657.93,-368.02 1664.17,-364.84\"/>\n</g>\n<!-- 117 -->\n<g id=\"node118\" class=\"node\">\n<title>117</title>\n<path fill=\"#e78a47\" stroke=\"black\" d=\"M1807,-365C1807,-365 1726,-365 1726,-365 1720,-365 1714,-359 1714,-353 1714,-353 1714,-309 1714,-309 1714,-303 1720,-297 1726,-297 1726,-297 1807,-297 1807,-297 1813,-297 1819,-303 1819,-309 1819,-309 1819,-353 1819,-353 1819,-359 1813,-365 1807,-365\"/>\n<text text-anchor=\"start\" x=\"1723.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.811</text>\n<text text-anchor=\"start\" x=\"1729\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.124</text>\n<text text-anchor=\"start\" x=\"1723\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\n<text text-anchor=\"start\" x=\"1722\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [14, 1]</text>\n</g>\n<!-- 115&#45;&gt;117 -->\n<g id=\"edge117\" class=\"edge\">\n<title>115&#45;&gt;117</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1718.55,-400.88C1724.63,-392.15 1731.26,-382.62 1737.6,-373.51\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1740.48,-375.51 1743.32,-365.3 1734.74,-371.51 1740.48,-375.51\"/>\n</g>\n<!-- 118 -->\n<g id=\"node119\" class=\"node\">\n<title>118</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M1773,-261C1773,-261 1698,-261 1698,-261 1692,-261 1686,-255 1686,-249 1686,-249 1686,-205 1686,-205 1686,-199 1692,-193 1698,-193 1698,-193 1773,-193 1773,-193 1779,-193 1785,-199 1785,-205 1785,-205 1785,-249 1785,-249 1785,-255 1779,-261 1773,-261\"/>\n<text text-anchor=\"start\" x=\"1694\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.771</text>\n<text text-anchor=\"start\" x=\"1698\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"1696\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1695\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 1]</text>\n</g>\n<!-- 117&#45;&gt;118 -->\n<g id=\"edge118\" class=\"edge\">\n<title>117&#45;&gt;118</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1756.44,-296.88C1753.92,-288.6 1751.18,-279.6 1748.54,-270.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1751.88,-269.85 1745.62,-261.3 1745.18,-271.89 1751.88,-269.85\"/>\n</g>\n<!-- 123 -->\n<g id=\"node124\" class=\"node\">\n<title>123</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1896,-253.5C1896,-253.5 1815,-253.5 1815,-253.5 1809,-253.5 1803,-247.5 1803,-241.5 1803,-241.5 1803,-212.5 1803,-212.5 1803,-206.5 1809,-200.5 1815,-200.5 1815,-200.5 1896,-200.5 1896,-200.5 1902,-200.5 1908,-206.5 1908,-212.5 1908,-212.5 1908,-241.5 1908,-241.5 1908,-247.5 1902,-253.5 1896,-253.5\"/>\n<text text-anchor=\"start\" x=\"1826.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1812\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\n<text text-anchor=\"start\" x=\"1811\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [12, 0]</text>\n</g>\n<!-- 117&#45;&gt;123 -->\n<g id=\"edge123\" class=\"edge\">\n<title>117&#45;&gt;123</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1795.4,-296.88C1805.38,-285.45 1816.55,-272.63 1826.54,-261.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1829.3,-263.36 1833.23,-253.52 1824.02,-258.75 1829.3,-263.36\"/>\n</g>\n<!-- 119 -->\n<g id=\"node120\" class=\"node\">\n<title>119</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1714,-149.5C1714,-149.5 1641,-149.5 1641,-149.5 1635,-149.5 1629,-143.5 1629,-137.5 1629,-137.5 1629,-108.5 1629,-108.5 1629,-102.5 1635,-96.5 1641,-96.5 1641,-96.5 1714,-96.5 1714,-96.5 1720,-96.5 1726,-102.5 1726,-108.5 1726,-108.5 1726,-137.5 1726,-137.5 1726,-143.5 1720,-149.5 1714,-149.5\"/>\n<text text-anchor=\"start\" x=\"1648.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1638\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1637\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 118&#45;&gt;119 -->\n<g id=\"edge119\" class=\"edge\">\n<title>118&#45;&gt;119</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1716.67,-192.88C1710.42,-181.89 1703.44,-169.62 1697.13,-158.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1700,-156.48 1692.01,-149.52 1693.91,-159.94 1700,-156.48\"/>\n</g>\n<!-- 120 -->\n<g id=\"node121\" class=\"node\">\n<title>120</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M1831,-157C1831,-157 1756,-157 1756,-157 1750,-157 1744,-151 1744,-145 1744,-145 1744,-101 1744,-101 1744,-95 1750,-89 1756,-89 1756,-89 1831,-89 1831,-89 1837,-89 1843,-95 1843,-101 1843,-101 1843,-145 1843,-145 1843,-151 1837,-157 1831,-157\"/>\n<text text-anchor=\"start\" x=\"1752\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.545</text>\n<text text-anchor=\"start\" x=\"1764.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"1754\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1753\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 118&#45;&gt;120 -->\n<g id=\"edge120\" class=\"edge\">\n<title>118&#45;&gt;120</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1754.33,-192.88C1759.19,-184.33 1764.49,-175.01 1769.58,-166.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1772.66,-167.72 1774.57,-157.3 1766.58,-164.26 1772.66,-167.72\"/>\n</g>\n<!-- 121 -->\n<g id=\"node122\" class=\"node\">\n<title>121</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1773,-53C1773,-53 1700,-53 1700,-53 1694,-53 1688,-47 1688,-41 1688,-41 1688,-12 1688,-12 1688,-6 1694,0 1700,0 1700,0 1773,0 1773,0 1779,0 1785,-6 1785,-12 1785,-12 1785,-41 1785,-41 1785,-47 1779,-53 1773,-53\"/>\n<text text-anchor=\"start\" x=\"1707.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1697\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1696\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 120&#45;&gt;121 -->\n<g id=\"edge121\" class=\"edge\">\n<title>120&#45;&gt;121</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1773.56,-88.95C1768.27,-80.17 1762.53,-70.66 1757.2,-61.82\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1760.19,-59.99 1752.02,-53.24 1754.19,-63.61 1760.19,-59.99\"/>\n</g>\n<!-- 122 -->\n<g id=\"node123\" class=\"node\">\n<title>122</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1888,-53C1888,-53 1815,-53 1815,-53 1809,-53 1803,-47 1803,-41 1803,-41 1803,-12 1803,-12 1803,-6 1809,0 1815,0 1815,0 1888,0 1888,0 1894,0 1900,-6 1900,-12 1900,-12 1900,-41 1900,-41 1900,-47 1894,-53 1888,-53\"/>\n<text text-anchor=\"start\" x=\"1822.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1812\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1811\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 120&#45;&gt;122 -->\n<g id=\"edge122\" class=\"edge\">\n<title>120&#45;&gt;122</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1813.79,-88.95C1819.18,-80.17 1825.01,-70.66 1830.44,-61.82\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1833.46,-63.59 1835.7,-53.24 1827.49,-59.93 1833.46,-63.59\"/>\n</g>\n<!-- 125 -->\n<g id=\"node126\" class=\"node\">\n<title>125</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M1922,-469C1922,-469 1847,-469 1847,-469 1841,-469 1835,-463 1835,-457 1835,-457 1835,-413 1835,-413 1835,-407 1841,-401 1847,-401 1847,-401 1922,-401 1922,-401 1928,-401 1934,-407 1934,-413 1934,-413 1934,-457 1934,-457 1934,-463 1928,-469 1922,-469\"/>\n<text text-anchor=\"start\" x=\"1843\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.167</text>\n<text text-anchor=\"start\" x=\"1855.5\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"1845\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1844\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 124&#45;&gt;125 -->\n<g id=\"edge125\" class=\"edge\">\n<title>124&#45;&gt;125</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1941.23,-504.88C1933.97,-496.07 1926.03,-486.43 1918.46,-477.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1920.98,-474.79 1911.92,-469.3 1915.58,-479.24 1920.98,-474.79\"/>\n</g>\n<!-- 128 -->\n<g id=\"node129\" class=\"node\">\n<title>128</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2037,-461.5C2037,-461.5 1964,-461.5 1964,-461.5 1958,-461.5 1952,-455.5 1952,-449.5 1952,-449.5 1952,-420.5 1952,-420.5 1952,-414.5 1958,-408.5 1964,-408.5 1964,-408.5 2037,-408.5 2037,-408.5 2043,-408.5 2049,-414.5 2049,-420.5 2049,-420.5 2049,-449.5 2049,-449.5 2049,-455.5 2043,-461.5 2037,-461.5\"/>\n<text text-anchor=\"start\" x=\"1971.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1961\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1960\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 124&#45;&gt;128 -->\n<g id=\"edge128\" class=\"edge\">\n<title>124&#45;&gt;128</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1978.89,-504.88C1982.27,-494.11 1986.03,-482.11 1989.46,-471.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1992.84,-472.11 1992.49,-461.52 1986.16,-470.01 1992.84,-472.11\"/>\n</g>\n<!-- 126 -->\n<g id=\"node127\" class=\"node\">\n<title>126</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1922,-357.5C1922,-357.5 1849,-357.5 1849,-357.5 1843,-357.5 1837,-351.5 1837,-345.5 1837,-345.5 1837,-316.5 1837,-316.5 1837,-310.5 1843,-304.5 1849,-304.5 1849,-304.5 1922,-304.5 1922,-304.5 1928,-304.5 1934,-310.5 1934,-316.5 1934,-316.5 1934,-345.5 1934,-345.5 1934,-351.5 1928,-357.5 1922,-357.5\"/>\n<text text-anchor=\"start\" x=\"1856.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1846\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1845\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 125&#45;&gt;126 -->\n<g id=\"edge126\" class=\"edge\">\n<title>125&#45;&gt;126</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1884.82,-400.88C1884.93,-390.33 1885.04,-378.6 1885.15,-367.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1888.65,-367.55 1885.25,-357.52 1881.65,-367.49 1888.65,-367.55\"/>\n</g>\n<!-- 127 -->\n<g id=\"node128\" class=\"node\">\n<title>127</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2037,-357.5C2037,-357.5 1964,-357.5 1964,-357.5 1958,-357.5 1952,-351.5 1952,-345.5 1952,-345.5 1952,-316.5 1952,-316.5 1952,-310.5 1958,-304.5 1964,-304.5 1964,-304.5 2037,-304.5 2037,-304.5 2043,-304.5 2049,-310.5 2049,-316.5 2049,-316.5 2049,-345.5 2049,-345.5 2049,-351.5 2043,-357.5 2037,-357.5\"/>\n<text text-anchor=\"start\" x=\"1971.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1961\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1960\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 125&#45;&gt;127 -->\n<g id=\"edge127\" class=\"edge\">\n<title>125&#45;&gt;127</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1922.16,-400.88C1935.54,-389.12 1950.58,-375.89 1963.88,-364.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1966.28,-366.75 1971.48,-357.52 1961.66,-361.49 1966.28,-366.75\"/>\n</g>\n<!-- 130 -->\n<g id=\"node131\" class=\"node\">\n<title>130</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M2150,-573C2150,-573 2077,-573 2077,-573 2071,-573 2065,-567 2065,-561 2065,-561 2065,-517 2065,-517 2065,-511 2071,-505 2077,-505 2077,-505 2150,-505 2150,-505 2156,-505 2162,-511 2162,-517 2162,-517 2162,-561 2162,-561 2162,-567 2156,-573 2150,-573\"/>\n<text text-anchor=\"start\" x=\"2076\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"2084.5\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"2074\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"2073\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 4]</text>\n</g>\n<!-- 129&#45;&gt;130 -->\n<g id=\"edge130\" class=\"edge\">\n<title>129&#45;&gt;130</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2131.73,-608.88C2129.56,-600.69 2127.21,-591.79 2124.93,-583.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2128.26,-582.07 2122.31,-573.3 2121.49,-583.86 2128.26,-582.07\"/>\n</g>\n<!-- 139 -->\n<g id=\"node140\" class=\"node\">\n<title>139</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2273,-565.5C2273,-565.5 2192,-565.5 2192,-565.5 2186,-565.5 2180,-559.5 2180,-553.5 2180,-553.5 2180,-524.5 2180,-524.5 2180,-518.5 2186,-512.5 2192,-512.5 2192,-512.5 2273,-512.5 2273,-512.5 2279,-512.5 2285,-518.5 2285,-524.5 2285,-524.5 2285,-553.5 2285,-553.5 2285,-559.5 2279,-565.5 2273,-565.5\"/>\n<text text-anchor=\"start\" x=\"2203.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2189\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"2188\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [10, 0]</text>\n</g>\n<!-- 129&#45;&gt;139 -->\n<g id=\"edge139\" class=\"edge\">\n<title>129&#45;&gt;139</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2170.37,-608.88C2180.69,-597.45 2192.24,-584.63 2202.56,-573.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2205.38,-575.29 2209.48,-565.52 2200.19,-570.6 2205.38,-575.29\"/>\n</g>\n<!-- 131 -->\n<g id=\"node132\" class=\"node\">\n<title>131</title>\n<path fill=\"#f8e0ce\" stroke=\"black\" d=\"M2154,-469C2154,-469 2079,-469 2079,-469 2073,-469 2067,-463 2067,-457 2067,-457 2067,-413 2067,-413 2067,-407 2073,-401 2079,-401 2079,-401 2154,-401 2154,-401 2160,-401 2166,-407 2166,-413 2166,-413 2166,-457 2166,-457 2166,-463 2160,-469 2154,-469\"/>\n<text text-anchor=\"start\" x=\"2075\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.771</text>\n<text text-anchor=\"start\" x=\"2083\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.49</text>\n<text text-anchor=\"start\" x=\"2077\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"2076\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 3]</text>\n</g>\n<!-- 130&#45;&gt;131 -->\n<g id=\"edge131\" class=\"edge\">\n<title>130&#45;&gt;131</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2114.47,-504.88C2114.71,-496.78 2114.97,-487.98 2115.22,-479.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2118.73,-479.4 2115.52,-469.3 2111.73,-479.19 2118.73,-479.4\"/>\n</g>\n<!-- 138 -->\n<g id=\"node139\" class=\"node\">\n<title>138</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2269,-461.5C2269,-461.5 2196,-461.5 2196,-461.5 2190,-461.5 2184,-455.5 2184,-449.5 2184,-449.5 2184,-420.5 2184,-420.5 2184,-414.5 2190,-408.5 2196,-408.5 2196,-408.5 2269,-408.5 2269,-408.5 2275,-408.5 2281,-414.5 2281,-420.5 2281,-420.5 2281,-449.5 2281,-449.5 2281,-455.5 2275,-461.5 2269,-461.5\"/>\n<text text-anchor=\"start\" x=\"2203.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2193\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2192\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 130&#45;&gt;138 -->\n<g id=\"edge138\" class=\"edge\">\n<title>130&#45;&gt;138</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2152.14,-504.88C2165.86,-493.12 2181.29,-479.89 2194.93,-468.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2197.41,-470.69 2202.73,-461.52 2192.86,-465.37 2197.41,-470.69\"/>\n</g>\n<!-- 132 -->\n<g id=\"node133\" class=\"node\">\n<title>132</title>\n<path fill=\"#bddef6\" stroke=\"black\" d=\"M2153,-365C2153,-365 2080,-365 2080,-365 2074,-365 2068,-359 2068,-353 2068,-353 2068,-309 2068,-309 2068,-303 2074,-297 2080,-297 2080,-297 2153,-297 2153,-297 2159,-297 2165,-303 2165,-309 2165,-309 2165,-353 2165,-353 2165,-359 2159,-365 2153,-365\"/>\n<text text-anchor=\"start\" x=\"2079\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.96</text>\n<text text-anchor=\"start\" x=\"2083\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n<text text-anchor=\"start\" x=\"2077\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"2076\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 3]</text>\n</g>\n<!-- 131&#45;&gt;132 -->\n<g id=\"edge132\" class=\"edge\">\n<title>131&#45;&gt;132</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2116.5,-400.88C2116.5,-392.78 2116.5,-383.98 2116.5,-375.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2120,-375.3 2116.5,-365.3 2113,-375.3 2120,-375.3\"/>\n</g>\n<!-- 137 -->\n<g id=\"node138\" class=\"node\">\n<title>137</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2268,-357.5C2268,-357.5 2195,-357.5 2195,-357.5 2189,-357.5 2183,-351.5 2183,-345.5 2183,-345.5 2183,-316.5 2183,-316.5 2183,-310.5 2189,-304.5 2195,-304.5 2195,-304.5 2268,-304.5 2268,-304.5 2274,-304.5 2280,-310.5 2280,-316.5 2280,-316.5 2280,-345.5 2280,-345.5 2280,-351.5 2274,-357.5 2268,-357.5\"/>\n<text text-anchor=\"start\" x=\"2202.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2192\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2191\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 131&#45;&gt;137 -->\n<g id=\"edge137\" class=\"edge\">\n<title>131&#45;&gt;137</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2153.84,-400.88C2167.1,-389.12 2182.01,-375.89 2195.19,-364.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2197.57,-366.77 2202.73,-357.52 2192.92,-361.54 2197.57,-366.77\"/>\n</g>\n<!-- 133 -->\n<g id=\"node134\" class=\"node\">\n<title>133</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M2068,-253.5C2068,-253.5 1995,-253.5 1995,-253.5 1989,-253.5 1983,-247.5 1983,-241.5 1983,-241.5 1983,-212.5 1983,-212.5 1983,-206.5 1989,-200.5 1995,-200.5 1995,-200.5 2068,-200.5 2068,-200.5 2074,-200.5 2080,-206.5 2080,-212.5 2080,-212.5 2080,-241.5 2080,-241.5 2080,-247.5 2074,-253.5 2068,-253.5\"/>\n<text text-anchor=\"start\" x=\"2002.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"1992\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1991\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 132&#45;&gt;133 -->\n<g id=\"edge133\" class=\"edge\">\n<title>132&#45;&gt;133</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2088.9,-296.88C2079.46,-285.56 2068.9,-272.88 2059.43,-261.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2061.86,-258.96 2052.77,-253.52 2056.48,-263.44 2061.86,-258.96\"/>\n</g>\n<!-- 134 -->\n<g id=\"node135\" class=\"node\">\n<title>134</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M2185,-261C2185,-261 2110,-261 2110,-261 2104,-261 2098,-255 2098,-249 2098,-249 2098,-205 2098,-205 2098,-199 2104,-193 2110,-193 2110,-193 2185,-193 2185,-193 2191,-193 2197,-199 2197,-205 2197,-205 2197,-249 2197,-249 2197,-255 2191,-261 2185,-261\"/>\n<text text-anchor=\"start\" x=\"2106\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.847</text>\n<text text-anchor=\"start\" x=\"2110\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"2108\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2107\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 132&#45;&gt;134 -->\n<g id=\"edge134\" class=\"edge\">\n<title>132&#45;&gt;134</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2126.56,-296.88C2129.08,-288.6 2131.82,-279.6 2134.46,-270.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2137.82,-271.89 2137.38,-261.3 2131.12,-269.85 2137.82,-271.89\"/>\n</g>\n<!-- 135 -->\n<g id=\"node136\" class=\"node\">\n<title>135</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2126,-149.5C2126,-149.5 2053,-149.5 2053,-149.5 2047,-149.5 2041,-143.5 2041,-137.5 2041,-137.5 2041,-108.5 2041,-108.5 2041,-102.5 2047,-96.5 2053,-96.5 2053,-96.5 2126,-96.5 2126,-96.5 2132,-96.5 2138,-102.5 2138,-108.5 2138,-108.5 2138,-137.5 2138,-137.5 2138,-143.5 2132,-149.5 2126,-149.5\"/>\n<text text-anchor=\"start\" x=\"2060.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2050\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2049\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 134&#45;&gt;135 -->\n<g id=\"edge135\" class=\"edge\">\n<title>134&#45;&gt;135</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2128.67,-192.88C2122.42,-181.89 2115.44,-169.62 2109.13,-158.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2112,-156.48 2104.01,-149.52 2105.91,-159.94 2112,-156.48\"/>\n</g>\n<!-- 136 -->\n<g id=\"node137\" class=\"node\">\n<title>136</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M2241,-149.5C2241,-149.5 2168,-149.5 2168,-149.5 2162,-149.5 2156,-143.5 2156,-137.5 2156,-137.5 2156,-108.5 2156,-108.5 2156,-102.5 2162,-96.5 2168,-96.5 2168,-96.5 2241,-96.5 2241,-96.5 2247,-96.5 2253,-102.5 2253,-108.5 2253,-108.5 2253,-137.5 2253,-137.5 2253,-143.5 2247,-149.5 2241,-149.5\"/>\n<text text-anchor=\"start\" x=\"2175.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"2165\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2164\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 134&#45;&gt;136 -->\n<g id=\"edge136\" class=\"edge\">\n<title>134&#45;&gt;136</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2166.01,-192.88C2172.15,-181.89 2179.01,-169.62 2185.21,-158.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2188.42,-159.96 2190.24,-149.52 2182.31,-156.54 2188.42,-159.96\"/>\n</g>\n<!-- 141 -->\n<g id=\"node142\" class=\"node\">\n<title>141</title>\n<path fill=\"#e78c4b\" stroke=\"black\" d=\"M2502,-677C2502,-677 2421,-677 2421,-677 2415,-677 2409,-671 2409,-665 2409,-665 2409,-621 2409,-621 2409,-615 2415,-609 2421,-609 2421,-609 2502,-609 2502,-609 2508,-609 2514,-615 2514,-621 2514,-621 2514,-665 2514,-665 2514,-671 2508,-677 2502,-677\"/>\n<text text-anchor=\"start\" x=\"2422\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pclass ≤ 2.5</text>\n<text text-anchor=\"start\" x=\"2424\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.153</text>\n<text text-anchor=\"start\" x=\"2418\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\n<text text-anchor=\"start\" x=\"2417\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 1]</text>\n</g>\n<!-- 140&#45;&gt;141 -->\n<g id=\"edge141\" class=\"edge\">\n<title>140&#45;&gt;141</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2544.57,-712.88C2533.39,-703.62 2521.14,-693.45 2509.55,-683.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2511.59,-680.99 2501.66,-677.3 2507.12,-686.38 2511.59,-680.99\"/>\n</g>\n<!-- 146 -->\n<g id=\"node147\" class=\"node\">\n<title>146</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2625,-669.5C2625,-669.5 2544,-669.5 2544,-669.5 2538,-669.5 2532,-663.5 2532,-657.5 2532,-657.5 2532,-628.5 2532,-628.5 2532,-622.5 2538,-616.5 2544,-616.5 2544,-616.5 2625,-616.5 2625,-616.5 2631,-616.5 2637,-622.5 2637,-628.5 2637,-628.5 2637,-657.5 2637,-657.5 2637,-663.5 2631,-669.5 2625,-669.5\"/>\n<text text-anchor=\"start\" x=\"2555.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2541\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 26</text>\n<text text-anchor=\"start\" x=\"2540\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [26, 0]</text>\n</g>\n<!-- 140&#45;&gt;146 -->\n<g id=\"edge146\" class=\"edge\">\n<title>140&#45;&gt;146</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2584.5,-712.88C2584.5,-702.33 2584.5,-690.6 2584.5,-679.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2588,-679.52 2584.5,-669.52 2581,-679.52 2588,-679.52\"/>\n</g>\n<!-- 142 -->\n<g id=\"node143\" class=\"node\">\n<title>142</title>\n<path fill=\"#eca06a\" stroke=\"black\" d=\"M2393.5,-573C2393.5,-573 2315.5,-573 2315.5,-573 2309.5,-573 2303.5,-567 2303.5,-561 2303.5,-561 2303.5,-517 2303.5,-517 2303.5,-511 2309.5,-505 2315.5,-505 2315.5,-505 2393.5,-505 2393.5,-505 2399.5,-505 2405.5,-511 2405.5,-517 2405.5,-517 2405.5,-561 2405.5,-561 2405.5,-567 2399.5,-573 2393.5,-573\"/>\n<text text-anchor=\"start\" x=\"2311.5\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.491</text>\n<text text-anchor=\"start\" x=\"2321\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"2315\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"2314\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 1]</text>\n</g>\n<!-- 141&#45;&gt;142 -->\n<g id=\"edge142\" class=\"edge\">\n<title>141&#45;&gt;142</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2426.76,-608.88C2417.23,-599.8 2406.79,-589.85 2396.88,-580.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2399.08,-577.67 2389.43,-573.3 2394.25,-582.73 2399.08,-577.67\"/>\n</g>\n<!-- 145 -->\n<g id=\"node146\" class=\"node\">\n<title>145</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2509,-565.5C2509,-565.5 2436,-565.5 2436,-565.5 2430,-565.5 2424,-559.5 2424,-553.5 2424,-553.5 2424,-524.5 2424,-524.5 2424,-518.5 2430,-512.5 2436,-512.5 2436,-512.5 2509,-512.5 2509,-512.5 2515,-512.5 2521,-518.5 2521,-524.5 2521,-524.5 2521,-553.5 2521,-553.5 2521,-559.5 2515,-565.5 2509,-565.5\"/>\n<text text-anchor=\"start\" x=\"2443.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2433\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"2432\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 0]</text>\n</g>\n<!-- 141&#45;&gt;145 -->\n<g id=\"edge145\" class=\"edge\">\n<title>141&#45;&gt;145</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2465.07,-608.88C2466.22,-598.22 2467.5,-586.35 2468.67,-575.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2472.16,-575.84 2469.75,-565.52 2465.2,-575.09 2472.16,-575.84\"/>\n</g>\n<!-- 143 -->\n<g id=\"node144\" class=\"node\">\n<title>143</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M2386,-461.5C2386,-461.5 2313,-461.5 2313,-461.5 2307,-461.5 2301,-455.5 2301,-449.5 2301,-449.5 2301,-420.5 2301,-420.5 2301,-414.5 2307,-408.5 2313,-408.5 2313,-408.5 2386,-408.5 2386,-408.5 2392,-408.5 2398,-414.5 2398,-420.5 2398,-420.5 2398,-449.5 2398,-449.5 2398,-455.5 2392,-461.5 2386,-461.5\"/>\n<text text-anchor=\"start\" x=\"2320.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"2310\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2309\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 142&#45;&gt;143 -->\n<g id=\"edge143\" class=\"edge\">\n<title>142&#45;&gt;143</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2352.88,-504.88C2352.35,-494.22 2351.77,-482.35 2351.24,-471.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2354.74,-471.34 2350.75,-461.52 2347.74,-471.68 2354.74,-471.34\"/>\n</g>\n<!-- 144 -->\n<g id=\"node145\" class=\"node\">\n<title>144</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2501,-461.5C2501,-461.5 2428,-461.5 2428,-461.5 2422,-461.5 2416,-455.5 2416,-449.5 2416,-449.5 2416,-420.5 2416,-420.5 2416,-414.5 2422,-408.5 2428,-408.5 2428,-408.5 2501,-408.5 2501,-408.5 2507,-408.5 2513,-414.5 2513,-420.5 2513,-420.5 2513,-449.5 2513,-449.5 2513,-455.5 2507,-461.5 2501,-461.5\"/>\n<text text-anchor=\"start\" x=\"2435.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2425\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2424\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 142&#45;&gt;144 -->\n<g id=\"edge144\" class=\"edge\">\n<title>142&#45;&gt;144</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2390.21,-504.88C2402.79,-493.23 2416.9,-480.14 2429.42,-468.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2432.03,-470.89 2436.98,-461.52 2427.27,-465.75 2432.03,-470.89\"/>\n</g>\n<!-- 148 -->\n<g id=\"node149\" class=\"node\">\n<title>148</title>\n<path fill=\"#eeab7b\" stroke=\"black\" d=\"M2748,-781C2748,-781 2667,-781 2667,-781 2661,-781 2655,-775 2655,-769 2655,-769 2655,-725 2655,-725 2655,-719 2661,-713 2667,-713 2667,-713 2748,-713 2748,-713 2754,-713 2760,-719 2760,-725 2760,-725 2760,-769 2760,-769 2760,-775 2754,-781 2748,-781\"/>\n<text text-anchor=\"start\" x=\"2664.5\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.705</text>\n<text text-anchor=\"start\" x=\"2670\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"2664\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 20</text>\n<text text-anchor=\"start\" x=\"2663\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [15, 5]</text>\n</g>\n<!-- 147&#45;&gt;148 -->\n<g id=\"edge148\" class=\"edge\">\n<title>147&#45;&gt;148</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2707.5,-816.88C2707.5,-808.78 2707.5,-799.98 2707.5,-791.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2711,-791.3 2707.5,-781.3 2704,-791.3 2711,-791.3\"/>\n</g>\n<!-- 165 -->\n<g id=\"node166\" class=\"node\">\n<title>165</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2863,-773.5C2863,-773.5 2790,-773.5 2790,-773.5 2784,-773.5 2778,-767.5 2778,-761.5 2778,-761.5 2778,-732.5 2778,-732.5 2778,-726.5 2784,-720.5 2790,-720.5 2790,-720.5 2863,-720.5 2863,-720.5 2869,-720.5 2875,-726.5 2875,-732.5 2875,-732.5 2875,-761.5 2875,-761.5 2875,-767.5 2869,-773.5 2863,-773.5\"/>\n<text text-anchor=\"start\" x=\"2797.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2787\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"2786\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 0]</text>\n</g>\n<!-- 147&#45;&gt;165 -->\n<g id=\"edge165\" class=\"edge\">\n<title>147&#45;&gt;165</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2746.14,-816.88C2759.86,-805.12 2775.29,-791.89 2788.93,-780.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2791.41,-782.69 2796.73,-773.52 2786.86,-777.37 2791.41,-782.69\"/>\n</g>\n<!-- 149 -->\n<g id=\"node150\" class=\"node\">\n<title>149</title>\n<path fill=\"#ea985d\" stroke=\"black\" d=\"M2748,-677C2748,-677 2667,-677 2667,-677 2661,-677 2655,-671 2655,-665 2655,-665 2655,-621 2655,-621 2655,-615 2661,-609 2667,-609 2667,-609 2748,-609 2748,-609 2754,-609 2760,-615 2760,-621 2760,-621 2760,-665 2760,-665 2760,-671 2754,-677 2748,-677\"/>\n<text text-anchor=\"start\" x=\"2664.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.803</text>\n<text text-anchor=\"start\" x=\"2674\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.26</text>\n<text text-anchor=\"start\" x=\"2664\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13</text>\n<text text-anchor=\"start\" x=\"2663\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 2]</text>\n</g>\n<!-- 148&#45;&gt;149 -->\n<g id=\"edge149\" class=\"edge\">\n<title>148&#45;&gt;149</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2707.5,-712.88C2707.5,-704.78 2707.5,-695.98 2707.5,-687.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2711,-687.3 2707.5,-677.3 2704,-687.3 2711,-687.3\"/>\n</g>\n<!-- 158 -->\n<g id=\"node159\" class=\"node\">\n<title>158</title>\n<path fill=\"#f8e0ce\" stroke=\"black\" d=\"M2868.5,-677C2868.5,-677 2790.5,-677 2790.5,-677 2784.5,-677 2778.5,-671 2778.5,-665 2778.5,-665 2778.5,-621 2778.5,-621 2778.5,-615 2784.5,-609 2790.5,-609 2790.5,-609 2868.5,-609 2868.5,-609 2874.5,-609 2880.5,-615 2880.5,-621 2880.5,-621 2880.5,-665 2880.5,-665 2880.5,-671 2874.5,-677 2868.5,-677\"/>\n<text text-anchor=\"start\" x=\"2786.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.581</text>\n<text text-anchor=\"start\" x=\"2796\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.49</text>\n<text text-anchor=\"start\" x=\"2790\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"2789\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 3]</text>\n</g>\n<!-- 148&#45;&gt;158 -->\n<g id=\"edge158\" class=\"edge\">\n<title>148&#45;&gt;158</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2747.11,-712.88C2758.19,-703.62 2770.35,-693.45 2781.84,-683.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2784.24,-686.4 2789.67,-677.3 2779.75,-681.03 2784.24,-686.4\"/>\n</g>\n<!-- 150 -->\n<g id=\"node151\" class=\"node\">\n<title>150</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M2629.5,-573C2629.5,-573 2551.5,-573 2551.5,-573 2545.5,-573 2539.5,-567 2539.5,-561 2539.5,-561 2539.5,-517 2539.5,-517 2539.5,-511 2545.5,-505 2551.5,-505 2551.5,-505 2629.5,-505 2629.5,-505 2635.5,-505 2641.5,-511 2641.5,-517 2641.5,-517 2641.5,-561 2641.5,-561 2641.5,-567 2635.5,-573 2629.5,-573\"/>\n<text text-anchor=\"start\" x=\"2547.5\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.809</text>\n<text text-anchor=\"start\" x=\"2553\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"2551\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"2550\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 2]</text>\n</g>\n<!-- 149&#45;&gt;150 -->\n<g id=\"edge150\" class=\"edge\">\n<title>149&#45;&gt;150</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2669.51,-608.88C2658.99,-599.71 2647.45,-589.65 2636.52,-580.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2638.53,-577.23 2628.7,-573.3 2633.93,-582.51 2638.53,-577.23\"/>\n</g>\n<!-- 157 -->\n<g id=\"node158\" class=\"node\">\n<title>157</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2745,-565.5C2745,-565.5 2672,-565.5 2672,-565.5 2666,-565.5 2660,-559.5 2660,-553.5 2660,-553.5 2660,-524.5 2660,-524.5 2660,-518.5 2666,-512.5 2672,-512.5 2672,-512.5 2745,-512.5 2745,-512.5 2751,-512.5 2757,-518.5 2757,-524.5 2757,-524.5 2757,-553.5 2757,-553.5 2757,-559.5 2751,-565.5 2745,-565.5\"/>\n<text text-anchor=\"start\" x=\"2679.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2669\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"2668\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 0]</text>\n</g>\n<!-- 149&#45;&gt;157 -->\n<g id=\"edge157\" class=\"edge\">\n<title>149&#45;&gt;157</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2707.82,-608.88C2707.93,-598.33 2708.04,-586.6 2708.15,-575.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2711.65,-575.55 2708.25,-565.52 2704.65,-575.49 2711.65,-575.55\"/>\n</g>\n<!-- 151 -->\n<g id=\"node152\" class=\"node\">\n<title>151</title>\n<path fill=\"#eca06a\" stroke=\"black\" d=\"M2620,-469C2620,-469 2545,-469 2545,-469 2539,-469 2533,-463 2533,-457 2533,-457 2533,-413 2533,-413 2533,-407 2539,-401 2545,-401 2545,-401 2620,-401 2620,-401 2626,-401 2632,-407 2632,-413 2632,-413 2632,-457 2632,-457 2632,-463 2626,-469 2620,-469\"/>\n<text text-anchor=\"start\" x=\"2541\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.016</text>\n<text text-anchor=\"start\" x=\"2549\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"2543\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"2542\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 1]</text>\n</g>\n<!-- 150&#45;&gt;151 -->\n<g id=\"edge151\" class=\"edge\">\n<title>150&#45;&gt;151</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2587.9,-504.88C2587.27,-496.78 2586.58,-487.98 2585.91,-479.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2589.38,-479 2585.11,-469.3 2582.4,-479.54 2589.38,-479\"/>\n</g>\n<!-- 156 -->\n<g id=\"node157\" class=\"node\">\n<title>156</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2735,-461.5C2735,-461.5 2662,-461.5 2662,-461.5 2656,-461.5 2650,-455.5 2650,-449.5 2650,-449.5 2650,-420.5 2650,-420.5 2650,-414.5 2656,-408.5 2662,-408.5 2662,-408.5 2735,-408.5 2735,-408.5 2741,-408.5 2747,-414.5 2747,-420.5 2747,-420.5 2747,-449.5 2747,-449.5 2747,-455.5 2741,-461.5 2735,-461.5\"/>\n<text text-anchor=\"start\" x=\"2669.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2659\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2658\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 150&#45;&gt;156 -->\n<g id=\"edge156\" class=\"edge\">\n<title>150&#45;&gt;156</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2625.56,-504.88C2637.91,-493.23 2651.76,-480.14 2664.05,-468.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2666.61,-470.93 2671.48,-461.52 2661.81,-465.84 2666.61,-470.93\"/>\n</g>\n<!-- 152 -->\n<g id=\"node153\" class=\"node\">\n<title>152</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M2562.5,-365C2562.5,-365 2484.5,-365 2484.5,-365 2478.5,-365 2472.5,-359 2472.5,-353 2472.5,-353 2472.5,-309 2472.5,-309 2472.5,-303 2478.5,-297 2484.5,-297 2484.5,-297 2562.5,-297 2562.5,-297 2568.5,-297 2574.5,-303 2574.5,-309 2574.5,-309 2574.5,-353 2574.5,-353 2574.5,-359 2568.5,-365 2562.5,-365\"/>\n<text text-anchor=\"start\" x=\"2480.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.815</text>\n<text text-anchor=\"start\" x=\"2494.5\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"2484\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2483\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 151&#45;&gt;152 -->\n<g id=\"edge152\" class=\"edge\">\n<title>151&#45;&gt;152</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2563.34,-400.88C2558.4,-392.33 2553.01,-383.01 2547.84,-374.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2550.8,-372.2 2542.76,-365.3 2544.74,-375.71 2550.8,-372.2\"/>\n</g>\n<!-- 155 -->\n<g id=\"node156\" class=\"node\">\n<title>155</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2678,-357.5C2678,-357.5 2605,-357.5 2605,-357.5 2599,-357.5 2593,-351.5 2593,-345.5 2593,-345.5 2593,-316.5 2593,-316.5 2593,-310.5 2599,-304.5 2605,-304.5 2605,-304.5 2678,-304.5 2678,-304.5 2684,-304.5 2690,-310.5 2690,-316.5 2690,-316.5 2690,-345.5 2690,-345.5 2690,-351.5 2684,-357.5 2678,-357.5\"/>\n<text text-anchor=\"start\" x=\"2612.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2602\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2601\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 151&#45;&gt;155 -->\n<g id=\"edge155\" class=\"edge\">\n<title>151&#45;&gt;155</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2601.66,-400.88C2608.08,-389.78 2615.26,-377.37 2621.73,-366.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2624.76,-367.93 2626.74,-357.52 2618.7,-364.42 2624.76,-367.93\"/>\n</g>\n<!-- 153 -->\n<g id=\"node154\" class=\"node\">\n<title>153</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2502,-253.5C2502,-253.5 2429,-253.5 2429,-253.5 2423,-253.5 2417,-247.5 2417,-241.5 2417,-241.5 2417,-212.5 2417,-212.5 2417,-206.5 2423,-200.5 2429,-200.5 2429,-200.5 2502,-200.5 2502,-200.5 2508,-200.5 2514,-206.5 2514,-212.5 2514,-212.5 2514,-241.5 2514,-241.5 2514,-247.5 2508,-253.5 2502,-253.5\"/>\n<text text-anchor=\"start\" x=\"2436.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2426\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2425\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 152&#45;&gt;153 -->\n<g id=\"edge153\" class=\"edge\">\n<title>152&#45;&gt;153</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2504.67,-296.88C2498.42,-285.89 2491.44,-273.62 2485.13,-262.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2488,-260.48 2480.01,-253.52 2481.91,-263.94 2488,-260.48\"/>\n</g>\n<!-- 154 -->\n<g id=\"node155\" class=\"node\">\n<title>154</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2617,-253.5C2617,-253.5 2544,-253.5 2544,-253.5 2538,-253.5 2532,-247.5 2532,-241.5 2532,-241.5 2532,-212.5 2532,-212.5 2532,-206.5 2538,-200.5 2544,-200.5 2544,-200.5 2617,-200.5 2617,-200.5 2623,-200.5 2629,-206.5 2629,-212.5 2629,-212.5 2629,-241.5 2629,-241.5 2629,-247.5 2623,-253.5 2617,-253.5\"/>\n<text text-anchor=\"start\" x=\"2551.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2541\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2540\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 152&#45;&gt;154 -->\n<g id=\"edge154\" class=\"edge\">\n<title>152&#45;&gt;154</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2542.01,-296.88C2548.15,-285.89 2555.01,-273.62 2561.21,-262.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2564.42,-263.96 2566.24,-253.52 2558.31,-260.54 2564.42,-263.96\"/>\n</g>\n<!-- 159 -->\n<g id=\"node160\" class=\"node\">\n<title>159</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2860,-565.5C2860,-565.5 2787,-565.5 2787,-565.5 2781,-565.5 2775,-559.5 2775,-553.5 2775,-553.5 2775,-524.5 2775,-524.5 2775,-518.5 2781,-512.5 2787,-512.5 2787,-512.5 2860,-512.5 2860,-512.5 2866,-512.5 2872,-518.5 2872,-524.5 2872,-524.5 2872,-553.5 2872,-553.5 2872,-559.5 2866,-565.5 2860,-565.5\"/>\n<text text-anchor=\"start\" x=\"2794.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2784\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2783\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 158&#45;&gt;159 -->\n<g id=\"edge159\" class=\"edge\">\n<title>158&#45;&gt;159</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2827.55,-608.88C2826.92,-598.22 2826.23,-586.35 2825.59,-575.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2829.08,-575.3 2825,-565.52 2822.09,-575.71 2829.08,-575.3\"/>\n</g>\n<!-- 160 -->\n<g id=\"node161\" class=\"node\">\n<title>160</title>\n<path fill=\"#eca06a\" stroke=\"black\" d=\"M2980.5,-573C2980.5,-573 2902.5,-573 2902.5,-573 2896.5,-573 2890.5,-567 2890.5,-561 2890.5,-561 2890.5,-517 2890.5,-517 2890.5,-511 2896.5,-505 2902.5,-505 2902.5,-505 2980.5,-505 2980.5,-505 2986.5,-505 2992.5,-511 2992.5,-517 2992.5,-517 2992.5,-561 2992.5,-561 2992.5,-567 2986.5,-573 2980.5,-573\"/>\n<text text-anchor=\"start\" x=\"2898.5\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.433</text>\n<text text-anchor=\"start\" x=\"2908\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"2902\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"2901\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 1]</text>\n</g>\n<!-- 158&#45;&gt;160 -->\n<g id=\"edge160\" class=\"edge\">\n<title>158&#45;&gt;160</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2865.86,-608.88C2875.94,-599.71 2886.98,-589.65 2897.44,-580.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2899.9,-582.62 2904.94,-573.3 2895.19,-577.44 2899.9,-582.62\"/>\n</g>\n<!-- 161 -->\n<g id=\"node162\" class=\"node\">\n<title>161</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2921,-461.5C2921,-461.5 2848,-461.5 2848,-461.5 2842,-461.5 2836,-455.5 2836,-449.5 2836,-449.5 2836,-420.5 2836,-420.5 2836,-414.5 2842,-408.5 2848,-408.5 2848,-408.5 2921,-408.5 2921,-408.5 2927,-408.5 2933,-414.5 2933,-420.5 2933,-420.5 2933,-449.5 2933,-449.5 2933,-455.5 2927,-461.5 2921,-461.5\"/>\n<text text-anchor=\"start\" x=\"2855.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2845\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2844\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 160&#45;&gt;161 -->\n<g id=\"edge161\" class=\"edge\">\n<title>160&#45;&gt;161</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2922.99,-504.88C2916.85,-493.89 2909.99,-481.62 2903.79,-470.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2906.69,-468.54 2898.76,-461.52 2900.58,-471.96 2906.69,-468.54\"/>\n</g>\n<!-- 162 -->\n<g id=\"node163\" class=\"node\">\n<title>162</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M3036,-469C3036,-469 2963,-469 2963,-469 2957,-469 2951,-463 2951,-457 2951,-457 2951,-413 2951,-413 2951,-407 2957,-401 2963,-401 2963,-401 3036,-401 3036,-401 3042,-401 3048,-407 3048,-413 3048,-413 3048,-457 3048,-457 3048,-463 3042,-469 3036,-469\"/>\n<text text-anchor=\"start\" x=\"2964.5\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.06</text>\n<text text-anchor=\"start\" x=\"2970.5\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"2960\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2959\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 160&#45;&gt;162 -->\n<g id=\"edge162\" class=\"edge\">\n<title>160&#45;&gt;162</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2960.33,-504.88C2965.19,-496.33 2970.49,-487.01 2975.58,-478.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2978.66,-479.72 2980.57,-469.3 2972.58,-476.26 2978.66,-479.72\"/>\n</g>\n<!-- 163 -->\n<g id=\"node164\" class=\"node\">\n<title>163</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2979,-357.5C2979,-357.5 2906,-357.5 2906,-357.5 2900,-357.5 2894,-351.5 2894,-345.5 2894,-345.5 2894,-316.5 2894,-316.5 2894,-310.5 2900,-304.5 2906,-304.5 2906,-304.5 2979,-304.5 2979,-304.5 2985,-304.5 2991,-310.5 2991,-316.5 2991,-316.5 2991,-345.5 2991,-345.5 2991,-351.5 2985,-357.5 2979,-357.5\"/>\n<text text-anchor=\"start\" x=\"2913.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2903\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2902\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 162&#45;&gt;163 -->\n<g id=\"edge163\" class=\"edge\">\n<title>162&#45;&gt;163</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2980.99,-400.88C2974.85,-389.89 2967.99,-377.62 2961.79,-366.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2964.69,-364.54 2956.76,-357.52 2958.58,-367.96 2964.69,-364.54\"/>\n</g>\n<!-- 164 -->\n<g id=\"node165\" class=\"node\">\n<title>164</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3094,-357.5C3094,-357.5 3021,-357.5 3021,-357.5 3015,-357.5 3009,-351.5 3009,-345.5 3009,-345.5 3009,-316.5 3009,-316.5 3009,-310.5 3015,-304.5 3021,-304.5 3021,-304.5 3094,-304.5 3094,-304.5 3100,-304.5 3106,-310.5 3106,-316.5 3106,-316.5 3106,-345.5 3106,-345.5 3106,-351.5 3100,-357.5 3094,-357.5\"/>\n<text text-anchor=\"start\" x=\"3028.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3018\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3017\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 162&#45;&gt;164 -->\n<g id=\"edge164\" class=\"edge\">\n<title>162&#45;&gt;164</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3018.33,-400.88C3024.58,-389.89 3031.56,-377.62 3037.87,-366.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3041.09,-367.94 3042.99,-357.52 3035,-364.48 3041.09,-367.94\"/>\n</g>\n<!-- 167 -->\n<g id=\"node168\" class=\"node\">\n<title>167</title>\n<path fill=\"#f6d5bd\" stroke=\"black\" d=\"M2926,-989C2926,-989 2847,-989 2847,-989 2841,-989 2835,-983 2835,-977 2835,-977 2835,-933 2835,-933 2835,-927 2841,-921 2847,-921 2847,-921 2926,-921 2926,-921 2932,-921 2938,-927 2938,-933 2938,-933 2938,-977 2938,-977 2938,-983 2932,-989 2926,-989\"/>\n<text text-anchor=\"start\" x=\"2845\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.922</text>\n<text text-anchor=\"start\" x=\"2853\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n<text text-anchor=\"start\" x=\"2843\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"2846\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 4]</text>\n</g>\n<!-- 166&#45;&gt;167 -->\n<g id=\"edge167\" class=\"edge\">\n<title>166&#45;&gt;167</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2926.34,-1024.88C2921.4,-1016.33 2916.01,-1007.01 2910.84,-998.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2913.8,-996.2 2905.76,-989.3 2907.74,-999.71 2913.8,-996.2\"/>\n</g>\n<!-- 176 -->\n<g id=\"node177\" class=\"node\">\n<title>176</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3041,-981.5C3041,-981.5 2968,-981.5 2968,-981.5 2962,-981.5 2956,-975.5 2956,-969.5 2956,-969.5 2956,-940.5 2956,-940.5 2956,-934.5 2962,-928.5 2968,-928.5 2968,-928.5 3041,-928.5 3041,-928.5 3047,-928.5 3053,-934.5 3053,-940.5 3053,-940.5 3053,-969.5 3053,-969.5 3053,-975.5 3047,-981.5 3041,-981.5\"/>\n<text text-anchor=\"start\" x=\"2975.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2965\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2964\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 166&#45;&gt;176 -->\n<g id=\"edge176\" class=\"edge\">\n<title>166&#45;&gt;176</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2964.66,-1024.88C2971.08,-1013.78 2978.26,-1001.37 2984.73,-990.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2987.76,-991.93 2989.74,-981.52 2981.7,-988.42 2987.76,-991.93\"/>\n</g>\n<!-- 168 -->\n<g id=\"node169\" class=\"node\">\n<title>168</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2866,-877.5C2866,-877.5 2793,-877.5 2793,-877.5 2787,-877.5 2781,-871.5 2781,-865.5 2781,-865.5 2781,-836.5 2781,-836.5 2781,-830.5 2787,-824.5 2793,-824.5 2793,-824.5 2866,-824.5 2866,-824.5 2872,-824.5 2878,-830.5 2878,-836.5 2878,-836.5 2878,-865.5 2878,-865.5 2878,-871.5 2872,-877.5 2866,-877.5\"/>\n<text text-anchor=\"start\" x=\"2800.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2790\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2789\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 167&#45;&gt;168 -->\n<g id=\"edge168\" class=\"edge\">\n<title>167&#45;&gt;168</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2867.99,-920.88C2861.85,-909.89 2854.99,-897.62 2848.79,-886.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2851.69,-884.54 2843.76,-877.52 2845.58,-887.96 2851.69,-884.54\"/>\n</g>\n<!-- 169 -->\n<g id=\"node170\" class=\"node\">\n<title>169</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M2981,-885C2981,-885 2908,-885 2908,-885 2902,-885 2896,-879 2896,-873 2896,-873 2896,-829 2896,-829 2896,-823 2902,-817 2908,-817 2908,-817 2981,-817 2981,-817 2987,-817 2993,-823 2993,-829 2993,-829 2993,-873 2993,-873 2993,-879 2987,-885 2981,-885\"/>\n<text text-anchor=\"start\" x=\"2907\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.62</text>\n<text text-anchor=\"start\" x=\"2915.5\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"2905\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"2904\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 4]</text>\n</g>\n<!-- 167&#45;&gt;169 -->\n<g id=\"edge169\" class=\"edge\">\n<title>167&#45;&gt;169</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2905.33,-920.88C2910.19,-912.33 2915.49,-903.01 2920.58,-894.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2923.66,-895.72 2925.57,-885.3 2917.58,-892.26 2923.66,-895.72\"/>\n</g>\n<!-- 170 -->\n<g id=\"node171\" class=\"node\">\n<title>170</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2980,-773.5C2980,-773.5 2907,-773.5 2907,-773.5 2901,-773.5 2895,-767.5 2895,-761.5 2895,-761.5 2895,-732.5 2895,-732.5 2895,-726.5 2901,-720.5 2907,-720.5 2907,-720.5 2980,-720.5 2980,-720.5 2986,-720.5 2992,-726.5 2992,-732.5 2992,-732.5 2992,-761.5 2992,-761.5 2992,-767.5 2986,-773.5 2980,-773.5\"/>\n<text text-anchor=\"start\" x=\"2914.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2904\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2903\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 169&#45;&gt;170 -->\n<g id=\"edge170\" class=\"edge\">\n<title>169&#45;&gt;170</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2944.18,-816.88C2944.07,-806.33 2943.96,-794.6 2943.85,-783.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2947.35,-783.49 2943.75,-773.52 2940.35,-783.55 2947.35,-783.49\"/>\n</g>\n<!-- 171 -->\n<g id=\"node172\" class=\"node\">\n<title>171</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M3097,-781C3097,-781 3022,-781 3022,-781 3016,-781 3010,-775 3010,-769 3010,-769 3010,-725 3010,-725 3010,-719 3016,-713 3022,-713 3022,-713 3097,-713 3097,-713 3103,-713 3109,-719 3109,-725 3109,-725 3109,-769 3109,-769 3109,-775 3103,-781 3097,-781\"/>\n<text text-anchor=\"start\" x=\"3018\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.072</text>\n<text text-anchor=\"start\" x=\"3022\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"3020\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"3019\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 2]</text>\n</g>\n<!-- 169&#45;&gt;171 -->\n<g id=\"edge171\" class=\"edge\">\n<title>169&#45;&gt;171</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2981.84,-816.88C2992.18,-807.71 3003.52,-797.65 3014.26,-788.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3016.8,-790.55 3021.96,-781.3 3012.15,-785.32 3016.8,-790.55\"/>\n</g>\n<!-- 172 -->\n<g id=\"node173\" class=\"node\">\n<title>172</title>\n<path fill=\"#eca06a\" stroke=\"black\" d=\"M3097.5,-677C3097.5,-677 3019.5,-677 3019.5,-677 3013.5,-677 3007.5,-671 3007.5,-665 3007.5,-665 3007.5,-621 3007.5,-621 3007.5,-615 3013.5,-609 3019.5,-609 3019.5,-609 3097.5,-609 3097.5,-609 3103.5,-609 3109.5,-615 3109.5,-621 3109.5,-621 3109.5,-665 3109.5,-665 3109.5,-671 3103.5,-677 3097.5,-677\"/>\n<text text-anchor=\"start\" x=\"3015.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.081</text>\n<text text-anchor=\"start\" x=\"3025\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"3019\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"3018\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 1]</text>\n</g>\n<!-- 171&#45;&gt;172 -->\n<g id=\"edge172\" class=\"edge\">\n<title>171&#45;&gt;172</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3059.18,-712.88C3059.1,-704.78 3059.01,-695.98 3058.93,-687.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3062.42,-687.26 3058.83,-677.3 3055.42,-687.33 3062.42,-687.26\"/>\n</g>\n<!-- 175 -->\n<g id=\"node176\" class=\"node\">\n<title>175</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3213,-669.5C3213,-669.5 3140,-669.5 3140,-669.5 3134,-669.5 3128,-663.5 3128,-657.5 3128,-657.5 3128,-628.5 3128,-628.5 3128,-622.5 3134,-616.5 3140,-616.5 3140,-616.5 3213,-616.5 3213,-616.5 3219,-616.5 3225,-622.5 3225,-628.5 3225,-628.5 3225,-657.5 3225,-657.5 3225,-663.5 3219,-669.5 3213,-669.5\"/>\n<text text-anchor=\"start\" x=\"3147.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3137\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3136\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 171&#45;&gt;175 -->\n<g id=\"edge175\" class=\"edge\">\n<title>171&#45;&gt;175</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3097.49,-712.88C3110.98,-701.12 3126.15,-687.89 3139.56,-676.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3141.99,-678.73 3147.23,-669.52 3137.39,-673.45 3141.99,-678.73\"/>\n</g>\n<!-- 173 -->\n<g id=\"node174\" class=\"node\">\n<title>173</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3096,-565.5C3096,-565.5 3023,-565.5 3023,-565.5 3017,-565.5 3011,-559.5 3011,-553.5 3011,-553.5 3011,-524.5 3011,-524.5 3011,-518.5 3017,-512.5 3023,-512.5 3023,-512.5 3096,-512.5 3096,-512.5 3102,-512.5 3108,-518.5 3108,-524.5 3108,-524.5 3108,-553.5 3108,-553.5 3108,-559.5 3102,-565.5 3096,-565.5\"/>\n<text text-anchor=\"start\" x=\"3030.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3020\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"3019\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 0]</text>\n</g>\n<!-- 172&#45;&gt;173 -->\n<g id=\"edge173\" class=\"edge\">\n<title>172&#45;&gt;173</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3058.82,-608.88C3058.93,-598.33 3059.04,-586.6 3059.15,-575.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3062.65,-575.55 3059.25,-565.52 3055.65,-575.49 3062.65,-575.55\"/>\n</g>\n<!-- 174 -->\n<g id=\"node175\" class=\"node\">\n<title>174</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3211,-565.5C3211,-565.5 3138,-565.5 3138,-565.5 3132,-565.5 3126,-559.5 3126,-553.5 3126,-553.5 3126,-524.5 3126,-524.5 3126,-518.5 3132,-512.5 3138,-512.5 3138,-512.5 3211,-512.5 3211,-512.5 3217,-512.5 3223,-518.5 3223,-524.5 3223,-524.5 3223,-553.5 3223,-553.5 3223,-559.5 3217,-565.5 3211,-565.5\"/>\n<text text-anchor=\"start\" x=\"3145.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3135\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3134\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 172&#45;&gt;174 -->\n<g id=\"edge174\" class=\"edge\">\n<title>172&#45;&gt;174</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3096.16,-608.88C3109.54,-597.12 3124.58,-583.89 3137.88,-572.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3140.28,-574.75 3145.48,-565.52 3135.66,-569.49 3140.28,-574.75\"/>\n</g>\n<!-- 179 -->\n<g id=\"node180\" class=\"node\">\n<title>179</title>\n<path fill=\"#e6853f\" stroke=\"black\" d=\"M3524,-1197C3524,-1197 3443,-1197 3443,-1197 3437,-1197 3431,-1191 3431,-1185 3431,-1185 3431,-1141 3431,-1141 3431,-1135 3437,-1129 3443,-1129 3443,-1129 3524,-1129 3524,-1129 3530,-1129 3536,-1135 3536,-1141 3536,-1141 3536,-1185 3536,-1185 3536,-1191 3530,-1197 3524,-1197\"/>\n<text text-anchor=\"start\" x=\"3444\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.225</text>\n<text text-anchor=\"start\" x=\"3446\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.056</text>\n<text text-anchor=\"start\" x=\"3440\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 69</text>\n<text text-anchor=\"start\" x=\"3439\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [67, 2]</text>\n</g>\n<!-- 178&#45;&gt;179 -->\n<g id=\"edge179\" class=\"edge\">\n<title>178&#45;&gt;179</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3483.5,-1232.88C3483.5,-1224.78 3483.5,-1215.98 3483.5,-1207.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3487,-1207.3 3483.5,-1197.3 3480,-1207.3 3487,-1207.3\"/>\n</g>\n<!-- 192 -->\n<g id=\"node193\" class=\"node\">\n<title>192</title>\n<path fill=\"#e88f4f\" stroke=\"black\" d=\"M3681,-1197C3681,-1197 3600,-1197 3600,-1197 3594,-1197 3588,-1191 3588,-1185 3588,-1185 3588,-1141 3588,-1141 3588,-1135 3594,-1129 3600,-1129 3600,-1129 3681,-1129 3681,-1129 3687,-1129 3693,-1135 3693,-1141 3693,-1141 3693,-1185 3693,-1185 3693,-1191 3687,-1197 3681,-1197\"/>\n<text text-anchor=\"start\" x=\"3597.5\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.789</text>\n<text text-anchor=\"start\" x=\"3603\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.182</text>\n<text text-anchor=\"start\" x=\"3597\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 69</text>\n<text text-anchor=\"start\" x=\"3596\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [62, 7]</text>\n</g>\n<!-- 178&#45;&gt;192 -->\n<g id=\"edge192\" class=\"edge\">\n<title>178&#45;&gt;192</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3534.47,-1232.88C3549.36,-1223.21 3565.75,-1212.56 3581.11,-1202.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3583.04,-1205.51 3589.51,-1197.12 3579.22,-1199.64 3583.04,-1205.51\"/>\n</g>\n<!-- 180 -->\n<g id=\"node181\" class=\"node\">\n<title>180</title>\n<path fill=\"#e68743\" stroke=\"black\" d=\"M3420,-1093C3420,-1093 3307,-1093 3307,-1093 3301,-1093 3295,-1087 3295,-1081 3295,-1081 3295,-1037 3295,-1037 3295,-1031 3301,-1025 3307,-1025 3307,-1025 3420,-1025 3420,-1025 3426,-1025 3432,-1031 3432,-1037 3432,-1037 3432,-1081 3432,-1081 3432,-1087 3426,-1093 3420,-1093\"/>\n<text text-anchor=\"start\" x=\"3303\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Embarked_Q ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"3326\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.091</text>\n<text text-anchor=\"start\" x=\"3320\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 42</text>\n<text text-anchor=\"start\" x=\"3319\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [40, 2]</text>\n</g>\n<!-- 179&#45;&gt;180 -->\n<g id=\"edge180\" class=\"edge\">\n<title>179&#45;&gt;180</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3444.54,-1128.88C3433.64,-1119.62 3421.68,-1109.45 3410.38,-1099.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3412.56,-1097.11 3402.68,-1093.3 3408.03,-1102.44 3412.56,-1097.11\"/>\n</g>\n<!-- 191 -->\n<g id=\"node192\" class=\"node\">\n<title>191</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3543,-1085.5C3543,-1085.5 3462,-1085.5 3462,-1085.5 3456,-1085.5 3450,-1079.5 3450,-1073.5 3450,-1073.5 3450,-1044.5 3450,-1044.5 3450,-1038.5 3456,-1032.5 3462,-1032.5 3462,-1032.5 3543,-1032.5 3543,-1032.5 3549,-1032.5 3555,-1038.5 3555,-1044.5 3555,-1044.5 3555,-1073.5 3555,-1073.5 3555,-1079.5 3549,-1085.5 3543,-1085.5\"/>\n<text text-anchor=\"start\" x=\"3473.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3459\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 27</text>\n<text text-anchor=\"start\" x=\"3458\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [27, 0]</text>\n</g>\n<!-- 179&#45;&gt;191 -->\n<g id=\"edge191\" class=\"edge\">\n<title>179&#45;&gt;191</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3489.67,-1128.88C3491.66,-1118.22 3493.87,-1106.35 3495.88,-1095.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3499.36,-1095.99 3497.75,-1085.52 3492.47,-1094.71 3499.36,-1095.99\"/>\n</g>\n<!-- 181 -->\n<g id=\"node182\" class=\"node\">\n<title>181</title>\n<path fill=\"#e78a47\" stroke=\"black\" d=\"M3330,-989C3330,-989 3249,-989 3249,-989 3243,-989 3237,-983 3237,-977 3237,-977 3237,-933 3237,-933 3237,-927 3243,-921 3249,-921 3249,-921 3330,-921 3330,-921 3336,-921 3342,-927 3342,-933 3342,-933 3342,-977 3342,-977 3342,-983 3336,-989 3330,-989\"/>\n<text text-anchor=\"start\" x=\"3246.5\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.807</text>\n<text text-anchor=\"start\" x=\"3252\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.124</text>\n<text text-anchor=\"start\" x=\"3246\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30</text>\n<text text-anchor=\"start\" x=\"3245\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [28, 2]</text>\n</g>\n<!-- 180&#45;&gt;181 -->\n<g id=\"edge181\" class=\"edge\">\n<title>180&#45;&gt;181</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3339.47,-1024.88C3333.14,-1016.15 3326.23,-1006.62 3319.62,-997.51\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3322.36,-995.34 3313.66,-989.3 3316.7,-999.45 3322.36,-995.34\"/>\n</g>\n<!-- 190 -->\n<g id=\"node191\" class=\"node\">\n<title>190</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3453,-981.5C3453,-981.5 3372,-981.5 3372,-981.5 3366,-981.5 3360,-975.5 3360,-969.5 3360,-969.5 3360,-940.5 3360,-940.5 3360,-934.5 3366,-928.5 3372,-928.5 3372,-928.5 3453,-928.5 3453,-928.5 3459,-928.5 3465,-934.5 3465,-940.5 3465,-940.5 3465,-969.5 3465,-969.5 3465,-975.5 3459,-981.5 3453,-981.5\"/>\n<text text-anchor=\"start\" x=\"3383.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3369\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\n<text text-anchor=\"start\" x=\"3368\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [12, 0]</text>\n</g>\n<!-- 180&#45;&gt;190 -->\n<g id=\"edge190\" class=\"edge\">\n<title>180&#45;&gt;190</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3379.41,-1024.88C3384.64,-1014 3390.47,-1001.86 3395.76,-990.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3399.07,-992.05 3400.24,-981.52 3392.76,-989.02 3399.07,-992.05\"/>\n</g>\n<!-- 182 -->\n<g id=\"node183\" class=\"node\">\n<title>182</title>\n<path fill=\"#e89050\" stroke=\"black\" d=\"M3330,-885C3330,-885 3249,-885 3249,-885 3243,-885 3237,-879 3237,-873 3237,-873 3237,-829 3237,-829 3237,-823 3243,-817 3249,-817 3249,-817 3330,-817 3330,-817 3336,-817 3342,-823 3342,-829 3342,-829 3342,-873 3342,-873 3342,-879 3336,-885 3330,-885\"/>\n<text text-anchor=\"start\" x=\"3246.5\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.827</text>\n<text text-anchor=\"start\" x=\"3252\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.188</text>\n<text text-anchor=\"start\" x=\"3246\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\n<text text-anchor=\"start\" x=\"3245\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 2]</text>\n</g>\n<!-- 181&#45;&gt;182 -->\n<g id=\"edge182\" class=\"edge\">\n<title>181&#45;&gt;182</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3289.5,-920.88C3289.5,-912.78 3289.5,-903.98 3289.5,-895.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3293,-895.3 3289.5,-885.3 3286,-895.3 3293,-895.3\"/>\n</g>\n<!-- 189 -->\n<g id=\"node190\" class=\"node\">\n<title>189</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3453,-877.5C3453,-877.5 3372,-877.5 3372,-877.5 3366,-877.5 3360,-871.5 3360,-865.5 3360,-865.5 3360,-836.5 3360,-836.5 3360,-830.5 3366,-824.5 3372,-824.5 3372,-824.5 3453,-824.5 3453,-824.5 3459,-824.5 3465,-830.5 3465,-836.5 3465,-836.5 3465,-865.5 3465,-865.5 3465,-871.5 3459,-877.5 3453,-877.5\"/>\n<text text-anchor=\"start\" x=\"3383.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3369\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"start\" x=\"3368\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 0]</text>\n</g>\n<!-- 181&#45;&gt;189 -->\n<g id=\"edge189\" class=\"edge\">\n<title>181&#45;&gt;189</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3329.43,-920.88C3343.63,-909.12 3359.57,-895.89 3373.67,-884.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3376.26,-886.6 3381.73,-877.52 3371.79,-881.21 3376.26,-886.6\"/>\n</g>\n<!-- 183 -->\n<g id=\"node184\" class=\"node\">\n<title>183</title>\n<path fill=\"#e78845\" stroke=\"black\" d=\"M3346,-781C3346,-781 3235,-781 3235,-781 3229,-781 3223,-775 3223,-769 3223,-769 3223,-725 3223,-725 3223,-719 3229,-713 3235,-713 3235,-713 3346,-713 3346,-713 3352,-713 3358,-719 3358,-725 3358,-725 3358,-769 3358,-769 3358,-775 3352,-781 3346,-781\"/>\n<text text-anchor=\"start\" x=\"3231\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Embarked_S ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"3253\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.105</text>\n<text text-anchor=\"start\" x=\"3247\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n<text text-anchor=\"start\" x=\"3246\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 1]</text>\n</g>\n<!-- 182&#45;&gt;183 -->\n<g id=\"edge183\" class=\"edge\">\n<title>182&#45;&gt;183</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3289.82,-816.88C3289.9,-808.78 3289.99,-799.98 3290.07,-791.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3293.58,-791.33 3290.17,-781.3 3286.58,-791.26 3293.58,-791.33\"/>\n</g>\n<!-- 188 -->\n<g id=\"node189\" class=\"node\">\n<title>188</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3461,-773.5C3461,-773.5 3388,-773.5 3388,-773.5 3382,-773.5 3376,-767.5 3376,-761.5 3376,-761.5 3376,-732.5 3376,-732.5 3376,-726.5 3382,-720.5 3388,-720.5 3388,-720.5 3461,-720.5 3461,-720.5 3467,-720.5 3473,-726.5 3473,-732.5 3473,-732.5 3473,-761.5 3473,-761.5 3473,-767.5 3467,-773.5 3461,-773.5\"/>\n<text text-anchor=\"start\" x=\"3395.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3385\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3384\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 182&#45;&gt;188 -->\n<g id=\"edge188\" class=\"edge\">\n<title>182&#45;&gt;188</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3333.33,-816.88C3349.2,-804.9 3367.06,-791.4 3382.74,-779.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3384.85,-782.34 3390.72,-773.52 3380.63,-776.76 3384.85,-782.34\"/>\n</g>\n<!-- 184 -->\n<g id=\"node185\" class=\"node\">\n<title>184</title>\n<path fill=\"#e99355\" stroke=\"black\" d=\"M3328,-677C3328,-677 3255,-677 3255,-677 3249,-677 3243,-671 3243,-665 3243,-665 3243,-621 3243,-621 3243,-615 3249,-609 3255,-609 3255,-609 3328,-609 3328,-609 3334,-609 3340,-615 3340,-621 3340,-621 3340,-665 3340,-665 3340,-671 3334,-677 3328,-677\"/>\n<text text-anchor=\"start\" x=\"3252.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.88</text>\n<text text-anchor=\"start\" x=\"3254\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.219</text>\n<text text-anchor=\"start\" x=\"3252\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"3251\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 1]</text>\n</g>\n<!-- 183&#45;&gt;184 -->\n<g id=\"edge184\" class=\"edge\">\n<title>183&#45;&gt;184</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3290.82,-712.88C3290.9,-704.78 3290.99,-695.98 3291.07,-687.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3294.58,-687.33 3291.17,-677.3 3287.58,-687.26 3294.58,-687.33\"/>\n</g>\n<!-- 187 -->\n<g id=\"node188\" class=\"node\">\n<title>187</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3451,-669.5C3451,-669.5 3370,-669.5 3370,-669.5 3364,-669.5 3358,-663.5 3358,-657.5 3358,-657.5 3358,-628.5 3358,-628.5 3358,-622.5 3364,-616.5 3370,-616.5 3370,-616.5 3451,-616.5 3451,-616.5 3457,-616.5 3463,-622.5 3463,-628.5 3463,-628.5 3463,-657.5 3463,-657.5 3463,-663.5 3457,-669.5 3451,-669.5\"/>\n<text text-anchor=\"start\" x=\"3381.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3367\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"3366\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [10, 0]</text>\n</g>\n<!-- 183&#45;&gt;187 -->\n<g id=\"edge187\" class=\"edge\">\n<title>183&#45;&gt;187</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3329.46,-712.88C3343.3,-701.12 3358.86,-687.89 3372.61,-676.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3375.12,-678.66 3380.48,-669.52 3370.59,-673.33 3375.12,-678.66\"/>\n</g>\n<!-- 185 -->\n<g id=\"node186\" class=\"node\">\n<title>185</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3327,-565.5C3327,-565.5 3254,-565.5 3254,-565.5 3248,-565.5 3242,-559.5 3242,-553.5 3242,-553.5 3242,-524.5 3242,-524.5 3242,-518.5 3248,-512.5 3254,-512.5 3254,-512.5 3327,-512.5 3327,-512.5 3333,-512.5 3339,-518.5 3339,-524.5 3339,-524.5 3339,-553.5 3339,-553.5 3339,-559.5 3333,-565.5 3327,-565.5\"/>\n<text text-anchor=\"start\" x=\"3261.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3251\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"3250\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 184&#45;&gt;185 -->\n<g id=\"edge185\" class=\"edge\">\n<title>184&#45;&gt;185</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3291.18,-608.88C3291.07,-598.33 3290.96,-586.6 3290.85,-575.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3294.35,-575.49 3290.75,-565.52 3287.35,-575.55 3294.35,-575.49\"/>\n</g>\n<!-- 186 -->\n<g id=\"node187\" class=\"node\">\n<title>186</title>\n<path fill=\"#eca06a\" stroke=\"black\" d=\"M3442,-565.5C3442,-565.5 3369,-565.5 3369,-565.5 3363,-565.5 3357,-559.5 3357,-553.5 3357,-553.5 3357,-524.5 3357,-524.5 3357,-518.5 3363,-512.5 3369,-512.5 3369,-512.5 3442,-512.5 3442,-512.5 3448,-512.5 3454,-518.5 3454,-524.5 3454,-524.5 3454,-553.5 3454,-553.5 3454,-559.5 3448,-565.5 3442,-565.5\"/>\n<text text-anchor=\"start\" x=\"3372\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"3366\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"3365\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 1]</text>\n</g>\n<!-- 184&#45;&gt;186 -->\n<g id=\"edge186\" class=\"edge\">\n<title>184&#45;&gt;186</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3328.51,-608.88C3341.66,-597.12 3356.44,-583.89 3369.51,-572.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3371.86,-574.8 3376.98,-565.52 3367.19,-569.58 3371.86,-574.8\"/>\n</g>\n<!-- 193 -->\n<g id=\"node194\" class=\"node\">\n<title>193</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M3677,-1093C3677,-1093 3604,-1093 3604,-1093 3598,-1093 3592,-1087 3592,-1081 3592,-1081 3592,-1037 3592,-1037 3592,-1031 3598,-1025 3604,-1025 3604,-1025 3677,-1025 3677,-1025 3683,-1025 3689,-1031 3689,-1037 3689,-1037 3689,-1081 3689,-1081 3689,-1087 3683,-1093 3677,-1093\"/>\n<text text-anchor=\"start\" x=\"3601\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.626</text>\n<text text-anchor=\"start\" x=\"3603\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"3601\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"3600\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 192&#45;&gt;193 -->\n<g id=\"edge193\" class=\"edge\">\n<title>192&#45;&gt;193</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3640.5,-1128.88C3640.5,-1120.78 3640.5,-1111.98 3640.5,-1103.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3644,-1103.3 3640.5,-1093.3 3637,-1103.3 3644,-1103.3\"/>\n</g>\n<!-- 196 -->\n<g id=\"node197\" class=\"node\">\n<title>196</title>\n<path fill=\"#e78b49\" stroke=\"black\" d=\"M3805,-1093C3805,-1093 3724,-1093 3724,-1093 3718,-1093 3712,-1087 3712,-1081 3712,-1081 3712,-1037 3712,-1037 3712,-1031 3718,-1025 3724,-1025 3724,-1025 3805,-1025 3805,-1025 3811,-1025 3817,-1031 3817,-1037 3817,-1037 3817,-1081 3817,-1081 3817,-1087 3811,-1093 3805,-1093\"/>\n<text text-anchor=\"start\" x=\"3721.5\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.261</text>\n<text text-anchor=\"start\" x=\"3731\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.14</text>\n<text text-anchor=\"start\" x=\"3721\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 66</text>\n<text text-anchor=\"start\" x=\"3720\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [61, 5]</text>\n</g>\n<!-- 192&#45;&gt;196 -->\n<g id=\"edge196\" class=\"edge\">\n<title>192&#45;&gt;196</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3680.76,-1128.88C3692.02,-1119.62 3704.38,-1109.45 3716.06,-1099.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3718.52,-1102.36 3724.02,-1093.3 3714.07,-1096.95 3718.52,-1102.36\"/>\n</g>\n<!-- 194 -->\n<g id=\"node195\" class=\"node\">\n<title>194</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3568,-981.5C3568,-981.5 3495,-981.5 3495,-981.5 3489,-981.5 3483,-975.5 3483,-969.5 3483,-969.5 3483,-940.5 3483,-940.5 3483,-934.5 3489,-928.5 3495,-928.5 3495,-928.5 3568,-928.5 3568,-928.5 3574,-928.5 3580,-934.5 3580,-940.5 3580,-940.5 3580,-969.5 3580,-969.5 3580,-975.5 3574,-981.5 3568,-981.5\"/>\n<text text-anchor=\"start\" x=\"3502.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3492\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3491\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 193&#45;&gt;194 -->\n<g id=\"edge194\" class=\"edge\">\n<title>193&#45;&gt;194</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3605.11,-1024.88C3592.65,-1013.23 3578.67,-1000.14 3566.26,-988.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3568.46,-985.8 3558.77,-981.52 3563.68,-990.91 3568.46,-985.8\"/>\n</g>\n<!-- 195 -->\n<g id=\"node196\" class=\"node\">\n<title>195</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3683,-981.5C3683,-981.5 3610,-981.5 3610,-981.5 3604,-981.5 3598,-975.5 3598,-969.5 3598,-969.5 3598,-940.5 3598,-940.5 3598,-934.5 3604,-928.5 3610,-928.5 3610,-928.5 3683,-928.5 3683,-928.5 3689,-928.5 3695,-934.5 3695,-940.5 3695,-940.5 3695,-969.5 3695,-969.5 3695,-975.5 3689,-981.5 3683,-981.5\"/>\n<text text-anchor=\"start\" x=\"3617.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3607\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"3606\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 193&#45;&gt;195 -->\n<g id=\"edge195\" class=\"edge\">\n<title>193&#45;&gt;195</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3642.45,-1024.88C3643.08,-1014.22 3643.77,-1002.35 3644.41,-991.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3647.91,-991.71 3645,-981.52 3640.92,-991.3 3647.91,-991.71\"/>\n</g>\n<!-- 197 -->\n<g id=\"node198\" class=\"node\">\n<title>197</title>\n<path fill=\"#e99559\" stroke=\"black\" d=\"M3806,-989C3806,-989 3725,-989 3725,-989 3719,-989 3713,-983 3713,-977 3713,-977 3713,-933 3713,-933 3713,-927 3719,-921 3725,-921 3725,-921 3806,-921 3806,-921 3812,-921 3818,-927 3818,-933 3818,-933 3818,-977 3818,-977 3818,-983 3812,-989 3806,-989\"/>\n<text text-anchor=\"start\" x=\"3730.5\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.3</text>\n<text text-anchor=\"start\" x=\"3728\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.239</text>\n<text text-anchor=\"start\" x=\"3722\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 36</text>\n<text text-anchor=\"start\" x=\"3721\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 5]</text>\n</g>\n<!-- 196&#45;&gt;197 -->\n<g id=\"edge197\" class=\"edge\">\n<title>196&#45;&gt;197</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3764.82,-1024.88C3764.9,-1016.78 3764.99,-1007.98 3765.07,-999.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3768.58,-999.33 3765.17,-989.3 3761.58,-999.26 3768.58,-999.33\"/>\n</g>\n<!-- 216 -->\n<g id=\"node217\" class=\"node\">\n<title>216</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3929,-981.5C3929,-981.5 3848,-981.5 3848,-981.5 3842,-981.5 3836,-975.5 3836,-969.5 3836,-969.5 3836,-940.5 3836,-940.5 3836,-934.5 3842,-928.5 3848,-928.5 3848,-928.5 3929,-928.5 3929,-928.5 3935,-928.5 3941,-934.5 3941,-940.5 3941,-940.5 3941,-969.5 3941,-969.5 3941,-975.5 3935,-981.5 3929,-981.5\"/>\n<text text-anchor=\"start\" x=\"3859.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3845\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30</text>\n<text text-anchor=\"start\" x=\"3844\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [30, 0]</text>\n</g>\n<!-- 196&#45;&gt;216 -->\n<g id=\"edge216\" class=\"edge\">\n<title>196&#45;&gt;216</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3804.76,-1024.88C3819.2,-1013.01 3835.44,-999.65 3849.75,-987.88\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3851.98,-990.58 3857.48,-981.52 3847.53,-985.17 3851.98,-990.58\"/>\n</g>\n<!-- 198 -->\n<g id=\"node199\" class=\"node\">\n<title>198</title>\n<path fill=\"#e89153\" stroke=\"black\" d=\"M3770,-885C3770,-885 3689,-885 3689,-885 3683,-885 3677,-879 3677,-873 3677,-873 3677,-829 3677,-829 3677,-823 3683,-817 3689,-817 3689,-817 3770,-817 3770,-817 3776,-817 3782,-823 3782,-829 3782,-829 3782,-873 3782,-873 3782,-879 3776,-885 3770,-885\"/>\n<text text-anchor=\"start\" x=\"3686.5\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.358</text>\n<text text-anchor=\"start\" x=\"3692\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.202</text>\n<text text-anchor=\"start\" x=\"3686\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 35</text>\n<text text-anchor=\"start\" x=\"3685\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 4]</text>\n</g>\n<!-- 197&#45;&gt;198 -->\n<g id=\"edge198\" class=\"edge\">\n<title>197&#45;&gt;198</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3753.81,-920.88C3750.89,-912.6 3747.71,-903.6 3744.65,-894.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3747.88,-893.56 3741.25,-885.3 3741.28,-895.89 3747.88,-893.56\"/>\n</g>\n<!-- 215 -->\n<g id=\"node216\" class=\"node\">\n<title>215</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3885,-877.5C3885,-877.5 3812,-877.5 3812,-877.5 3806,-877.5 3800,-871.5 3800,-865.5 3800,-865.5 3800,-836.5 3800,-836.5 3800,-830.5 3806,-824.5 3812,-824.5 3812,-824.5 3885,-824.5 3885,-824.5 3891,-824.5 3897,-830.5 3897,-836.5 3897,-836.5 3897,-865.5 3897,-865.5 3897,-871.5 3891,-877.5 3885,-877.5\"/>\n<text text-anchor=\"start\" x=\"3819.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3809\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3808\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 197&#45;&gt;215 -->\n<g id=\"edge215\" class=\"edge\">\n<title>197&#45;&gt;215</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3792.45,-920.88C3801.67,-909.56 3811.98,-896.88 3821.22,-885.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3824.14,-887.49 3827.73,-877.52 3818.71,-883.07 3824.14,-887.49\"/>\n</g>\n<!-- 199 -->\n<g id=\"node200\" class=\"node\">\n<title>199</title>\n<path fill=\"#e78b49\" stroke=\"black\" d=\"M3735,-781C3735,-781 3654,-781 3654,-781 3648,-781 3642,-775 3642,-769 3642,-769 3642,-725 3642,-725 3642,-719 3648,-713 3654,-713 3654,-713 3735,-713 3735,-713 3741,-713 3747,-719 3747,-725 3747,-725 3747,-769 3747,-769 3747,-775 3741,-781 3735,-781\"/>\n<text text-anchor=\"start\" x=\"3651.5\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.745</text>\n<text text-anchor=\"start\" x=\"3657\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.137</text>\n<text text-anchor=\"start\" x=\"3651\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 27</text>\n<text text-anchor=\"start\" x=\"3650\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [25, 2]</text>\n</g>\n<!-- 198&#45;&gt;199 -->\n<g id=\"edge199\" class=\"edge\">\n<title>198&#45;&gt;199</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3718.14,-816.88C3715.29,-808.6 3712.2,-799.6 3709.22,-790.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3712.48,-789.62 3705.93,-781.3 3705.86,-791.89 3712.48,-789.62\"/>\n</g>\n<!-- 208 -->\n<g id=\"node209\" class=\"node\">\n<title>208</title>\n<path fill=\"#eeab7b\" stroke=\"black\" d=\"M3850,-781C3850,-781 3777,-781 3777,-781 3771,-781 3765,-775 3765,-769 3765,-769 3765,-725 3765,-725 3765,-719 3771,-713 3777,-713 3777,-713 3850,-713 3850,-713 3856,-713 3862,-719 3862,-725 3862,-725 3862,-769 3862,-769 3862,-775 3856,-781 3850,-781\"/>\n<text text-anchor=\"start\" x=\"3774\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.263</text>\n<text text-anchor=\"start\" x=\"3776\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"3774\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"3773\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 2]</text>\n</g>\n<!-- 198&#45;&gt;208 -->\n<g id=\"edge208\" class=\"edge\">\n<title>198&#45;&gt;208</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3756.77,-816.88C3764.03,-808.07 3771.97,-798.43 3779.54,-789.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3782.42,-791.24 3786.08,-781.3 3777.02,-786.79 3782.42,-791.24\"/>\n</g>\n<!-- 200 -->\n<g id=\"node201\" class=\"node\">\n<title>200</title>\n<path fill=\"#e99355\" stroke=\"black\" d=\"M3612,-677C3612,-677 3531,-677 3531,-677 3525,-677 3519,-671 3519,-665 3519,-665 3519,-621 3519,-621 3519,-615 3525,-609 3531,-609 3531,-609 3612,-609 3612,-609 3618,-609 3624,-615 3624,-621 3624,-621 3624,-665 3624,-665 3624,-671 3618,-677 3612,-677\"/>\n<text text-anchor=\"start\" x=\"3528.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.778</text>\n<text text-anchor=\"start\" x=\"3534\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.219</text>\n<text text-anchor=\"start\" x=\"3528\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"start\" x=\"3527\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [14, 2]</text>\n</g>\n<!-- 199&#45;&gt;200 -->\n<g id=\"edge200\" class=\"edge\">\n<title>199&#45;&gt;200</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3654.57,-712.88C3643.39,-703.62 3631.14,-693.45 3619.55,-683.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3621.59,-680.99 3611.66,-677.3 3617.12,-686.38 3621.59,-680.99\"/>\n</g>\n<!-- 207 -->\n<g id=\"node208\" class=\"node\">\n<title>207</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3735,-669.5C3735,-669.5 3654,-669.5 3654,-669.5 3648,-669.5 3642,-663.5 3642,-657.5 3642,-657.5 3642,-628.5 3642,-628.5 3642,-622.5 3648,-616.5 3654,-616.5 3654,-616.5 3735,-616.5 3735,-616.5 3741,-616.5 3747,-622.5 3747,-628.5 3747,-628.5 3747,-657.5 3747,-657.5 3747,-663.5 3741,-669.5 3735,-669.5\"/>\n<text text-anchor=\"start\" x=\"3665.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3651\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"start\" x=\"3650\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 0]</text>\n</g>\n<!-- 199&#45;&gt;207 -->\n<g id=\"edge207\" class=\"edge\">\n<title>199&#45;&gt;207</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3694.5,-712.88C3694.5,-702.33 3694.5,-690.6 3694.5,-679.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3698,-679.52 3694.5,-669.52 3691,-679.52 3698,-679.52\"/>\n</g>\n<!-- 201 -->\n<g id=\"node202\" class=\"node\">\n<title>201</title>\n<path fill=\"#e78a47\" stroke=\"black\" d=\"M3569,-573C3569,-573 3488,-573 3488,-573 3482,-573 3476,-567 3476,-561 3476,-561 3476,-517 3476,-517 3476,-511 3482,-505 3488,-505 3488,-505 3569,-505 3569,-505 3575,-505 3581,-511 3581,-517 3581,-517 3581,-561 3581,-561 3581,-567 3575,-573 3569,-573\"/>\n<text text-anchor=\"start\" x=\"3489\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 1.117</text>\n<text text-anchor=\"start\" x=\"3491\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.124</text>\n<text text-anchor=\"start\" x=\"3485\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\n<text text-anchor=\"start\" x=\"3484\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [14, 1]</text>\n</g>\n<!-- 200&#45;&gt;201 -->\n<g id=\"edge201\" class=\"edge\">\n<title>200&#45;&gt;201</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3557.54,-608.88C3554.01,-600.51 3550.17,-591.4 3546.47,-582.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3549.65,-581.15 3542.54,-573.3 3543.2,-583.87 3549.65,-581.15\"/>\n</g>\n<!-- 206 -->\n<g id=\"node207\" class=\"node\">\n<title>206</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3684,-565.5C3684,-565.5 3611,-565.5 3611,-565.5 3605,-565.5 3599,-559.5 3599,-553.5 3599,-553.5 3599,-524.5 3599,-524.5 3599,-518.5 3605,-512.5 3611,-512.5 3611,-512.5 3684,-512.5 3684,-512.5 3690,-512.5 3696,-518.5 3696,-524.5 3696,-524.5 3696,-553.5 3696,-553.5 3696,-559.5 3690,-565.5 3684,-565.5\"/>\n<text text-anchor=\"start\" x=\"3618.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3608\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3607\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 200&#45;&gt;206 -->\n<g id=\"edge206\" class=\"edge\">\n<title>200&#45;&gt;206</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3596.18,-608.88C3604.53,-597.67 3613.88,-585.13 3622.28,-573.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3625.32,-575.63 3628.49,-565.52 3619.7,-571.45 3625.32,-575.63\"/>\n</g>\n<!-- 202 -->\n<g id=\"node203\" class=\"node\">\n<title>202</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3509,-461.5C3509,-461.5 3428,-461.5 3428,-461.5 3422,-461.5 3416,-455.5 3416,-449.5 3416,-449.5 3416,-420.5 3416,-420.5 3416,-414.5 3422,-408.5 3428,-408.5 3428,-408.5 3509,-408.5 3509,-408.5 3515,-408.5 3521,-414.5 3521,-420.5 3521,-420.5 3521,-449.5 3521,-449.5 3521,-455.5 3515,-461.5 3509,-461.5\"/>\n<text text-anchor=\"start\" x=\"3439.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3425\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\n<text text-anchor=\"start\" x=\"3424\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [12, 0]</text>\n</g>\n<!-- 201&#45;&gt;202 -->\n<g id=\"edge202\" class=\"edge\">\n<title>201&#45;&gt;202</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3509.02,-504.88C3502.49,-493.78 3495.19,-481.37 3488.61,-470.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3491.6,-468.36 3483.51,-461.52 3485.57,-471.91 3491.6,-468.36\"/>\n</g>\n<!-- 203 -->\n<g id=\"node204\" class=\"node\">\n<title>203</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M3624,-469C3624,-469 3551,-469 3551,-469 3545,-469 3539,-463 3539,-457 3539,-457 3539,-413 3539,-413 3539,-407 3545,-401 3551,-401 3551,-401 3624,-401 3624,-401 3630,-401 3636,-407 3636,-413 3636,-413 3636,-457 3636,-457 3636,-463 3630,-469 3624,-469\"/>\n<text text-anchor=\"start\" x=\"3548\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 1.382</text>\n<text text-anchor=\"start\" x=\"3550\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"3548\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"3547\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 1]</text>\n</g>\n<!-- 201&#45;&gt;203 -->\n<g id=\"edge203\" class=\"edge\">\n<title>201&#45;&gt;203</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3547.66,-504.88C3552.6,-496.33 3557.99,-487.01 3563.16,-478.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3566.26,-479.71 3568.24,-469.3 3560.2,-476.2 3566.26,-479.71\"/>\n</g>\n<!-- 204 -->\n<g id=\"node205\" class=\"node\">\n<title>204</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3566,-357.5C3566,-357.5 3493,-357.5 3493,-357.5 3487,-357.5 3481,-351.5 3481,-345.5 3481,-345.5 3481,-316.5 3481,-316.5 3481,-310.5 3487,-304.5 3493,-304.5 3493,-304.5 3566,-304.5 3566,-304.5 3572,-304.5 3578,-310.5 3578,-316.5 3578,-316.5 3578,-345.5 3578,-345.5 3578,-351.5 3572,-357.5 3566,-357.5\"/>\n<text text-anchor=\"start\" x=\"3500.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3490\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3489\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 203&#45;&gt;204 -->\n<g id=\"edge204\" class=\"edge\">\n<title>203&#45;&gt;204</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3568.67,-400.88C3562.42,-389.89 3555.44,-377.62 3549.13,-366.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3552,-364.48 3544.01,-357.52 3545.91,-367.94 3552,-364.48\"/>\n</g>\n<!-- 205 -->\n<g id=\"node206\" class=\"node\">\n<title>205</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3681,-357.5C3681,-357.5 3608,-357.5 3608,-357.5 3602,-357.5 3596,-351.5 3596,-345.5 3596,-345.5 3596,-316.5 3596,-316.5 3596,-310.5 3602,-304.5 3608,-304.5 3608,-304.5 3681,-304.5 3681,-304.5 3687,-304.5 3693,-310.5 3693,-316.5 3693,-316.5 3693,-345.5 3693,-345.5 3693,-351.5 3687,-357.5 3681,-357.5\"/>\n<text text-anchor=\"start\" x=\"3615.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3605\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"3604\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 203&#45;&gt;205 -->\n<g id=\"edge205\" class=\"edge\">\n<title>203&#45;&gt;205</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3606.01,-400.88C3612.15,-389.89 3619.01,-377.62 3625.21,-366.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3628.42,-367.96 3630.24,-357.52 3622.31,-364.54 3628.42,-367.96\"/>\n</g>\n<!-- 209 -->\n<g id=\"node210\" class=\"node\">\n<title>209</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3850,-669.5C3850,-669.5 3777,-669.5 3777,-669.5 3771,-669.5 3765,-663.5 3765,-657.5 3765,-657.5 3765,-628.5 3765,-628.5 3765,-622.5 3771,-616.5 3777,-616.5 3777,-616.5 3850,-616.5 3850,-616.5 3856,-616.5 3862,-622.5 3862,-628.5 3862,-628.5 3862,-657.5 3862,-657.5 3862,-663.5 3856,-669.5 3850,-669.5\"/>\n<text text-anchor=\"start\" x=\"3784.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3774\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3773\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 208&#45;&gt;209 -->\n<g id=\"edge209\" class=\"edge\">\n<title>208&#45;&gt;209</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3813.5,-712.88C3813.5,-702.33 3813.5,-690.6 3813.5,-679.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3817,-679.52 3813.5,-669.52 3810,-679.52 3817,-679.52\"/>\n</g>\n<!-- 210 -->\n<g id=\"node211\" class=\"node\">\n<title>210</title>\n<path fill=\"#e9965a\" stroke=\"black\" d=\"M3965,-677C3965,-677 3892,-677 3892,-677 3886,-677 3880,-671 3880,-665 3880,-665 3880,-621 3880,-621 3880,-615 3886,-609 3892,-609 3892,-609 3965,-609 3965,-609 3971,-609 3977,-615 3977,-621 3977,-621 3977,-665 3977,-665 3977,-671 3971,-677 3965,-677\"/>\n<text text-anchor=\"start\" x=\"3889\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.815</text>\n<text text-anchor=\"start\" x=\"3891\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.245</text>\n<text text-anchor=\"start\" x=\"3889\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"3888\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 1]</text>\n</g>\n<!-- 208&#45;&gt;210 -->\n<g id=\"edge210\" class=\"edge\">\n<title>208&#45;&gt;210</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3850.84,-712.88C3861.18,-703.71 3872.52,-693.65 3883.26,-684.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3885.8,-686.55 3890.96,-677.3 3881.15,-681.32 3885.8,-686.55\"/>\n</g>\n<!-- 211 -->\n<g id=\"node212\" class=\"node\">\n<title>211</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3906,-565.5C3906,-565.5 3833,-565.5 3833,-565.5 3827,-565.5 3821,-559.5 3821,-553.5 3821,-553.5 3821,-524.5 3821,-524.5 3821,-518.5 3827,-512.5 3833,-512.5 3833,-512.5 3906,-512.5 3906,-512.5 3912,-512.5 3918,-518.5 3918,-524.5 3918,-524.5 3918,-553.5 3918,-553.5 3918,-559.5 3912,-565.5 3906,-565.5\"/>\n<text text-anchor=\"start\" x=\"3840.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3830\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"3829\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 0]</text>\n</g>\n<!-- 210&#45;&gt;211 -->\n<g id=\"edge211\" class=\"edge\">\n<title>210&#45;&gt;211</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3909.34,-608.88C3902.92,-597.78 3895.74,-585.37 3889.27,-574.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3892.3,-572.42 3884.26,-565.52 3886.24,-575.93 3892.3,-572.42\"/>\n</g>\n<!-- 212 -->\n<g id=\"node213\" class=\"node\">\n<title>212</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M4021,-573C4021,-573 3948,-573 3948,-573 3942,-573 3936,-567 3936,-561 3936,-561 3936,-517 3936,-517 3936,-511 3942,-505 3948,-505 3948,-505 4021,-505 4021,-505 4027,-505 4033,-511 4033,-517 4033,-517 4033,-561 4033,-561 4033,-567 4027,-573 4021,-573\"/>\n<text text-anchor=\"start\" x=\"3945\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 1.231</text>\n<text text-anchor=\"start\" x=\"3947\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"3945\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"3944\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 1]</text>\n</g>\n<!-- 210&#45;&gt;212 -->\n<g id=\"edge212\" class=\"edge\">\n<title>210&#45;&gt;212</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3946.68,-608.88C3951.38,-600.33 3956.49,-591.01 3961.4,-582.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3964.47,-583.75 3966.22,-573.3 3958.34,-580.38 3964.47,-583.75\"/>\n</g>\n<!-- 213 -->\n<g id=\"node214\" class=\"node\">\n<title>213</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3963,-461.5C3963,-461.5 3890,-461.5 3890,-461.5 3884,-461.5 3878,-455.5 3878,-449.5 3878,-449.5 3878,-420.5 3878,-420.5 3878,-414.5 3884,-408.5 3890,-408.5 3890,-408.5 3963,-408.5 3963,-408.5 3969,-408.5 3975,-414.5 3975,-420.5 3975,-420.5 3975,-449.5 3975,-449.5 3975,-455.5 3969,-461.5 3963,-461.5\"/>\n<text text-anchor=\"start\" x=\"3897.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3887\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3886\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 212&#45;&gt;213 -->\n<g id=\"edge213\" class=\"edge\">\n<title>212&#45;&gt;213</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3965.67,-504.88C3959.42,-493.89 3952.44,-481.62 3946.13,-470.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3949,-468.48 3941.01,-461.52 3942.91,-471.94 3949,-468.48\"/>\n</g>\n<!-- 214 -->\n<g id=\"node215\" class=\"node\">\n<title>214</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4078,-461.5C4078,-461.5 4005,-461.5 4005,-461.5 3999,-461.5 3993,-455.5 3993,-449.5 3993,-449.5 3993,-420.5 3993,-420.5 3993,-414.5 3999,-408.5 4005,-408.5 4005,-408.5 4078,-408.5 4078,-408.5 4084,-408.5 4090,-414.5 4090,-420.5 4090,-420.5 4090,-449.5 4090,-449.5 4090,-455.5 4084,-461.5 4078,-461.5\"/>\n<text text-anchor=\"start\" x=\"4012.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4002\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"4001\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 212&#45;&gt;214 -->\n<g id=\"edge214\" class=\"edge\">\n<title>212&#45;&gt;214</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4003.01,-504.88C4009.15,-493.89 4016.01,-481.62 4022.21,-470.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4025.42,-471.96 4027.24,-461.52 4019.31,-468.54 4025.42,-471.96\"/>\n</g>\n<!-- 219 -->\n<g id=\"node220\" class=\"node\">\n<title>219</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3786,-1397.5C3786,-1397.5 3713,-1397.5 3713,-1397.5 3707,-1397.5 3701,-1391.5 3701,-1385.5 3701,-1385.5 3701,-1356.5 3701,-1356.5 3701,-1350.5 3707,-1344.5 3713,-1344.5 3713,-1344.5 3786,-1344.5 3786,-1344.5 3792,-1344.5 3798,-1350.5 3798,-1356.5 3798,-1356.5 3798,-1385.5 3798,-1385.5 3798,-1391.5 3792,-1397.5 3786,-1397.5\"/>\n<text text-anchor=\"start\" x=\"3720.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3710\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"3709\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4]</text>\n</g>\n<!-- 218&#45;&gt;219 -->\n<g id=\"edge219\" class=\"edge\">\n<title>218&#45;&gt;219</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3749.5,-1440.88C3749.5,-1430.33 3749.5,-1418.6 3749.5,-1407.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3753,-1407.52 3749.5,-1397.52 3746,-1407.52 3753,-1407.52\"/>\n</g>\n<!-- 220 -->\n<g id=\"node221\" class=\"node\">\n<title>220</title>\n<path fill=\"#f0b68c\" stroke=\"black\" d=\"M3940,-1405C3940,-1405 3851,-1405 3851,-1405 3845,-1405 3839,-1399 3839,-1393 3839,-1393 3839,-1349 3839,-1349 3839,-1343 3845,-1337 3851,-1337 3851,-1337 3940,-1337 3940,-1337 3946,-1337 3952,-1343 3952,-1349 3952,-1349 3952,-1393 3952,-1393 3952,-1399 3946,-1405 3940,-1405\"/>\n<text text-anchor=\"start\" x=\"3854\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.394</text>\n<text text-anchor=\"start\" x=\"3858\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.416</text>\n<text text-anchor=\"start\" x=\"3852\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 88</text>\n<text text-anchor=\"start\" x=\"3847\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [62, 26]</text>\n</g>\n<!-- 218&#45;&gt;220 -->\n<g id=\"edge220\" class=\"edge\">\n<title>218&#45;&gt;220</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3796.9,-1440.88C3810.42,-1431.44 3825.27,-1421.06 3839.26,-1411.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3841.64,-1413.9 3847.84,-1405.3 3837.63,-1408.16 3841.64,-1413.9\"/>\n</g>\n<!-- 221 -->\n<g id=\"node222\" class=\"node\">\n<title>221</title>\n<path fill=\"#e78c49\" stroke=\"black\" d=\"M3936,-1301C3936,-1301 3855,-1301 3855,-1301 3849,-1301 3843,-1295 3843,-1289 3843,-1289 3843,-1245 3843,-1245 3843,-1239 3849,-1233 3855,-1233 3855,-1233 3936,-1233 3936,-1233 3942,-1233 3948,-1239 3948,-1245 3948,-1245 3948,-1289 3948,-1289 3948,-1295 3942,-1301 3936,-1301\"/>\n<text text-anchor=\"start\" x=\"3854\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.922</text>\n<text text-anchor=\"start\" x=\"3858\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.142</text>\n<text text-anchor=\"start\" x=\"3852\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13</text>\n<text text-anchor=\"start\" x=\"3851\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [12, 1]</text>\n</g>\n<!-- 220&#45;&gt;221 -->\n<g id=\"edge221\" class=\"edge\">\n<title>220&#45;&gt;221</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3895.5,-1336.88C3895.5,-1328.78 3895.5,-1319.98 3895.5,-1311.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3899,-1311.3 3895.5,-1301.3 3892,-1311.3 3899,-1311.3\"/>\n</g>\n<!-- 226 -->\n<g id=\"node227\" class=\"node\">\n<title>226</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M4222,-1301C4222,-1301 4133,-1301 4133,-1301 4127,-1301 4121,-1295 4121,-1289 4121,-1289 4121,-1245 4121,-1245 4121,-1239 4127,-1233 4133,-1233 4133,-1233 4222,-1233 4222,-1233 4228,-1233 4234,-1239 4234,-1245 4234,-1245 4234,-1289 4234,-1289 4234,-1295 4228,-1301 4222,-1301\"/>\n<text text-anchor=\"start\" x=\"4136\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.167</text>\n<text text-anchor=\"start\" x=\"4140\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"4134\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 75</text>\n<text text-anchor=\"start\" x=\"4129\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 25]</text>\n</g>\n<!-- 220&#45;&gt;226 -->\n<g id=\"edge226\" class=\"edge\">\n<title>220&#45;&gt;226</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3952.23,-1349.48C3998.22,-1332.85 4063.1,-1309.38 4111.43,-1291.9\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4112.65,-1295.18 4120.86,-1288.49 4110.27,-1288.6 4112.65,-1295.18\"/>\n</g>\n<!-- 222 -->\n<g id=\"node223\" class=\"node\">\n<title>222</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M3925,-1197C3925,-1197 3850,-1197 3850,-1197 3844,-1197 3838,-1191 3838,-1185 3838,-1185 3838,-1141 3838,-1141 3838,-1135 3844,-1129 3850,-1129 3850,-1129 3925,-1129 3925,-1129 3931,-1129 3937,-1135 3937,-1141 3937,-1141 3937,-1185 3937,-1185 3937,-1191 3931,-1197 3925,-1197\"/>\n<text text-anchor=\"start\" x=\"3846\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.998</text>\n<text text-anchor=\"start\" x=\"3858.5\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"3848\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"3847\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 221&#45;&gt;222 -->\n<g id=\"edge222\" class=\"edge\">\n<title>221&#45;&gt;222</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3892.9,-1232.88C3892.27,-1224.78 3891.58,-1215.98 3890.91,-1207.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3894.38,-1207 3890.11,-1197.3 3887.4,-1207.54 3894.38,-1207\"/>\n</g>\n<!-- 225 -->\n<g id=\"node226\" class=\"node\">\n<title>225</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4048,-1189.5C4048,-1189.5 3967,-1189.5 3967,-1189.5 3961,-1189.5 3955,-1183.5 3955,-1177.5 3955,-1177.5 3955,-1148.5 3955,-1148.5 3955,-1142.5 3961,-1136.5 3967,-1136.5 3967,-1136.5 4048,-1136.5 4048,-1136.5 4054,-1136.5 4060,-1142.5 4060,-1148.5 4060,-1148.5 4060,-1177.5 4060,-1177.5 4060,-1183.5 4054,-1189.5 4048,-1189.5\"/>\n<text text-anchor=\"start\" x=\"3978.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3964\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"start\" x=\"3963\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 0]</text>\n</g>\n<!-- 221&#45;&gt;225 -->\n<g id=\"edge225\" class=\"edge\">\n<title>221&#45;&gt;225</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3931.86,-1232.88C3944.66,-1221.23 3959.03,-1208.14 3971.78,-1196.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3974.44,-1198.84 3979.48,-1189.52 3969.73,-1193.67 3974.44,-1198.84\"/>\n</g>\n<!-- 223 -->\n<g id=\"node224\" class=\"node\">\n<title>223</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3920,-1085.5C3920,-1085.5 3847,-1085.5 3847,-1085.5 3841,-1085.5 3835,-1079.5 3835,-1073.5 3835,-1073.5 3835,-1044.5 3835,-1044.5 3835,-1038.5 3841,-1032.5 3847,-1032.5 3847,-1032.5 3920,-1032.5 3920,-1032.5 3926,-1032.5 3932,-1038.5 3932,-1044.5 3932,-1044.5 3932,-1073.5 3932,-1073.5 3932,-1079.5 3926,-1085.5 3920,-1085.5\"/>\n<text text-anchor=\"start\" x=\"3854.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3844\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3843\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 222&#45;&gt;223 -->\n<g id=\"edge223\" class=\"edge\">\n<title>222&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3886.2,-1128.88C3885.78,-1118.22 3885.32,-1106.35 3884.89,-1095.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3888.39,-1095.38 3884.5,-1085.52 3881.4,-1095.65 3888.39,-1095.38\"/>\n</g>\n<!-- 224 -->\n<g id=\"node225\" class=\"node\">\n<title>224</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4035,-1085.5C4035,-1085.5 3962,-1085.5 3962,-1085.5 3956,-1085.5 3950,-1079.5 3950,-1073.5 3950,-1073.5 3950,-1044.5 3950,-1044.5 3950,-1038.5 3956,-1032.5 3962,-1032.5 3962,-1032.5 4035,-1032.5 4035,-1032.5 4041,-1032.5 4047,-1038.5 4047,-1044.5 4047,-1044.5 4047,-1073.5 4047,-1073.5 4047,-1079.5 4041,-1085.5 4035,-1085.5\"/>\n<text text-anchor=\"start\" x=\"3969.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3959\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3958\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 222&#45;&gt;224 -->\n<g id=\"edge224\" class=\"edge\">\n<title>222&#45;&gt;224</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3923.54,-1128.88C3936.22,-1117.23 3950.46,-1104.14 3963.1,-1092.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3965.73,-1094.86 3970.73,-1085.52 3961,-1089.71 3965.73,-1094.86\"/>\n</g>\n<!-- 227 -->\n<g id=\"node228\" class=\"node\">\n<title>227</title>\n<path fill=\"#7bbeee\" stroke=\"black\" d=\"M4214,-1197C4214,-1197 4141,-1197 4141,-1197 4135,-1197 4129,-1191 4129,-1185 4129,-1185 4129,-1141 4129,-1141 4129,-1135 4135,-1129 4141,-1129 4141,-1129 4214,-1129 4214,-1129 4220,-1129 4226,-1135 4226,-1141 4226,-1141 4226,-1185 4226,-1185 4226,-1191 4220,-1197 4214,-1197\"/>\n<text text-anchor=\"start\" x=\"4141\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 1.0</text>\n<text text-anchor=\"start\" x=\"4140\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"4138\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"4137\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 6]</text>\n</g>\n<!-- 226&#45;&gt;227 -->\n<g id=\"edge227\" class=\"edge\">\n<title>226&#45;&gt;227</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4177.5,-1232.88C4177.5,-1224.78 4177.5,-1215.98 4177.5,-1207.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4181,-1207.3 4177.5,-1197.3 4174,-1207.3 4181,-1207.3\"/>\n</g>\n<!-- 230 -->\n<g id=\"node231\" class=\"node\">\n<title>230</title>\n<path fill=\"#efb387\" stroke=\"black\" d=\"M4392,-1197C4392,-1197 4303,-1197 4303,-1197 4297,-1197 4291,-1191 4291,-1185 4291,-1185 4291,-1141 4291,-1141 4291,-1135 4297,-1129 4303,-1129 4303,-1129 4392,-1129 4392,-1129 4398,-1129 4404,-1135 4404,-1141 4404,-1141 4404,-1185 4404,-1185 4404,-1191 4398,-1197 4392,-1197\"/>\n<text text-anchor=\"start\" x=\"4306.5\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 1.051</text>\n<text text-anchor=\"start\" x=\"4310\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.406</text>\n<text text-anchor=\"start\" x=\"4304\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 67</text>\n<text text-anchor=\"start\" x=\"4299\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [48, 19]</text>\n</g>\n<!-- 226&#45;&gt;230 -->\n<g id=\"edge230\" class=\"edge\">\n<title>226&#45;&gt;230</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4232.69,-1232.88C4248.96,-1223.12 4266.89,-1212.37 4283.65,-1202.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4285.52,-1205.27 4292.29,-1197.12 4281.92,-1199.27 4285.52,-1205.27\"/>\n</g>\n<!-- 228 -->\n<g id=\"node229\" class=\"node\">\n<title>228</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4150,-1085.5C4150,-1085.5 4077,-1085.5 4077,-1085.5 4071,-1085.5 4065,-1079.5 4065,-1073.5 4065,-1073.5 4065,-1044.5 4065,-1044.5 4065,-1038.5 4071,-1032.5 4077,-1032.5 4077,-1032.5 4150,-1032.5 4150,-1032.5 4156,-1032.5 4162,-1038.5 4162,-1044.5 4162,-1044.5 4162,-1073.5 4162,-1073.5 4162,-1079.5 4156,-1085.5 4150,-1085.5\"/>\n<text text-anchor=\"start\" x=\"4084.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4074\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"4073\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 6]</text>\n</g>\n<!-- 227&#45;&gt;228 -->\n<g id=\"edge228\" class=\"edge\">\n<title>227&#45;&gt;228</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4156.72,-1128.88C4149.75,-1117.78 4141.97,-1105.37 4134.95,-1094.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4137.79,-1092.13 4129.51,-1085.52 4131.86,-1095.85 4137.79,-1092.13\"/>\n</g>\n<!-- 229 -->\n<g id=\"node230\" class=\"node\">\n<title>229</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4265,-1085.5C4265,-1085.5 4192,-1085.5 4192,-1085.5 4186,-1085.5 4180,-1079.5 4180,-1073.5 4180,-1073.5 4180,-1044.5 4180,-1044.5 4180,-1038.5 4186,-1032.5 4192,-1032.5 4192,-1032.5 4265,-1032.5 4265,-1032.5 4271,-1032.5 4277,-1038.5 4277,-1044.5 4277,-1044.5 4277,-1073.5 4277,-1073.5 4277,-1079.5 4271,-1085.5 4265,-1085.5\"/>\n<text text-anchor=\"start\" x=\"4199.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4189\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"4188\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 227&#45;&gt;229 -->\n<g id=\"edge229\" class=\"edge\">\n<title>227&#45;&gt;229</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4194.06,-1128.88C4199.56,-1117.89 4205.69,-1105.62 4211.24,-1094.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4214.4,-1096.03 4215.74,-1085.52 4208.14,-1092.9 4214.4,-1096.03\"/>\n</g>\n<!-- 231 -->\n<g id=\"node232\" class=\"node\">\n<title>231</title>\n<path fill=\"#eb9d66\" stroke=\"black\" d=\"M4388,-1093C4388,-1093 4307,-1093 4307,-1093 4301,-1093 4295,-1087 4295,-1081 4295,-1081 4295,-1037 4295,-1037 4295,-1031 4301,-1025 4307,-1025 4307,-1025 4388,-1025 4388,-1025 4394,-1025 4400,-1031 4400,-1037 4400,-1037 4400,-1081 4400,-1081 4400,-1087 4394,-1093 4388,-1093\"/>\n<text text-anchor=\"start\" x=\"4306.5\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.511</text>\n<text text-anchor=\"start\" x=\"4310\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.301</text>\n<text text-anchor=\"start\" x=\"4304\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 38</text>\n<text text-anchor=\"start\" x=\"4303\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 7]</text>\n</g>\n<!-- 230&#45;&gt;231 -->\n<g id=\"edge231\" class=\"edge\">\n<title>230&#45;&gt;231</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4347.5,-1128.88C4347.5,-1120.78 4347.5,-1111.98 4347.5,-1103.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4351,-1103.3 4347.5,-1093.3 4344,-1103.3 4351,-1103.3\"/>\n</g>\n<!-- 246 -->\n<g id=\"node247\" class=\"node\">\n<title>246</title>\n<path fill=\"#f7dac5\" stroke=\"black\" d=\"M4534,-1093C4534,-1093 4445,-1093 4445,-1093 4439,-1093 4433,-1087 4433,-1081 4433,-1081 4433,-1037 4433,-1037 4433,-1031 4439,-1025 4445,-1025 4445,-1025 4534,-1025 4534,-1025 4540,-1025 4546,-1031 4546,-1037 4546,-1037 4546,-1081 4546,-1081 4546,-1087 4540,-1093 4534,-1093\"/>\n<text text-anchor=\"start\" x=\"4448.5\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 1.175</text>\n<text text-anchor=\"start\" x=\"4452\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.485</text>\n<text text-anchor=\"start\" x=\"4446\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 29</text>\n<text text-anchor=\"start\" x=\"4441\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 12]</text>\n</g>\n<!-- 230&#45;&gt;246 -->\n<g id=\"edge246\" class=\"edge\">\n<title>230&#45;&gt;246</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4393.6,-1128.88C4406.75,-1119.44 4421.2,-1109.06 4434.8,-1099.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4437.06,-1101.98 4443.14,-1093.3 4432.98,-1096.29 4437.06,-1101.98\"/>\n</g>\n<!-- 232 -->\n<g id=\"node233\" class=\"node\">\n<title>232</title>\n<path fill=\"#f3c5a4\" stroke=\"black\" d=\"M4265,-989C4265,-989 4184,-989 4184,-989 4178,-989 4172,-983 4172,-977 4172,-977 4172,-933 4172,-933 4172,-927 4178,-921 4184,-921 4184,-921 4265,-921 4265,-921 4271,-921 4277,-927 4277,-933 4277,-933 4277,-977 4277,-977 4277,-983 4271,-989 4265,-989\"/>\n<text text-anchor=\"start\" x=\"4187\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"4187\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.455</text>\n<text text-anchor=\"start\" x=\"4181\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 20</text>\n<text text-anchor=\"start\" x=\"4180\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 7]</text>\n</g>\n<!-- 231&#45;&gt;232 -->\n<g id=\"edge232\" class=\"edge\">\n<title>231&#45;&gt;232</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4307.57,-1024.88C4296.39,-1015.62 4284.14,-1005.45 4272.55,-995.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4274.59,-992.99 4264.66,-989.3 4270.12,-998.38 4274.59,-992.99\"/>\n</g>\n<!-- 245 -->\n<g id=\"node246\" class=\"node\">\n<title>245</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4388,-981.5C4388,-981.5 4307,-981.5 4307,-981.5 4301,-981.5 4295,-975.5 4295,-969.5 4295,-969.5 4295,-940.5 4295,-940.5 4295,-934.5 4301,-928.5 4307,-928.5 4307,-928.5 4388,-928.5 4388,-928.5 4394,-928.5 4400,-934.5 4400,-940.5 4400,-940.5 4400,-969.5 4400,-969.5 4400,-975.5 4394,-981.5 4388,-981.5\"/>\n<text text-anchor=\"start\" x=\"4318.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4304\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n<text text-anchor=\"start\" x=\"4303\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [18, 0]</text>\n</g>\n<!-- 231&#45;&gt;245 -->\n<g id=\"edge245\" class=\"edge\">\n<title>231&#45;&gt;245</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4347.5,-1024.88C4347.5,-1014.33 4347.5,-1002.6 4347.5,-991.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4351,-991.52 4347.5,-981.52 4344,-991.52 4351,-991.52\"/>\n</g>\n<!-- 233 -->\n<g id=\"node234\" class=\"node\">\n<title>233</title>\n<path fill=\"#f9e3d3\" stroke=\"black\" d=\"M4196,-885C4196,-885 4117,-885 4117,-885 4111,-885 4105,-879 4105,-873 4105,-873 4105,-829 4105,-829 4105,-823 4111,-817 4117,-817 4117,-817 4196,-817 4196,-817 4202,-817 4208,-823 4208,-829 4208,-829 4208,-873 4208,-873 4208,-879 4202,-885 4196,-885\"/>\n<text text-anchor=\"start\" x=\"4117\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 1.759</text>\n<text text-anchor=\"start\" x=\"4119\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.492</text>\n<text text-anchor=\"start\" x=\"4113\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"start\" x=\"4116\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 7]</text>\n</g>\n<!-- 232&#45;&gt;233 -->\n<g id=\"edge233\" class=\"edge\">\n<title>232&#45;&gt;233</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4202.42,-920.88C4196.66,-912.24 4190.38,-902.82 4184.36,-893.79\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4187.16,-891.68 4178.7,-885.3 4181.33,-895.56 4187.16,-891.68\"/>\n</g>\n<!-- 244 -->\n<g id=\"node245\" class=\"node\">\n<title>244</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4311,-877.5C4311,-877.5 4238,-877.5 4238,-877.5 4232,-877.5 4226,-871.5 4226,-865.5 4226,-865.5 4226,-836.5 4226,-836.5 4226,-830.5 4232,-824.5 4238,-824.5 4238,-824.5 4311,-824.5 4311,-824.5 4317,-824.5 4323,-830.5 4323,-836.5 4323,-836.5 4323,-865.5 4323,-865.5 4323,-871.5 4317,-877.5 4311,-877.5\"/>\n<text text-anchor=\"start\" x=\"4245.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4235\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"4234\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 0]</text>\n</g>\n<!-- 232&#45;&gt;244 -->\n<g id=\"edge244\" class=\"edge\">\n<title>232&#45;&gt;244</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4240.73,-920.88C4246.12,-909.89 4252.14,-897.62 4257.58,-886.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4260.73,-888.04 4261.99,-877.52 4254.45,-884.96 4260.73,-888.04\"/>\n</g>\n<!-- 234 -->\n<g id=\"node235\" class=\"node\">\n<title>234</title>\n<path fill=\"#bddef6\" stroke=\"black\" d=\"M4212.5,-781C4212.5,-781 4092.5,-781 4092.5,-781 4086.5,-781 4080.5,-775 4080.5,-769 4080.5,-769 4080.5,-725 4080.5,-725 4080.5,-719 4086.5,-713 4092.5,-713 4092.5,-713 4212.5,-713 4212.5,-713 4218.5,-713 4224.5,-719 4224.5,-725 4224.5,-725 4224.5,-769 4224.5,-769 4224.5,-775 4218.5,-781 4212.5,-781\"/>\n<text text-anchor=\"start\" x=\"4088.5\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_C ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"4119\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n<text text-anchor=\"start\" x=\"4109\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"4112\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 6]</text>\n</g>\n<!-- 233&#45;&gt;234 -->\n<g id=\"edge234\" class=\"edge\">\n<title>233&#45;&gt;234</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4155.2,-816.88C4154.88,-808.78 4154.54,-799.98 4154.2,-791.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4157.7,-791.15 4153.81,-781.3 4150.7,-791.43 4157.7,-791.15\"/>\n</g>\n<!-- 241 -->\n<g id=\"node242\" class=\"node\">\n<title>241</title>\n<path fill=\"#ea9a61\" stroke=\"black\" d=\"M4374,-781C4374,-781 4255,-781 4255,-781 4249,-781 4243,-775 4243,-769 4243,-769 4243,-725 4243,-725 4243,-719 4249,-713 4255,-713 4255,-713 4374,-713 4374,-713 4380,-713 4386,-719 4386,-725 4386,-725 4386,-769 4386,-769 4386,-775 4380,-781 4374,-781\"/>\n<text text-anchor=\"start\" x=\"4251\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_A ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"4277\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.278</text>\n<text text-anchor=\"start\" x=\"4275\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"4274\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 1]</text>\n</g>\n<!-- 233&#45;&gt;241 -->\n<g id=\"edge241\" class=\"edge\">\n<title>233&#45;&gt;241</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4207.8,-816.88C4222.78,-807.21 4239.27,-796.56 4254.73,-786.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4256.69,-789.49 4263.19,-781.12 4252.89,-783.61 4256.69,-789.49\"/>\n</g>\n<!-- 235 -->\n<g id=\"node236\" class=\"node\">\n<title>235</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4099,-669.5C4099,-669.5 4026,-669.5 4026,-669.5 4020,-669.5 4014,-663.5 4014,-657.5 4014,-657.5 4014,-628.5 4014,-628.5 4014,-622.5 4020,-616.5 4026,-616.5 4026,-616.5 4099,-616.5 4099,-616.5 4105,-616.5 4111,-622.5 4111,-628.5 4111,-628.5 4111,-657.5 4111,-657.5 4111,-663.5 4105,-669.5 4099,-669.5\"/>\n<text text-anchor=\"start\" x=\"4033.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4023\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"4022\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4]</text>\n</g>\n<!-- 234&#45;&gt;235 -->\n<g id=\"edge235\" class=\"edge\">\n<title>234&#45;&gt;235</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4123.28,-712.88C4113.19,-701.45 4101.88,-688.63 4091.79,-677.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4094.26,-674.7 4085.02,-669.52 4089.01,-679.33 4094.26,-674.7\"/>\n</g>\n<!-- 236 -->\n<g id=\"node237\" class=\"node\">\n<title>236</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M4214,-677C4214,-677 4141,-677 4141,-677 4135,-677 4129,-671 4129,-665 4129,-665 4129,-621 4129,-621 4129,-615 4135,-609 4141,-609 4141,-609 4214,-609 4214,-609 4220,-609 4226,-615 4226,-621 4226,-621 4226,-665 4226,-665 4226,-671 4220,-677 4214,-677\"/>\n<text text-anchor=\"start\" x=\"4141\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.46</text>\n<text text-anchor=\"start\" x=\"4140\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"4138\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"4137\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 2]</text>\n</g>\n<!-- 234&#45;&gt;236 -->\n<g id=\"edge236\" class=\"edge\">\n<title>234&#45;&gt;236</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4160.62,-712.88C4162.63,-704.69 4164.81,-695.79 4166.91,-687.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4170.36,-687.85 4169.34,-677.3 4163.56,-686.18 4170.36,-687.85\"/>\n</g>\n<!-- 237 -->\n<g id=\"node238\" class=\"node\">\n<title>237</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4193,-565.5C4193,-565.5 4120,-565.5 4120,-565.5 4114,-565.5 4108,-559.5 4108,-553.5 4108,-553.5 4108,-524.5 4108,-524.5 4108,-518.5 4114,-512.5 4120,-512.5 4120,-512.5 4193,-512.5 4193,-512.5 4199,-512.5 4205,-518.5 4205,-524.5 4205,-524.5 4205,-553.5 4205,-553.5 4205,-559.5 4199,-565.5 4193,-565.5\"/>\n<text text-anchor=\"start\" x=\"4127.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4117\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"4116\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 236&#45;&gt;237 -->\n<g id=\"edge237\" class=\"edge\">\n<title>236&#45;&gt;237</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4170.68,-608.88C4168.49,-598.22 4166.04,-586.35 4163.81,-575.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4167.2,-574.61 4161.75,-565.52 4160.34,-576.02 4167.2,-574.61\"/>\n</g>\n<!-- 238 -->\n<g id=\"node239\" class=\"node\">\n<title>238</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M4308,-573C4308,-573 4235,-573 4235,-573 4229,-573 4223,-567 4223,-561 4223,-561 4223,-517 4223,-517 4223,-511 4229,-505 4235,-505 4235,-505 4308,-505 4308,-505 4314,-505 4320,-511 4320,-517 4320,-517 4320,-561 4320,-561 4320,-567 4314,-573 4308,-573\"/>\n<text text-anchor=\"start\" x=\"4235\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"4234\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"4232\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"4231\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 236&#45;&gt;238 -->\n<g id=\"edge238\" class=\"edge\">\n<title>236&#45;&gt;238</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4208.02,-608.88C4216.31,-599.89 4225.38,-590.04 4234.01,-580.68\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4236.61,-583.02 4240.81,-573.3 4231.46,-578.28 4236.61,-583.02\"/>\n</g>\n<!-- 239 -->\n<g id=\"node240\" class=\"node\">\n<title>239</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4279,-461.5C4279,-461.5 4206,-461.5 4206,-461.5 4200,-461.5 4194,-455.5 4194,-449.5 4194,-449.5 4194,-420.5 4194,-420.5 4194,-414.5 4200,-408.5 4206,-408.5 4206,-408.5 4279,-408.5 4279,-408.5 4285,-408.5 4291,-414.5 4291,-420.5 4291,-420.5 4291,-449.5 4291,-449.5 4291,-455.5 4285,-461.5 4279,-461.5\"/>\n<text text-anchor=\"start\" x=\"4213.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4203\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"4202\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 238&#45;&gt;239 -->\n<g id=\"edge239\" class=\"edge\">\n<title>238&#45;&gt;239</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4262.08,-504.88C4259.02,-494.11 4255.61,-482.11 4252.5,-471.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4255.86,-470.18 4249.76,-461.52 4249.12,-472.1 4255.86,-470.18\"/>\n</g>\n<!-- 240 -->\n<g id=\"node241\" class=\"node\">\n<title>240</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4394,-461.5C4394,-461.5 4321,-461.5 4321,-461.5 4315,-461.5 4309,-455.5 4309,-449.5 4309,-449.5 4309,-420.5 4309,-420.5 4309,-414.5 4315,-408.5 4321,-408.5 4321,-408.5 4394,-408.5 4394,-408.5 4400,-408.5 4406,-414.5 4406,-420.5 4406,-420.5 4406,-449.5 4406,-449.5 4406,-455.5 4400,-461.5 4394,-461.5\"/>\n<text text-anchor=\"start\" x=\"4328.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4318\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"4317\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 238&#45;&gt;240 -->\n<g id=\"edge240\" class=\"edge\">\n<title>238&#45;&gt;240</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4299.42,-504.88C4309.07,-493.45 4319.87,-480.63 4329.52,-469.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4332.21,-471.42 4335.98,-461.52 4326.86,-466.91 4332.21,-471.42\"/>\n</g>\n<!-- 242 -->\n<g id=\"node243\" class=\"node\">\n<title>242</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4339,-669.5C4339,-669.5 4266,-669.5 4266,-669.5 4260,-669.5 4254,-663.5 4254,-657.5 4254,-657.5 4254,-628.5 4254,-628.5 4254,-622.5 4260,-616.5 4266,-616.5 4266,-616.5 4339,-616.5 4339,-616.5 4345,-616.5 4351,-622.5 4351,-628.5 4351,-628.5 4351,-657.5 4351,-657.5 4351,-663.5 4345,-669.5 4339,-669.5\"/>\n<text text-anchor=\"start\" x=\"4273.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4263\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"4262\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 0]</text>\n</g>\n<!-- 241&#45;&gt;242 -->\n<g id=\"edge242\" class=\"edge\">\n<title>241&#45;&gt;242</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4310.6,-712.88C4309.35,-702.22 4307.95,-690.35 4306.68,-679.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4310.15,-679.04 4305.5,-669.52 4303.19,-679.86 4310.15,-679.04\"/>\n</g>\n<!-- 243 -->\n<g id=\"node244\" class=\"node\">\n<title>243</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4454,-669.5C4454,-669.5 4381,-669.5 4381,-669.5 4375,-669.5 4369,-663.5 4369,-657.5 4369,-657.5 4369,-628.5 4369,-628.5 4369,-622.5 4375,-616.5 4381,-616.5 4381,-616.5 4454,-616.5 4454,-616.5 4460,-616.5 4466,-622.5 4466,-628.5 4466,-628.5 4466,-657.5 4466,-657.5 4466,-663.5 4460,-669.5 4454,-669.5\"/>\n<text text-anchor=\"start\" x=\"4388.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4378\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"4377\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 241&#45;&gt;243 -->\n<g id=\"edge243\" class=\"edge\">\n<title>241&#45;&gt;243</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4347.94,-712.88C4359.6,-701.34 4372.68,-688.39 4384.32,-676.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4387.09,-679.04 4391.73,-669.52 4382.16,-674.07 4387.09,-679.04\"/>\n</g>\n<!-- 247 -->\n<g id=\"node248\" class=\"node\">\n<title>247</title>\n<path fill=\"#5aade9\" stroke=\"black\" d=\"M4549,-989C4549,-989 4430,-989 4430,-989 4424,-989 4418,-983 4418,-977 4418,-977 4418,-933 4418,-933 4418,-927 4424,-921 4430,-921 4430,-921 4549,-921 4549,-921 4555,-921 4561,-927 4561,-933 4561,-933 4561,-977 4561,-977 4561,-983 4555,-989 4549,-989\"/>\n<text text-anchor=\"start\" x=\"4426\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_E ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"4452\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.245</text>\n<text text-anchor=\"start\" x=\"4450\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"4449\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 6]</text>\n</g>\n<!-- 246&#45;&gt;247 -->\n<g id=\"edge247\" class=\"edge\">\n<title>246&#45;&gt;247</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4489.5,-1024.88C4489.5,-1016.78 4489.5,-1007.98 4489.5,-999.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4493,-999.3 4489.5,-989.3 4486,-999.3 4493,-999.3\"/>\n</g>\n<!-- 250 -->\n<g id=\"node251\" class=\"node\">\n<title>250</title>\n<path fill=\"#efb083\" stroke=\"black\" d=\"M4710,-989C4710,-989 4591,-989 4591,-989 4585,-989 4579,-983 4579,-977 4579,-977 4579,-933 4579,-933 4579,-927 4585,-921 4591,-921 4591,-921 4710,-921 4710,-921 4716,-921 4722,-927 4722,-933 4722,-933 4722,-977 4722,-977 4722,-983 4716,-989 4710,-989\"/>\n<text text-anchor=\"start\" x=\"4587\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_B ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"4613\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.397</text>\n<text text-anchor=\"start\" x=\"4607\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 22</text>\n<text text-anchor=\"start\" x=\"4606\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [16, 6]</text>\n</g>\n<!-- 246&#45;&gt;250 -->\n<g id=\"edge250\" class=\"edge\">\n<title>246&#45;&gt;250</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4541.77,-1024.88C4557.03,-1015.21 4573.85,-1004.56 4589.59,-994.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4591.64,-997.43 4598.21,-989.12 4587.89,-991.52 4591.64,-997.43\"/>\n</g>\n<!-- 248 -->\n<g id=\"node249\" class=\"node\">\n<title>248</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4444,-877.5C4444,-877.5 4371,-877.5 4371,-877.5 4365,-877.5 4359,-871.5 4359,-865.5 4359,-865.5 4359,-836.5 4359,-836.5 4359,-830.5 4365,-824.5 4371,-824.5 4371,-824.5 4444,-824.5 4444,-824.5 4450,-824.5 4456,-830.5 4456,-836.5 4456,-836.5 4456,-865.5 4456,-865.5 4456,-871.5 4450,-877.5 4444,-877.5\"/>\n<text text-anchor=\"start\" x=\"4378.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4368\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"4367\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 6]</text>\n</g>\n<!-- 247&#45;&gt;248 -->\n<g id=\"edge248\" class=\"edge\">\n<title>247&#45;&gt;248</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4462.88,-920.88C4453.77,-909.56 4443.58,-896.88 4434.45,-885.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4437.01,-883.12 4428.02,-877.52 4431.55,-887.51 4437.01,-883.12\"/>\n</g>\n<!-- 249 -->\n<g id=\"node250\" class=\"node\">\n<title>249</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4559,-877.5C4559,-877.5 4486,-877.5 4486,-877.5 4480,-877.5 4474,-871.5 4474,-865.5 4474,-865.5 4474,-836.5 4474,-836.5 4474,-830.5 4480,-824.5 4486,-824.5 4486,-824.5 4559,-824.5 4559,-824.5 4565,-824.5 4571,-830.5 4571,-836.5 4571,-836.5 4571,-865.5 4571,-865.5 4571,-871.5 4565,-877.5 4559,-877.5\"/>\n<text text-anchor=\"start\" x=\"4493.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4483\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"4482\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 247&#45;&gt;249 -->\n<g id=\"edge249\" class=\"edge\">\n<title>247&#45;&gt;249</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4500.21,-920.88C4503.7,-910.11 4507.58,-898.11 4511.12,-887.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4514.5,-888.11 4514.24,-877.52 4507.84,-885.96 4514.5,-888.11\"/>\n</g>\n<!-- 251 -->\n<g id=\"node252\" class=\"node\">\n<title>251</title>\n<path fill=\"#ea9a61\" stroke=\"black\" d=\"M4691,-885C4691,-885 4610,-885 4610,-885 4604,-885 4598,-879 4598,-873 4598,-873 4598,-829 4598,-829 4598,-823 4604,-817 4610,-817 4610,-817 4691,-817 4691,-817 4697,-817 4703,-823 4703,-829 4703,-829 4703,-873 4703,-873 4703,-879 4697,-885 4691,-885\"/>\n<text text-anchor=\"start\" x=\"4614\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"4613\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.278</text>\n<text text-anchor=\"start\" x=\"4607\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n<text text-anchor=\"start\" x=\"4606\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [15, 3]</text>\n</g>\n<!-- 250&#45;&gt;251 -->\n<g id=\"edge251\" class=\"edge\">\n<title>250&#45;&gt;251</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4650.5,-920.88C4650.5,-912.78 4650.5,-903.98 4650.5,-895.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4654,-895.3 4650.5,-885.3 4647,-895.3 4654,-895.3\"/>\n</g>\n<!-- 260 -->\n<g id=\"node261\" class=\"node\">\n<title>260</title>\n<path fill=\"#7bbeee\" stroke=\"black\" d=\"M4806,-885C4806,-885 4733,-885 4733,-885 4727,-885 4721,-879 4721,-873 4721,-873 4721,-829 4721,-829 4721,-823 4727,-817 4733,-817 4733,-817 4806,-817 4806,-817 4812,-817 4818,-823 4818,-829 4818,-829 4818,-873 4818,-873 4818,-879 4812,-885 4806,-885\"/>\n<text text-anchor=\"start\" x=\"4733\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"4732\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"4730\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"4729\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 3]</text>\n</g>\n<!-- 250&#45;&gt;260 -->\n<g id=\"edge260\" class=\"edge\">\n<title>250&#45;&gt;260</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4689.14,-920.88C4699.94,-911.62 4711.8,-901.45 4723.01,-891.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4725.34,-894.46 4730.65,-885.3 4720.78,-889.15 4725.34,-894.46\"/>\n</g>\n<!-- 252 -->\n<g id=\"node253\" class=\"node\">\n<title>252</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M4574,-781C4574,-781 4501,-781 4501,-781 4495,-781 4489,-775 4489,-769 4489,-769 4489,-725 4489,-725 4489,-719 4495,-713 4501,-713 4501,-713 4574,-713 4574,-713 4580,-713 4586,-719 4586,-725 4586,-725 4586,-769 4586,-769 4586,-775 4580,-781 4574,-781\"/>\n<text text-anchor=\"start\" x=\"4498\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 1.306</text>\n<text text-anchor=\"start\" x=\"4500\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"4498\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"4497\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 3]</text>\n</g>\n<!-- 251&#45;&gt;252 -->\n<g id=\"edge252\" class=\"edge\">\n<title>251&#45;&gt;252</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4613.81,-816.88C4603.65,-807.71 4592.5,-797.65 4581.95,-788.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4584.16,-785.4 4574.39,-781.3 4579.47,-790.6 4584.16,-785.4\"/>\n</g>\n<!-- 259 -->\n<g id=\"node260\" class=\"node\">\n<title>259</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4689,-773.5C4689,-773.5 4616,-773.5 4616,-773.5 4610,-773.5 4604,-767.5 4604,-761.5 4604,-761.5 4604,-732.5 4604,-732.5 4604,-726.5 4610,-720.5 4616,-720.5 4616,-720.5 4689,-720.5 4689,-720.5 4695,-720.5 4701,-726.5 4701,-732.5 4701,-732.5 4701,-761.5 4701,-761.5 4701,-767.5 4695,-773.5 4689,-773.5\"/>\n<text text-anchor=\"start\" x=\"4623.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4613\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"4612\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 0]</text>\n</g>\n<!-- 251&#45;&gt;259 -->\n<g id=\"edge259\" class=\"edge\">\n<title>251&#45;&gt;259</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4651.15,-816.88C4651.36,-806.22 4651.59,-794.35 4651.8,-783.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4655.3,-783.59 4652,-773.52 4648.3,-783.45 4655.3,-783.59\"/>\n</g>\n<!-- 253 -->\n<g id=\"node254\" class=\"node\">\n<title>253</title>\n<path fill=\"#e9965a\" stroke=\"black\" d=\"M4574,-677C4574,-677 4501,-677 4501,-677 4495,-677 4489,-671 4489,-665 4489,-665 4489,-621 4489,-621 4489,-615 4495,-609 4501,-609 4501,-609 4574,-609 4574,-609 4580,-609 4586,-615 4586,-621 4586,-621 4586,-665 4586,-665 4586,-671 4580,-677 4574,-677\"/>\n<text text-anchor=\"start\" x=\"4498\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.414</text>\n<text text-anchor=\"start\" x=\"4500\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.245</text>\n<text text-anchor=\"start\" x=\"4498\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"4497\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 1]</text>\n</g>\n<!-- 252&#45;&gt;253 -->\n<g id=\"edge253\" class=\"edge\">\n<title>252&#45;&gt;253</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4537.5,-712.88C4537.5,-704.78 4537.5,-695.98 4537.5,-687.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4541,-687.3 4537.5,-677.3 4534,-687.3 4541,-687.3\"/>\n</g>\n<!-- 258 -->\n<g id=\"node259\" class=\"node\">\n<title>258</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4689,-669.5C4689,-669.5 4616,-669.5 4616,-669.5 4610,-669.5 4604,-663.5 4604,-657.5 4604,-657.5 4604,-628.5 4604,-628.5 4604,-622.5 4610,-616.5 4616,-616.5 4616,-616.5 4689,-616.5 4689,-616.5 4695,-616.5 4701,-622.5 4701,-628.5 4701,-628.5 4701,-657.5 4701,-657.5 4701,-663.5 4695,-669.5 4689,-669.5\"/>\n<text text-anchor=\"start\" x=\"4623.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4613\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"4612\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 252&#45;&gt;258 -->\n<g id=\"edge258\" class=\"edge\">\n<title>252&#45;&gt;258</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4574.84,-712.88C4588.1,-701.12 4603.01,-687.89 4616.19,-676.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4618.57,-678.77 4623.73,-669.52 4613.92,-673.54 4618.57,-678.77\"/>\n</g>\n<!-- 254 -->\n<g id=\"node255\" class=\"node\">\n<title>254</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4480,-565.5C4480,-565.5 4407,-565.5 4407,-565.5 4401,-565.5 4395,-559.5 4395,-553.5 4395,-553.5 4395,-524.5 4395,-524.5 4395,-518.5 4401,-512.5 4407,-512.5 4407,-512.5 4480,-512.5 4480,-512.5 4486,-512.5 4492,-518.5 4492,-524.5 4492,-524.5 4492,-553.5 4492,-553.5 4492,-559.5 4486,-565.5 4480,-565.5\"/>\n<text text-anchor=\"start\" x=\"4414.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4404\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"4403\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 0]</text>\n</g>\n<!-- 253&#45;&gt;254 -->\n<g id=\"edge254\" class=\"edge\">\n<title>253&#45;&gt;254</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4506.98,-608.88C4496.44,-597.45 4484.63,-584.63 4474.09,-573.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4476.37,-570.5 4467.02,-565.52 4471.22,-575.25 4476.37,-570.5\"/>\n</g>\n<!-- 255 -->\n<g id=\"node256\" class=\"node\">\n<title>255</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M4596.5,-573C4596.5,-573 4522.5,-573 4522.5,-573 4516.5,-573 4510.5,-567 4510.5,-561 4510.5,-561 4510.5,-517 4510.5,-517 4510.5,-511 4516.5,-505 4522.5,-505 4522.5,-505 4596.5,-505 4596.5,-505 4602.5,-505 4608.5,-511 4608.5,-517 4608.5,-517 4608.5,-561 4608.5,-561 4608.5,-567 4602.5,-573 4596.5,-573\"/>\n<text text-anchor=\"start\" x=\"4518.5\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 1.566</text>\n<text text-anchor=\"start\" x=\"4522\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"4520\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"4519\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 1]</text>\n</g>\n<!-- 253&#45;&gt;255 -->\n<g id=\"edge255\" class=\"edge\">\n<title>253&#45;&gt;255</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4544.64,-608.88C4546.41,-600.69 4548.33,-591.79 4550.18,-583.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4553.63,-583.81 4552.32,-573.3 4546.79,-582.34 4553.63,-583.81\"/>\n</g>\n<!-- 256 -->\n<g id=\"node257\" class=\"node\">\n<title>256</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4509,-461.5C4509,-461.5 4436,-461.5 4436,-461.5 4430,-461.5 4424,-455.5 4424,-449.5 4424,-449.5 4424,-420.5 4424,-420.5 4424,-414.5 4430,-408.5 4436,-408.5 4436,-408.5 4509,-408.5 4509,-408.5 4515,-408.5 4521,-414.5 4521,-420.5 4521,-420.5 4521,-449.5 4521,-449.5 4521,-455.5 4515,-461.5 4509,-461.5\"/>\n<text text-anchor=\"start\" x=\"4443.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4433\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"4432\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 255&#45;&gt;256 -->\n<g id=\"edge256\" class=\"edge\">\n<title>255&#45;&gt;256</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4531.25,-504.88C4521.5,-493.45 4510.57,-480.63 4500.81,-469.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4503.42,-466.86 4494.27,-461.52 4498.09,-471.4 4503.42,-466.86\"/>\n</g>\n<!-- 257 -->\n<g id=\"node258\" class=\"node\">\n<title>257</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4624,-461.5C4624,-461.5 4551,-461.5 4551,-461.5 4545,-461.5 4539,-455.5 4539,-449.5 4539,-449.5 4539,-420.5 4539,-420.5 4539,-414.5 4545,-408.5 4551,-408.5 4551,-408.5 4624,-408.5 4624,-408.5 4630,-408.5 4636,-414.5 4636,-420.5 4636,-420.5 4636,-449.5 4636,-449.5 4636,-455.5 4630,-461.5 4624,-461.5\"/>\n<text text-anchor=\"start\" x=\"4558.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4548\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"4547\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 255&#45;&gt;257 -->\n<g id=\"edge257\" class=\"edge\">\n<title>255&#45;&gt;257</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4568.59,-504.88C4571.55,-494.11 4574.84,-482.11 4577.84,-471.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4581.22,-472.09 4580.49,-461.52 4574.47,-470.24 4581.22,-472.09\"/>\n</g>\n<!-- 261 -->\n<g id=\"node262\" class=\"node\">\n<title>261</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4806,-773.5C4806,-773.5 4733,-773.5 4733,-773.5 4727,-773.5 4721,-767.5 4721,-761.5 4721,-761.5 4721,-732.5 4721,-732.5 4721,-726.5 4727,-720.5 4733,-720.5 4733,-720.5 4806,-720.5 4806,-720.5 4812,-720.5 4818,-726.5 4818,-732.5 4818,-732.5 4818,-761.5 4818,-761.5 4818,-767.5 4812,-773.5 4806,-773.5\"/>\n<text text-anchor=\"start\" x=\"4740.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4730\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"4729\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 260&#45;&gt;261 -->\n<g id=\"edge261\" class=\"edge\">\n<title>260&#45;&gt;261</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4769.5,-816.88C4769.5,-806.33 4769.5,-794.6 4769.5,-783.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4773,-783.52 4769.5,-773.52 4766,-783.52 4773,-783.52\"/>\n</g>\n<!-- 262 -->\n<g id=\"node263\" class=\"node\">\n<title>262</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4921,-773.5C4921,-773.5 4848,-773.5 4848,-773.5 4842,-773.5 4836,-767.5 4836,-761.5 4836,-761.5 4836,-732.5 4836,-732.5 4836,-726.5 4842,-720.5 4848,-720.5 4848,-720.5 4921,-720.5 4921,-720.5 4927,-720.5 4933,-726.5 4933,-732.5 4933,-732.5 4933,-761.5 4933,-761.5 4933,-767.5 4927,-773.5 4921,-773.5\"/>\n<text text-anchor=\"start\" x=\"4855.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4845\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"4844\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\n</g>\n<!-- 260&#45;&gt;262 -->\n<g id=\"edge262\" class=\"edge\">\n<title>260&#45;&gt;262</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4806.84,-816.88C4820.1,-805.12 4835.01,-791.89 4848.19,-780.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4850.57,-782.77 4855.73,-773.52 4845.92,-777.54 4850.57,-782.77\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": "<graphviz.sources.Source at 0x28d0fb6eb30>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(dt, out_file=None,\n",
    "                      feature_names=X_train.loc[:, X_train.columns != 'PassengerId'].columns,\n",
    "                      filled=True, rounded=True,\n",
    "                      special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, the complexity of the tree is very large. Perhaps this is also why it is not good at modeling data and making good predictions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### K Nearest Neighbor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.856      0.848      0.84677419 0.83870968 0.83870968]\n",
      "0.8456387096774194\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "cv = cross_val_score(knn,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I wasn't expecting good accuracies like this. In fact, I believed that the algorithm would have made it difficult to define which were the closest points. In fact, having a 38-dimensional space, I didn't think it was easy to define the distance between points in space."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.832      0.848      0.86290323 0.83064516 0.7983871 ]\n",
      "0.8343870967741935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state = 1)\n",
    "cv = cross_val_score(rf,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7865168539325843"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(y_pred, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Support vector machine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84       0.864      0.81451613 0.83870968 0.83064516]\n",
      "0.8375741935483871\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(probability=True)\n",
    "cv = cross_val_score(svc,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8127340823970037"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svc.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(y_pred, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### XGboost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.792      0.808      0.87096774 0.84677419 0.81451613]\n",
      "0.8264516129032259\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "cv = cross_val_score(xgb,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Voting classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(estimators = [('lr',lr),('knn',knn),('rf',rf),('gnb',gnb),('svm',svc),('xgb',xgb)], voting = 'soft')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cv = cross_val_score(voting_clf,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.832      0.872      0.84677419 0.84677419 0.83064516]\n",
      "0.8456387096774194\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This method consists in having the various models vote. I expected it to be the best because different models can and are able to capture information other than data. I compensate each other for the shortcomings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8014981273408239"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "p_v = voting_clf.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(p_v, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we try it with the test data, perhaps we see that this voting model goes into overfitting a bit."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### GridSearch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "from utils import clf_performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "param_grid_lr = {'max_iter' : [2000],\n",
    "              'penalty' : ['l1', 'l2'],\n",
    "              'C' : np.logspace(-4, 4, 20),\n",
    "              'solver' : ['liblinear']}\n",
    "\n",
    "param_grid_knn = {'n_neighbors' : [3,5,7,9],\n",
    "              'weights' : ['uniform', 'distance'],\n",
    "              'algorithm' : ['auto', 'ball_tree','kd_tree'],\n",
    "              'p' : [1,2]}\n",
    "\n",
    "param_grid_svc = tuned_parameters = [{'kernel': ['rbf'], 'gamma': [.1,.5,1,2,5,10],\n",
    "                                  'C': [.1, 1, 10, 100, 1000]},\n",
    "                                 {'kernel': ['linear'], 'C': [.1, 1, 10, 100, 1000]},\n",
    "                                 {'kernel': ['poly'], 'degree' : [2,3,4,5], 'C': [.1, 1, 10, 100, 1000]}]\n",
    "\n",
    "param_grid_rf =  {'n_estimators': [100,500,1000],\n",
    "                                  'bootstrap': [True,False],\n",
    "                                  'max_depth': [3,5,10,20,50,75,100,None],\n",
    "                                  'max_features': ['auto','sqrt'],\n",
    "                                  'min_samples_leaf': [1,2,4,10],\n",
    "                                  'min_samples_split': [2,5,10]}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [20, 50, 100, 250, 500,1000],\n",
    "    'colsample_bytree': [0.2, 0.5, 0.7, 0.8, 1],\n",
    "    'max_depth': [2, 5, 10, 15, 20, 25, None],\n",
    "    'reg_alpha': [0, 0.5, 1],\n",
    "    'reg_lambda': [1, 1.5, 2],\n",
    "    'subsample': [0.5,0.6,0.7, 0.8, 0.9],\n",
    "    'learning_rate':[.01,0.1,0.2,0.3,0.5, 0.7, 0.9],\n",
    "    'gamma':[0,.01,.1,1,10,100],\n",
    "    'min_child_weight':[0,.01,0.1,1,10,100],\n",
    "    'sampling_method': ['uniform', 'gradient_based']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "lr_g = LogisticRegression()\n",
    "knn_g = KNeighborsClassifier()\n",
    "svc_g = SVC(probability = True)\n",
    "rf_g = RandomForestClassifier(random_state = 1)\n",
    "xgb_g = XGBClassifier(random_state = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Logistic Regression\n",
      "Best Score: 0.8295354838709678\n",
      "Best Parameters: {'C': 1.623776739188721, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "clf_lr = GridSearchCV(lr_g, param_grid = param_grid_lr, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_lr = clf_lr.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_lr,'Logistic Regression')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "KNN\n",
      "Best Score: 0.8552645161290323\n",
      "Best Parameters: {'algorithm': 'auto', 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "clf_knn = GridSearchCV(knn_g, param_grid = param_grid_knn, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_knn = clf_knn.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_knn,'KNN')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7752808988764045"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_best = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 5, p= 1, weights= 'uniform')\n",
    "knn_best.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "\n",
    "y_pred_best_knn = knn_best.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(y_pred_best_knn, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "SVC\n",
      "Best Score: 0.8472645161290323\n",
      "Best Parameters: {'C': 1, 'gamma': 0.5, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "clf_svc = GridSearchCV(svc_g, param_grid = param_grid_svc, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_svc = clf_svc.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_svc,'SVC')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "0.797752808988764"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_best = SVC(C= 1, gamma= 0.5, kernel= 'rbf')\n",
    "svc_best.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "\n",
    "y_pred_best = svc_best.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(y_pred_best, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Random Forest\n",
      "Best Score: 0.8681290322580646\n",
      "Best Parameters: {'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 50, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "clf_rf_rnd = RandomizedSearchCV(rf_g, param_distributions = param_grid_rf, n_iter = 100, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_rf_rnd = clf_rf_rnd.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_rf_rnd,'Random Forest')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1152 candidates, totalling 5760 fits\n",
      "Random Forest\n",
      "Best Score: 0.868141935483871\n",
      "Best Parameters: {'bootstrap': False, 'max_depth': 50, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "clf_rf = GridSearchCV(rf_g, param_grid = param_grid_rf, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_rf = clf_rf.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_rf,'Random Forest')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8014981273408239"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_best = RandomForestClassifier(bootstrap= False, max_depth= 50, max_features= 'auto', min_samples_leaf= 2, min_samples_split= 10, n_estimators= 500)\n",
    "rf_best.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "pred_rf_best = rf_best.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(pred_rf_best, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(rf_best.feature_importances_, index=X_train.loc[:, X_train.columns != 'PassengerId'].columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n",
      "XGB\n",
      "Best Score: 0.860116129032258\n",
      "Best Parameters: {'subsample': 0.8, 'sampling_method': 'uniform', 'reg_lambda': 1, 'reg_alpha': 0, 'n_estimators': 20, 'min_child_weight': 0.01, 'max_depth': 25, 'learning_rate': 0.3, 'gamma': 1, 'colsample_bytree': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2460 fits failed out of a total of 5000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:44] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:45] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:46] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:48] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:49] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:50] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "55 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:51] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "11 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:53] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:52] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:58] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:54] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:56] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "17 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:00] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "36 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:01] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:03] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:57] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [13:59:59] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "23 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:12] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:02] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:04] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:05] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:06] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:07] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:09] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:11] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:14] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:17] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:15] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:18] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "23 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:19] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:20] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "41 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:21] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:26] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:23] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:22] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "34 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:24] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "17 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:28] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:25] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:29] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:30] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:32] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "19 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:33] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "26 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:34] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:35] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "17 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:38] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:36] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:37] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:39] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:40] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:57] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:41] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:42] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "19 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:05] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:44] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:45] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:46] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:48] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "23 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:49] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:50] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:51] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:54] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:00:59] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:00] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:02] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:04] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "29 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:09] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "19 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:07] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:12] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:10] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:11] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:13] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:14] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:15] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:17] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:18] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:20] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:19] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:21] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:22] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:23] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:24] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:25] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:26] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:28] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:29] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:31] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:32] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:33] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:35] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:36] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:37] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:38] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:40] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:41] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:43] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:44] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:45] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:46] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:47] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:49] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:48] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:50] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:51] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:53] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "29 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:54] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:56] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:58] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:01:59] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:00] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:02] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "36 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:03] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:04] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:07] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:05] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:08] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:09] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:10] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:11] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:12] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:13] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:14] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:15] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:18] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:21] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:19] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:20] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:22] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:24] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:25] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:26] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:29] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:30] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "11 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:31] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:32] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:33] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:34] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "64 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:35] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:36] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "26 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:37] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:38] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:39] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:40] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:46] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:41] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:44] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:45] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:47] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:48] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:49] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:50] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:52] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:53] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:54] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:55] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:56] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:57] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:02:59] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:00] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:01] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "26 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:02] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:03] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:04] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:05] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:06] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:07] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:14] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:16] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:17] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:18] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:19] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:24] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:20] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:22] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:23] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "11 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:25] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:28] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:27] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:29] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:32] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:33] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:34] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:35] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:36] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:37] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:38] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:39] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [14:03:40] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.61414194        nan 0.78616774        nan 0.8424129  0.8215871\n",
      " 0.61414194 0.80864516        nan        nan 0.82323871 0.81190968\n",
      " 0.61414194        nan 0.71544516        nan 0.85206452 0.79256774\n",
      "        nan 0.8263871         nan 0.82962581 0.83443871        nan\n",
      " 0.81825806        nan        nan 0.84729032        nan 0.61414194\n",
      "        nan 0.82802581        nan        nan        nan        nan\n",
      "        nan        nan 0.68027097        nan 0.81996129        nan\n",
      "        nan        nan        nan        nan 0.8248129         nan\n",
      " 0.82477419 0.61414194        nan 0.81349677        nan 0.85370323\n",
      "        nan        nan 0.8280129         nan        nan        nan\n",
      " 0.84566452        nan 0.61414194        nan        nan 0.83443871\n",
      "        nan        nan 0.81192258        nan        nan 0.61414194\n",
      "        nan 0.61414194        nan        nan        nan 0.83446452\n",
      "        nan 0.85212903 0.82309677        nan        nan        nan\n",
      "        nan 0.61414194 0.8296     0.81836129        nan 0.84723871\n",
      "        nan        nan 0.61414194 0.80704516 0.84563871        nan\n",
      "        nan 0.81027097        nan        nan 0.81665806        nan\n",
      " 0.8136     0.84087742 0.61414194        nan        nan        nan\n",
      " 0.84729032        nan 0.85852903        nan 0.83437419 0.61414194\n",
      " 0.61414194        nan        nan 0.83762581 0.61414194 0.8263871\n",
      "        nan 0.79096774        nan        nan        nan 0.78778065\n",
      "        nan        nan 0.61414194 0.80869677 0.83597419        nan\n",
      " 0.84889032 0.61414194        nan 0.80060645 0.82323871 0.8376\n",
      "        nan 0.82962581        nan        nan        nan        nan\n",
      " 0.81514839 0.61414194 0.82308387 0.80379355 0.84562581        nan\n",
      " 0.80864516        nan 0.81343226 0.83277419        nan        nan\n",
      "        nan        nan 0.61414194 0.61414194 0.8408129         nan\n",
      " 0.82634839        nan        nan 0.80864516        nan        nan\n",
      "        nan 0.84406452 0.78932903        nan        nan 0.84403871\n",
      " 0.82962581        nan 0.82323871 0.82642581        nan 0.81670968\n",
      " 0.83929032        nan 0.84083871 0.85369032        nan 0.81989677\n",
      " 0.84243871        nan        nan        nan        nan 0.83117419\n",
      " 0.61414194        nan 0.80865806        nan        nan 0.83443871\n",
      " 0.82802581        nan        nan 0.61414194 0.61414194 0.85531613\n",
      " 0.84249032 0.81988387 0.82794839        nan        nan        nan\n",
      " 0.8311871         nan 0.82963871        nan 0.83442581 0.82474839\n",
      " 0.81353548        nan        nan 0.61414194 0.83285161        nan\n",
      "        nan 0.82152258 0.80545806 0.80219355 0.83763871 0.6480129\n",
      "        nan        nan 0.77661935        nan        nan        nan\n",
      "        nan        nan 0.80705806 0.81833548        nan        nan\n",
      "        nan 0.82803871        nan 0.83765161 0.78616774 0.83930323\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.61414194        nan 0.82156129\n",
      " 0.82633548 0.83116129 0.61414194        nan        nan        nan\n",
      "        nan        nan 0.61414194 0.85046452 0.61414194        nan\n",
      "        nan        nan        nan        nan 0.81664516 0.78616774\n",
      "        nan        nan 0.82314839 0.61414194        nan 0.81836129\n",
      " 0.83762581        nan 0.61414194        nan        nan        nan\n",
      " 0.61414194        nan 0.83765161        nan 0.8375871  0.8424\n",
      "        nan 0.61414194        nan        nan        nan        nan\n",
      "        nan 0.80550968 0.80381935        nan        nan 0.82803871\n",
      " 0.81505806 0.61414194 0.84889032 0.84087742        nan 0.8295871\n",
      " 0.81509677 0.84089032        nan 0.83766452 0.81027097 0.61414194\n",
      "        nan        nan 0.82802581        nan        nan 0.84886452\n",
      "        nan 0.80876129        nan 0.82802581 0.8296            nan\n",
      "        nan        nan 0.82962581 0.83286452 0.61414194        nan\n",
      " 0.78287742        nan        nan        nan        nan 0.61414194\n",
      "        nan 0.83603871        nan 0.81989677        nan 0.81834839\n",
      "        nan 0.61414194        nan 0.61414194 0.61414194 0.84249032\n",
      "        nan 0.82473548        nan        nan 0.81343226        nan\n",
      " 0.83442581        nan        nan        nan 0.8472129         nan\n",
      " 0.8376129         nan        nan 0.79411613 0.80864516        nan\n",
      " 0.82956129 0.61414194 0.84567742 0.83756129 0.79579355        nan\n",
      " 0.8264            nan        nan        nan        nan 0.81667097\n",
      " 0.82153548 0.84727742        nan        nan        nan 0.61414194\n",
      "        nan 0.80383226        nan        nan        nan        nan\n",
      " 0.61414194        nan 0.83283871        nan 0.61414194 0.61414194\n",
      "        nan        nan        nan        nan 0.8280129         nan\n",
      "        nan 0.79096774 0.78294194        nan 0.81829677 0.61414194\n",
      "        nan 0.68294194        nan 0.82474839        nan 0.81188387\n",
      "        nan 0.78294194        nan 0.8328129  0.61414194 0.61414194\n",
      "        nan        nan 0.82003871        nan 0.82153548        nan\n",
      " 0.84887742 0.61414194 0.81033548 0.78616774        nan        nan\n",
      "        nan        nan 0.61414194 0.8247871  0.8247871  0.61414194\n",
      "        nan        nan 0.61414194        nan        nan        nan\n",
      "        nan        nan 0.8264     0.83445161        nan        nan\n",
      " 0.61414194 0.61414194        nan 0.8247871  0.8247871         nan\n",
      "        nan        nan        nan        nan 0.83282581 0.85371613\n",
      "        nan        nan 0.8215871         nan        nan 0.83285161\n",
      "        nan        nan        nan 0.81507097 0.8232     0.82317419\n",
      "        nan 0.86011613        nan        nan 0.79416774 0.84411613\n",
      " 0.82954839        nan        nan 0.82314839 0.84249032 0.79096774\n",
      " 0.81997419        nan 0.84249032 0.78616774 0.83443871        nan\n",
      "        nan 0.61414194 0.81187097 0.85211613 0.61414194        nan\n",
      "        nan        nan 0.81984516        nan 0.81023226 0.61414194\n",
      "        nan        nan        nan 0.84566452        nan 0.85210323\n",
      " 0.81025806        nan 0.85690323 0.8264129         nan        nan\n",
      "        nan 0.84729032        nan 0.83122581 0.61414194        nan\n",
      " 0.79418065 0.84247742 0.61414194 0.81357419        nan 0.82312258\n",
      " 0.61414194        nan        nan        nan 0.8184            nan\n",
      "        nan        nan 0.61414194 0.8279871         nan        nan\n",
      "        nan        nan 0.84725161 0.79415484 0.8440129  0.80060645\n",
      "        nan        nan        nan 0.84406452 0.8247871  0.8344\n",
      "        nan        nan 0.81343226 0.84406452 0.83926452 0.81505806\n",
      " 0.81505806 0.83766452        nan        nan        nan        nan\n",
      "        nan 0.83286452        nan 0.79735484        nan        nan\n",
      "        nan        nan        nan 0.84245161 0.85527742 0.82472258\n",
      "        nan 0.61414194        nan 0.84245161 0.81989677        nan\n",
      "        nan 0.79736774 0.83926452 0.81664516        nan 0.61414194\n",
      "        nan        nan 0.61414194        nan 0.81352258        nan\n",
      " 0.81348387        nan 0.75256774 0.81507097 0.82953548 0.85371613\n",
      " 0.61414194        nan 0.83603871 0.8328            nan 0.82152258\n",
      "        nan        nan 0.74584516        nan 0.82642581        nan\n",
      "        nan 0.82157419        nan        nan        nan 0.84249032\n",
      "        nan 0.82154839 0.61414194        nan 0.84407742 0.80221935\n",
      " 0.82632258 0.85049032        nan        nan        nan 0.82805161\n",
      " 0.61414194        nan 0.85049032 0.65254194        nan        nan\n",
      "        nan 0.61414194 0.81513548 0.84729032 0.61414194        nan\n",
      "        nan 0.61414194 0.82645161 0.61414194        nan 0.61414194\n",
      " 0.61414194 0.8312     0.83925161        nan 0.61414194 0.81988387\n",
      "        nan 0.61414194        nan 0.82634839 0.82645161        nan\n",
      " 0.83110968        nan 0.82314839 0.84891613 0.84725161 0.79578065\n",
      "        nan 0.84567742 0.83765161 0.6480129  0.61414194        nan\n",
      "        nan 0.79739355 0.82634839        nan        nan 0.61414194\n",
      "        nan        nan        nan 0.82314839 0.83923871 0.79418065\n",
      " 0.61414194        nan 0.81512258        nan        nan        nan\n",
      "        nan 0.81837419        nan 0.81665806        nan        nan\n",
      "        nan        nan        nan        nan 0.83446452        nan\n",
      "        nan        nan        nan        nan 0.8344            nan\n",
      "        nan 0.8328129  0.84569032        nan        nan        nan\n",
      "        nan 0.78775484 0.81837419        nan 0.61414194        nan\n",
      " 0.61414194 0.82633548        nan        nan 0.79259355        nan\n",
      "        nan 0.61414194 0.61414194        nan 0.78612903 0.61414194\n",
      " 0.61414194        nan        nan        nan        nan 0.82157419\n",
      "        nan        nan 0.79579355 0.81989677        nan 0.82310968\n",
      "        nan        nan 0.61414194        nan 0.79579355        nan\n",
      " 0.81507097        nan        nan 0.83437419 0.8263871         nan\n",
      " 0.83283871        nan 0.79899355        nan        nan 0.85529032\n",
      "        nan        nan 0.8344     0.61414194 0.84407742        nan\n",
      "        nan 0.81668387 0.82153548        nan 0.83282581 0.81023226\n",
      " 0.61414194        nan 0.61414194        nan 0.82156129        nan\n",
      "        nan 0.61414194 0.61414194        nan        nan 0.61414194\n",
      " 0.85689032        nan        nan 0.61414194        nan        nan\n",
      "        nan        nan 0.85210323 0.81837419 0.84087742 0.79096774\n",
      " 0.82476129 0.61414194        nan 0.84409032 0.61414194 0.61414194\n",
      " 0.82794839 0.61414194        nan        nan        nan        nan\n",
      " 0.78616774 0.61414194 0.78938065 0.82803871        nan 0.82312258\n",
      "        nan        nan        nan        nan        nan 0.8279871\n",
      "        nan        nan        nan 0.61414194 0.82482581        nan\n",
      " 0.84730323 0.82150968        nan 0.61414194        nan        nan\n",
      " 0.82952258        nan        nan        nan 0.78616774 0.78294194\n",
      "        nan        nan        nan        nan 0.61414194 0.78616774\n",
      "        nan 0.81994839        nan        nan 0.8520129  0.81828387\n",
      "        nan        nan 0.84727742        nan        nan 0.82953548\n",
      " 0.82797419 0.85527742 0.83606452        nan 0.78610323        nan\n",
      "        nan 0.61414194 0.82153548 0.6783871  0.81192258 0.84885161\n",
      " 0.78616774 0.78616774 0.83274839 0.83925161 0.61414194        nan\n",
      " 0.84082581        nan 0.61414194 0.61414194 0.61414194 0.83445161\n",
      "        nan 0.81992258 0.828             nan 0.64934194        nan\n",
      " 0.61414194 0.81832258        nan 0.83122581        nan        nan\n",
      "        nan 0.61414194        nan 0.78616774        nan 0.61414194\n",
      " 0.8295871         nan        nan        nan 0.85210323 0.8456\n",
      " 0.61414194        nan        nan        nan        nan        nan\n",
      " 0.78294194 0.61414194 0.82637419        nan        nan        nan\n",
      "        nan 0.61414194 0.81025806        nan 0.8376            nan\n",
      " 0.80383226 0.82154839 0.81510968 0.61414194 0.8232129         nan\n",
      " 0.80383226 0.74584516        nan 0.61414194 0.8392     0.82152258\n",
      "        nan 0.61414194 0.71064516 0.84892903 0.61414194 0.84077419\n",
      " 0.85529032 0.84083871        nan        nan        nan 0.81030968\n",
      "        nan        nan 0.81185806        nan 0.61414194 0.8296\n",
      "        nan 0.6447871  0.78932903 0.61414194 0.82953548        nan\n",
      " 0.84889032 0.82472258        nan 0.8168            nan 0.8392129\n",
      " 0.79096774 0.80704516        nan 0.61414194 0.84727742        nan\n",
      " 0.8184     0.84731613 0.85372903        nan        nan 0.79256774\n",
      " 0.61414194 0.61414194        nan        nan        nan 0.61414194\n",
      "        nan        nan        nan        nan 0.61414194 0.84410323\n",
      " 0.61414194 0.61414194 0.77487742 0.8183871 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf_xgb_rnd = RandomizedSearchCV(xgb_g, param_distributions = param_grid_xgb, n_iter = 1000, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_xgb_rnd = clf_xgb_rnd.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_xgb_rnd,'XGB')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "XGB\n",
      "Best Score: 0.8537161290322581\n",
      "Best Parameters: {'colsample_bytree': 0.85, 'gamma': 1, 'learning_rate': 0.5, 'max_depth': None, 'min_child_weight': 0.01, 'n_estimators': 550, 'reg_alpha': 1, 'reg_lambda': 10, 'sampling_method': 'uniform', 'subsample': 0.65}\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state = 1)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [450,500,550],\n",
    "    'colsample_bytree': [0.75,0.8,0.85],\n",
    "    'max_depth': [None],\n",
    "    'reg_alpha': [1],\n",
    "    'reg_lambda': [2, 5, 10],\n",
    "    'subsample': [0.55, 0.6, .65],\n",
    "    'learning_rate':[0.5],\n",
    "    'gamma':[.5,1,2],\n",
    "    'min_child_weight':[0.01],\n",
    "    'sampling_method': ['uniform']\n",
    "}\n",
    "\n",
    "clf_xgb = GridSearchCV(xgb, param_grid = param_grid, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_xgb = clf_xgb.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_xgb,'XGB')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:07:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"colsample_bytre\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8014981273408239"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_best = XGBClassifier(colsample_bytre= 0.75, gamma= 1, learning_rate= 0.5, max_depth= None, min_child_weight= 0.01, n_estimators= 450, reg_alpha= 1, reg_lambda= 5, sampling_method= 'uniform', subsample= 0.6)\n",
    "xgb_best.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "\n",
    "y_pred_best_xgb = xgb_best.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(y_pred_best_xgb, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "\"clf_xgb = GridSearchCV(xgb_g, param_grid = param_grid_xgb, cv = 5, verbose = True, n_jobs = -1)\\nbest_clf_xgb = clf_xgb.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\\nclf_performance(best_clf_xgb,'XGB')\""
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"clf_xgb = GridSearchCV(xgb_g, param_grid = param_grid_xgb, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_xgb = clf_xgb.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_xgb,'XGB')\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "best_lr = best_clf_lr.best_estimator_\n",
    "best_knn = best_clf_knn.best_estimator_\n",
    "best_svc = best_clf_svc.best_estimator_\n",
    "best_rf = best_clf_rf.best_estimator_\n",
    "best_xgb = best_clf_xgb_rnd.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "voting_clf_hard = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc)], voting = 'hard')\n",
    "voting_clf_soft = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc)], voting = 'soft')\n",
    "voting_clf_all = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc), ('lr', best_lr)], voting = 'soft')\n",
    "voting_clf_xgb = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc), ('xgb', best_xgb),('lr', best_lr)], voting = 'soft')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting_clf_hard : [0.72       0.688      0.75       0.68548387 0.72580645]\n",
      "voting_clf_hard mean : 0.7138580645161291\n",
      "voting_clf_soft : [0.816      0.808      0.7983871  0.75       0.79032258]\n",
      "voting_clf_soft mean : 0.7893419354838709\n",
      "voting_clf_all : [0.832      0.856      0.83870968 0.83064516 0.7983871 ]\n",
      "voting_clf_all mean : 0.8311483870967742\n",
      "voting_clf_xgb : [0.848      0.856      0.84677419 0.85483871 0.84677419]\n",
      "voting_clf_xgb mean : 0.8504774193548388\n"
     ]
    }
   ],
   "source": [
    "print('voting_clf_hard :',cross_val_score(voting_clf_hard,X_train,y_train,cv=5))\n",
    "print('voting_clf_hard mean :',cross_val_score(voting_clf_hard,X_train,y_train,cv=5).mean())\n",
    "\n",
    "print('voting_clf_soft :',cross_val_score(voting_clf_soft,X_train,y_train,cv=5))\n",
    "print('voting_clf_soft mean :',cross_val_score(voting_clf_soft,X_train,y_train,cv=5).mean())\n",
    "\n",
    "print('voting_clf_all :',cross_val_score(voting_clf_all,X_train,y_train,cv=5))\n",
    "print('voting_clf_all mean :',cross_val_score(voting_clf_all,X_train,y_train,cv=5).mean())\n",
    "\n",
    "print('voting_clf_xgb :',cross_val_score(voting_clf_xgb,X_train,y_train,cv=5))\n",
    "print('voting_clf_xgb mean :',cross_val_score(voting_clf_xgb,X_train,y_train,cv=5).mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "params_voting = {'weights' : [[1,1,1,1,1],[1,1,1,1,2],[1,1,1,2,2],[1,1,2,2,2],[1,2,2,2,2],\n",
    "                              [3,4,2,3,1]]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "VC Weights\n",
      "Best Score: 0.8552774193548387\n",
      "Best Parameters: {'weights': [3, 4, 2, 3, 1]}\n"
     ]
    }
   ],
   "source": [
    "vote_weight = GridSearchCV(voting_clf_xgb, param_grid = params_voting, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_weight = vote_weight.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_weight,'VC Weights')\n",
    "voting_clf_sub = best_clf_weight.best_estimator_.predict(X_test.loc[:, X_test.columns != 'PassengerId'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7902621722846442"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf_best = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc), ('xgb', best_xgb),('lr', best_lr)], voting = 'soft', weights=[3,4,2,3,1])\n",
    "voting_clf_best.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "p_v_best = voting_clf_best.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(p_v_best, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The weights chosen as the best are the ones I entered by hand. In fact, looking at the performance of the various models from the cells above, I gave a greater weight to the best models and a lesser weight to the models that had earlier had lower accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### At the end the best model is the xgb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deep learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section I try to implement some simple neural networks in keras. I don't expect good performance because neural networks are too complex for this task and will likely overfit the model right away. In any case it is necessary to do some tests."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "keras_classifier = Sequential()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "keras_classifier.add(Dense(16, input_dim=X_train.shape[1]-1, kernel_initializer='uniform', activation='relu'))\n",
    "keras_classifier.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "keras_classifier.add(Dense(4, kernel_initializer='uniform', activation='relu'))\n",
    "keras_classifier.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "keras_classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 0s 751us/step - loss: 0.6923 - accuracy: 0.5981\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6904 - accuracy: 0.6141\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.6141\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 843us/step - loss: 0.6873 - accuracy: 0.6141\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 783us/step - loss: 0.6857 - accuracy: 0.6141\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x28d2144e500>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_classifier.fit(X_train.loc[:, X_train.columns != 'PassengerId'], y_train, epochs = 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "#keras_prediction = keras_classifier.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "#k_pred = np.rint(keras_prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "#accuracy_score(k_pred, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.6255\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.6841917037963867, 0.6254681944847107]"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_classifier.evaluate(X_test.loc[:, X_test.columns != 'PassengerId'], y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### keras 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "20/20 [==============================] - 0s 554us/step - loss: 0.6923 - accuracy: 0.5852\n",
      "Epoch 2/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.6141\n",
      "Epoch 3/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6806 - accuracy: 0.6158\n",
      "Epoch 4/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6594 - accuracy: 0.6511\n",
      "Epoch 5/25\n",
      "20/20 [==============================] - 0s 985us/step - loss: 0.6190 - accuracy: 0.7122\n",
      "Epoch 6/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7219\n",
      "Epoch 7/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5234 - accuracy: 0.7717\n",
      "Epoch 8/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4891 - accuracy: 0.8023\n",
      "Epoch 9/25\n",
      "20/20 [==============================] - 0s 385us/step - loss: 0.4622 - accuracy: 0.8039\n",
      "Epoch 10/25\n",
      "20/20 [==============================] - 0s 648us/step - loss: 0.4454 - accuracy: 0.7990\n",
      "Epoch 11/25\n",
      "20/20 [==============================] - 0s 825us/step - loss: 0.4340 - accuracy: 0.8023\n",
      "Epoch 12/25\n",
      "20/20 [==============================] - 0s 862us/step - loss: 0.4251 - accuracy: 0.8039\n",
      "Epoch 13/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4196 - accuracy: 0.8103\n",
      "Epoch 14/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8167\n",
      "Epoch 15/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4121 - accuracy: 0.8167\n",
      "Epoch 16/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8264\n",
      "Epoch 17/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4054 - accuracy: 0.8264\n",
      "Epoch 18/25\n",
      "20/20 [==============================] - 0s 836us/step - loss: 0.4022 - accuracy: 0.8296\n",
      "Epoch 19/25\n",
      "20/20 [==============================] - 0s 835us/step - loss: 0.4017 - accuracy: 0.8296\n",
      "Epoch 20/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4005 - accuracy: 0.8264\n",
      "Epoch 21/25\n",
      "20/20 [==============================] - 0s 732us/step - loss: 0.3982 - accuracy: 0.8312\n",
      "Epoch 22/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8328\n",
      "Epoch 23/25\n",
      "20/20 [==============================] - 0s 836us/step - loss: 0.3986 - accuracy: 0.8296\n",
      "Epoch 24/25\n",
      "20/20 [==============================] - 0s 858us/step - loss: 0.3950 - accuracy: 0.8360\n",
      "Epoch 25/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3955 - accuracy: 0.8312\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x28d2272f370>"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_classifier2 = Sequential()\n",
    "\n",
    "keras_classifier2.add(Dense(16, input_dim=X_train.shape[1]-1, kernel_initializer='uniform', activation='relu'))\n",
    "keras_classifier2.add(Dense(6, kernel_initializer='uniform', activation='relu'))\n",
    "keras_classifier2.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "keras_classifier2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "keras_classifier2.fit(X_train.loc[:, X_train.columns != 'PassengerId'], y_train, epochs =25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 0s/step - loss: 0.4442 - accuracy: 0.8052\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.44424349069595337, 0.8052434325218201]"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_classifier2.evaluate(X_test.loc[:, X_test.columns != 'PassengerId'], y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### keras 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.6141\n",
      "Epoch 2/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7476\n",
      "Epoch 3/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7974\n",
      "Epoch 4/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8215\n",
      "Epoch 5/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4134 - accuracy: 0.8280\n",
      "Epoch 6/25\n",
      "20/20 [==============================] - 0s 874us/step - loss: 0.4048 - accuracy: 0.8312\n",
      "Epoch 7/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8392\n",
      "Epoch 8/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8424\n",
      "Epoch 9/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3921 - accuracy: 0.8376\n",
      "Epoch 10/25\n",
      "20/20 [==============================] - 0s 823us/step - loss: 0.4016 - accuracy: 0.8392\n",
      "Epoch 11/25\n",
      "20/20 [==============================] - 0s 828us/step - loss: 0.4009 - accuracy: 0.8376\n",
      "Epoch 12/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3945 - accuracy: 0.8360\n",
      "Epoch 13/25\n",
      "20/20 [==============================] - 0s 917us/step - loss: 0.3926 - accuracy: 0.8376\n",
      "Epoch 14/25\n",
      "20/20 [==============================] - 0s 864us/step - loss: 0.3917 - accuracy: 0.8408\n",
      "Epoch 15/25\n",
      "20/20 [==============================] - 0s 826us/step - loss: 0.3901 - accuracy: 0.8408\n",
      "Epoch 16/25\n",
      "20/20 [==============================] - 0s 756us/step - loss: 0.3874 - accuracy: 0.8376\n",
      "Epoch 17/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3885 - accuracy: 0.8328\n",
      "Epoch 18/25\n",
      "20/20 [==============================] - 0s 881us/step - loss: 0.3901 - accuracy: 0.8360\n",
      "Epoch 19/25\n",
      "20/20 [==============================] - 0s 823us/step - loss: 0.3896 - accuracy: 0.8457\n",
      "Epoch 20/25\n",
      "20/20 [==============================] - 0s 701us/step - loss: 0.3841 - accuracy: 0.8424\n",
      "Epoch 21/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8408\n",
      "Epoch 22/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8376\n",
      "Epoch 23/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3814 - accuracy: 0.8457\n",
      "Epoch 24/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3839 - accuracy: 0.8392\n",
      "Epoch 25/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3797 - accuracy: 0.8376\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x28d23846890>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_classifier3 = Sequential()\n",
    "\n",
    "keras_classifier3.add(Dense(10, input_dim=X_train.shape[1]-1, kernel_initializer='uniform', activation='relu'))\n",
    "keras_classifier3.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "keras_classifier3.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "keras_classifier3.fit(X_train.loc[:, X_train.columns != 'PassengerId'], y_train, epochs =25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 0s/step - loss: 0.4636 - accuracy: 0.8127\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.4636099636554718, 0.812734067440033]"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_classifier3.evaluate(X_test.loc[:, X_test.columns != 'PassengerId'], y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Among the deep learning classifiers the best classifier is the keras_classifier2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 10)                280       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 291\n",
      "Trainable params: 291\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_classifier3.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save best models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "utils.save_obj('./save_best_model/pickle_best_models', first = svc_best, second = xgb_best, third = voting_clf_best)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./save_best_model_pickle/keras_classifier3\\assets\n"
     ]
    }
   ],
   "source": [
    "keras_classifier2.save(\"./save_best_model_pickle/keras_classifier3\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}