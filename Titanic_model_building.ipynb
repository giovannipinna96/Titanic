{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Titanic model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pandas.core.common import SettingWithCopyWarning\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=SettingWithCopyWarning)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from loadDataUtils import loadDataUtils"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "path_train = r'C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\data\\train.csv'\n",
    "path_test = r'C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\data\\test.csv'\n",
    "data = loadDataUtils(path_train, path_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_train, df_test = data.get_train_and_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Clean data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from titanicPreprocessing import preprocess"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "p = preprocess(df_train.copy(), df_test.copy())\n",
    "p.do_preprocess()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train, test = p.get_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 889 entries, 0 to 890\n",
      "Data columns (total 39 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   PassengerId          889 non-null    int64  \n",
      " 1   Survived             889 non-null    int64  \n",
      " 2   Pclass               889 non-null    int64  \n",
      " 3   Age                  889 non-null    float64\n",
      " 4   SibSp                889 non-null    int64  \n",
      " 5   Parch                889 non-null    int64  \n",
      " 6   Fare                 889 non-null    float64\n",
      " 7   cabin_multiple       889 non-null    int64  \n",
      " 8   Sex_female           889 non-null    uint8  \n",
      " 9   Sex_male             889 non-null    uint8  \n",
      " 10  Embarked_C           889 non-null    uint8  \n",
      " 11  Embarked_Q           889 non-null    uint8  \n",
      " 12  Embarked_S           889 non-null    uint8  \n",
      " 13  cabin_letter_0       889 non-null    uint8  \n",
      " 14  cabin_letter_A       889 non-null    uint8  \n",
      " 15  cabin_letter_B       889 non-null    uint8  \n",
      " 16  cabin_letter_C       889 non-null    uint8  \n",
      " 17  cabin_letter_D       889 non-null    uint8  \n",
      " 18  cabin_letter_E       889 non-null    uint8  \n",
      " 19  cabin_letter_F       889 non-null    uint8  \n",
      " 20  cabin_letter_G       889 non-null    uint8  \n",
      " 21  cabin_letter_T       889 non-null    uint8  \n",
      " 22  name_title_Capt      889 non-null    uint8  \n",
      " 23  name_title_Col       889 non-null    uint8  \n",
      " 24  name_title_Countess  889 non-null    uint8  \n",
      " 25  name_title_Don       889 non-null    uint8  \n",
      " 26  name_title_Dr        889 non-null    uint8  \n",
      " 27  name_title_Jonkheer  889 non-null    uint8  \n",
      " 28  name_title_Lady      889 non-null    uint8  \n",
      " 29  name_title_Major     889 non-null    uint8  \n",
      " 30  name_title_Master    889 non-null    uint8  \n",
      " 31  name_title_Miss      889 non-null    uint8  \n",
      " 32  name_title_Mlle      889 non-null    uint8  \n",
      " 33  name_title_Mme       889 non-null    uint8  \n",
      " 34  name_title_Mr        889 non-null    uint8  \n",
      " 35  name_title_Mrs       889 non-null    uint8  \n",
      " 36  name_title_Ms        889 non-null    uint8  \n",
      " 37  name_title_Rev       889 non-null    uint8  \n",
      " 38  name_title_Sir       889 non-null    uint8  \n",
      "dtypes: float64(2), int64(6), uint8(31)\n",
      "memory usage: 121.7 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_target = train['Survived']\n",
    "train.drop(columns=['Survived'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, train_target, test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model building"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Baseline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "the gender submission provided by kaggle could be our baseline. In fact, this dataset is characterized by the fact that they assumed that all women would have survived, so we expect an accuracy of about 50%."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "baseline = pd.read_csv(r'C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\data\\gender_submission.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   PassengerId  418 non-null    int64\n",
      " 1   Survived     418 non-null    int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 6.7 KB\n"
     ]
    }
   ],
   "source": [
    "baseline.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "0.49760765550239233"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "baseline_acc = accuracy_score(baseline['Survived'], y_train[0:418])\n",
    "baseline_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "we put the value of 418 in the y_train to make a comparison. When we divided the dataset our trainset had more than 418 observations, so we put the limit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Gaussian Naive Bayes (GaussianNB)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.688      0.688      0.75806452 0.71774194 0.75      ]\n",
      "0.7203612903225807\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#I usually use Naive Bayes as a baseline for my classification tasks\n",
    "gnb = GaussianNB()\n",
    "cv = cross_val_score(gnb,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.832      0.856      0.83064516 0.84677419 0.78225806]\n",
      "0.8295354838709678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\"\"\"\n",
    "lr = LogisticRegression(max_iter = 20000)\n",
    "cv = cross_val_score(lr,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87301587 0.77777778 0.83870968 0.85483871 0.87096774 0.79032258\n",
      " 0.87096774 0.80645161 0.79032258 0.79032258]\n",
      "0.8263696876600102\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter = 2000)\n",
    "cv = cross_val_score(lr,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=10)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "we can already observe that with the logistic regression we get almost 10% more accuracy than the GaussianNB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Deciosion tree"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.712      0.8        0.79032258 0.80645161 0.81451613]\n",
      "0.7846580645161291\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(random_state = 1)\n",
    "cv = cross_val_score(dt,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7640449438202247"
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "dt.score(X_test.loc[:, X_test.columns != 'PassengerId'],y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "outputs": [
    {
     "data": {
      "text/plain": "'titanic.pdf'"
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "dot_data = tree.export_graphviz(dt, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"Titanic_decision_tree\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"4876pt\" height=\"1725pt\"\n viewBox=\"0.00 0.00 4876.00 1725.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 1721)\">\n<title>Tree</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-1721 4872,-1721 4872,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#f5d0b5\" stroke=\"black\" d=\"M2102,-1717C2102,-1717 1985,-1717 1985,-1717 1979,-1717 1973,-1711 1973,-1705 1973,-1705 1973,-1661 1973,-1661 1973,-1655 1979,-1649 1985,-1649 1985,-1649 2102,-1649 2102,-1649 2108,-1649 2114,-1655 2114,-1661 2114,-1661 2114,-1705 2114,-1705 2114,-1711 2108,-1717 2102,-1717\"/>\n<text text-anchor=\"start\" x=\"1981\" y=\"-1701.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">name_title_Mr ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"2006\" y=\"-1686.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.474</text>\n<text text-anchor=\"start\" x=\"1996\" y=\"-1671.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 622</text>\n<text text-anchor=\"start\" x=\"1986.5\" y=\"-1656.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [382, 240]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#8ac5f0\" stroke=\"black\" d=\"M1135.5,-1613C1135.5,-1613 1037.5,-1613 1037.5,-1613 1031.5,-1613 1025.5,-1607 1025.5,-1601 1025.5,-1601 1025.5,-1557 1025.5,-1557 1025.5,-1551 1031.5,-1545 1037.5,-1545 1037.5,-1545 1135.5,-1545 1135.5,-1545 1141.5,-1545 1147.5,-1551 1147.5,-1557 1147.5,-1557 1147.5,-1601 1147.5,-1601 1147.5,-1607 1141.5,-1613 1135.5,-1613\"/>\n<text text-anchor=\"start\" x=\"1047\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pclass ≤ 2.5</text>\n<text text-anchor=\"start\" x=\"1049\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.412</text>\n<text text-anchor=\"start\" x=\"1039\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 255</text>\n<text text-anchor=\"start\" x=\"1033.5\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [74, 181]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1972.74,-1674.46C1795.75,-1655.59 1335.36,-1606.52 1157.8,-1587.6\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1158.1,-1584.11 1147.78,-1586.53 1157.35,-1591.07 1158.1,-1584.11\"/>\n<text text-anchor=\"middle\" x=\"1163.49\" y=\"-1602.28\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n</g>\n<!-- 98 -->\n<g id=\"node99\" class=\"node\">\n<title>98</title>\n<path fill=\"#ea995f\" stroke=\"black\" d=\"M3455.5,-1613C3455.5,-1613 3357.5,-1613 3357.5,-1613 3351.5,-1613 3345.5,-1607 3345.5,-1601 3345.5,-1601 3345.5,-1557 3345.5,-1557 3345.5,-1551 3351.5,-1545 3357.5,-1545 3357.5,-1545 3455.5,-1545 3455.5,-1545 3461.5,-1545 3467.5,-1551 3467.5,-1557 3467.5,-1557 3467.5,-1601 3467.5,-1601 3467.5,-1607 3461.5,-1613 3455.5,-1613\"/>\n<text text-anchor=\"start\" x=\"3365.5\" y=\"-1597.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.358</text>\n<text text-anchor=\"start\" x=\"3373\" y=\"-1582.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.27</text>\n<text text-anchor=\"start\" x=\"3359\" y=\"-1567.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 367</text>\n<text text-anchor=\"start\" x=\"3353.5\" y=\"-1552.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [308, 59]</text>\n</g>\n<!-- 0&#45;&gt;98 -->\n<g id=\"edge98\" class=\"edge\">\n<title>0&#45;&gt;98</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2114.39,-1676.7C2349.14,-1659.13 3099.67,-1602.96 3335.13,-1585.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3335.58,-1588.82 3345.29,-1584.58 3335.06,-1581.84 3335.58,-1588.82\"/>\n<text text-anchor=\"middle\" x=\"3328.98\" y=\"-1599.83\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#4ba6e7\" stroke=\"black\" d=\"M950,-1509C950,-1509 823,-1509 823,-1509 817,-1509 811,-1503 811,-1497 811,-1497 811,-1453 811,-1453 811,-1447 817,-1441 823,-1441 823,-1441 950,-1441 950,-1441 956,-1441 962,-1447 962,-1453 962,-1453 962,-1497 962,-1497 962,-1503 956,-1509 950,-1509\"/>\n<text text-anchor=\"start\" x=\"819\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">name_title_Rev ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"849\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.151</text>\n<text text-anchor=\"start\" x=\"839\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 134</text>\n<text text-anchor=\"start\" x=\"833.5\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 123]</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1025.41,-1546.84C1004.9,-1536.38 981.81,-1524.61 960.43,-1513.7\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"961.88,-1510.52 951.38,-1509.09 958.7,-1516.75 961.88,-1510.52\"/>\n</g>\n<!-- 33 -->\n<g id=\"node34\" class=\"node\">\n<title>33</title>\n<path fill=\"#fdf5ef\" stroke=\"black\" d=\"M1131,-1509C1131,-1509 1042,-1509 1042,-1509 1036,-1509 1030,-1503 1030,-1497 1030,-1497 1030,-1453 1030,-1453 1030,-1447 1036,-1441 1042,-1441 1042,-1441 1131,-1441 1131,-1441 1137,-1441 1143,-1447 1143,-1453 1143,-1453 1143,-1497 1143,-1497 1143,-1503 1137,-1509 1131,-1509\"/>\n<text text-anchor=\"start\" x=\"1045.5\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.241</text>\n<text text-anchor=\"start\" x=\"1049\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.499</text>\n<text text-anchor=\"start\" x=\"1039\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 121</text>\n<text text-anchor=\"start\" x=\"1038\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [63, 58]</text>\n</g>\n<!-- 1&#45;&gt;33 -->\n<g id=\"edge33\" class=\"edge\">\n<title>1&#45;&gt;33</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1086.5,-1544.88C1086.5,-1536.78 1086.5,-1527.98 1086.5,-1519.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1090,-1519.3 1086.5,-1509.3 1083,-1519.3 1090,-1519.3\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#46a3e7\" stroke=\"black\" d=\"M775,-1405C775,-1405 686,-1405 686,-1405 680,-1405 674,-1399 674,-1393 674,-1393 674,-1349 674,-1349 674,-1343 680,-1337 686,-1337 686,-1337 775,-1337 775,-1337 781,-1337 787,-1343 787,-1349 787,-1349 787,-1393 787,-1393 787,-1399 781,-1405 775,-1405\"/>\n<text text-anchor=\"start\" x=\"687.5\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.471</text>\n<text text-anchor=\"start\" x=\"693\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.115</text>\n<text text-anchor=\"start\" x=\"683\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 131</text>\n<text text-anchor=\"start\" x=\"682\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [8, 123]</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M835.85,-1440.88C821.2,-1431.3 805.08,-1420.76 789.94,-1410.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"791.45,-1407.67 781.16,-1405.12 787.62,-1413.53 791.45,-1407.67\"/>\n</g>\n<!-- 32 -->\n<g id=\"node33\" class=\"node\">\n<title>32</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M923,-1397.5C923,-1397.5 850,-1397.5 850,-1397.5 844,-1397.5 838,-1391.5 838,-1385.5 838,-1385.5 838,-1356.5 838,-1356.5 838,-1350.5 844,-1344.5 850,-1344.5 850,-1344.5 923,-1344.5 923,-1344.5 929,-1344.5 935,-1350.5 935,-1356.5 935,-1356.5 935,-1385.5 935,-1385.5 935,-1391.5 929,-1397.5 923,-1397.5\"/>\n<text text-anchor=\"start\" x=\"857.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"847\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"846\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 2&#45;&gt;32 -->\n<g id=\"edge32\" class=\"edge\">\n<title>2&#45;&gt;32</title>\n<path fill=\"none\" stroke=\"black\" d=\"M886.5,-1440.88C886.5,-1430.33 886.5,-1418.6 886.5,-1407.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"890,-1407.52 886.5,-1397.52 883,-1407.52 890,-1407.52\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#cee6f8\" stroke=\"black\" d=\"M584,-1301C584,-1301 453,-1301 453,-1301 447,-1301 441,-1295 441,-1289 441,-1289 441,-1245 441,-1245 441,-1239 447,-1233 453,-1233 453,-1233 584,-1233 584,-1233 590,-1233 596,-1239 596,-1245 596,-1245 596,-1289 596,-1289 596,-1295 590,-1301 584,-1301\"/>\n<text text-anchor=\"start\" x=\"449\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">name_title_Miss ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"485\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.49</text>\n<text text-anchor=\"start\" x=\"479\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"478\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 4]</text>\n</g>\n<!-- 3&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M673.97,-1342.8C650.26,-1331.39 622.3,-1317.94 596.67,-1305.61\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"597.88,-1302.31 587.35,-1301.13 594.84,-1308.62 597.88,-1302.31\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#41a1e6\" stroke=\"black\" d=\"M798.5,-1301C798.5,-1301 662.5,-1301 662.5,-1301 656.5,-1301 650.5,-1295 650.5,-1289 650.5,-1289 650.5,-1245 650.5,-1245 650.5,-1239 656.5,-1233 662.5,-1233 662.5,-1233 798.5,-1233 798.5,-1233 804.5,-1233 810.5,-1239 810.5,-1245 810.5,-1245 810.5,-1289 810.5,-1289 810.5,-1295 804.5,-1301 798.5,-1301\"/>\n<text text-anchor=\"start\" x=\"658.5\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">name_title_Major ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"693\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.077</text>\n<text text-anchor=\"start\" x=\"683\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 124</text>\n<text text-anchor=\"start\" x=\"682\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 119]</text>\n</g>\n<!-- 3&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>3&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"black\" d=\"M730.5,-1336.88C730.5,-1328.78 730.5,-1319.98 730.5,-1311.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"734,-1311.3 730.5,-1301.3 727,-1311.3 734,-1311.3\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#eeab7b\" stroke=\"black\" d=\"M440,-1197C440,-1197 321,-1197 321,-1197 315,-1197 309,-1191 309,-1185 309,-1185 309,-1141 309,-1141 309,-1135 315,-1129 321,-1129 321,-1129 440,-1129 440,-1129 446,-1129 452,-1135 452,-1141 452,-1141 452,-1185 452,-1185 452,-1191 446,-1197 440,-1197\"/>\n<text text-anchor=\"start\" x=\"317\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_F ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"343\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"341\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"340\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 1]</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M473.7,-1232.88C460.92,-1223.44 446.88,-1213.06 433.66,-1203.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"435.67,-1200.43 425.55,-1197.3 431.51,-1206.06 435.67,-1200.43\"/>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M555,-1189.5C555,-1189.5 482,-1189.5 482,-1189.5 476,-1189.5 470,-1183.5 470,-1177.5 470,-1177.5 470,-1148.5 470,-1148.5 470,-1142.5 476,-1136.5 482,-1136.5 482,-1136.5 555,-1136.5 555,-1136.5 561,-1136.5 567,-1142.5 567,-1148.5 567,-1148.5 567,-1177.5 567,-1177.5 567,-1183.5 561,-1189.5 555,-1189.5\"/>\n<text text-anchor=\"start\" x=\"489.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"479\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"478\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\n</g>\n<!-- 4&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>4&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"black\" d=\"M518.5,-1232.88C518.5,-1222.33 518.5,-1210.6 518.5,-1199.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"522,-1199.52 518.5,-1189.52 515,-1199.52 522,-1199.52\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M303,-1085.5C303,-1085.5 230,-1085.5 230,-1085.5 224,-1085.5 218,-1079.5 218,-1073.5 218,-1073.5 218,-1044.5 218,-1044.5 218,-1038.5 224,-1032.5 230,-1032.5 230,-1032.5 303,-1032.5 303,-1032.5 309,-1032.5 315,-1038.5 315,-1044.5 315,-1044.5 315,-1073.5 315,-1073.5 315,-1079.5 309,-1085.5 303,-1085.5\"/>\n<text text-anchor=\"start\" x=\"237.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"227\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"226\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"black\" d=\"M343.49,-1128.88C330.34,-1117.12 315.56,-1103.89 302.49,-1092.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"304.81,-1089.58 295.02,-1085.52 300.14,-1094.8 304.81,-1089.58\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M418,-1085.5C418,-1085.5 345,-1085.5 345,-1085.5 339,-1085.5 333,-1079.5 333,-1073.5 333,-1073.5 333,-1044.5 333,-1044.5 333,-1038.5 339,-1032.5 345,-1032.5 345,-1032.5 418,-1032.5 418,-1032.5 424,-1032.5 430,-1038.5 430,-1044.5 430,-1044.5 430,-1073.5 430,-1073.5 430,-1079.5 424,-1085.5 418,-1085.5\"/>\n<text text-anchor=\"start\" x=\"352.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"342\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"341\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"black\" d=\"M380.82,-1128.88C380.93,-1118.33 381.04,-1106.6 381.15,-1095.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"384.65,-1095.55 381.25,-1085.52 377.65,-1095.49 384.65,-1095.55\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#40a0e6\" stroke=\"black\" d=\"M686,-1197C686,-1197 597,-1197 597,-1197 591,-1197 585,-1191 585,-1185 585,-1185 585,-1141 585,-1141 585,-1135 591,-1129 597,-1129 597,-1129 686,-1129 686,-1129 692,-1129 698,-1135 698,-1141 698,-1141 698,-1185 698,-1185 698,-1191 692,-1197 686,-1197\"/>\n<text text-anchor=\"start\" x=\"600.5\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.452</text>\n<text text-anchor=\"start\" x=\"604\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.063</text>\n<text text-anchor=\"start\" x=\"594\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 123</text>\n<text text-anchor=\"start\" x=\"593\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 119]</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"black\" d=\"M701.6,-1232.88C693.83,-1223.98 685.33,-1214.24 677.24,-1204.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"679.77,-1202.53 670.56,-1197.3 674.49,-1207.14 679.77,-1202.53\"/>\n</g>\n<!-- 31 -->\n<g id=\"node32\" class=\"node\">\n<title>31</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M801,-1189.5C801,-1189.5 728,-1189.5 728,-1189.5 722,-1189.5 716,-1183.5 716,-1177.5 716,-1177.5 716,-1148.5 716,-1148.5 716,-1142.5 722,-1136.5 728,-1136.5 728,-1136.5 801,-1136.5 801,-1136.5 807,-1136.5 813,-1142.5 813,-1148.5 813,-1148.5 813,-1177.5 813,-1177.5 813,-1183.5 807,-1189.5 801,-1189.5\"/>\n<text text-anchor=\"start\" x=\"735.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"725\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"724\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 9&#45;&gt;31 -->\n<g id=\"edge31\" class=\"edge\">\n<title>9&#45;&gt;31</title>\n<path fill=\"none\" stroke=\"black\" d=\"M741.54,-1232.88C745.13,-1222.11 749.13,-1210.11 752.77,-1199.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"756.15,-1200.11 755.99,-1189.52 749.51,-1197.9 756.15,-1200.11\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<path fill=\"#4ba6e7\" stroke=\"black\" d=\"M541,-1093C541,-1093 460,-1093 460,-1093 454,-1093 448,-1087 448,-1081 448,-1081 448,-1037 448,-1037 448,-1031 454,-1025 460,-1025 460,-1025 541,-1025 541,-1025 547,-1025 553,-1031 553,-1037 553,-1037 553,-1081 553,-1081 553,-1087 547,-1093 541,-1093\"/>\n<text text-anchor=\"start\" x=\"464\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.43</text>\n<text text-anchor=\"start\" x=\"467\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.15</text>\n<text text-anchor=\"start\" x=\"457\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 49</text>\n<text text-anchor=\"start\" x=\"456\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 45]</text>\n</g>\n<!-- 10&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>10&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"black\" d=\"M595.72,-1128.88C582.67,-1119.44 568.32,-1109.06 554.81,-1099.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"556.69,-1096.32 546.53,-1093.3 552.58,-1102 556.69,-1096.32\"/>\n</g>\n<!-- 30 -->\n<g id=\"node31\" class=\"node\">\n<title>30</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M682,-1085.5C682,-1085.5 601,-1085.5 601,-1085.5 595,-1085.5 589,-1079.5 589,-1073.5 589,-1073.5 589,-1044.5 589,-1044.5 589,-1038.5 595,-1032.5 601,-1032.5 601,-1032.5 682,-1032.5 682,-1032.5 688,-1032.5 694,-1038.5 694,-1044.5 694,-1044.5 694,-1073.5 694,-1073.5 694,-1079.5 688,-1085.5 682,-1085.5\"/>\n<text text-anchor=\"start\" x=\"612.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"598\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 74</text>\n<text text-anchor=\"start\" x=\"597\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 74]</text>\n</g>\n<!-- 10&#45;&gt;30 -->\n<g id=\"edge30\" class=\"edge\">\n<title>10&#45;&gt;30</title>\n<path fill=\"none\" stroke=\"black\" d=\"M641.5,-1128.88C641.5,-1118.33 641.5,-1106.6 641.5,-1095.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"645,-1095.52 641.5,-1085.52 638,-1095.52 645,-1095.52\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<path fill=\"#46a4e7\" stroke=\"black\" d=\"M422,-989C422,-989 341,-989 341,-989 335,-989 329,-983 329,-977 329,-977 329,-933 329,-933 329,-927 335,-921 341,-921 341,-921 422,-921 422,-921 428,-921 434,-927 434,-933 434,-933 434,-977 434,-977 434,-983 428,-989 422,-989\"/>\n<text text-anchor=\"start\" x=\"345\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"344\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.117</text>\n<text text-anchor=\"start\" x=\"338\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 48</text>\n<text text-anchor=\"start\" x=\"337\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 45]</text>\n</g>\n<!-- 11&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>11&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"black\" d=\"M461.86,-1024.88C451.06,-1015.62 439.2,-1005.45 427.99,-995.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"430.22,-993.15 420.35,-989.3 425.66,-998.46 430.22,-993.15\"/>\n</g>\n<!-- 29 -->\n<g id=\"node30\" class=\"node\">\n<title>29</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M537,-981.5C537,-981.5 464,-981.5 464,-981.5 458,-981.5 452,-975.5 452,-969.5 452,-969.5 452,-940.5 452,-940.5 452,-934.5 458,-928.5 464,-928.5 464,-928.5 537,-928.5 537,-928.5 543,-928.5 549,-934.5 549,-940.5 549,-940.5 549,-969.5 549,-969.5 549,-975.5 543,-981.5 537,-981.5\"/>\n<text text-anchor=\"start\" x=\"471.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"461\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"460\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 11&#45;&gt;29 -->\n<g id=\"edge29\" class=\"edge\">\n<title>11&#45;&gt;29</title>\n<path fill=\"none\" stroke=\"black\" d=\"M500.5,-1024.88C500.5,-1014.33 500.5,-1002.6 500.5,-991.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"504,-991.52 500.5,-981.52 497,-991.52 504,-991.52\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<path fill=\"#50a8e8\" stroke=\"black\" d=\"M308,-885C308,-885 227,-885 227,-885 221,-885 215,-879 215,-873 215,-873 215,-829 215,-829 215,-823 221,-817 227,-817 227,-817 308,-817 308,-817 314,-817 320,-823 320,-829 320,-829 320,-873 320,-873 320,-879 314,-885 308,-885\"/>\n<text text-anchor=\"start\" x=\"230\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"230\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.185</text>\n<text text-anchor=\"start\" x=\"224\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 29</text>\n<text text-anchor=\"start\" x=\"223\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 26]</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"black\" d=\"M344.49,-920.88C334.23,-911.71 322.99,-901.65 312.34,-892.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"314.5,-889.36 304.72,-885.3 309.84,-894.58 314.5,-889.36\"/>\n</g>\n<!-- 28 -->\n<g id=\"node29\" class=\"node\">\n<title>28</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M431,-877.5C431,-877.5 350,-877.5 350,-877.5 344,-877.5 338,-871.5 338,-865.5 338,-865.5 338,-836.5 338,-836.5 338,-830.5 344,-824.5 350,-824.5 350,-824.5 431,-824.5 431,-824.5 437,-824.5 443,-830.5 443,-836.5 443,-836.5 443,-865.5 443,-865.5 443,-871.5 437,-877.5 431,-877.5\"/>\n<text text-anchor=\"start\" x=\"361.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"347\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\n<text text-anchor=\"start\" x=\"346\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 19]</text>\n</g>\n<!-- 12&#45;&gt;28 -->\n<g id=\"edge28\" class=\"edge\">\n<title>12&#45;&gt;28</title>\n<path fill=\"none\" stroke=\"black\" d=\"M384.42,-920.88C385.36,-910.22 386.41,-898.35 387.37,-887.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"390.86,-887.79 388.25,-877.52 383.88,-887.17 390.86,-887.79\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<path fill=\"#44a2e6\" stroke=\"black\" d=\"M206,-781C206,-781 125,-781 125,-781 119,-781 113,-775 113,-769 113,-769 113,-725 113,-725 113,-719 119,-713 125,-713 125,-713 206,-713 206,-713 212,-713 218,-719 218,-725 218,-725 218,-769 218,-769 218,-775 212,-781 206,-781\"/>\n<text text-anchor=\"start\" x=\"126\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.551</text>\n<text text-anchor=\"start\" x=\"136.5\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.1</text>\n<text text-anchor=\"start\" x=\"122\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\n<text text-anchor=\"start\" x=\"121\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 18]</text>\n</g>\n<!-- 13&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>13&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"black\" d=\"M234.38,-816.88C225.3,-807.8 215.35,-797.85 205.9,-788.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"208.35,-785.9 198.8,-781.3 203.4,-790.85 208.35,-785.9\"/>\n</g>\n<!-- 19 -->\n<g id=\"node20\" class=\"node\">\n<title>19</title>\n<path fill=\"#6ab6ec\" stroke=\"black\" d=\"M327,-781C327,-781 248,-781 248,-781 242,-781 236,-775 236,-769 236,-769 236,-725 236,-725 236,-719 242,-713 248,-713 248,-713 327,-713 327,-713 333,-713 339,-719 339,-725 339,-725 339,-769 339,-769 339,-775 333,-781 327,-781\"/>\n<text text-anchor=\"start\" x=\"248\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.777</text>\n<text text-anchor=\"start\" x=\"254\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"244\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"247\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 8]</text>\n</g>\n<!-- 13&#45;&gt;19 -->\n<g id=\"edge19\" class=\"edge\">\n<title>13&#45;&gt;19</title>\n<path fill=\"none\" stroke=\"black\" d=\"M273.99,-816.88C275.6,-808.69 277.35,-799.79 279.03,-791.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"282.48,-791.79 280.97,-781.3 275.61,-790.44 282.48,-791.79\"/>\n</g>\n<!-- 15 -->\n<g id=\"node16\" class=\"node\">\n<title>15</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M85,-669.5C85,-669.5 12,-669.5 12,-669.5 6,-669.5 0,-663.5 0,-657.5 0,-657.5 0,-628.5 0,-628.5 0,-622.5 6,-616.5 12,-616.5 12,-616.5 85,-616.5 85,-616.5 91,-616.5 97,-622.5 97,-628.5 97,-628.5 97,-657.5 97,-657.5 97,-663.5 91,-669.5 85,-669.5\"/>\n<text text-anchor=\"start\" x=\"19.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"9\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 9]</text>\n</g>\n<!-- 14&#45;&gt;15 -->\n<g id=\"edge15\" class=\"edge\">\n<title>14&#45;&gt;15</title>\n<path fill=\"none\" stroke=\"black\" d=\"M127.51,-712.88C114.02,-701.12 98.85,-687.89 85.44,-676.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"87.61,-673.45 77.77,-669.52 83.01,-678.73 87.61,-673.45\"/>\n</g>\n<!-- 16 -->\n<g id=\"node17\" class=\"node\">\n<title>16</title>\n<path fill=\"#4fa8e8\" stroke=\"black\" d=\"M206,-677C206,-677 127,-677 127,-677 121,-677 115,-671 115,-665 115,-665 115,-621 115,-621 115,-615 121,-609 127,-609 127,-609 206,-609 206,-609 212,-609 218,-615 218,-621 218,-621 218,-665 218,-665 218,-671 212,-677 206,-677\"/>\n<text text-anchor=\"start\" x=\"127\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.702</text>\n<text text-anchor=\"start\" x=\"133\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.18</text>\n<text text-anchor=\"start\" x=\"123\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"126\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 9]</text>\n</g>\n<!-- 14&#45;&gt;16 -->\n<g id=\"edge16\" class=\"edge\">\n<title>14&#45;&gt;16</title>\n<path fill=\"none\" stroke=\"black\" d=\"M165.82,-712.88C165.9,-704.78 165.99,-695.98 166.07,-687.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"169.58,-687.33 166.17,-677.3 162.58,-687.26 169.58,-687.33\"/>\n</g>\n<!-- 17 -->\n<g id=\"node18\" class=\"node\">\n<title>17</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M89,-565.5C89,-565.5 16,-565.5 16,-565.5 10,-565.5 4,-559.5 4,-553.5 4,-553.5 4,-524.5 4,-524.5 4,-518.5 10,-512.5 16,-512.5 16,-512.5 89,-512.5 89,-512.5 95,-512.5 101,-518.5 101,-524.5 101,-524.5 101,-553.5 101,-553.5 101,-559.5 95,-565.5 89,-565.5\"/>\n<text text-anchor=\"start\" x=\"23.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"13\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"12\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 16&#45;&gt;17 -->\n<g id=\"edge17\" class=\"edge\">\n<title>16&#45;&gt;17</title>\n<path fill=\"none\" stroke=\"black\" d=\"M129.49,-608.88C116.34,-597.12 101.56,-583.89 88.49,-572.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"90.81,-569.58 81.02,-565.52 86.14,-574.8 90.81,-569.58\"/>\n</g>\n<!-- 18 -->\n<g id=\"node19\" class=\"node\">\n<title>18</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M204,-565.5C204,-565.5 131,-565.5 131,-565.5 125,-565.5 119,-559.5 119,-553.5 119,-553.5 119,-524.5 119,-524.5 119,-518.5 125,-512.5 131,-512.5 131,-512.5 204,-512.5 204,-512.5 210,-512.5 216,-518.5 216,-524.5 216,-524.5 216,-553.5 216,-553.5 216,-559.5 210,-565.5 204,-565.5\"/>\n<text text-anchor=\"start\" x=\"138.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"128\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"127\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 9]</text>\n</g>\n<!-- 16&#45;&gt;18 -->\n<g id=\"edge18\" class=\"edge\">\n<title>16&#45;&gt;18</title>\n<path fill=\"none\" stroke=\"black\" d=\"M166.82,-608.88C166.93,-598.33 167.04,-586.6 167.15,-575.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"170.65,-575.55 167.25,-565.52 163.65,-575.49 170.65,-575.55\"/>\n</g>\n<!-- 20 -->\n<g id=\"node21\" class=\"node\">\n<title>20</title>\n<path fill=\"#52a9e8\" stroke=\"black\" d=\"M324.5,-677C324.5,-677 250.5,-677 250.5,-677 244.5,-677 238.5,-671 238.5,-665 238.5,-665 238.5,-621 238.5,-621 238.5,-615 244.5,-609 250.5,-609 250.5,-609 324.5,-609 324.5,-609 330.5,-609 336.5,-615 336.5,-621 336.5,-621 336.5,-665 336.5,-665 336.5,-671 330.5,-677 324.5,-677\"/>\n<text text-anchor=\"start\" x=\"246.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.203</text>\n<text text-anchor=\"start\" x=\"250\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.198</text>\n<text text-anchor=\"start\" x=\"248\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"247\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 8]</text>\n</g>\n<!-- 19&#45;&gt;20 -->\n<g id=\"edge20\" class=\"edge\">\n<title>19&#45;&gt;20</title>\n<path fill=\"none\" stroke=\"black\" d=\"M287.5,-712.88C287.5,-704.78 287.5,-695.98 287.5,-687.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"291,-687.3 287.5,-677.3 284,-687.3 291,-687.3\"/>\n</g>\n<!-- 27 -->\n<g id=\"node28\" class=\"node\">\n<title>27</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M440,-669.5C440,-669.5 367,-669.5 367,-669.5 361,-669.5 355,-663.5 355,-657.5 355,-657.5 355,-628.5 355,-628.5 355,-622.5 361,-616.5 367,-616.5 367,-616.5 440,-616.5 440,-616.5 446,-616.5 452,-622.5 452,-628.5 452,-628.5 452,-657.5 452,-657.5 452,-663.5 446,-669.5 440,-669.5\"/>\n<text text-anchor=\"start\" x=\"374.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"364\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"363\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 19&#45;&gt;27 -->\n<g id=\"edge27\" class=\"edge\">\n<title>19&#45;&gt;27</title>\n<path fill=\"none\" stroke=\"black\" d=\"M325.16,-712.88C338.54,-701.12 353.58,-687.89 366.88,-676.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"369.28,-678.75 374.48,-669.52 364.66,-673.49 369.28,-678.75\"/>\n</g>\n<!-- 21 -->\n<g id=\"node22\" class=\"node\">\n<title>21</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M326.5,-573C326.5,-573 248.5,-573 248.5,-573 242.5,-573 236.5,-567 236.5,-561 236.5,-561 236.5,-517 236.5,-517 236.5,-511 242.5,-505 248.5,-505 248.5,-505 326.5,-505 326.5,-505 332.5,-505 338.5,-511 338.5,-517 338.5,-517 338.5,-561 338.5,-561 338.5,-567 332.5,-573 326.5,-573\"/>\n<text text-anchor=\"start\" x=\"244.5\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.066</text>\n<text text-anchor=\"start\" x=\"250\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"248\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"247\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 20&#45;&gt;21 -->\n<g id=\"edge21\" class=\"edge\">\n<title>20&#45;&gt;21</title>\n<path fill=\"none\" stroke=\"black\" d=\"M287.5,-608.88C287.5,-600.78 287.5,-591.98 287.5,-583.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"291,-583.3 287.5,-573.3 284,-583.3 291,-583.3\"/>\n</g>\n<!-- 26 -->\n<g id=\"node27\" class=\"node\">\n<title>26</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M442,-565.5C442,-565.5 369,-565.5 369,-565.5 363,-565.5 357,-559.5 357,-553.5 357,-553.5 357,-524.5 357,-524.5 357,-518.5 363,-512.5 369,-512.5 369,-512.5 442,-512.5 442,-512.5 448,-512.5 454,-518.5 454,-524.5 454,-524.5 454,-553.5 454,-553.5 454,-559.5 448,-565.5 442,-565.5\"/>\n<text text-anchor=\"start\" x=\"376.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"366\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"365\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 6]</text>\n</g>\n<!-- 20&#45;&gt;26 -->\n<g id=\"edge26\" class=\"edge\">\n<title>20&#45;&gt;26</title>\n<path fill=\"none\" stroke=\"black\" d=\"M325.81,-608.88C339.42,-597.12 354.72,-583.89 368.25,-572.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"370.7,-574.71 375.98,-565.52 366.12,-569.41 370.7,-574.71\"/>\n</g>\n<!-- 22 -->\n<g id=\"node23\" class=\"node\">\n<title>22</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M266,-461.5C266,-461.5 193,-461.5 193,-461.5 187,-461.5 181,-455.5 181,-449.5 181,-449.5 181,-420.5 181,-420.5 181,-414.5 187,-408.5 193,-408.5 193,-408.5 266,-408.5 266,-408.5 272,-408.5 278,-414.5 278,-420.5 278,-420.5 278,-449.5 278,-449.5 278,-455.5 272,-461.5 266,-461.5\"/>\n<text text-anchor=\"start\" x=\"200.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"190\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"189\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 21&#45;&gt;22 -->\n<g id=\"edge22\" class=\"edge\">\n<title>21&#45;&gt;22</title>\n<path fill=\"none\" stroke=\"black\" d=\"M268.67,-504.88C262.42,-493.89 255.44,-481.62 249.13,-470.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"252,-468.48 244.01,-461.52 245.91,-471.94 252,-468.48\"/>\n</g>\n<!-- 23 -->\n<g id=\"node24\" class=\"node\">\n<title>23</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M381,-469C381,-469 308,-469 308,-469 302,-469 296,-463 296,-457 296,-457 296,-413 296,-413 296,-407 302,-401 308,-401 308,-401 381,-401 381,-401 387,-401 393,-407 393,-413 393,-413 393,-457 393,-457 393,-463 387,-469 381,-469\"/>\n<text text-anchor=\"start\" x=\"307\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 2.0</text>\n<text text-anchor=\"start\" x=\"315.5\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"305\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"304\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 21&#45;&gt;23 -->\n<g id=\"edge23\" class=\"edge\">\n<title>21&#45;&gt;23</title>\n<path fill=\"none\" stroke=\"black\" d=\"M306.01,-504.88C310.78,-496.33 315.99,-487.01 320.99,-478.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"324.07,-479.74 325.89,-469.3 317.96,-476.32 324.07,-479.74\"/>\n</g>\n<!-- 24 -->\n<g id=\"node25\" class=\"node\">\n<title>24</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M324,-357.5C324,-357.5 251,-357.5 251,-357.5 245,-357.5 239,-351.5 239,-345.5 239,-345.5 239,-316.5 239,-316.5 239,-310.5 245,-304.5 251,-304.5 251,-304.5 324,-304.5 324,-304.5 330,-304.5 336,-310.5 336,-316.5 336,-316.5 336,-345.5 336,-345.5 336,-351.5 330,-357.5 324,-357.5\"/>\n<text text-anchor=\"start\" x=\"258.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"248\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"247\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 23&#45;&gt;24 -->\n<g id=\"edge24\" class=\"edge\">\n<title>23&#45;&gt;24</title>\n<path fill=\"none\" stroke=\"black\" d=\"M325.99,-400.88C319.85,-389.89 312.99,-377.62 306.79,-366.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"309.69,-364.54 301.76,-357.52 303.58,-367.96 309.69,-364.54\"/>\n</g>\n<!-- 25 -->\n<g id=\"node26\" class=\"node\">\n<title>25</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M439,-357.5C439,-357.5 366,-357.5 366,-357.5 360,-357.5 354,-351.5 354,-345.5 354,-345.5 354,-316.5 354,-316.5 354,-310.5 360,-304.5 366,-304.5 366,-304.5 439,-304.5 439,-304.5 445,-304.5 451,-310.5 451,-316.5 451,-316.5 451,-345.5 451,-345.5 451,-351.5 445,-357.5 439,-357.5\"/>\n<text text-anchor=\"start\" x=\"373.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"363\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"362\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 23&#45;&gt;25 -->\n<g id=\"edge25\" class=\"edge\">\n<title>23&#45;&gt;25</title>\n<path fill=\"none\" stroke=\"black\" d=\"M363.33,-400.88C369.58,-389.89 376.56,-377.62 382.87,-366.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"386.09,-367.94 387.99,-357.52 380,-364.48 386.09,-367.94\"/>\n</g>\n<!-- 34 -->\n<g id=\"node35\" class=\"node\">\n<title>34</title>\n<path fill=\"#aad5f4\" stroke=\"black\" d=\"M1092,-1405C1092,-1405 1003,-1405 1003,-1405 997,-1405 991,-1399 991,-1393 991,-1393 991,-1349 991,-1349 991,-1343 997,-1337 1003,-1337 1003,-1337 1092,-1337 1092,-1337 1098,-1337 1104,-1343 1104,-1349 1104,-1349 1104,-1393 1104,-1393 1104,-1399 1098,-1405 1092,-1405\"/>\n<text text-anchor=\"start\" x=\"1008\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.509</text>\n<text text-anchor=\"start\" x=\"1010\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.463</text>\n<text text-anchor=\"start\" x=\"1004\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 88</text>\n<text text-anchor=\"start\" x=\"999\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [32, 56]</text>\n</g>\n<!-- 33&#45;&gt;34 -->\n<g id=\"edge34\" class=\"edge\">\n<title>33&#45;&gt;34</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1073.84,-1440.88C1070.67,-1432.6 1067.23,-1423.6 1063.91,-1414.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1067.07,-1413.39 1060.23,-1405.3 1060.53,-1415.89 1067.07,-1413.39\"/>\n</g>\n<!-- 91 -->\n<g id=\"node92\" class=\"node\">\n<title>91</title>\n<path fill=\"#e78946\" stroke=\"black\" d=\"M1215,-1405C1215,-1405 1134,-1405 1134,-1405 1128,-1405 1122,-1399 1122,-1393 1122,-1393 1122,-1349 1122,-1349 1122,-1343 1128,-1337 1134,-1337 1134,-1337 1215,-1337 1215,-1337 1221,-1337 1227,-1343 1227,-1349 1227,-1349 1227,-1393 1227,-1393 1227,-1399 1221,-1405 1215,-1405\"/>\n<text text-anchor=\"start\" x=\"1138\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1137\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.114</text>\n<text text-anchor=\"start\" x=\"1131\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 33</text>\n<text text-anchor=\"start\" x=\"1130\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 2]</text>\n</g>\n<!-- 33&#45;&gt;91 -->\n<g id=\"edge91\" class=\"edge\">\n<title>33&#45;&gt;91</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1115.07,-1440.88C1122.76,-1431.98 1131.16,-1422.24 1139.16,-1412.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1141.89,-1415.16 1145.77,-1405.3 1136.59,-1410.58 1141.89,-1415.16\"/>\n</g>\n<!-- 35 -->\n<g id=\"node36\" class=\"node\">\n<title>35</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M975,-1301C975,-1301 886,-1301 886,-1301 880,-1301 874,-1295 874,-1289 874,-1289 874,-1245 874,-1245 874,-1239 880,-1233 886,-1233 886,-1233 975,-1233 975,-1233 981,-1233 987,-1239 987,-1245 987,-1245 987,-1289 987,-1289 987,-1295 981,-1301 975,-1301\"/>\n<text text-anchor=\"start\" x=\"889\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.998</text>\n<text text-anchor=\"start\" x=\"893\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"887\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 84</text>\n<text text-anchor=\"start\" x=\"882\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [28, 56]</text>\n</g>\n<!-- 34&#45;&gt;35 -->\n<g id=\"edge35\" class=\"edge\">\n<title>34&#45;&gt;35</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1009.51,-1336.88C998.99,-1327.71 987.45,-1317.65 976.52,-1308.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"978.53,-1305.23 968.7,-1301.3 973.93,-1310.51 978.53,-1305.23\"/>\n</g>\n<!-- 90 -->\n<g id=\"node91\" class=\"node\">\n<title>90</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1090,-1293.5C1090,-1293.5 1017,-1293.5 1017,-1293.5 1011,-1293.5 1005,-1287.5 1005,-1281.5 1005,-1281.5 1005,-1252.5 1005,-1252.5 1005,-1246.5 1011,-1240.5 1017,-1240.5 1017,-1240.5 1090,-1240.5 1090,-1240.5 1096,-1240.5 1102,-1246.5 1102,-1252.5 1102,-1252.5 1102,-1281.5 1102,-1281.5 1102,-1287.5 1096,-1293.5 1090,-1293.5\"/>\n<text text-anchor=\"start\" x=\"1024.5\" y=\"-1278.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1014\" y=\"-1263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"1013\" y=\"-1248.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 0]</text>\n</g>\n<!-- 34&#45;&gt;90 -->\n<g id=\"edge90\" class=\"edge\">\n<title>34&#45;&gt;90</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1049.45,-1336.88C1050.08,-1326.22 1050.77,-1314.35 1051.41,-1303.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1054.91,-1303.71 1052,-1293.52 1047.92,-1303.3 1054.91,-1303.71\"/>\n</g>\n<!-- 36 -->\n<g id=\"node37\" class=\"node\">\n<title>36</title>\n<path fill=\"#57ace9\" stroke=\"black\" d=\"M926,-1197C926,-1197 845,-1197 845,-1197 839,-1197 833,-1191 833,-1185 833,-1185 833,-1141 833,-1141 833,-1135 839,-1129 845,-1129 845,-1129 926,-1129 926,-1129 932,-1129 938,-1135 938,-1141 938,-1141 938,-1185 938,-1185 938,-1191 932,-1197 926,-1197\"/>\n<text text-anchor=\"start\" x=\"848\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 2.5</text>\n<text text-anchor=\"start\" x=\"848\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.227</text>\n<text text-anchor=\"start\" x=\"842\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 23</text>\n<text text-anchor=\"start\" x=\"841\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 20]</text>\n</g>\n<!-- 35&#45;&gt;36 -->\n<g id=\"edge36\" class=\"edge\">\n<title>35&#45;&gt;36</title>\n<path fill=\"none\" stroke=\"black\" d=\"M915.89,-1232.88C912.2,-1224.51 908.18,-1215.4 904.31,-1206.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"907.43,-1205.04 900.19,-1197.3 901.03,-1207.86 907.43,-1205.04\"/>\n</g>\n<!-- 43 -->\n<g id=\"node44\" class=\"node\">\n<title>43</title>\n<path fill=\"#c2e1f7\" stroke=\"black\" d=\"M1057,-1197C1057,-1197 968,-1197 968,-1197 962,-1197 956,-1191 956,-1185 956,-1185 956,-1141 956,-1141 956,-1135 962,-1129 968,-1129 968,-1129 1057,-1129 1057,-1129 1063,-1129 1069,-1135 1069,-1141 1069,-1141 1069,-1185 1069,-1185 1069,-1191 1063,-1197 1057,-1197\"/>\n<text text-anchor=\"start\" x=\"969.5\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.801</text>\n<text text-anchor=\"start\" x=\"975\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.484</text>\n<text text-anchor=\"start\" x=\"969\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 61</text>\n<text text-anchor=\"start\" x=\"964\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [25, 36]</text>\n</g>\n<!-- 35&#45;&gt;43 -->\n<g id=\"edge43\" class=\"edge\">\n<title>35&#45;&gt;43</title>\n<path fill=\"none\" stroke=\"black\" d=\"M957.12,-1232.88C964.21,-1224.07 971.96,-1214.43 979.35,-1205.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"982.19,-1207.29 985.73,-1197.3 976.74,-1202.9 982.19,-1207.29\"/>\n</g>\n<!-- 37 -->\n<g id=\"node38\" class=\"node\">\n<title>37</title>\n<path fill=\"#43a2e6\" stroke=\"black\" d=\"M810,-1093C810,-1093 729,-1093 729,-1093 723,-1093 717,-1087 717,-1081 717,-1081 717,-1037 717,-1037 717,-1031 723,-1025 729,-1025 729,-1025 810,-1025 810,-1025 816,-1025 822,-1031 822,-1037 822,-1037 822,-1081 822,-1081 822,-1087 816,-1093 810,-1093\"/>\n<text text-anchor=\"start\" x=\"726.5\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.794</text>\n<text text-anchor=\"start\" x=\"732\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.091</text>\n<text text-anchor=\"start\" x=\"726\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 21</text>\n<text text-anchor=\"start\" x=\"725\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 20]</text>\n</g>\n<!-- 36&#45;&gt;37 -->\n<g id=\"edge37\" class=\"edge\">\n<title>36&#45;&gt;37</title>\n<path fill=\"none\" stroke=\"black\" d=\"M847.84,-1128.88C837.4,-1119.71 825.96,-1109.65 815.13,-1100.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"817.19,-1097.27 807.37,-1093.3 812.57,-1102.53 817.19,-1097.27\"/>\n</g>\n<!-- 42 -->\n<g id=\"node43\" class=\"node\">\n<title>42</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M925,-1085.5C925,-1085.5 852,-1085.5 852,-1085.5 846,-1085.5 840,-1079.5 840,-1073.5 840,-1073.5 840,-1044.5 840,-1044.5 840,-1038.5 846,-1032.5 852,-1032.5 852,-1032.5 925,-1032.5 925,-1032.5 931,-1032.5 937,-1038.5 937,-1044.5 937,-1044.5 937,-1073.5 937,-1073.5 937,-1079.5 931,-1085.5 925,-1085.5\"/>\n<text text-anchor=\"start\" x=\"859.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"849\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"848\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 36&#45;&gt;42 -->\n<g id=\"edge42\" class=\"edge\">\n<title>36&#45;&gt;42</title>\n<path fill=\"none\" stroke=\"black\" d=\"M886.47,-1128.88C886.79,-1118.22 887.14,-1106.35 887.46,-1095.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"890.95,-1095.62 887.75,-1085.52 883.96,-1095.41 890.95,-1095.62\"/>\n</g>\n<!-- 38 -->\n<g id=\"node39\" class=\"node\">\n<title>38</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M690,-989C690,-989 579,-989 579,-989 573,-989 567,-983 567,-977 567,-977 567,-933 567,-933 567,-927 573,-921 579,-921 579,-921 690,-921 690,-921 696,-921 702,-927 702,-933 702,-933 702,-977 702,-977 702,-983 696,-989 690,-989\"/>\n<text text-anchor=\"start\" x=\"575\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Embarked_S ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"597\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"595\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"594\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 37&#45;&gt;38 -->\n<g id=\"edge38\" class=\"edge\">\n<title>37&#45;&gt;38</title>\n<path fill=\"none\" stroke=\"black\" d=\"M725.67,-1024.88C713.29,-1015.53 699.7,-1005.26 686.87,-995.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"688.66,-992.54 678.57,-989.3 684.44,-998.12 688.66,-992.54\"/>\n</g>\n<!-- 41 -->\n<g id=\"node42\" class=\"node\">\n<title>41</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M813,-981.5C813,-981.5 732,-981.5 732,-981.5 726,-981.5 720,-975.5 720,-969.5 720,-969.5 720,-940.5 720,-940.5 720,-934.5 726,-928.5 732,-928.5 732,-928.5 813,-928.5 813,-928.5 819,-928.5 825,-934.5 825,-940.5 825,-940.5 825,-969.5 825,-969.5 825,-975.5 819,-981.5 813,-981.5\"/>\n<text text-anchor=\"start\" x=\"743.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"729\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n<text text-anchor=\"start\" x=\"728\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 18]</text>\n</g>\n<!-- 37&#45;&gt;41 -->\n<g id=\"edge41\" class=\"edge\">\n<title>37&#45;&gt;41</title>\n<path fill=\"none\" stroke=\"black\" d=\"M770.47,-1024.88C770.79,-1014.22 771.14,-1002.35 771.46,-991.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"774.95,-991.62 771.75,-981.52 767.96,-991.41 774.95,-991.62\"/>\n</g>\n<!-- 39 -->\n<g id=\"node40\" class=\"node\">\n<title>39</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M567,-877.5C567,-877.5 494,-877.5 494,-877.5 488,-877.5 482,-871.5 482,-865.5 482,-865.5 482,-836.5 482,-836.5 482,-830.5 488,-824.5 494,-824.5 494,-824.5 567,-824.5 567,-824.5 573,-824.5 579,-830.5 579,-836.5 579,-836.5 579,-865.5 579,-865.5 579,-871.5 573,-877.5 567,-877.5\"/>\n<text text-anchor=\"start\" x=\"501.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"491\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"490\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 38&#45;&gt;39 -->\n<g id=\"edge39\" class=\"edge\">\n<title>38&#45;&gt;39</title>\n<path fill=\"none\" stroke=\"black\" d=\"M600.73,-920.88C588.85,-909.23 575.51,-896.14 563.67,-884.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"566.11,-882.02 556.52,-877.52 561.21,-887.02 566.11,-882.02\"/>\n</g>\n<!-- 40 -->\n<g id=\"node41\" class=\"node\">\n<title>40</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M682,-877.5C682,-877.5 609,-877.5 609,-877.5 603,-877.5 597,-871.5 597,-865.5 597,-865.5 597,-836.5 597,-836.5 597,-830.5 603,-824.5 609,-824.5 609,-824.5 682,-824.5 682,-824.5 688,-824.5 694,-830.5 694,-836.5 694,-836.5 694,-865.5 694,-865.5 694,-871.5 688,-877.5 682,-877.5\"/>\n<text text-anchor=\"start\" x=\"616.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"606\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"605\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 38&#45;&gt;40 -->\n<g id=\"edge40\" class=\"edge\">\n<title>38&#45;&gt;40</title>\n<path fill=\"none\" stroke=\"black\" d=\"M638.07,-920.88C639.22,-910.22 640.5,-898.35 641.67,-887.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"645.16,-887.84 642.75,-877.52 638.2,-887.09 645.16,-887.84\"/>\n</g>\n<!-- 44 -->\n<g id=\"node45\" class=\"node\">\n<title>44</title>\n<path fill=\"#82c1ef\" stroke=\"black\" d=\"M1050,-1093C1050,-1093 969,-1093 969,-1093 963,-1093 957,-1087 957,-1081 957,-1081 957,-1037 957,-1037 957,-1031 963,-1025 969,-1025 969,-1025 1050,-1025 1050,-1025 1056,-1025 1062,-1031 1062,-1037 1062,-1037 1062,-1081 1062,-1081 1062,-1087 1056,-1093 1050,-1093\"/>\n<text text-anchor=\"start\" x=\"968\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.431</text>\n<text text-anchor=\"start\" x=\"972\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.393</text>\n<text text-anchor=\"start\" x=\"966\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 26</text>\n<text text-anchor=\"start\" x=\"965\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 19]</text>\n</g>\n<!-- 43&#45;&gt;44 -->\n<g id=\"edge44\" class=\"edge\">\n<title>43&#45;&gt;44</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1011.53,-1128.88C1011.29,-1120.78 1011.03,-1111.98 1010.78,-1103.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1014.27,-1103.19 1010.48,-1093.3 1007.27,-1103.4 1014.27,-1103.19\"/>\n</g>\n<!-- 65 -->\n<g id=\"node66\" class=\"node\">\n<title>65</title>\n<path fill=\"#fef8f4\" stroke=\"black\" d=\"M1181,-1093C1181,-1093 1092,-1093 1092,-1093 1086,-1093 1080,-1087 1080,-1081 1080,-1081 1080,-1037 1080,-1037 1080,-1031 1086,-1025 1092,-1025 1092,-1025 1181,-1025 1181,-1025 1187,-1025 1193,-1031 1193,-1037 1193,-1037 1193,-1081 1193,-1081 1193,-1087 1187,-1093 1181,-1093\"/>\n<text text-anchor=\"start\" x=\"1093.5\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.713</text>\n<text text-anchor=\"start\" x=\"1107.5\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"1093\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 35</text>\n<text text-anchor=\"start\" x=\"1088\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [18, 17]</text>\n</g>\n<!-- 43&#45;&gt;65 -->\n<g id=\"edge65\" class=\"edge\">\n<title>43&#45;&gt;65</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1052.76,-1128.88C1064.02,-1119.62 1076.38,-1109.45 1088.06,-1099.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1090.52,-1102.36 1096.02,-1093.3 1086.07,-1096.95 1090.52,-1102.36\"/>\n</g>\n<!-- 45 -->\n<g id=\"node46\" class=\"node\">\n<title>45</title>\n<path fill=\"#68b4eb\" stroke=\"black\" d=\"M936,-989C936,-989 855,-989 855,-989 849,-989 843,-983 843,-977 843,-977 843,-933 843,-933 843,-927 849,-921 855,-921 855,-921 936,-921 936,-921 942,-921 948,-927 948,-933 948,-933 948,-977 948,-977 948,-983 942,-989 936,-989\"/>\n<text text-anchor=\"start\" x=\"859\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 1.0</text>\n<text text-anchor=\"start\" x=\"858\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.308</text>\n<text text-anchor=\"start\" x=\"852\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 21</text>\n<text text-anchor=\"start\" x=\"851\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 17]</text>\n</g>\n<!-- 44&#45;&gt;45 -->\n<g id=\"edge45\" class=\"edge\">\n<title>44&#45;&gt;45</title>\n<path fill=\"none\" stroke=\"black\" d=\"M972.49,-1024.88C962.23,-1015.71 950.99,-1005.65 940.34,-996.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"942.5,-993.36 932.72,-989.3 937.84,-998.58 942.5,-993.36\"/>\n</g>\n<!-- 62 -->\n<g id=\"node63\" class=\"node\">\n<title>62</title>\n<path fill=\"#f6d5bd\" stroke=\"black\" d=\"M1056.5,-989C1056.5,-989 978.5,-989 978.5,-989 972.5,-989 966.5,-983 966.5,-977 966.5,-977 966.5,-933 966.5,-933 966.5,-927 972.5,-921 978.5,-921 978.5,-921 1056.5,-921 1056.5,-921 1062.5,-921 1068.5,-927 1068.5,-933 1068.5,-933 1068.5,-977 1068.5,-977 1068.5,-983 1062.5,-989 1056.5,-989\"/>\n<text text-anchor=\"start\" x=\"974.5\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.848</text>\n<text text-anchor=\"start\" x=\"984\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n<text text-anchor=\"start\" x=\"978\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"977\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 2]</text>\n</g>\n<!-- 44&#45;&gt;62 -->\n<g id=\"edge62\" class=\"edge\">\n<title>44&#45;&gt;62</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1012.1,-1024.88C1012.73,-1016.78 1013.42,-1007.98 1014.09,-999.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1017.6,-999.54 1014.89,-989.3 1010.62,-999 1017.6,-999.54\"/>\n</g>\n<!-- 46 -->\n<g id=\"node47\" class=\"node\">\n<title>46</title>\n<path fill=\"#5caeea\" stroke=\"black\" d=\"M817,-885C817,-885 736,-885 736,-885 730,-885 724,-879 724,-873 724,-873 724,-829 724,-829 724,-823 730,-817 736,-817 736,-817 817,-817 817,-817 823,-817 829,-823 829,-829 829,-829 829,-873 829,-873 829,-879 823,-885 817,-885\"/>\n<text text-anchor=\"start\" x=\"733.5\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.895</text>\n<text text-anchor=\"start\" x=\"739\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.255</text>\n<text text-anchor=\"start\" x=\"733\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 20</text>\n<text text-anchor=\"start\" x=\"732\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 17]</text>\n</g>\n<!-- 45&#45;&gt;46 -->\n<g id=\"edge46\" class=\"edge\">\n<title>45&#45;&gt;46</title>\n<path fill=\"none\" stroke=\"black\" d=\"M856.86,-920.88C846.06,-911.62 834.2,-901.45 822.99,-891.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"825.22,-889.15 815.35,-885.3 820.66,-894.46 825.22,-889.15\"/>\n</g>\n<!-- 61 -->\n<g id=\"node62\" class=\"node\">\n<title>61</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M932,-877.5C932,-877.5 859,-877.5 859,-877.5 853,-877.5 847,-871.5 847,-865.5 847,-865.5 847,-836.5 847,-836.5 847,-830.5 853,-824.5 859,-824.5 859,-824.5 932,-824.5 932,-824.5 938,-824.5 944,-830.5 944,-836.5 944,-836.5 944,-865.5 944,-865.5 944,-871.5 938,-877.5 932,-877.5\"/>\n<text text-anchor=\"start\" x=\"866.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"856\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"855\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 45&#45;&gt;61 -->\n<g id=\"edge61\" class=\"edge\">\n<title>45&#45;&gt;61</title>\n<path fill=\"none\" stroke=\"black\" d=\"M895.5,-920.88C895.5,-910.33 895.5,-898.6 895.5,-887.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"899,-887.52 895.5,-877.52 892,-887.52 899,-887.52\"/>\n</g>\n<!-- 47 -->\n<g id=\"node48\" class=\"node\">\n<title>47</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M723,-773.5C723,-773.5 650,-773.5 650,-773.5 644,-773.5 638,-767.5 638,-761.5 638,-761.5 638,-732.5 638,-732.5 638,-726.5 644,-720.5 650,-720.5 650,-720.5 723,-720.5 723,-720.5 729,-720.5 735,-726.5 735,-732.5 735,-732.5 735,-761.5 735,-761.5 735,-767.5 729,-773.5 723,-773.5\"/>\n<text text-anchor=\"start\" x=\"657.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"647\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"646\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 46&#45;&gt;47 -->\n<g id=\"edge47\" class=\"edge\">\n<title>46&#45;&gt;47</title>\n<path fill=\"none\" stroke=\"black\" d=\"M747.28,-816.88C737.19,-805.45 725.88,-792.63 715.79,-781.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"718.26,-778.7 709.02,-773.52 713.01,-783.33 718.26,-778.7\"/>\n</g>\n<!-- 48 -->\n<g id=\"node49\" class=\"node\">\n<title>48</title>\n<path fill=\"#50a9e8\" stroke=\"black\" d=\"M846,-781C846,-781 765,-781 765,-781 759,-781 753,-775 753,-769 753,-769 753,-725 753,-725 753,-719 759,-713 765,-713 765,-713 846,-713 846,-713 852,-713 858,-719 858,-725 858,-725 858,-769 858,-769 858,-775 852,-781 846,-781\"/>\n<text text-anchor=\"start\" x=\"762.5\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.835</text>\n<text text-anchor=\"start\" x=\"768\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.188</text>\n<text text-anchor=\"start\" x=\"762\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\n<text text-anchor=\"start\" x=\"761\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 17]</text>\n</g>\n<!-- 46&#45;&gt;48 -->\n<g id=\"edge48\" class=\"edge\">\n<title>46&#45;&gt;48</title>\n<path fill=\"none\" stroke=\"black\" d=\"M785.92,-816.88C788.25,-808.69 790.78,-799.79 793.22,-791.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"796.66,-791.88 796.03,-781.3 789.93,-789.96 796.66,-791.88\"/>\n</g>\n<!-- 49 -->\n<g id=\"node50\" class=\"node\">\n<title>49</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M737,-677C737,-677 662,-677 662,-677 656,-677 650,-671 650,-665 650,-665 650,-621 650,-621 650,-615 656,-609 662,-609 662,-609 737,-609 737,-609 743,-609 749,-615 749,-621 749,-621 749,-665 749,-665 749,-671 743,-677 737,-677\"/>\n<text text-anchor=\"start\" x=\"658\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.742</text>\n<text text-anchor=\"start\" x=\"662\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"660\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"659\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 48&#45;&gt;49 -->\n<g id=\"edge49\" class=\"edge\">\n<title>48&#45;&gt;49</title>\n<path fill=\"none\" stroke=\"black\" d=\"M771.08,-712.88C761.64,-703.8 751.3,-693.85 741.48,-684.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"743.74,-681.71 734.11,-677.3 738.88,-686.76 743.74,-681.71\"/>\n</g>\n<!-- 54 -->\n<g id=\"node55\" class=\"node\">\n<title>54</title>\n<path fill=\"#46a4e7\" stroke=\"black\" d=\"M860,-677C860,-677 779,-677 779,-677 773,-677 767,-671 767,-665 767,-665 767,-621 767,-621 767,-615 773,-609 779,-609 779,-609 860,-609 860,-609 866,-609 872,-615 872,-621 872,-621 872,-665 872,-665 872,-671 866,-677 860,-677\"/>\n<text text-anchor=\"start\" x=\"776.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.815</text>\n<text text-anchor=\"start\" x=\"782\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.117</text>\n<text text-anchor=\"start\" x=\"776\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"start\" x=\"775\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 15]</text>\n</g>\n<!-- 48&#45;&gt;54 -->\n<g id=\"edge54\" class=\"edge\">\n<title>48&#45;&gt;54</title>\n<path fill=\"none\" stroke=\"black\" d=\"M810.05,-712.88C811.16,-704.78 812.37,-695.98 813.53,-687.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"817.04,-687.68 814.93,-677.3 810.1,-686.73 817.04,-687.68\"/>\n</g>\n<!-- 50 -->\n<g id=\"node51\" class=\"node\">\n<title>50</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M620,-565.5C620,-565.5 547,-565.5 547,-565.5 541,-565.5 535,-559.5 535,-553.5 535,-553.5 535,-524.5 535,-524.5 535,-518.5 541,-512.5 547,-512.5 547,-512.5 620,-512.5 620,-512.5 626,-512.5 632,-518.5 632,-524.5 632,-524.5 632,-553.5 632,-553.5 632,-559.5 626,-565.5 620,-565.5\"/>\n<text text-anchor=\"start\" x=\"554.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"544\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"543\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 49&#45;&gt;50 -->\n<g id=\"edge50\" class=\"edge\">\n<title>49&#45;&gt;50</title>\n<path fill=\"none\" stroke=\"black\" d=\"M661.84,-608.88C648.46,-597.12 633.42,-583.89 620.12,-572.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"622.34,-569.49 612.52,-565.52 617.72,-574.75 622.34,-569.49\"/>\n</g>\n<!-- 51 -->\n<g id=\"node52\" class=\"node\">\n<title>51</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M737,-573C737,-573 662,-573 662,-573 656,-573 650,-567 650,-561 650,-561 650,-517 650,-517 650,-511 656,-505 662,-505 662,-505 737,-505 737,-505 743,-505 749,-511 749,-517 749,-517 749,-561 749,-561 749,-567 743,-573 737,-573\"/>\n<text text-anchor=\"start\" x=\"658\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.553</text>\n<text text-anchor=\"start\" x=\"670.5\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"660\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"659\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 49&#45;&gt;51 -->\n<g id=\"edge51\" class=\"edge\">\n<title>49&#45;&gt;51</title>\n<path fill=\"none\" stroke=\"black\" d=\"M699.5,-608.88C699.5,-600.78 699.5,-591.98 699.5,-583.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"703,-583.3 699.5,-573.3 696,-583.3 703,-583.3\"/>\n</g>\n<!-- 52 -->\n<g id=\"node53\" class=\"node\">\n<title>52</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M623,-461.5C623,-461.5 550,-461.5 550,-461.5 544,-461.5 538,-455.5 538,-449.5 538,-449.5 538,-420.5 538,-420.5 538,-414.5 544,-408.5 550,-408.5 550,-408.5 623,-408.5 623,-408.5 629,-408.5 635,-414.5 635,-420.5 635,-420.5 635,-449.5 635,-449.5 635,-455.5 629,-461.5 623,-461.5\"/>\n<text text-anchor=\"start\" x=\"557.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"547\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"546\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 51&#45;&gt;52 -->\n<g id=\"edge52\" class=\"edge\">\n<title>51&#45;&gt;52</title>\n<path fill=\"none\" stroke=\"black\" d=\"M662.81,-504.88C649.9,-493.23 635.4,-480.14 622.54,-468.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"624.54,-465.62 614.77,-461.52 619.85,-470.82 624.54,-465.62\"/>\n</g>\n<!-- 53 -->\n<g id=\"node54\" class=\"node\">\n<title>53</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M738,-461.5C738,-461.5 665,-461.5 665,-461.5 659,-461.5 653,-455.5 653,-449.5 653,-449.5 653,-420.5 653,-420.5 653,-414.5 659,-408.5 665,-408.5 665,-408.5 738,-408.5 738,-408.5 744,-408.5 750,-414.5 750,-420.5 750,-420.5 750,-449.5 750,-449.5 750,-455.5 744,-461.5 738,-461.5\"/>\n<text text-anchor=\"start\" x=\"672.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"662\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"661\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 51&#45;&gt;53 -->\n<g id=\"edge53\" class=\"edge\">\n<title>51&#45;&gt;53</title>\n<path fill=\"none\" stroke=\"black\" d=\"M700.15,-504.88C700.36,-494.22 700.59,-482.35 700.8,-471.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"704.3,-471.59 701,-461.52 697.3,-471.45 704.3,-471.59\"/>\n</g>\n<!-- 55 -->\n<g id=\"node56\" class=\"node\">\n<title>55</title>\n<path fill=\"#4da7e8\" stroke=\"black\" d=\"M860,-573C860,-573 779,-573 779,-573 773,-573 767,-567 767,-561 767,-561 767,-517 767,-517 767,-511 773,-505 779,-505 779,-505 860,-505 860,-505 866,-505 872,-511 872,-517 872,-517 872,-561 872,-561 872,-567 866,-573 860,-573\"/>\n<text text-anchor=\"start\" x=\"776.5\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.817</text>\n<text text-anchor=\"start\" x=\"782\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.165</text>\n<text text-anchor=\"start\" x=\"776\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"start\" x=\"775\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 10]</text>\n</g>\n<!-- 54&#45;&gt;55 -->\n<g id=\"edge55\" class=\"edge\">\n<title>54&#45;&gt;55</title>\n<path fill=\"none\" stroke=\"black\" d=\"M819.5,-608.88C819.5,-600.78 819.5,-591.98 819.5,-583.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"823,-583.3 819.5,-573.3 816,-583.3 823,-583.3\"/>\n</g>\n<!-- 60 -->\n<g id=\"node61\" class=\"node\">\n<title>60</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M975,-565.5C975,-565.5 902,-565.5 902,-565.5 896,-565.5 890,-559.5 890,-553.5 890,-553.5 890,-524.5 890,-524.5 890,-518.5 896,-512.5 902,-512.5 902,-512.5 975,-512.5 975,-512.5 981,-512.5 987,-518.5 987,-524.5 987,-524.5 987,-553.5 987,-553.5 987,-559.5 981,-565.5 975,-565.5\"/>\n<text text-anchor=\"start\" x=\"909.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"899\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"898\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 5]</text>\n</g>\n<!-- 54&#45;&gt;60 -->\n<g id=\"edge60\" class=\"edge\">\n<title>54&#45;&gt;60</title>\n<path fill=\"none\" stroke=\"black\" d=\"M858.14,-608.88C871.86,-597.12 887.29,-583.89 900.93,-572.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"903.41,-574.69 908.73,-565.52 898.86,-569.37 903.41,-574.69\"/>\n</g>\n<!-- 56 -->\n<g id=\"node57\" class=\"node\">\n<title>56</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M855,-461.5C855,-461.5 782,-461.5 782,-461.5 776,-461.5 770,-455.5 770,-449.5 770,-449.5 770,-420.5 770,-420.5 770,-414.5 776,-408.5 782,-408.5 782,-408.5 855,-408.5 855,-408.5 861,-408.5 867,-414.5 867,-420.5 867,-420.5 867,-449.5 867,-449.5 867,-455.5 861,-461.5 855,-461.5\"/>\n<text text-anchor=\"start\" x=\"789.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"779\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"778\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\n</g>\n<!-- 55&#45;&gt;56 -->\n<g id=\"edge56\" class=\"edge\">\n<title>55&#45;&gt;56</title>\n<path fill=\"none\" stroke=\"black\" d=\"M819.18,-504.88C819.07,-494.33 818.96,-482.6 818.85,-471.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"822.35,-471.49 818.75,-461.52 815.35,-471.55 822.35,-471.49\"/>\n</g>\n<!-- 57 -->\n<g id=\"node58\" class=\"node\">\n<title>57</title>\n<path fill=\"#55abe9\" stroke=\"black\" d=\"M972,-469C972,-469 897,-469 897,-469 891,-469 885,-463 885,-457 885,-457 885,-413 885,-413 885,-407 891,-401 897,-401 897,-401 972,-401 972,-401 978,-401 984,-407 984,-413 984,-413 984,-457 984,-457 984,-463 978,-469 972,-469\"/>\n<text text-anchor=\"start\" x=\"893\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.591</text>\n<text text-anchor=\"start\" x=\"897\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.219</text>\n<text text-anchor=\"start\" x=\"895\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"894\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 7]</text>\n</g>\n<!-- 55&#45;&gt;57 -->\n<g id=\"edge57\" class=\"edge\">\n<title>55&#45;&gt;57</title>\n<path fill=\"none\" stroke=\"black\" d=\"M856.84,-504.88C867.18,-495.71 878.52,-485.65 889.26,-476.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"891.8,-478.55 896.96,-469.3 887.15,-473.32 891.8,-478.55\"/>\n</g>\n<!-- 58 -->\n<g id=\"node59\" class=\"node\">\n<title>58</title>\n<path fill=\"#61b1ea\" stroke=\"black\" d=\"M909,-357.5C909,-357.5 836,-357.5 836,-357.5 830,-357.5 824,-351.5 824,-345.5 824,-345.5 824,-316.5 824,-316.5 824,-310.5 830,-304.5 836,-304.5 836,-304.5 909,-304.5 909,-304.5 915,-304.5 921,-310.5 921,-316.5 921,-316.5 921,-345.5 921,-345.5 921,-351.5 915,-357.5 909,-357.5\"/>\n<text text-anchor=\"start\" x=\"835\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.278</text>\n<text text-anchor=\"start\" x=\"833\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"832\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 5]</text>\n</g>\n<!-- 57&#45;&gt;58 -->\n<g id=\"edge58\" class=\"edge\">\n<title>57&#45;&gt;58</title>\n<path fill=\"none\" stroke=\"black\" d=\"M914.37,-400.88C907.62,-389.78 900.08,-377.37 893.28,-366.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"896.2,-364.25 888.01,-357.52 890.22,-367.88 896.2,-364.25\"/>\n</g>\n<!-- 59 -->\n<g id=\"node60\" class=\"node\">\n<title>59</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1024,-357.5C1024,-357.5 951,-357.5 951,-357.5 945,-357.5 939,-351.5 939,-345.5 939,-345.5 939,-316.5 939,-316.5 939,-310.5 945,-304.5 951,-304.5 951,-304.5 1024,-304.5 1024,-304.5 1030,-304.5 1036,-310.5 1036,-316.5 1036,-316.5 1036,-345.5 1036,-345.5 1036,-351.5 1030,-357.5 1024,-357.5\"/>\n<text text-anchor=\"start\" x=\"958.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"948\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"947\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 57&#45;&gt;59 -->\n<g id=\"edge59\" class=\"edge\">\n<title>57&#45;&gt;59</title>\n<path fill=\"none\" stroke=\"black\" d=\"M951.71,-400.88C957.42,-389.89 963.8,-377.62 969.56,-366.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"972.73,-368.01 974.24,-357.52 966.52,-364.78 972.73,-368.01\"/>\n</g>\n<!-- 63 -->\n<g id=\"node64\" class=\"node\">\n<title>63</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1047,-877.5C1047,-877.5 974,-877.5 974,-877.5 968,-877.5 962,-871.5 962,-865.5 962,-865.5 962,-836.5 962,-836.5 962,-830.5 968,-824.5 974,-824.5 974,-824.5 1047,-824.5 1047,-824.5 1053,-824.5 1059,-830.5 1059,-836.5 1059,-836.5 1059,-865.5 1059,-865.5 1059,-871.5 1053,-877.5 1047,-877.5\"/>\n<text text-anchor=\"start\" x=\"981.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"971\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"970\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 62&#45;&gt;63 -->\n<g id=\"edge63\" class=\"edge\">\n<title>62&#45;&gt;63</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1015.23,-920.88C1014.5,-910.22 1013.68,-898.35 1012.94,-887.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1016.43,-887.26 1012.25,-877.52 1009.44,-887.74 1016.43,-887.26\"/>\n</g>\n<!-- 64 -->\n<g id=\"node65\" class=\"node\">\n<title>64</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1162,-877.5C1162,-877.5 1089,-877.5 1089,-877.5 1083,-877.5 1077,-871.5 1077,-865.5 1077,-865.5 1077,-836.5 1077,-836.5 1077,-830.5 1083,-824.5 1089,-824.5 1089,-824.5 1162,-824.5 1162,-824.5 1168,-824.5 1174,-830.5 1174,-836.5 1174,-836.5 1174,-865.5 1174,-865.5 1174,-871.5 1168,-877.5 1162,-877.5\"/>\n<text text-anchor=\"start\" x=\"1096.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1086\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1085\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 62&#45;&gt;64 -->\n<g id=\"edge64\" class=\"edge\">\n<title>62&#45;&gt;64</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1052.56,-920.88C1064.91,-909.23 1078.76,-896.14 1091.05,-884.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1093.61,-886.93 1098.48,-877.52 1088.81,-881.84 1093.61,-886.93\"/>\n</g>\n<!-- 66 -->\n<g id=\"node67\" class=\"node\">\n<title>66</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1172,-981.5C1172,-981.5 1099,-981.5 1099,-981.5 1093,-981.5 1087,-975.5 1087,-969.5 1087,-969.5 1087,-940.5 1087,-940.5 1087,-934.5 1093,-928.5 1099,-928.5 1099,-928.5 1172,-928.5 1172,-928.5 1178,-928.5 1184,-934.5 1184,-940.5 1184,-940.5 1184,-969.5 1184,-969.5 1184,-975.5 1178,-981.5 1172,-981.5\"/>\n<text text-anchor=\"start\" x=\"1106.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1096\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"1095\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 0]</text>\n</g>\n<!-- 65&#45;&gt;66 -->\n<g id=\"edge66\" class=\"edge\">\n<title>65&#45;&gt;66</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1136.18,-1024.88C1136.07,-1014.33 1135.96,-1002.6 1135.85,-991.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1139.35,-991.49 1135.75,-981.52 1132.35,-991.55 1139.35,-991.49\"/>\n</g>\n<!-- 67 -->\n<g id=\"node68\" class=\"node\">\n<title>67</title>\n<path fill=\"#c5e2f7\" stroke=\"black\" d=\"M1303,-989C1303,-989 1214,-989 1214,-989 1208,-989 1202,-983 1202,-977 1202,-977 1202,-933 1202,-933 1202,-927 1208,-921 1214,-921 1214,-921 1303,-921 1303,-921 1309,-921 1315,-927 1315,-933 1315,-933 1315,-977 1315,-977 1315,-983 1309,-989 1303,-989\"/>\n<text text-anchor=\"start\" x=\"1217\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.629</text>\n<text text-anchor=\"start\" x=\"1221\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.485</text>\n<text text-anchor=\"start\" x=\"1215\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 29</text>\n<text text-anchor=\"start\" x=\"1210\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [12, 17]</text>\n</g>\n<!-- 65&#45;&gt;67 -->\n<g id=\"edge67\" class=\"edge\">\n<title>65&#45;&gt;67</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1176.11,-1024.88C1187.19,-1015.62 1199.35,-1005.45 1210.84,-995.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1213.24,-998.4 1218.67,-989.3 1208.75,-993.03 1213.24,-998.4\"/>\n</g>\n<!-- 68 -->\n<g id=\"node69\" class=\"node\">\n<title>68</title>\n<path fill=\"#efb388\" stroke=\"black\" d=\"M1277,-885C1277,-885 1204,-885 1204,-885 1198,-885 1192,-879 1192,-873 1192,-873 1192,-829 1192,-829 1192,-823 1198,-817 1204,-817 1204,-817 1277,-817 1277,-817 1283,-817 1289,-823 1289,-829 1289,-829 1289,-873 1289,-873 1289,-879 1283,-885 1277,-885\"/>\n<text text-anchor=\"start\" x=\"1201.5\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.62</text>\n<text text-anchor=\"start\" x=\"1203\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.408</text>\n<text text-anchor=\"start\" x=\"1201\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"1200\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 2]</text>\n</g>\n<!-- 67&#45;&gt;68 -->\n<g id=\"edge68\" class=\"edge\">\n<title>67&#45;&gt;68</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1252.66,-920.88C1251.21,-912.69 1249.64,-903.79 1248.12,-895.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1251.56,-894.54 1246.38,-885.3 1244.67,-895.76 1251.56,-894.54\"/>\n</g>\n<!-- 75 -->\n<g id=\"node76\" class=\"node\">\n<title>75</title>\n<path fill=\"#95cbf1\" stroke=\"black\" d=\"M1400,-885C1400,-885 1319,-885 1319,-885 1313,-885 1307,-879 1307,-873 1307,-873 1307,-829 1307,-829 1307,-823 1313,-817 1319,-817 1319,-817 1400,-817 1400,-817 1406,-817 1412,-823 1412,-829 1412,-829 1412,-873 1412,-873 1412,-879 1406,-885 1400,-885\"/>\n<text text-anchor=\"start\" x=\"1318\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.591</text>\n<text text-anchor=\"start\" x=\"1322\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.434</text>\n<text text-anchor=\"start\" x=\"1316\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 22</text>\n<text text-anchor=\"start\" x=\"1315\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 15]</text>\n</g>\n<!-- 67&#45;&gt;75 -->\n<g id=\"edge75\" class=\"edge\">\n<title>67&#45;&gt;75</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1291.29,-920.88C1300.2,-911.89 1309.95,-902.04 1319.22,-892.68\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1321.98,-894.87 1326.53,-885.3 1317,-889.94 1321.98,-894.87\"/>\n</g>\n<!-- 69 -->\n<g id=\"node70\" class=\"node\">\n<title>69</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1159,-773.5C1159,-773.5 1086,-773.5 1086,-773.5 1080,-773.5 1074,-767.5 1074,-761.5 1074,-761.5 1074,-732.5 1074,-732.5 1074,-726.5 1080,-720.5 1086,-720.5 1086,-720.5 1159,-720.5 1159,-720.5 1165,-720.5 1171,-726.5 1171,-732.5 1171,-732.5 1171,-761.5 1171,-761.5 1171,-767.5 1165,-773.5 1159,-773.5\"/>\n<text text-anchor=\"start\" x=\"1093.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1083\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1082\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 68&#45;&gt;69 -->\n<g id=\"edge69\" class=\"edge\">\n<title>68&#45;&gt;69</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1202.19,-816.88C1188.58,-805.12 1173.28,-791.89 1159.75,-780.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1161.88,-777.41 1152.02,-773.52 1157.3,-782.71 1161.88,-777.41\"/>\n</g>\n<!-- 70 -->\n<g id=\"node71\" class=\"node\">\n<title>70</title>\n<path fill=\"#ea9a61\" stroke=\"black\" d=\"M1279.5,-781C1279.5,-781 1201.5,-781 1201.5,-781 1195.5,-781 1189.5,-775 1189.5,-769 1189.5,-769 1189.5,-725 1189.5,-725 1189.5,-719 1195.5,-713 1201.5,-713 1201.5,-713 1279.5,-713 1279.5,-713 1285.5,-713 1291.5,-719 1291.5,-725 1291.5,-725 1291.5,-769 1291.5,-769 1291.5,-775 1285.5,-781 1279.5,-781\"/>\n<text text-anchor=\"start\" x=\"1197.5\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.412</text>\n<text text-anchor=\"start\" x=\"1203\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.278</text>\n<text text-anchor=\"start\" x=\"1201\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"1200\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 1]</text>\n</g>\n<!-- 68&#45;&gt;70 -->\n<g id=\"edge70\" class=\"edge\">\n<title>68&#45;&gt;70</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1240.5,-816.88C1240.5,-808.78 1240.5,-799.98 1240.5,-791.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1244,-791.3 1240.5,-781.3 1237,-791.3 1244,-791.3\"/>\n</g>\n<!-- 71 -->\n<g id=\"node72\" class=\"node\">\n<title>71</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M1163.5,-677C1163.5,-677 1085.5,-677 1085.5,-677 1079.5,-677 1073.5,-671 1073.5,-665 1073.5,-665 1073.5,-621 1073.5,-621 1073.5,-615 1079.5,-609 1085.5,-609 1085.5,-609 1163.5,-609 1163.5,-609 1169.5,-609 1175.5,-615 1175.5,-621 1175.5,-621 1175.5,-665 1175.5,-665 1175.5,-671 1169.5,-677 1163.5,-677\"/>\n<text text-anchor=\"start\" x=\"1081.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.596</text>\n<text text-anchor=\"start\" x=\"1087\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"1085\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1084\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 1]</text>\n</g>\n<!-- 70&#45;&gt;71 -->\n<g id=\"edge71\" class=\"edge\">\n<title>70&#45;&gt;71</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1202.84,-712.88C1192.4,-703.71 1180.96,-693.65 1170.13,-684.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1172.19,-681.27 1162.37,-677.3 1167.57,-686.53 1172.19,-681.27\"/>\n</g>\n<!-- 74 -->\n<g id=\"node75\" class=\"node\">\n<title>74</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1279,-669.5C1279,-669.5 1206,-669.5 1206,-669.5 1200,-669.5 1194,-663.5 1194,-657.5 1194,-657.5 1194,-628.5 1194,-628.5 1194,-622.5 1200,-616.5 1206,-616.5 1206,-616.5 1279,-616.5 1279,-616.5 1285,-616.5 1291,-622.5 1291,-628.5 1291,-628.5 1291,-657.5 1291,-657.5 1291,-663.5 1285,-669.5 1279,-669.5\"/>\n<text text-anchor=\"start\" x=\"1213.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1203\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1202\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 70&#45;&gt;74 -->\n<g id=\"edge74\" class=\"edge\">\n<title>70&#45;&gt;74</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1241.15,-712.88C1241.36,-702.22 1241.59,-690.35 1241.8,-679.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1245.3,-679.59 1242,-669.52 1238.3,-679.45 1245.3,-679.59\"/>\n</g>\n<!-- 72 -->\n<g id=\"node73\" class=\"node\">\n<title>72</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1091,-565.5C1091,-565.5 1018,-565.5 1018,-565.5 1012,-565.5 1006,-559.5 1006,-553.5 1006,-553.5 1006,-524.5 1006,-524.5 1006,-518.5 1012,-512.5 1018,-512.5 1018,-512.5 1091,-512.5 1091,-512.5 1097,-512.5 1103,-518.5 1103,-524.5 1103,-524.5 1103,-553.5 1103,-553.5 1103,-559.5 1097,-565.5 1091,-565.5\"/>\n<text text-anchor=\"start\" x=\"1025.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1015\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1014\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 71&#45;&gt;72 -->\n<g id=\"edge72\" class=\"edge\">\n<title>71&#45;&gt;72</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1101.77,-608.88C1094.07,-597.67 1085.47,-585.13 1077.73,-573.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1080.56,-571.78 1072.01,-565.52 1074.79,-575.75 1080.56,-571.78\"/>\n</g>\n<!-- 73 -->\n<g id=\"node74\" class=\"node\">\n<title>73</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1206,-565.5C1206,-565.5 1133,-565.5 1133,-565.5 1127,-565.5 1121,-559.5 1121,-553.5 1121,-553.5 1121,-524.5 1121,-524.5 1121,-518.5 1127,-512.5 1133,-512.5 1133,-512.5 1206,-512.5 1206,-512.5 1212,-512.5 1218,-518.5 1218,-524.5 1218,-524.5 1218,-553.5 1218,-553.5 1218,-559.5 1212,-565.5 1206,-565.5\"/>\n<text text-anchor=\"start\" x=\"1140.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1130\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1129\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 71&#45;&gt;73 -->\n<g id=\"edge73\" class=\"edge\">\n<title>71&#45;&gt;73</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1139.11,-608.88C1143.91,-598 1149.27,-585.86 1154.13,-574.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1157.41,-576.08 1158.24,-565.52 1151,-573.26 1157.41,-576.08\"/>\n</g>\n<!-- 76 -->\n<g id=\"node77\" class=\"node\">\n<title>76</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1395,-773.5C1395,-773.5 1322,-773.5 1322,-773.5 1316,-773.5 1310,-767.5 1310,-761.5 1310,-761.5 1310,-732.5 1310,-732.5 1310,-726.5 1316,-720.5 1322,-720.5 1322,-720.5 1395,-720.5 1395,-720.5 1401,-720.5 1407,-726.5 1407,-732.5 1407,-732.5 1407,-761.5 1407,-761.5 1407,-767.5 1401,-773.5 1395,-773.5\"/>\n<text text-anchor=\"start\" x=\"1329.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1319\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"1318\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4]</text>\n</g>\n<!-- 75&#45;&gt;76 -->\n<g id=\"edge76\" class=\"edge\">\n<title>75&#45;&gt;76</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1359.18,-816.88C1359.07,-806.33 1358.96,-794.6 1358.85,-783.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1362.35,-783.49 1358.75,-773.52 1355.35,-783.55 1362.35,-783.49\"/>\n</g>\n<!-- 77 -->\n<g id=\"node78\" class=\"node\">\n<title>77</title>\n<path fill=\"#b7dbf6\" stroke=\"black\" d=\"M1562,-781C1562,-781 1437,-781 1437,-781 1431,-781 1425,-775 1425,-769 1425,-769 1425,-725 1425,-725 1425,-719 1431,-713 1437,-713 1437,-713 1562,-713 1562,-713 1568,-713 1574,-719 1574,-725 1574,-725 1574,-769 1574,-769 1574,-775 1568,-781 1562,-781\"/>\n<text text-anchor=\"start\" x=\"1433\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">name_title_Mrs ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1462\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.475</text>\n<text text-anchor=\"start\" x=\"1456\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n<text text-anchor=\"start\" x=\"1455\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 11]</text>\n</g>\n<!-- 75&#45;&gt;77 -->\n<g id=\"edge77\" class=\"edge\">\n<title>75&#45;&gt;77</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1404.95,-816.88C1417.91,-807.44 1432.16,-797.06 1445.57,-787.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1447.77,-790.02 1453.79,-781.3 1443.65,-784.36 1447.77,-790.02\"/>\n</g>\n<!-- 78 -->\n<g id=\"node79\" class=\"node\">\n<title>78</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1417,-669.5C1417,-669.5 1344,-669.5 1344,-669.5 1338,-669.5 1332,-663.5 1332,-657.5 1332,-657.5 1332,-628.5 1332,-628.5 1332,-622.5 1338,-616.5 1344,-616.5 1344,-616.5 1417,-616.5 1417,-616.5 1423,-616.5 1429,-622.5 1429,-628.5 1429,-628.5 1429,-657.5 1429,-657.5 1429,-663.5 1423,-669.5 1417,-669.5\"/>\n<text text-anchor=\"start\" x=\"1351.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1341\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1340\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 77&#45;&gt;78 -->\n<g id=\"edge78\" class=\"edge\">\n<title>77&#45;&gt;78</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1460.86,-712.88C1447.14,-701.12 1431.71,-687.89 1418.07,-676.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1420.14,-673.37 1410.27,-669.52 1415.59,-678.69 1420.14,-673.37\"/>\n</g>\n<!-- 79 -->\n<g id=\"node80\" class=\"node\">\n<title>79</title>\n<path fill=\"#93caf1\" stroke=\"black\" d=\"M1540,-677C1540,-677 1459,-677 1459,-677 1453,-677 1447,-671 1447,-665 1447,-665 1447,-621 1447,-621 1447,-615 1453,-609 1459,-609 1459,-609 1540,-609 1540,-609 1546,-609 1552,-615 1552,-621 1552,-621 1552,-665 1552,-665 1552,-671 1546,-677 1540,-677\"/>\n<text text-anchor=\"start\" x=\"1463\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 3.5</text>\n<text text-anchor=\"start\" x=\"1466\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.43</text>\n<text text-anchor=\"start\" x=\"1456\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"start\" x=\"1455\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 11]</text>\n</g>\n<!-- 77&#45;&gt;79 -->\n<g id=\"edge79\" class=\"edge\">\n<title>77&#45;&gt;79</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1499.5,-712.88C1499.5,-704.78 1499.5,-695.98 1499.5,-687.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1503,-687.3 1499.5,-677.3 1496,-687.3 1503,-687.3\"/>\n</g>\n<!-- 80 -->\n<g id=\"node81\" class=\"node\">\n<title>80</title>\n<path fill=\"#81c1ee\" stroke=\"black\" d=\"M1329,-573C1329,-573 1248,-573 1248,-573 1242,-573 1236,-567 1236,-561 1236,-561 1236,-517 1236,-517 1236,-511 1242,-505 1248,-505 1248,-505 1329,-505 1329,-505 1335,-505 1341,-511 1341,-517 1341,-517 1341,-561 1341,-561 1341,-567 1335,-573 1329,-573\"/>\n<text text-anchor=\"start\" x=\"1251\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1251\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.391</text>\n<text text-anchor=\"start\" x=\"1245\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\n<text text-anchor=\"start\" x=\"1244\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 11]</text>\n</g>\n<!-- 79&#45;&gt;80 -->\n<g id=\"edge80\" class=\"edge\">\n<title>79&#45;&gt;80</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1446.84,-613.72C1443.69,-612.1 1440.56,-610.52 1437.5,-609 1409.19,-594.92 1377.44,-580.09 1350.54,-567.8\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1351.8,-564.53 1341.24,-563.56 1348.89,-570.9 1351.8,-564.53\"/>\n</g>\n<!-- 89 -->\n<g id=\"node90\" class=\"node\">\n<title>89</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1536,-565.5C1536,-565.5 1463,-565.5 1463,-565.5 1457,-565.5 1451,-559.5 1451,-553.5 1451,-553.5 1451,-524.5 1451,-524.5 1451,-518.5 1457,-512.5 1463,-512.5 1463,-512.5 1536,-512.5 1536,-512.5 1542,-512.5 1548,-518.5 1548,-524.5 1548,-524.5 1548,-553.5 1548,-553.5 1548,-559.5 1542,-565.5 1536,-565.5\"/>\n<text text-anchor=\"start\" x=\"1470.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1460\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1459\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 79&#45;&gt;89 -->\n<g id=\"edge89\" class=\"edge\">\n<title>79&#45;&gt;89</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1499.5,-608.88C1499.5,-598.33 1499.5,-586.6 1499.5,-575.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1503,-575.52 1499.5,-565.52 1496,-575.52 1503,-575.52\"/>\n</g>\n<!-- 81 -->\n<g id=\"node82\" class=\"node\">\n<title>81</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1210,-461.5C1210,-461.5 1137,-461.5 1137,-461.5 1131,-461.5 1125,-455.5 1125,-449.5 1125,-449.5 1125,-420.5 1125,-420.5 1125,-414.5 1131,-408.5 1137,-408.5 1137,-408.5 1210,-408.5 1210,-408.5 1216,-408.5 1222,-414.5 1222,-420.5 1222,-420.5 1222,-449.5 1222,-449.5 1222,-455.5 1216,-461.5 1210,-461.5\"/>\n<text text-anchor=\"start\" x=\"1144.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1134\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"1133\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 6]</text>\n</g>\n<!-- 80&#45;&gt;81 -->\n<g id=\"edge81\" class=\"edge\">\n<title>80&#45;&gt;81</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1251.16,-504.88C1237.9,-493.12 1222.99,-479.89 1209.81,-468.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1212.08,-465.54 1202.27,-461.52 1207.43,-470.77 1212.08,-465.54\"/>\n</g>\n<!-- 82 -->\n<g id=\"node83\" class=\"node\">\n<title>82</title>\n<path fill=\"#d7ebfa\" stroke=\"black\" d=\"M1325,-469C1325,-469 1252,-469 1252,-469 1246,-469 1240,-463 1240,-457 1240,-457 1240,-413 1240,-413 1240,-407 1246,-401 1252,-401 1252,-401 1325,-401 1325,-401 1331,-401 1337,-407 1337,-413 1337,-413 1337,-457 1337,-457 1337,-463 1331,-469 1325,-469\"/>\n<text text-anchor=\"start\" x=\"1249\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.286</text>\n<text text-anchor=\"start\" x=\"1251\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.494</text>\n<text text-anchor=\"start\" x=\"1249\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"1248\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 5]</text>\n</g>\n<!-- 80&#45;&gt;82 -->\n<g id=\"edge82\" class=\"edge\">\n<title>80&#45;&gt;82</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1288.5,-504.88C1288.5,-496.78 1288.5,-487.98 1288.5,-479.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1292,-479.3 1288.5,-469.3 1285,-479.3 1292,-479.3\"/>\n</g>\n<!-- 83 -->\n<g id=\"node84\" class=\"node\">\n<title>83</title>\n<path fill=\"#eeab7b\" stroke=\"black\" d=\"M1190.5,-365C1190.5,-365 1116.5,-365 1116.5,-365 1110.5,-365 1104.5,-359 1104.5,-353 1104.5,-353 1104.5,-309 1104.5,-309 1104.5,-303 1110.5,-297 1116.5,-297 1116.5,-297 1190.5,-297 1190.5,-297 1196.5,-297 1202.5,-303 1202.5,-309 1202.5,-309 1202.5,-353 1202.5,-353 1202.5,-359 1196.5,-365 1190.5,-365\"/>\n<text text-anchor=\"start\" x=\"1112.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.049</text>\n<text text-anchor=\"start\" x=\"1116\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"1114\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"1113\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 1]</text>\n</g>\n<!-- 82&#45;&gt;83 -->\n<g id=\"edge83\" class=\"edge\">\n<title>82&#45;&gt;83</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1244.67,-400.88C1232.29,-391.53 1218.7,-381.26 1205.87,-371.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1207.66,-368.54 1197.57,-365.3 1203.44,-374.12 1207.66,-368.54\"/>\n</g>\n<!-- 86 -->\n<g id=\"node87\" class=\"node\">\n<title>86</title>\n<path fill=\"#6ab6ec\" stroke=\"black\" d=\"M1344.5,-365C1344.5,-365 1232.5,-365 1232.5,-365 1226.5,-365 1220.5,-359 1220.5,-353 1220.5,-353 1220.5,-309 1220.5,-309 1220.5,-303 1226.5,-297 1232.5,-297 1232.5,-297 1344.5,-297 1344.5,-297 1350.5,-297 1356.5,-303 1356.5,-309 1356.5,-309 1356.5,-353 1356.5,-353 1356.5,-359 1350.5,-365 1344.5,-365\"/>\n<text text-anchor=\"start\" x=\"1228.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Embarked_C ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"1255\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"1249\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"1248\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 4]</text>\n</g>\n<!-- 82&#45;&gt;86 -->\n<g id=\"edge86\" class=\"edge\">\n<title>82&#45;&gt;86</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1288.5,-400.88C1288.5,-392.78 1288.5,-383.98 1288.5,-375.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1292,-375.3 1288.5,-365.3 1285,-375.3 1292,-375.3\"/>\n</g>\n<!-- 84 -->\n<g id=\"node85\" class=\"node\">\n<title>84</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1080,-253.5C1080,-253.5 1007,-253.5 1007,-253.5 1001,-253.5 995,-247.5 995,-241.5 995,-241.5 995,-212.5 995,-212.5 995,-206.5 1001,-200.5 1007,-200.5 1007,-200.5 1080,-200.5 1080,-200.5 1086,-200.5 1092,-206.5 1092,-212.5 1092,-212.5 1092,-241.5 1092,-241.5 1092,-247.5 1086,-253.5 1080,-253.5\"/>\n<text text-anchor=\"start\" x=\"1014.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1004\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1003\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 83&#45;&gt;84 -->\n<g id=\"edge84\" class=\"edge\">\n<title>83&#45;&gt;84</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1117.79,-296.88C1105.21,-285.23 1091.1,-272.14 1078.58,-260.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1080.73,-257.75 1071.02,-253.52 1075.97,-262.89 1080.73,-257.75\"/>\n</g>\n<!-- 85 -->\n<g id=\"node86\" class=\"node\">\n<title>85</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1195,-253.5C1195,-253.5 1122,-253.5 1122,-253.5 1116,-253.5 1110,-247.5 1110,-241.5 1110,-241.5 1110,-212.5 1110,-212.5 1110,-206.5 1116,-200.5 1122,-200.5 1122,-200.5 1195,-200.5 1195,-200.5 1201,-200.5 1207,-206.5 1207,-212.5 1207,-212.5 1207,-241.5 1207,-241.5 1207,-247.5 1201,-253.5 1195,-253.5\"/>\n<text text-anchor=\"start\" x=\"1129.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1119\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1118\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 83&#45;&gt;85 -->\n<g id=\"edge85\" class=\"edge\">\n<title>83&#45;&gt;85</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1155.12,-296.88C1155.65,-286.22 1156.23,-274.35 1156.76,-263.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1160.26,-263.68 1157.25,-253.52 1153.26,-263.34 1160.26,-263.68\"/>\n</g>\n<!-- 87 -->\n<g id=\"node88\" class=\"node\">\n<title>87</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1320,-253.5C1320,-253.5 1247,-253.5 1247,-253.5 1241,-253.5 1235,-247.5 1235,-241.5 1235,-241.5 1235,-212.5 1235,-212.5 1235,-206.5 1241,-200.5 1247,-200.5 1247,-200.5 1320,-200.5 1320,-200.5 1326,-200.5 1332,-206.5 1332,-212.5 1332,-212.5 1332,-241.5 1332,-241.5 1332,-247.5 1326,-253.5 1320,-253.5\"/>\n<text text-anchor=\"start\" x=\"1254.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1244\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"1243\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4]</text>\n</g>\n<!-- 86&#45;&gt;87 -->\n<g id=\"edge87\" class=\"edge\">\n<title>86&#45;&gt;87</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1286.88,-296.88C1286.35,-286.22 1285.77,-274.35 1285.24,-263.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1288.74,-263.34 1284.75,-253.52 1281.74,-263.68 1288.74,-263.34\"/>\n</g>\n<!-- 88 -->\n<g id=\"node89\" class=\"node\">\n<title>88</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1435,-253.5C1435,-253.5 1362,-253.5 1362,-253.5 1356,-253.5 1350,-247.5 1350,-241.5 1350,-241.5 1350,-212.5 1350,-212.5 1350,-206.5 1356,-200.5 1362,-200.5 1362,-200.5 1435,-200.5 1435,-200.5 1441,-200.5 1447,-206.5 1447,-212.5 1447,-212.5 1447,-241.5 1447,-241.5 1447,-247.5 1441,-253.5 1435,-253.5\"/>\n<text text-anchor=\"start\" x=\"1369.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1359\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1358\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 86&#45;&gt;88 -->\n<g id=\"edge88\" class=\"edge\">\n<title>86&#45;&gt;88</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1324.21,-296.88C1336.79,-285.23 1350.9,-272.14 1363.42,-260.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1366.03,-262.89 1370.98,-253.52 1361.27,-257.75 1366.03,-262.89\"/>\n</g>\n<!-- 92 -->\n<g id=\"node93\" class=\"node\">\n<title>92</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1208,-1293.5C1208,-1293.5 1135,-1293.5 1135,-1293.5 1129,-1293.5 1123,-1287.5 1123,-1281.5 1123,-1281.5 1123,-1252.5 1123,-1252.5 1123,-1246.5 1129,-1240.5 1135,-1240.5 1135,-1240.5 1208,-1240.5 1208,-1240.5 1214,-1240.5 1220,-1246.5 1220,-1252.5 1220,-1252.5 1220,-1281.5 1220,-1281.5 1220,-1287.5 1214,-1293.5 1208,-1293.5\"/>\n<text text-anchor=\"start\" x=\"1142.5\" y=\"-1278.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1132\" y=\"-1263.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1131\" y=\"-1248.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 91&#45;&gt;92 -->\n<g id=\"edge92\" class=\"edge\">\n<title>91&#45;&gt;92</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1173.53,-1336.88C1173.21,-1326.22 1172.86,-1314.35 1172.54,-1303.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1176.04,-1303.41 1172.25,-1293.52 1169.05,-1303.62 1176.04,-1303.41\"/>\n</g>\n<!-- 93 -->\n<g id=\"node94\" class=\"node\">\n<title>93</title>\n<path fill=\"#e6853f\" stroke=\"black\" d=\"M1331,-1301C1331,-1301 1250,-1301 1250,-1301 1244,-1301 1238,-1295 1238,-1289 1238,-1289 1238,-1245 1238,-1245 1238,-1239 1244,-1233 1250,-1233 1250,-1233 1331,-1233 1331,-1233 1337,-1233 1343,-1239 1343,-1245 1343,-1245 1343,-1289 1343,-1289 1343,-1295 1337,-1301 1331,-1301\"/>\n<text text-anchor=\"start\" x=\"1249\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;1.791</text>\n<text text-anchor=\"start\" x=\"1253\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.061</text>\n<text text-anchor=\"start\" x=\"1247\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 32</text>\n<text text-anchor=\"start\" x=\"1246\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 1]</text>\n</g>\n<!-- 91&#45;&gt;93 -->\n<g id=\"edge93\" class=\"edge\">\n<title>91&#45;&gt;93</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1212.16,-1336.88C1222.6,-1327.71 1234.04,-1317.65 1244.87,-1308.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1247.43,-1310.53 1252.63,-1301.3 1242.81,-1305.27 1247.43,-1310.53\"/>\n</g>\n<!-- 94 -->\n<g id=\"node95\" class=\"node\">\n<title>94</title>\n<path fill=\"#e88f4f\" stroke=\"black\" d=\"M1315,-1197C1315,-1197 1236,-1197 1236,-1197 1230,-1197 1224,-1191 1224,-1185 1224,-1185 1224,-1141 1224,-1141 1224,-1135 1230,-1129 1236,-1129 1236,-1129 1315,-1129 1315,-1129 1321,-1129 1327,-1135 1327,-1141 1327,-1141 1327,-1185 1327,-1185 1327,-1191 1321,-1197 1315,-1197\"/>\n<text text-anchor=\"start\" x=\"1234\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;1.883</text>\n<text text-anchor=\"start\" x=\"1242\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.18</text>\n<text text-anchor=\"start\" x=\"1232\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"1235\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 1]</text>\n</g>\n<!-- 93&#45;&gt;94 -->\n<g id=\"edge94\" class=\"edge\">\n<title>93&#45;&gt;94</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1285.63,-1232.88C1284.44,-1224.78 1283.14,-1215.98 1281.89,-1207.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1285.31,-1206.68 1280.4,-1197.3 1278.39,-1207.7 1285.31,-1206.68\"/>\n</g>\n<!-- 97 -->\n<g id=\"node98\" class=\"node\">\n<title>97</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1438,-1189.5C1438,-1189.5 1357,-1189.5 1357,-1189.5 1351,-1189.5 1345,-1183.5 1345,-1177.5 1345,-1177.5 1345,-1148.5 1345,-1148.5 1345,-1142.5 1351,-1136.5 1357,-1136.5 1357,-1136.5 1438,-1136.5 1438,-1136.5 1444,-1136.5 1450,-1142.5 1450,-1148.5 1450,-1148.5 1450,-1177.5 1450,-1177.5 1450,-1183.5 1444,-1189.5 1438,-1189.5\"/>\n<text text-anchor=\"start\" x=\"1368.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1354\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 22</text>\n<text text-anchor=\"start\" x=\"1353\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [22, 0]</text>\n</g>\n<!-- 93&#45;&gt;97 -->\n<g id=\"edge97\" class=\"edge\">\n<title>93&#45;&gt;97</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1325.24,-1232.88C1337.47,-1221.23 1351.2,-1208.14 1363.37,-1196.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1365.91,-1198.95 1370.73,-1189.52 1361.08,-1193.89 1365.91,-1198.95\"/>\n</g>\n<!-- 95 -->\n<g id=\"node96\" class=\"node\">\n<title>95</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1304,-1085.5C1304,-1085.5 1231,-1085.5 1231,-1085.5 1225,-1085.5 1219,-1079.5 1219,-1073.5 1219,-1073.5 1219,-1044.5 1219,-1044.5 1219,-1038.5 1225,-1032.5 1231,-1032.5 1231,-1032.5 1304,-1032.5 1304,-1032.5 1310,-1032.5 1316,-1038.5 1316,-1044.5 1316,-1044.5 1316,-1073.5 1316,-1073.5 1316,-1079.5 1310,-1085.5 1304,-1085.5\"/>\n<text text-anchor=\"start\" x=\"1238.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1228\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"1227\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 0]</text>\n</g>\n<!-- 94&#45;&gt;95 -->\n<g id=\"edge95\" class=\"edge\">\n<title>94&#45;&gt;95</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1272.9,-1128.88C1272.07,-1118.22 1271.14,-1106.35 1270.29,-1095.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1273.77,-1095.22 1269.5,-1085.52 1266.79,-1095.76 1273.77,-1095.22\"/>\n</g>\n<!-- 96 -->\n<g id=\"node97\" class=\"node\">\n<title>96</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1419,-1085.5C1419,-1085.5 1346,-1085.5 1346,-1085.5 1340,-1085.5 1334,-1079.5 1334,-1073.5 1334,-1073.5 1334,-1044.5 1334,-1044.5 1334,-1038.5 1340,-1032.5 1346,-1032.5 1346,-1032.5 1419,-1032.5 1419,-1032.5 1425,-1032.5 1431,-1038.5 1431,-1044.5 1431,-1044.5 1431,-1073.5 1431,-1073.5 1431,-1079.5 1425,-1085.5 1419,-1085.5\"/>\n<text text-anchor=\"start\" x=\"1353.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1343\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1342\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 94&#45;&gt;96 -->\n<g id=\"edge96\" class=\"edge\">\n<title>94&#45;&gt;96</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1310.24,-1128.88C1322.47,-1117.23 1336.2,-1104.14 1348.37,-1092.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1350.91,-1094.95 1355.73,-1085.52 1346.08,-1089.89 1350.91,-1094.95\"/>\n</g>\n<!-- 99 -->\n<g id=\"node100\" class=\"node\">\n<title>99</title>\n<path fill=\"#e89050\" stroke=\"black\" d=\"M3466.5,-1509C3466.5,-1509 3346.5,-1509 3346.5,-1509 3340.5,-1509 3334.5,-1503 3334.5,-1497 3334.5,-1497 3334.5,-1453 3334.5,-1453 3334.5,-1447 3340.5,-1441 3346.5,-1441 3346.5,-1441 3466.5,-1441 3466.5,-1441 3472.5,-1441 3478.5,-1447 3478.5,-1453 3478.5,-1453 3478.5,-1497 3478.5,-1497 3478.5,-1503 3472.5,-1509 3466.5,-1509\"/>\n<text text-anchor=\"start\" x=\"3342.5\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_D ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"3369\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.189</text>\n<text text-anchor=\"start\" x=\"3359\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 275</text>\n<text text-anchor=\"start\" x=\"3353.5\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [246, 29]</text>\n</g>\n<!-- 98&#45;&gt;99 -->\n<g id=\"edge99\" class=\"edge\">\n<title>98&#45;&gt;99</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3406.5,-1544.88C3406.5,-1536.78 3406.5,-1527.98 3406.5,-1519.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3410,-1519.3 3406.5,-1509.3 3403,-1519.3 3410,-1519.3\"/>\n</g>\n<!-- 216 -->\n<g id=\"node217\" class=\"node\">\n<title>216</title>\n<path fill=\"#f2be99\" stroke=\"black\" d=\"M3646,-1509C3646,-1509 3557,-1509 3557,-1509 3551,-1509 3545,-1503 3545,-1497 3545,-1497 3545,-1453 3545,-1453 3545,-1447 3551,-1441 3557,-1441 3557,-1441 3646,-1441 3646,-1441 3652,-1441 3658,-1447 3658,-1453 3658,-1453 3658,-1497 3658,-1497 3658,-1503 3652,-1509 3646,-1509\"/>\n<text text-anchor=\"start\" x=\"3560.5\" y=\"-1493.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.366</text>\n<text text-anchor=\"start\" x=\"3568\" y=\"-1478.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.44</text>\n<text text-anchor=\"start\" x=\"3558\" y=\"-1463.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 92</text>\n<text text-anchor=\"start\" x=\"3553\" y=\"-1448.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [62, 30]</text>\n</g>\n<!-- 98&#45;&gt;216 -->\n<g id=\"edge216\" class=\"edge\">\n<title>98&#45;&gt;216</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3467.66,-1546.01C3489.36,-1534.66 3513.86,-1521.84 3535.9,-1510.31\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3537.63,-1513.36 3544.87,-1505.62 3534.38,-1507.16 3537.63,-1513.36\"/>\n</g>\n<!-- 100 -->\n<g id=\"node101\" class=\"node\">\n<title>100</title>\n<path fill=\"#e88f50\" stroke=\"black\" d=\"M3367.5,-1405C3367.5,-1405 3269.5,-1405 3269.5,-1405 3263.5,-1405 3257.5,-1399 3257.5,-1393 3257.5,-1393 3257.5,-1349 3257.5,-1349 3257.5,-1343 3263.5,-1337 3269.5,-1337 3269.5,-1337 3367.5,-1337 3367.5,-1337 3373.5,-1337 3379.5,-1343 3379.5,-1349 3379.5,-1349 3379.5,-1393 3379.5,-1393 3379.5,-1399 3373.5,-1405 3367.5,-1405\"/>\n<text text-anchor=\"start\" x=\"3279\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.187</text>\n<text text-anchor=\"start\" x=\"3281\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.183</text>\n<text text-anchor=\"start\" x=\"3271\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 274</text>\n<text text-anchor=\"start\" x=\"3265.5\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [246, 28]</text>\n</g>\n<!-- 99&#45;&gt;100 -->\n<g id=\"edge100\" class=\"edge\">\n<title>99&#45;&gt;100</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3377.93,-1440.88C3370.24,-1431.98 3361.84,-1422.24 3353.84,-1412.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3356.41,-1410.58 3347.23,-1405.3 3351.11,-1415.16 3356.41,-1410.58\"/>\n</g>\n<!-- 215 -->\n<g id=\"node216\" class=\"node\">\n<title>215</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3483,-1397.5C3483,-1397.5 3410,-1397.5 3410,-1397.5 3404,-1397.5 3398,-1391.5 3398,-1385.5 3398,-1385.5 3398,-1356.5 3398,-1356.5 3398,-1350.5 3404,-1344.5 3410,-1344.5 3410,-1344.5 3483,-1344.5 3483,-1344.5 3489,-1344.5 3495,-1350.5 3495,-1356.5 3495,-1356.5 3495,-1385.5 3495,-1385.5 3495,-1391.5 3489,-1397.5 3483,-1397.5\"/>\n<text text-anchor=\"start\" x=\"3417.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3407\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3406\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 99&#45;&gt;215 -->\n<g id=\"edge215\" class=\"edge\">\n<title>99&#45;&gt;215</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3419.49,-1440.88C3423.76,-1430 3428.51,-1417.86 3432.83,-1406.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3436.1,-1408.11 3436.49,-1397.52 3429.58,-1405.55 3436.1,-1408.11\"/>\n</g>\n<!-- 101 -->\n<g id=\"node102\" class=\"node\">\n<title>101</title>\n<path fill=\"#e99559\" stroke=\"black\" d=\"M3259,-1301C3259,-1301 3140,-1301 3140,-1301 3134,-1301 3128,-1295 3128,-1289 3128,-1289 3128,-1245 3128,-1245 3128,-1239 3134,-1233 3140,-1233 3140,-1233 3259,-1233 3259,-1233 3265,-1233 3271,-1239 3271,-1245 3271,-1245 3271,-1289 3271,-1289 3271,-1295 3265,-1301 3259,-1301\"/>\n<text text-anchor=\"start\" x=\"3136\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_E ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"3166\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.24</text>\n<text text-anchor=\"start\" x=\"3152\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 136</text>\n<text text-anchor=\"start\" x=\"3146.5\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [117, 19]</text>\n</g>\n<!-- 100&#45;&gt;101 -->\n<g id=\"edge101\" class=\"edge\">\n<title>100&#45;&gt;101</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3279.86,-1336.88C3269.06,-1327.62 3257.2,-1317.45 3245.99,-1307.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3248.22,-1305.15 3238.35,-1301.3 3243.66,-1310.46 3248.22,-1305.15\"/>\n</g>\n<!-- 178 -->\n<g id=\"node179\" class=\"node\">\n<title>178</title>\n<path fill=\"#e78a47\" stroke=\"black\" d=\"M3402,-1301C3402,-1301 3313,-1301 3313,-1301 3307,-1301 3301,-1295 3301,-1289 3301,-1289 3301,-1245 3301,-1245 3301,-1239 3307,-1233 3313,-1233 3313,-1233 3402,-1233 3402,-1233 3408,-1233 3414,-1239 3414,-1245 3414,-1245 3414,-1289 3414,-1289 3414,-1295 3408,-1301 3402,-1301\"/>\n<text text-anchor=\"start\" x=\"3314.5\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.798</text>\n<text text-anchor=\"start\" x=\"3320\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.122</text>\n<text text-anchor=\"start\" x=\"3310\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 138</text>\n<text text-anchor=\"start\" x=\"3309\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [129, 9]</text>\n</g>\n<!-- 100&#45;&gt;178 -->\n<g id=\"edge178\" class=\"edge\">\n<title>100&#45;&gt;178</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3331.16,-1336.88C3334.33,-1328.6 3337.77,-1319.6 3341.09,-1310.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3344.47,-1311.89 3344.77,-1301.3 3337.93,-1309.39 3344.47,-1311.89\"/>\n</g>\n<!-- 102 -->\n<g id=\"node103\" class=\"node\">\n<title>102</title>\n<path fill=\"#e99457\" stroke=\"black\" d=\"M2968.5,-1197C2968.5,-1197 2856.5,-1197 2856.5,-1197 2850.5,-1197 2844.5,-1191 2844.5,-1185 2844.5,-1185 2844.5,-1141 2844.5,-1141 2844.5,-1135 2850.5,-1129 2856.5,-1129 2856.5,-1129 2968.5,-1129 2968.5,-1129 2974.5,-1129 2980.5,-1135 2980.5,-1141 2980.5,-1141 2980.5,-1185 2980.5,-1185 2980.5,-1191 2974.5,-1197 2968.5,-1197\"/>\n<text text-anchor=\"start\" x=\"2852.5\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Embarked_C ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"2875\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.231</text>\n<text text-anchor=\"start\" x=\"2865\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 135</text>\n<text text-anchor=\"start\" x=\"2859.5\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [117, 18]</text>\n</g>\n<!-- 101&#45;&gt;102 -->\n<g id=\"edge102\" class=\"edge\">\n<title>101&#45;&gt;102</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3127.82,-1240.52C3085.99,-1225.66 3033.19,-1206.89 2990.34,-1191.67\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2991.4,-1188.33 2980.8,-1188.27 2989.05,-1194.92 2991.4,-1188.33\"/>\n</g>\n<!-- 177 -->\n<g id=\"node178\" class=\"node\">\n<title>177</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3236,-1189.5C3236,-1189.5 3163,-1189.5 3163,-1189.5 3157,-1189.5 3151,-1183.5 3151,-1177.5 3151,-1177.5 3151,-1148.5 3151,-1148.5 3151,-1142.5 3157,-1136.5 3163,-1136.5 3163,-1136.5 3236,-1136.5 3236,-1136.5 3242,-1136.5 3248,-1142.5 3248,-1148.5 3248,-1148.5 3248,-1177.5 3248,-1177.5 3248,-1183.5 3242,-1189.5 3236,-1189.5\"/>\n<text text-anchor=\"start\" x=\"3170.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3160\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3159\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 101&#45;&gt;177 -->\n<g id=\"edge177\" class=\"edge\">\n<title>101&#45;&gt;177</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3199.5,-1232.88C3199.5,-1222.33 3199.5,-1210.6 3199.5,-1199.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3203,-1199.52 3199.5,-1189.52 3196,-1199.52 3203,-1199.52\"/>\n</g>\n<!-- 103 -->\n<g id=\"node104\" class=\"node\">\n<title>103</title>\n<path fill=\"#e89153\" stroke=\"black\" d=\"M2710.5,-1093C2710.5,-1093 2612.5,-1093 2612.5,-1093 2606.5,-1093 2600.5,-1087 2600.5,-1081 2600.5,-1081 2600.5,-1037 2600.5,-1037 2600.5,-1031 2606.5,-1025 2612.5,-1025 2612.5,-1025 2710.5,-1025 2710.5,-1025 2716.5,-1025 2722.5,-1031 2722.5,-1037 2722.5,-1037 2722.5,-1081 2722.5,-1081 2722.5,-1087 2716.5,-1093 2710.5,-1093\"/>\n<text text-anchor=\"start\" x=\"2618.5\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;2.001</text>\n<text text-anchor=\"start\" x=\"2624\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.203</text>\n<text text-anchor=\"start\" x=\"2614\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 122</text>\n<text text-anchor=\"start\" x=\"2608.5\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [108, 14]</text>\n</g>\n<!-- 102&#45;&gt;103 -->\n<g id=\"edge103\" class=\"edge\">\n<title>102&#45;&gt;103</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2844.24,-1134.26C2809.61,-1120.19 2767.58,-1103.11 2732.56,-1088.88\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2733.46,-1085.46 2722.88,-1084.94 2730.82,-1091.95 2733.46,-1085.46\"/>\n</g>\n<!-- 166 -->\n<g id=\"node167\" class=\"node\">\n<title>166</title>\n<path fill=\"#f1b991\" stroke=\"black\" d=\"M2952,-1093C2952,-1093 2873,-1093 2873,-1093 2867,-1093 2861,-1087 2861,-1081 2861,-1081 2861,-1037 2861,-1037 2861,-1031 2867,-1025 2873,-1025 2873,-1025 2952,-1025 2952,-1025 2958,-1025 2964,-1031 2964,-1037 2964,-1037 2964,-1081 2964,-1081 2964,-1087 2958,-1093 2952,-1093\"/>\n<text text-anchor=\"start\" x=\"2871\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.016</text>\n<text text-anchor=\"start\" x=\"2875\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.426</text>\n<text text-anchor=\"start\" x=\"2869\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13</text>\n<text text-anchor=\"start\" x=\"2872\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 4]</text>\n</g>\n<!-- 102&#45;&gt;166 -->\n<g id=\"edge166\" class=\"edge\">\n<title>102&#45;&gt;166</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2912.5,-1128.88C2912.5,-1120.78 2912.5,-1111.98 2912.5,-1103.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2916,-1103.3 2912.5,-1093.3 2909,-1103.3 2916,-1103.3\"/>\n</g>\n<!-- 104 -->\n<g id=\"node105\" class=\"node\">\n<title>104</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M2519,-989C2519,-989 2444,-989 2444,-989 2438,-989 2432,-983 2432,-977 2432,-977 2432,-933 2432,-933 2432,-927 2438,-921 2444,-921 2444,-921 2519,-921 2519,-921 2525,-921 2531,-927 2531,-933 2531,-933 2531,-977 2531,-977 2531,-983 2525,-989 2519,-989\"/>\n<text text-anchor=\"start\" x=\"2440\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.582</text>\n<text text-anchor=\"start\" x=\"2452.5\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"2442\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2441\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 103&#45;&gt;104 -->\n<g id=\"edge104\" class=\"edge\">\n<title>103&#45;&gt;104</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2603.06,-1024.88C2582.85,-1013.43 2560.21,-1000.6 2540,-989.15\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2541.62,-986.05 2531.2,-984.16 2538.17,-992.14 2541.62,-986.05\"/>\n</g>\n<!-- 107 -->\n<g id=\"node108\" class=\"node\">\n<title>107</title>\n<path fill=\"#e89051\" stroke=\"black\" d=\"M2710.5,-989C2710.5,-989 2612.5,-989 2612.5,-989 2606.5,-989 2600.5,-983 2600.5,-977 2600.5,-977 2600.5,-933 2600.5,-933 2600.5,-927 2606.5,-921 2612.5,-921 2612.5,-921 2710.5,-921 2710.5,-921 2716.5,-921 2722.5,-927 2722.5,-933 2722.5,-933 2722.5,-977 2722.5,-977 2722.5,-983 2716.5,-989 2710.5,-989\"/>\n<text text-anchor=\"start\" x=\"2620\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.072</text>\n<text text-anchor=\"start\" x=\"2624\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.193</text>\n<text text-anchor=\"start\" x=\"2614\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 120</text>\n<text text-anchor=\"start\" x=\"2608.5\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [107, 13]</text>\n</g>\n<!-- 103&#45;&gt;107 -->\n<g id=\"edge107\" class=\"edge\">\n<title>103&#45;&gt;107</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2661.5,-1024.88C2661.5,-1016.78 2661.5,-1007.98 2661.5,-999.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2665,-999.3 2661.5,-989.3 2658,-999.3 2665,-999.3\"/>\n</g>\n<!-- 105 -->\n<g id=\"node106\" class=\"node\">\n<title>105</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2403,-877.5C2403,-877.5 2330,-877.5 2330,-877.5 2324,-877.5 2318,-871.5 2318,-865.5 2318,-865.5 2318,-836.5 2318,-836.5 2318,-830.5 2324,-824.5 2330,-824.5 2330,-824.5 2403,-824.5 2403,-824.5 2409,-824.5 2415,-830.5 2415,-836.5 2415,-836.5 2415,-865.5 2415,-865.5 2415,-871.5 2409,-877.5 2403,-877.5\"/>\n<text text-anchor=\"start\" x=\"2337.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2327\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2326\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 104&#45;&gt;105 -->\n<g id=\"edge105\" class=\"edge\">\n<title>104&#45;&gt;105</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2444.16,-920.88C2430.9,-909.12 2415.99,-895.89 2402.81,-884.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2405.08,-881.54 2395.27,-877.52 2400.43,-886.77 2405.08,-881.54\"/>\n</g>\n<!-- 106 -->\n<g id=\"node107\" class=\"node\">\n<title>106</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2518,-877.5C2518,-877.5 2445,-877.5 2445,-877.5 2439,-877.5 2433,-871.5 2433,-865.5 2433,-865.5 2433,-836.5 2433,-836.5 2433,-830.5 2439,-824.5 2445,-824.5 2445,-824.5 2518,-824.5 2518,-824.5 2524,-824.5 2530,-830.5 2530,-836.5 2530,-836.5 2530,-865.5 2530,-865.5 2530,-871.5 2524,-877.5 2518,-877.5\"/>\n<text text-anchor=\"start\" x=\"2452.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2442\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2441\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 104&#45;&gt;106 -->\n<g id=\"edge106\" class=\"edge\">\n<title>104&#45;&gt;106</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2481.5,-920.88C2481.5,-910.33 2481.5,-898.6 2481.5,-887.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2485,-887.52 2481.5,-877.52 2478,-887.52 2485,-887.52\"/>\n</g>\n<!-- 108 -->\n<g id=\"node109\" class=\"node\">\n<title>108</title>\n<path fill=\"#e78d4b\" stroke=\"black\" d=\"M2641,-885C2641,-885 2560,-885 2560,-885 2554,-885 2548,-879 2548,-873 2548,-873 2548,-829 2548,-829 2548,-823 2554,-817 2560,-817 2560,-817 2641,-817 2641,-817 2647,-817 2653,-823 2653,-829 2653,-829 2653,-873 2653,-873 2653,-879 2647,-885 2641,-885\"/>\n<text text-anchor=\"start\" x=\"2557.5\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.768</text>\n<text text-anchor=\"start\" x=\"2563\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.154</text>\n<text text-anchor=\"start\" x=\"2557\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 95</text>\n<text text-anchor=\"start\" x=\"2556\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [87, 8]</text>\n</g>\n<!-- 107&#45;&gt;108 -->\n<g id=\"edge108\" class=\"edge\">\n<title>107&#45;&gt;108</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2641.7,-920.88C2636.58,-912.33 2631.01,-903.01 2625.66,-894.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2628.55,-892.09 2620.41,-885.3 2622.54,-895.68 2628.55,-892.09\"/>\n</g>\n<!-- 147 -->\n<g id=\"node148\" class=\"node\">\n<title>147</title>\n<path fill=\"#eca06a\" stroke=\"black\" d=\"M2764,-885C2764,-885 2683,-885 2683,-885 2677,-885 2671,-879 2671,-873 2671,-873 2671,-829 2671,-829 2671,-823 2677,-817 2683,-817 2683,-817 2764,-817 2764,-817 2770,-817 2776,-823 2776,-829 2776,-829 2776,-873 2776,-873 2776,-879 2770,-885 2764,-885\"/>\n<text text-anchor=\"start\" x=\"2686\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"2690\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"2680\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 25</text>\n<text text-anchor=\"start\" x=\"2679\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [20, 5]</text>\n</g>\n<!-- 107&#45;&gt;147 -->\n<g id=\"edge147\" class=\"edge\">\n<title>107&#45;&gt;147</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2681.63,-920.88C2686.83,-912.33 2692.49,-903.01 2697.93,-894.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2701.06,-895.66 2703.26,-885.3 2695.07,-892.03 2701.06,-895.66\"/>\n</g>\n<!-- 109 -->\n<g id=\"node110\" class=\"node\">\n<title>109</title>\n<path fill=\"#e99355\" stroke=\"black\" d=\"M2200,-781C2200,-781 2119,-781 2119,-781 2113,-781 2107,-775 2107,-769 2107,-769 2107,-725 2107,-725 2107,-719 2113,-713 2119,-713 2119,-713 2200,-713 2200,-713 2206,-713 2212,-719 2212,-725 2212,-725 2212,-769 2212,-769 2212,-775 2206,-781 2200,-781\"/>\n<text text-anchor=\"start\" x=\"2116.5\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.798</text>\n<text text-anchor=\"start\" x=\"2122\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.215</text>\n<text text-anchor=\"start\" x=\"2116\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 57</text>\n<text text-anchor=\"start\" x=\"2115\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 7]</text>\n</g>\n<!-- 108&#45;&gt;109 -->\n<g id=\"edge109\" class=\"edge\">\n<title>108&#45;&gt;109</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2547.89,-820.62C2544.75,-819.3 2541.61,-818.08 2538.5,-817 2430.89,-779.59 2298.67,-761.41 2222.25,-753.44\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2222.6,-749.96 2212.3,-752.43 2221.89,-756.92 2222.6,-749.96\"/>\n</g>\n<!-- 140 -->\n<g id=\"node141\" class=\"node\">\n<title>140</title>\n<path fill=\"#e6843e\" stroke=\"black\" d=\"M2641,-781C2641,-781 2560,-781 2560,-781 2554,-781 2548,-775 2548,-769 2548,-769 2548,-725 2548,-725 2548,-719 2554,-713 2560,-713 2560,-713 2641,-713 2641,-713 2647,-713 2653,-719 2653,-725 2653,-725 2653,-769 2653,-769 2653,-775 2647,-781 2641,-781\"/>\n<text text-anchor=\"start\" x=\"2559\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.771</text>\n<text text-anchor=\"start\" x=\"2563\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.051</text>\n<text text-anchor=\"start\" x=\"2557\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 38</text>\n<text text-anchor=\"start\" x=\"2556\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [37, 1]</text>\n</g>\n<!-- 108&#45;&gt;140 -->\n<g id=\"edge140\" class=\"edge\">\n<title>108&#45;&gt;140</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2600.5,-816.88C2600.5,-808.78 2600.5,-799.98 2600.5,-791.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2604,-791.3 2600.5,-781.3 2597,-791.3 2604,-791.3\"/>\n</g>\n<!-- 110 -->\n<g id=\"node111\" class=\"node\">\n<title>110</title>\n<path fill=\"#e78c49\" stroke=\"black\" d=\"M2024,-677C2024,-677 1943,-677 1943,-677 1937,-677 1931,-671 1931,-665 1931,-665 1931,-621 1931,-621 1931,-615 1937,-609 1943,-609 1943,-609 2024,-609 2024,-609 2030,-609 2036,-615 2036,-621 2036,-621 2036,-665 2036,-665 2036,-671 2030,-677 2024,-677\"/>\n<text text-anchor=\"start\" x=\"1942\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.242</text>\n<text text-anchor=\"start\" x=\"1946\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.142</text>\n<text text-anchor=\"start\" x=\"1940\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 39</text>\n<text text-anchor=\"start\" x=\"1939\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [36, 3]</text>\n</g>\n<!-- 109&#45;&gt;110 -->\n<g id=\"edge110\" class=\"edge\">\n<title>109&#45;&gt;110</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2106.69,-715.4C2087.29,-704.15 2065.15,-691.32 2045.05,-679.67\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2046.68,-676.57 2036.27,-674.58 2043.17,-682.62 2046.68,-676.57\"/>\n</g>\n<!-- 129 -->\n<g id=\"node130\" class=\"node\">\n<title>129</title>\n<path fill=\"#eca572\" stroke=\"black\" d=\"M2200,-677C2200,-677 2119,-677 2119,-677 2113,-677 2107,-671 2107,-665 2107,-665 2107,-621 2107,-621 2107,-615 2113,-609 2119,-609 2119,-609 2200,-609 2200,-609 2206,-609 2212,-615 2212,-621 2212,-621 2212,-665 2212,-665 2212,-671 2206,-677 2200,-677\"/>\n<text text-anchor=\"start\" x=\"2118\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.696</text>\n<text text-anchor=\"start\" x=\"2122\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.346</text>\n<text text-anchor=\"start\" x=\"2116\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n<text text-anchor=\"start\" x=\"2115\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [14, 4]</text>\n</g>\n<!-- 109&#45;&gt;129 -->\n<g id=\"edge129\" class=\"edge\">\n<title>109&#45;&gt;129</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2159.5,-712.88C2159.5,-704.78 2159.5,-695.98 2159.5,-687.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2163,-687.3 2159.5,-677.3 2156,-687.3 2163,-687.3\"/>\n</g>\n<!-- 111 -->\n<g id=\"node112\" class=\"node\">\n<title>111</title>\n<path fill=\"#e78945\" stroke=\"black\" d=\"M1716,-573C1716,-573 1635,-573 1635,-573 1629,-573 1623,-567 1623,-561 1623,-561 1623,-517 1623,-517 1623,-511 1629,-505 1635,-505 1635,-505 1716,-505 1716,-505 1722,-505 1728,-511 1728,-517 1728,-517 1728,-561 1728,-561 1728,-567 1722,-573 1716,-573\"/>\n<text text-anchor=\"start\" x=\"1632.5\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.884</text>\n<text text-anchor=\"start\" x=\"1638\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.108</text>\n<text text-anchor=\"start\" x=\"1632\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 35</text>\n<text text-anchor=\"start\" x=\"1631\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [33, 2]</text>\n</g>\n<!-- 110&#45;&gt;111 -->\n<g id=\"edge111\" class=\"edge\">\n<title>110&#45;&gt;111</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1930.9,-624.58C1877.39,-606.86 1794.46,-579.4 1737.71,-560.6\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1738.73,-557.25 1728.14,-557.43 1736.53,-563.9 1738.73,-557.25\"/>\n</g>\n<!-- 124 -->\n<g id=\"node125\" class=\"node\">\n<title>124</title>\n<path fill=\"#eeab7b\" stroke=\"black\" d=\"M2021,-573C2021,-573 1946,-573 1946,-573 1940,-573 1934,-567 1934,-561 1934,-561 1934,-517 1934,-517 1934,-511 1940,-505 1946,-505 1946,-505 2021,-505 2021,-505 2027,-505 2033,-511 2033,-517 2033,-517 2033,-561 2033,-561 2033,-567 2027,-573 2021,-573\"/>\n<text text-anchor=\"start\" x=\"1942\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.167</text>\n<text text-anchor=\"start\" x=\"1946\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"1944\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"1943\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 1]</text>\n</g>\n<!-- 110&#45;&gt;124 -->\n<g id=\"edge124\" class=\"edge\">\n<title>110&#45;&gt;124</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1983.5,-608.88C1983.5,-600.78 1983.5,-591.98 1983.5,-583.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1987,-583.3 1983.5,-573.3 1980,-583.3 1987,-583.3\"/>\n</g>\n<!-- 112 -->\n<g id=\"node113\" class=\"node\">\n<title>112</title>\n<path fill=\"#ea9a61\" stroke=\"black\" d=\"M1577.5,-469C1577.5,-469 1499.5,-469 1499.5,-469 1493.5,-469 1487.5,-463 1487.5,-457 1487.5,-457 1487.5,-413 1487.5,-413 1487.5,-407 1493.5,-401 1499.5,-401 1499.5,-401 1577.5,-401 1577.5,-401 1583.5,-401 1589.5,-407 1589.5,-413 1589.5,-413 1589.5,-457 1589.5,-457 1589.5,-463 1583.5,-469 1577.5,-469\"/>\n<text text-anchor=\"start\" x=\"1495.5\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.892</text>\n<text text-anchor=\"start\" x=\"1501\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.278</text>\n<text text-anchor=\"start\" x=\"1499\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"1498\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 1]</text>\n</g>\n<!-- 111&#45;&gt;112 -->\n<g id=\"edge112\" class=\"edge\">\n<title>111&#45;&gt;112</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1631.02,-504.88C1618.34,-495.44 1604.4,-485.06 1591.27,-475.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1593.34,-472.46 1583.23,-469.3 1589.16,-478.08 1593.34,-472.46\"/>\n</g>\n<!-- 115 -->\n<g id=\"node116\" class=\"node\">\n<title>115</title>\n<path fill=\"#e68640\" stroke=\"black\" d=\"M1716,-469C1716,-469 1635,-469 1635,-469 1629,-469 1623,-463 1623,-457 1623,-457 1623,-413 1623,-413 1623,-407 1629,-401 1635,-401 1635,-401 1716,-401 1716,-401 1722,-401 1728,-407 1728,-413 1728,-413 1728,-457 1728,-457 1728,-463 1722,-469 1716,-469\"/>\n<text text-anchor=\"start\" x=\"1632.5\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.813</text>\n<text text-anchor=\"start\" x=\"1638\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.067</text>\n<text text-anchor=\"start\" x=\"1632\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 29</text>\n<text text-anchor=\"start\" x=\"1631\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [28, 1]</text>\n</g>\n<!-- 111&#45;&gt;115 -->\n<g id=\"edge115\" class=\"edge\">\n<title>111&#45;&gt;115</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1675.5,-504.88C1675.5,-496.78 1675.5,-487.98 1675.5,-479.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1679,-479.3 1675.5,-469.3 1672,-479.3 1679,-479.3\"/>\n</g>\n<!-- 113 -->\n<g id=\"node114\" class=\"node\">\n<title>113</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1460,-357.5C1460,-357.5 1387,-357.5 1387,-357.5 1381,-357.5 1375,-351.5 1375,-345.5 1375,-345.5 1375,-316.5 1375,-316.5 1375,-310.5 1381,-304.5 1387,-304.5 1387,-304.5 1460,-304.5 1460,-304.5 1466,-304.5 1472,-310.5 1472,-316.5 1472,-316.5 1472,-345.5 1472,-345.5 1472,-351.5 1466,-357.5 1460,-357.5\"/>\n<text text-anchor=\"start\" x=\"1394.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1384\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"1383\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 0]</text>\n</g>\n<!-- 112&#45;&gt;113 -->\n<g id=\"edge113\" class=\"edge\">\n<title>112&#45;&gt;113</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1501.16,-400.88C1487.9,-389.12 1472.99,-375.89 1459.81,-364.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1462.08,-361.54 1452.27,-357.52 1457.43,-366.77 1462.08,-361.54\"/>\n</g>\n<!-- 114 -->\n<g id=\"node115\" class=\"node\">\n<title>114</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1575,-357.5C1575,-357.5 1502,-357.5 1502,-357.5 1496,-357.5 1490,-351.5 1490,-345.5 1490,-345.5 1490,-316.5 1490,-316.5 1490,-310.5 1496,-304.5 1502,-304.5 1502,-304.5 1575,-304.5 1575,-304.5 1581,-304.5 1587,-310.5 1587,-316.5 1587,-316.5 1587,-345.5 1587,-345.5 1587,-351.5 1581,-357.5 1575,-357.5\"/>\n<text text-anchor=\"start\" x=\"1509.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1499\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1498\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 112&#45;&gt;114 -->\n<g id=\"edge114\" class=\"edge\">\n<title>112&#45;&gt;114</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1538.5,-400.88C1538.5,-390.33 1538.5,-378.6 1538.5,-367.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1542,-367.52 1538.5,-357.52 1535,-367.52 1542,-367.52\"/>\n</g>\n<!-- 116 -->\n<g id=\"node117\" class=\"node\">\n<title>116</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1698,-357.5C1698,-357.5 1617,-357.5 1617,-357.5 1611,-357.5 1605,-351.5 1605,-345.5 1605,-345.5 1605,-316.5 1605,-316.5 1605,-310.5 1611,-304.5 1617,-304.5 1617,-304.5 1698,-304.5 1698,-304.5 1704,-304.5 1710,-310.5 1710,-316.5 1710,-316.5 1710,-345.5 1710,-345.5 1710,-351.5 1704,-357.5 1698,-357.5\"/>\n<text text-anchor=\"start\" x=\"1628.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1614\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 14</text>\n<text text-anchor=\"start\" x=\"1613\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [14, 0]</text>\n</g>\n<!-- 115&#45;&gt;116 -->\n<g id=\"edge116\" class=\"edge\">\n<title>115&#45;&gt;116</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1669.66,-400.88C1667.77,-390.22 1665.68,-378.35 1663.77,-367.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1667.19,-366.76 1662,-357.52 1660.29,-367.98 1667.19,-366.76\"/>\n</g>\n<!-- 117 -->\n<g id=\"node118\" class=\"node\">\n<title>117</title>\n<path fill=\"#e78a47\" stroke=\"black\" d=\"M1821,-365C1821,-365 1740,-365 1740,-365 1734,-365 1728,-359 1728,-353 1728,-353 1728,-309 1728,-309 1728,-303 1734,-297 1740,-297 1740,-297 1821,-297 1821,-297 1827,-297 1833,-303 1833,-309 1833,-309 1833,-353 1833,-353 1833,-359 1827,-365 1821,-365\"/>\n<text text-anchor=\"start\" x=\"1737.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.811</text>\n<text text-anchor=\"start\" x=\"1743\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.124</text>\n<text text-anchor=\"start\" x=\"1737\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\n<text text-anchor=\"start\" x=\"1736\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [14, 1]</text>\n</g>\n<!-- 115&#45;&gt;117 -->\n<g id=\"edge117\" class=\"edge\">\n<title>115&#45;&gt;117</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1709.59,-400.88C1718.94,-391.8 1729.19,-381.85 1738.91,-372.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1741.49,-374.78 1746.22,-365.3 1736.61,-369.76 1741.49,-374.78\"/>\n</g>\n<!-- 118 -->\n<g id=\"node119\" class=\"node\">\n<title>118</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M1758,-261C1758,-261 1683,-261 1683,-261 1677,-261 1671,-255 1671,-249 1671,-249 1671,-205 1671,-205 1671,-199 1677,-193 1683,-193 1683,-193 1758,-193 1758,-193 1764,-193 1770,-199 1770,-205 1770,-205 1770,-249 1770,-249 1770,-255 1764,-261 1758,-261\"/>\n<text text-anchor=\"start\" x=\"1679\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.771</text>\n<text text-anchor=\"start\" x=\"1683\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"1681\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"1680\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 1]</text>\n</g>\n<!-- 117&#45;&gt;118 -->\n<g id=\"edge118\" class=\"edge\">\n<title>117&#45;&gt;118</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1761.02,-296.88C1755.99,-288.33 1750.51,-279.01 1745.25,-270.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1748.17,-268.14 1740.09,-261.3 1742.14,-271.69 1748.17,-268.14\"/>\n</g>\n<!-- 123 -->\n<g id=\"node124\" class=\"node\">\n<title>123</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1881,-253.5C1881,-253.5 1800,-253.5 1800,-253.5 1794,-253.5 1788,-247.5 1788,-241.5 1788,-241.5 1788,-212.5 1788,-212.5 1788,-206.5 1794,-200.5 1800,-200.5 1800,-200.5 1881,-200.5 1881,-200.5 1887,-200.5 1893,-206.5 1893,-212.5 1893,-212.5 1893,-241.5 1893,-241.5 1893,-247.5 1887,-253.5 1881,-253.5\"/>\n<text text-anchor=\"start\" x=\"1811.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1797\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\n<text text-anchor=\"start\" x=\"1796\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [12, 0]</text>\n</g>\n<!-- 117&#45;&gt;123 -->\n<g id=\"edge123\" class=\"edge\">\n<title>117&#45;&gt;123</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1799.98,-296.88C1806.51,-285.78 1813.81,-273.37 1820.39,-262.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1823.43,-263.91 1825.49,-253.52 1817.4,-260.36 1823.43,-263.91\"/>\n</g>\n<!-- 119 -->\n<g id=\"node120\" class=\"node\">\n<title>119</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1699,-149.5C1699,-149.5 1626,-149.5 1626,-149.5 1620,-149.5 1614,-143.5 1614,-137.5 1614,-137.5 1614,-108.5 1614,-108.5 1614,-102.5 1620,-96.5 1626,-96.5 1626,-96.5 1699,-96.5 1699,-96.5 1705,-96.5 1711,-102.5 1711,-108.5 1711,-108.5 1711,-137.5 1711,-137.5 1711,-143.5 1705,-149.5 1699,-149.5\"/>\n<text text-anchor=\"start\" x=\"1633.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1623\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1622\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 118&#45;&gt;119 -->\n<g id=\"edge119\" class=\"edge\">\n<title>118&#45;&gt;119</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1701.67,-192.88C1695.42,-181.89 1688.44,-169.62 1682.13,-158.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1685,-156.48 1677.01,-149.52 1678.91,-159.94 1685,-156.48\"/>\n</g>\n<!-- 120 -->\n<g id=\"node121\" class=\"node\">\n<title>120</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M1816,-157C1816,-157 1741,-157 1741,-157 1735,-157 1729,-151 1729,-145 1729,-145 1729,-101 1729,-101 1729,-95 1735,-89 1741,-89 1741,-89 1816,-89 1816,-89 1822,-89 1828,-95 1828,-101 1828,-101 1828,-145 1828,-145 1828,-151 1822,-157 1816,-157\"/>\n<text text-anchor=\"start\" x=\"1737\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.545</text>\n<text text-anchor=\"start\" x=\"1749.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"1739\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1738\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 118&#45;&gt;120 -->\n<g id=\"edge120\" class=\"edge\">\n<title>118&#45;&gt;120</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1739.33,-192.88C1744.19,-184.33 1749.49,-175.01 1754.58,-166.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1757.66,-167.72 1759.57,-157.3 1751.58,-164.26 1757.66,-167.72\"/>\n</g>\n<!-- 121 -->\n<g id=\"node122\" class=\"node\">\n<title>121</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1758,-53C1758,-53 1685,-53 1685,-53 1679,-53 1673,-47 1673,-41 1673,-41 1673,-12 1673,-12 1673,-6 1679,0 1685,0 1685,0 1758,0 1758,0 1764,0 1770,-6 1770,-12 1770,-12 1770,-41 1770,-41 1770,-47 1764,-53 1758,-53\"/>\n<text text-anchor=\"start\" x=\"1692.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1682\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1681\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 120&#45;&gt;121 -->\n<g id=\"edge121\" class=\"edge\">\n<title>120&#45;&gt;121</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1758.56,-88.95C1753.27,-80.17 1747.53,-70.66 1742.2,-61.82\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1745.19,-59.99 1737.02,-53.24 1739.19,-63.61 1745.19,-59.99\"/>\n</g>\n<!-- 122 -->\n<g id=\"node123\" class=\"node\">\n<title>122</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1873,-53C1873,-53 1800,-53 1800,-53 1794,-53 1788,-47 1788,-41 1788,-41 1788,-12 1788,-12 1788,-6 1794,0 1800,0 1800,0 1873,0 1873,0 1879,0 1885,-6 1885,-12 1885,-12 1885,-41 1885,-41 1885,-47 1879,-53 1873,-53\"/>\n<text text-anchor=\"start\" x=\"1807.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1797\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1796\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 120&#45;&gt;122 -->\n<g id=\"edge122\" class=\"edge\">\n<title>120&#45;&gt;122</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1798.79,-88.95C1804.18,-80.17 1810.01,-70.66 1815.44,-61.82\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1818.46,-63.59 1820.7,-53.24 1812.49,-59.93 1818.46,-63.59\"/>\n</g>\n<!-- 125 -->\n<g id=\"node126\" class=\"node\">\n<title>125</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M1937.5,-469C1937.5,-469 1859.5,-469 1859.5,-469 1853.5,-469 1847.5,-463 1847.5,-457 1847.5,-457 1847.5,-413 1847.5,-413 1847.5,-407 1853.5,-401 1859.5,-401 1859.5,-401 1937.5,-401 1937.5,-401 1943.5,-401 1949.5,-407 1949.5,-413 1949.5,-413 1949.5,-457 1949.5,-457 1949.5,-463 1943.5,-469 1937.5,-469\"/>\n<text text-anchor=\"start\" x=\"1855.5\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.806</text>\n<text text-anchor=\"start\" x=\"1869.5\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"1859\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1858\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 124&#45;&gt;125 -->\n<g id=\"edge125\" class=\"edge\">\n<title>124&#45;&gt;125</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1955.9,-504.88C1948.55,-496.07 1940.53,-486.43 1932.86,-477.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1935.34,-474.74 1926.25,-469.3 1929.96,-479.22 1935.34,-474.74\"/>\n</g>\n<!-- 128 -->\n<g id=\"node129\" class=\"node\">\n<title>128</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2053,-461.5C2053,-461.5 1980,-461.5 1980,-461.5 1974,-461.5 1968,-455.5 1968,-449.5 1968,-449.5 1968,-420.5 1968,-420.5 1968,-414.5 1974,-408.5 1980,-408.5 1980,-408.5 2053,-408.5 2053,-408.5 2059,-408.5 2065,-414.5 2065,-420.5 2065,-420.5 2065,-449.5 2065,-449.5 2065,-455.5 2059,-461.5 2053,-461.5\"/>\n<text text-anchor=\"start\" x=\"1987.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1977\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"1976\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 124&#45;&gt;128 -->\n<g id=\"edge128\" class=\"edge\">\n<title>124&#45;&gt;128</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1994.21,-504.88C1997.7,-494.11 2001.58,-482.11 2005.12,-471.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2008.5,-472.11 2008.24,-461.52 2001.84,-469.96 2008.5,-472.11\"/>\n</g>\n<!-- 126 -->\n<g id=\"node127\" class=\"node\">\n<title>126</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1936,-357.5C1936,-357.5 1863,-357.5 1863,-357.5 1857,-357.5 1851,-351.5 1851,-345.5 1851,-345.5 1851,-316.5 1851,-316.5 1851,-310.5 1857,-304.5 1863,-304.5 1863,-304.5 1936,-304.5 1936,-304.5 1942,-304.5 1948,-310.5 1948,-316.5 1948,-316.5 1948,-345.5 1948,-345.5 1948,-351.5 1942,-357.5 1936,-357.5\"/>\n<text text-anchor=\"start\" x=\"1870.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1860\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1859\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 125&#45;&gt;126 -->\n<g id=\"edge126\" class=\"edge\">\n<title>125&#45;&gt;126</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1898.82,-400.88C1898.93,-390.33 1899.04,-378.6 1899.15,-367.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1902.65,-367.55 1899.25,-357.52 1895.65,-367.49 1902.65,-367.55\"/>\n</g>\n<!-- 127 -->\n<g id=\"node128\" class=\"node\">\n<title>127</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2051,-357.5C2051,-357.5 1978,-357.5 1978,-357.5 1972,-357.5 1966,-351.5 1966,-345.5 1966,-345.5 1966,-316.5 1966,-316.5 1966,-310.5 1972,-304.5 1978,-304.5 1978,-304.5 2051,-304.5 2051,-304.5 2057,-304.5 2063,-310.5 2063,-316.5 2063,-316.5 2063,-345.5 2063,-345.5 2063,-351.5 2057,-357.5 2051,-357.5\"/>\n<text text-anchor=\"start\" x=\"1985.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"1975\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"1974\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 125&#45;&gt;127 -->\n<g id=\"edge127\" class=\"edge\">\n<title>125&#45;&gt;127</title>\n<path fill=\"none\" stroke=\"black\" d=\"M1936.16,-400.88C1949.54,-389.12 1964.58,-375.89 1977.88,-364.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"1980.28,-366.75 1985.48,-357.52 1975.66,-361.49 1980.28,-366.75\"/>\n</g>\n<!-- 130 -->\n<g id=\"node131\" class=\"node\">\n<title>130</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M2166,-573C2166,-573 2093,-573 2093,-573 2087,-573 2081,-567 2081,-561 2081,-561 2081,-517 2081,-517 2081,-511 2087,-505 2093,-505 2093,-505 2166,-505 2166,-505 2172,-505 2178,-511 2178,-517 2178,-517 2178,-561 2178,-561 2178,-567 2172,-573 2166,-573\"/>\n<text text-anchor=\"start\" x=\"2092\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"2100.5\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"2090\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"2089\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 4]</text>\n</g>\n<!-- 129&#45;&gt;130 -->\n<g id=\"edge130\" class=\"edge\">\n<title>129&#45;&gt;130</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2149.76,-608.88C2147.32,-600.6 2144.68,-591.6 2142.12,-582.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2145.47,-581.91 2139.29,-573.3 2138.76,-583.88 2145.47,-581.91\"/>\n</g>\n<!-- 139 -->\n<g id=\"node140\" class=\"node\">\n<title>139</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2289,-565.5C2289,-565.5 2208,-565.5 2208,-565.5 2202,-565.5 2196,-559.5 2196,-553.5 2196,-553.5 2196,-524.5 2196,-524.5 2196,-518.5 2202,-512.5 2208,-512.5 2208,-512.5 2289,-512.5 2289,-512.5 2295,-512.5 2301,-518.5 2301,-524.5 2301,-524.5 2301,-553.5 2301,-553.5 2301,-559.5 2295,-565.5 2289,-565.5\"/>\n<text text-anchor=\"start\" x=\"2219.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2205\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"2204\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [10, 0]</text>\n</g>\n<!-- 129&#45;&gt;139 -->\n<g id=\"edge139\" class=\"edge\">\n<title>129&#45;&gt;139</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2188.4,-608.88C2198.38,-597.45 2209.55,-584.63 2219.54,-573.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2222.3,-575.36 2226.23,-565.52 2217.02,-570.75 2222.3,-575.36\"/>\n</g>\n<!-- 131 -->\n<g id=\"node132\" class=\"node\">\n<title>131</title>\n<path fill=\"#f8e0ce\" stroke=\"black\" d=\"M2170,-469C2170,-469 2095,-469 2095,-469 2089,-469 2083,-463 2083,-457 2083,-457 2083,-413 2083,-413 2083,-407 2089,-401 2095,-401 2095,-401 2170,-401 2170,-401 2176,-401 2182,-407 2182,-413 2182,-413 2182,-457 2182,-457 2182,-463 2176,-469 2170,-469\"/>\n<text text-anchor=\"start\" x=\"2091\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.771</text>\n<text text-anchor=\"start\" x=\"2099\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.49</text>\n<text text-anchor=\"start\" x=\"2093\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"2092\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 3]</text>\n</g>\n<!-- 130&#45;&gt;131 -->\n<g id=\"edge131\" class=\"edge\">\n<title>130&#45;&gt;131</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2130.47,-504.88C2130.71,-496.78 2130.97,-487.98 2131.22,-479.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2134.73,-479.4 2131.52,-469.3 2127.73,-479.19 2134.73,-479.4\"/>\n</g>\n<!-- 138 -->\n<g id=\"node139\" class=\"node\">\n<title>138</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2285,-461.5C2285,-461.5 2212,-461.5 2212,-461.5 2206,-461.5 2200,-455.5 2200,-449.5 2200,-449.5 2200,-420.5 2200,-420.5 2200,-414.5 2206,-408.5 2212,-408.5 2212,-408.5 2285,-408.5 2285,-408.5 2291,-408.5 2297,-414.5 2297,-420.5 2297,-420.5 2297,-449.5 2297,-449.5 2297,-455.5 2291,-461.5 2285,-461.5\"/>\n<text text-anchor=\"start\" x=\"2219.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2209\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2208\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 130&#45;&gt;138 -->\n<g id=\"edge138\" class=\"edge\">\n<title>130&#45;&gt;138</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2168.14,-504.88C2181.86,-493.12 2197.29,-479.89 2210.93,-468.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2213.41,-470.69 2218.73,-461.52 2208.86,-465.37 2213.41,-470.69\"/>\n</g>\n<!-- 132 -->\n<g id=\"node133\" class=\"node\">\n<title>132</title>\n<path fill=\"#bddef6\" stroke=\"black\" d=\"M2168,-365C2168,-365 2095,-365 2095,-365 2089,-365 2083,-359 2083,-353 2083,-353 2083,-309 2083,-309 2083,-303 2089,-297 2095,-297 2095,-297 2168,-297 2168,-297 2174,-297 2180,-303 2180,-309 2180,-309 2180,-353 2180,-353 2180,-359 2174,-365 2168,-365\"/>\n<text text-anchor=\"start\" x=\"2094\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.96</text>\n<text text-anchor=\"start\" x=\"2098\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n<text text-anchor=\"start\" x=\"2092\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"2091\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 3]</text>\n</g>\n<!-- 131&#45;&gt;132 -->\n<g id=\"edge132\" class=\"edge\">\n<title>131&#45;&gt;132</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2132.18,-400.88C2132.1,-392.78 2132.01,-383.98 2131.93,-375.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2135.42,-375.26 2131.83,-365.3 2128.42,-375.33 2135.42,-375.26\"/>\n</g>\n<!-- 137 -->\n<g id=\"node138\" class=\"node\">\n<title>137</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2283,-357.5C2283,-357.5 2210,-357.5 2210,-357.5 2204,-357.5 2198,-351.5 2198,-345.5 2198,-345.5 2198,-316.5 2198,-316.5 2198,-310.5 2204,-304.5 2210,-304.5 2210,-304.5 2283,-304.5 2283,-304.5 2289,-304.5 2295,-310.5 2295,-316.5 2295,-316.5 2295,-345.5 2295,-345.5 2295,-351.5 2289,-357.5 2283,-357.5\"/>\n<text text-anchor=\"start\" x=\"2217.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2207\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2206\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 131&#45;&gt;137 -->\n<g id=\"edge137\" class=\"edge\">\n<title>131&#45;&gt;137</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2169.51,-400.88C2182.66,-389.12 2197.44,-375.89 2210.51,-364.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2212.86,-366.8 2217.98,-357.52 2208.19,-361.58 2212.86,-366.8\"/>\n</g>\n<!-- 133 -->\n<g id=\"node134\" class=\"node\">\n<title>133</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M2155,-253.5C2155,-253.5 2082,-253.5 2082,-253.5 2076,-253.5 2070,-247.5 2070,-241.5 2070,-241.5 2070,-212.5 2070,-212.5 2070,-206.5 2076,-200.5 2082,-200.5 2082,-200.5 2155,-200.5 2155,-200.5 2161,-200.5 2167,-206.5 2167,-212.5 2167,-212.5 2167,-241.5 2167,-241.5 2167,-247.5 2161,-253.5 2155,-253.5\"/>\n<text text-anchor=\"start\" x=\"2089.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"2079\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2078\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 132&#45;&gt;133 -->\n<g id=\"edge133\" class=\"edge\">\n<title>132&#45;&gt;133</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2127.28,-296.88C2125.92,-286.22 2124.41,-274.35 2123.03,-263.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2126.49,-263 2121.75,-253.52 2119.54,-263.88 2126.49,-263\"/>\n</g>\n<!-- 134 -->\n<g id=\"node135\" class=\"node\">\n<title>134</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M2272,-261C2272,-261 2197,-261 2197,-261 2191,-261 2185,-255 2185,-249 2185,-249 2185,-205 2185,-205 2185,-199 2191,-193 2197,-193 2197,-193 2272,-193 2272,-193 2278,-193 2284,-199 2284,-205 2284,-205 2284,-249 2284,-249 2284,-255 2278,-261 2272,-261\"/>\n<text text-anchor=\"start\" x=\"2193\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.847</text>\n<text text-anchor=\"start\" x=\"2197\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"2195\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2194\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 132&#45;&gt;134 -->\n<g id=\"edge134\" class=\"edge\">\n<title>132&#45;&gt;134</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2164.94,-296.88C2174.12,-287.8 2184.17,-277.85 2193.7,-268.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2196.23,-270.82 2200.87,-261.3 2191.31,-265.85 2196.23,-270.82\"/>\n</g>\n<!-- 135 -->\n<g id=\"node136\" class=\"node\">\n<title>135</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2213,-149.5C2213,-149.5 2140,-149.5 2140,-149.5 2134,-149.5 2128,-143.5 2128,-137.5 2128,-137.5 2128,-108.5 2128,-108.5 2128,-102.5 2134,-96.5 2140,-96.5 2140,-96.5 2213,-96.5 2213,-96.5 2219,-96.5 2225,-102.5 2225,-108.5 2225,-108.5 2225,-137.5 2225,-137.5 2225,-143.5 2219,-149.5 2213,-149.5\"/>\n<text text-anchor=\"start\" x=\"2147.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2137\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2136\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 134&#45;&gt;135 -->\n<g id=\"edge135\" class=\"edge\">\n<title>134&#45;&gt;135</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2215.67,-192.88C2209.42,-181.89 2202.44,-169.62 2196.13,-158.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2199,-156.48 2191.01,-149.52 2192.91,-159.94 2199,-156.48\"/>\n</g>\n<!-- 136 -->\n<g id=\"node137\" class=\"node\">\n<title>136</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M2328,-149.5C2328,-149.5 2255,-149.5 2255,-149.5 2249,-149.5 2243,-143.5 2243,-137.5 2243,-137.5 2243,-108.5 2243,-108.5 2243,-102.5 2249,-96.5 2255,-96.5 2255,-96.5 2328,-96.5 2328,-96.5 2334,-96.5 2340,-102.5 2340,-108.5 2340,-108.5 2340,-137.5 2340,-137.5 2340,-143.5 2334,-149.5 2328,-149.5\"/>\n<text text-anchor=\"start\" x=\"2262.5\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"2252\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2251\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 134&#45;&gt;136 -->\n<g id=\"edge136\" class=\"edge\">\n<title>134&#45;&gt;136</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2253.01,-192.88C2259.15,-181.89 2266.01,-169.62 2272.21,-158.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2275.42,-159.96 2277.24,-149.52 2269.31,-156.54 2275.42,-159.96\"/>\n</g>\n<!-- 141 -->\n<g id=\"node142\" class=\"node\">\n<title>141</title>\n<path fill=\"#e78c4b\" stroke=\"black\" d=\"M2518,-677C2518,-677 2437,-677 2437,-677 2431,-677 2425,-671 2425,-665 2425,-665 2425,-621 2425,-621 2425,-615 2431,-609 2437,-609 2437,-609 2518,-609 2518,-609 2524,-609 2530,-615 2530,-621 2530,-621 2530,-665 2530,-665 2530,-671 2524,-677 2518,-677\"/>\n<text text-anchor=\"start\" x=\"2438\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pclass ≤ 2.5</text>\n<text text-anchor=\"start\" x=\"2440\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.153</text>\n<text text-anchor=\"start\" x=\"2434\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\n<text text-anchor=\"start\" x=\"2433\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 1]</text>\n</g>\n<!-- 140&#45;&gt;141 -->\n<g id=\"edge141\" class=\"edge\">\n<title>140&#45;&gt;141</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2560.57,-712.88C2549.39,-703.62 2537.14,-693.45 2525.55,-683.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2527.59,-680.99 2517.66,-677.3 2523.12,-686.38 2527.59,-680.99\"/>\n</g>\n<!-- 146 -->\n<g id=\"node147\" class=\"node\">\n<title>146</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2641,-669.5C2641,-669.5 2560,-669.5 2560,-669.5 2554,-669.5 2548,-663.5 2548,-657.5 2548,-657.5 2548,-628.5 2548,-628.5 2548,-622.5 2554,-616.5 2560,-616.5 2560,-616.5 2641,-616.5 2641,-616.5 2647,-616.5 2653,-622.5 2653,-628.5 2653,-628.5 2653,-657.5 2653,-657.5 2653,-663.5 2647,-669.5 2641,-669.5\"/>\n<text text-anchor=\"start\" x=\"2571.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2557\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 26</text>\n<text text-anchor=\"start\" x=\"2556\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [26, 0]</text>\n</g>\n<!-- 140&#45;&gt;146 -->\n<g id=\"edge146\" class=\"edge\">\n<title>140&#45;&gt;146</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2600.5,-712.88C2600.5,-702.33 2600.5,-690.6 2600.5,-679.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2604,-679.52 2600.5,-669.52 2597,-679.52 2604,-679.52\"/>\n</g>\n<!-- 142 -->\n<g id=\"node143\" class=\"node\">\n<title>142</title>\n<path fill=\"#eca06a\" stroke=\"black\" d=\"M2409.5,-573C2409.5,-573 2331.5,-573 2331.5,-573 2325.5,-573 2319.5,-567 2319.5,-561 2319.5,-561 2319.5,-517 2319.5,-517 2319.5,-511 2325.5,-505 2331.5,-505 2331.5,-505 2409.5,-505 2409.5,-505 2415.5,-505 2421.5,-511 2421.5,-517 2421.5,-517 2421.5,-561 2421.5,-561 2421.5,-567 2415.5,-573 2409.5,-573\"/>\n<text text-anchor=\"start\" x=\"2327.5\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.491</text>\n<text text-anchor=\"start\" x=\"2337\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"2331\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"2330\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 1]</text>\n</g>\n<!-- 141&#45;&gt;142 -->\n<g id=\"edge142\" class=\"edge\">\n<title>141&#45;&gt;142</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2442.76,-608.88C2433.23,-599.8 2422.79,-589.85 2412.88,-580.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2415.08,-577.67 2405.43,-573.3 2410.25,-582.73 2415.08,-577.67\"/>\n</g>\n<!-- 145 -->\n<g id=\"node146\" class=\"node\">\n<title>145</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2525,-565.5C2525,-565.5 2452,-565.5 2452,-565.5 2446,-565.5 2440,-559.5 2440,-553.5 2440,-553.5 2440,-524.5 2440,-524.5 2440,-518.5 2446,-512.5 2452,-512.5 2452,-512.5 2525,-512.5 2525,-512.5 2531,-512.5 2537,-518.5 2537,-524.5 2537,-524.5 2537,-553.5 2537,-553.5 2537,-559.5 2531,-565.5 2525,-565.5\"/>\n<text text-anchor=\"start\" x=\"2459.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2449\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"2448\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 0]</text>\n</g>\n<!-- 141&#45;&gt;145 -->\n<g id=\"edge145\" class=\"edge\">\n<title>141&#45;&gt;145</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2481.07,-608.88C2482.22,-598.22 2483.5,-586.35 2484.67,-575.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2488.16,-575.84 2485.75,-565.52 2481.2,-575.09 2488.16,-575.84\"/>\n</g>\n<!-- 143 -->\n<g id=\"node144\" class=\"node\">\n<title>143</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M2405,-461.5C2405,-461.5 2332,-461.5 2332,-461.5 2326,-461.5 2320,-455.5 2320,-449.5 2320,-449.5 2320,-420.5 2320,-420.5 2320,-414.5 2326,-408.5 2332,-408.5 2332,-408.5 2405,-408.5 2405,-408.5 2411,-408.5 2417,-414.5 2417,-420.5 2417,-420.5 2417,-449.5 2417,-449.5 2417,-455.5 2411,-461.5 2405,-461.5\"/>\n<text text-anchor=\"start\" x=\"2339.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"2329\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2328\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 142&#45;&gt;143 -->\n<g id=\"edge143\" class=\"edge\">\n<title>142&#45;&gt;143</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2369.85,-504.88C2369.64,-494.22 2369.41,-482.35 2369.2,-471.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2372.7,-471.45 2369,-461.52 2365.7,-471.59 2372.7,-471.45\"/>\n</g>\n<!-- 144 -->\n<g id=\"node145\" class=\"node\">\n<title>144</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2520,-461.5C2520,-461.5 2447,-461.5 2447,-461.5 2441,-461.5 2435,-455.5 2435,-449.5 2435,-449.5 2435,-420.5 2435,-420.5 2435,-414.5 2441,-408.5 2447,-408.5 2447,-408.5 2520,-408.5 2520,-408.5 2526,-408.5 2532,-414.5 2532,-420.5 2532,-420.5 2532,-449.5 2532,-449.5 2532,-455.5 2526,-461.5 2520,-461.5\"/>\n<text text-anchor=\"start\" x=\"2454.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2444\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2443\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 142&#45;&gt;144 -->\n<g id=\"edge144\" class=\"edge\">\n<title>142&#45;&gt;144</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2407.19,-504.88C2420.1,-493.23 2434.6,-480.14 2447.46,-468.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2450.15,-470.82 2455.23,-461.52 2445.46,-465.62 2450.15,-470.82\"/>\n</g>\n<!-- 148 -->\n<g id=\"node149\" class=\"node\">\n<title>148</title>\n<path fill=\"#eeab7b\" stroke=\"black\" d=\"M2764,-781C2764,-781 2683,-781 2683,-781 2677,-781 2671,-775 2671,-769 2671,-769 2671,-725 2671,-725 2671,-719 2677,-713 2683,-713 2683,-713 2764,-713 2764,-713 2770,-713 2776,-719 2776,-725 2776,-725 2776,-769 2776,-769 2776,-775 2770,-781 2764,-781\"/>\n<text text-anchor=\"start\" x=\"2680.5\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.705</text>\n<text text-anchor=\"start\" x=\"2686\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"2680\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 20</text>\n<text text-anchor=\"start\" x=\"2679\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [15, 5]</text>\n</g>\n<!-- 147&#45;&gt;148 -->\n<g id=\"edge148\" class=\"edge\">\n<title>147&#45;&gt;148</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2723.5,-816.88C2723.5,-808.78 2723.5,-799.98 2723.5,-791.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2727,-791.3 2723.5,-781.3 2720,-791.3 2727,-791.3\"/>\n</g>\n<!-- 165 -->\n<g id=\"node166\" class=\"node\">\n<title>165</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2879,-773.5C2879,-773.5 2806,-773.5 2806,-773.5 2800,-773.5 2794,-767.5 2794,-761.5 2794,-761.5 2794,-732.5 2794,-732.5 2794,-726.5 2800,-720.5 2806,-720.5 2806,-720.5 2879,-720.5 2879,-720.5 2885,-720.5 2891,-726.5 2891,-732.5 2891,-732.5 2891,-761.5 2891,-761.5 2891,-767.5 2885,-773.5 2879,-773.5\"/>\n<text text-anchor=\"start\" x=\"2813.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2803\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"2802\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 0]</text>\n</g>\n<!-- 147&#45;&gt;165 -->\n<g id=\"edge165\" class=\"edge\">\n<title>147&#45;&gt;165</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2762.14,-816.88C2775.86,-805.12 2791.29,-791.89 2804.93,-780.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2807.41,-782.69 2812.73,-773.52 2802.86,-777.37 2807.41,-782.69\"/>\n</g>\n<!-- 149 -->\n<g id=\"node150\" class=\"node\">\n<title>149</title>\n<path fill=\"#ea985d\" stroke=\"black\" d=\"M2764,-677C2764,-677 2683,-677 2683,-677 2677,-677 2671,-671 2671,-665 2671,-665 2671,-621 2671,-621 2671,-615 2677,-609 2683,-609 2683,-609 2764,-609 2764,-609 2770,-609 2776,-615 2776,-621 2776,-621 2776,-665 2776,-665 2776,-671 2770,-677 2764,-677\"/>\n<text text-anchor=\"start\" x=\"2680.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.803</text>\n<text text-anchor=\"start\" x=\"2690\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.26</text>\n<text text-anchor=\"start\" x=\"2680\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13</text>\n<text text-anchor=\"start\" x=\"2679\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 2]</text>\n</g>\n<!-- 148&#45;&gt;149 -->\n<g id=\"edge149\" class=\"edge\">\n<title>148&#45;&gt;149</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2723.5,-712.88C2723.5,-704.78 2723.5,-695.98 2723.5,-687.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2727,-687.3 2723.5,-677.3 2720,-687.3 2727,-687.3\"/>\n</g>\n<!-- 158 -->\n<g id=\"node159\" class=\"node\">\n<title>158</title>\n<path fill=\"#f8e0ce\" stroke=\"black\" d=\"M2879,-677C2879,-677 2806,-677 2806,-677 2800,-677 2794,-671 2794,-665 2794,-665 2794,-621 2794,-621 2794,-615 2800,-609 2806,-609 2806,-609 2879,-609 2879,-609 2885,-609 2891,-615 2891,-621 2891,-621 2891,-665 2891,-665 2891,-671 2885,-677 2879,-677\"/>\n<text text-anchor=\"start\" x=\"2803\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pclass ≤ 2.5</text>\n<text text-anchor=\"start\" x=\"2809\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.49</text>\n<text text-anchor=\"start\" x=\"2803\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"2802\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 3]</text>\n</g>\n<!-- 148&#45;&gt;158 -->\n<g id=\"edge158\" class=\"edge\">\n<title>148&#45;&gt;158</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2762.14,-712.88C2772.94,-703.62 2784.8,-693.45 2796.01,-683.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2798.34,-686.46 2803.65,-677.3 2793.78,-681.15 2798.34,-686.46\"/>\n</g>\n<!-- 150 -->\n<g id=\"node151\" class=\"node\">\n<title>150</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M2645.5,-573C2645.5,-573 2567.5,-573 2567.5,-573 2561.5,-573 2555.5,-567 2555.5,-561 2555.5,-561 2555.5,-517 2555.5,-517 2555.5,-511 2561.5,-505 2567.5,-505 2567.5,-505 2645.5,-505 2645.5,-505 2651.5,-505 2657.5,-511 2657.5,-517 2657.5,-517 2657.5,-561 2657.5,-561 2657.5,-567 2651.5,-573 2645.5,-573\"/>\n<text text-anchor=\"start\" x=\"2563.5\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.809</text>\n<text text-anchor=\"start\" x=\"2569\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"2567\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"2566\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 2]</text>\n</g>\n<!-- 149&#45;&gt;150 -->\n<g id=\"edge150\" class=\"edge\">\n<title>149&#45;&gt;150</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2685.51,-608.88C2674.99,-599.71 2663.45,-589.65 2652.52,-580.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2654.53,-577.23 2644.7,-573.3 2649.93,-582.51 2654.53,-577.23\"/>\n</g>\n<!-- 157 -->\n<g id=\"node158\" class=\"node\">\n<title>157</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2761,-565.5C2761,-565.5 2688,-565.5 2688,-565.5 2682,-565.5 2676,-559.5 2676,-553.5 2676,-553.5 2676,-524.5 2676,-524.5 2676,-518.5 2682,-512.5 2688,-512.5 2688,-512.5 2761,-512.5 2761,-512.5 2767,-512.5 2773,-518.5 2773,-524.5 2773,-524.5 2773,-553.5 2773,-553.5 2773,-559.5 2767,-565.5 2761,-565.5\"/>\n<text text-anchor=\"start\" x=\"2695.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2685\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"2684\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 0]</text>\n</g>\n<!-- 149&#45;&gt;157 -->\n<g id=\"edge157\" class=\"edge\">\n<title>149&#45;&gt;157</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2723.82,-608.88C2723.93,-598.33 2724.04,-586.6 2724.15,-575.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2727.65,-575.55 2724.25,-565.52 2720.65,-575.49 2727.65,-575.55\"/>\n</g>\n<!-- 151 -->\n<g id=\"node152\" class=\"node\">\n<title>151</title>\n<path fill=\"#eca06a\" stroke=\"black\" d=\"M2640,-469C2640,-469 2565,-469 2565,-469 2559,-469 2553,-463 2553,-457 2553,-457 2553,-413 2553,-413 2553,-407 2559,-401 2565,-401 2565,-401 2640,-401 2640,-401 2646,-401 2652,-407 2652,-413 2652,-413 2652,-457 2652,-457 2652,-463 2646,-469 2640,-469\"/>\n<text text-anchor=\"start\" x=\"2561\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.016</text>\n<text text-anchor=\"start\" x=\"2569\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"2563\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"2562\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 1]</text>\n</g>\n<!-- 150&#45;&gt;151 -->\n<g id=\"edge151\" class=\"edge\">\n<title>150&#45;&gt;151</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2605.2,-504.88C2604.88,-496.78 2604.54,-487.98 2604.2,-479.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2607.7,-479.15 2603.81,-469.3 2600.7,-479.43 2607.7,-479.15\"/>\n</g>\n<!-- 156 -->\n<g id=\"node157\" class=\"node\">\n<title>156</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2755,-461.5C2755,-461.5 2682,-461.5 2682,-461.5 2676,-461.5 2670,-455.5 2670,-449.5 2670,-449.5 2670,-420.5 2670,-420.5 2670,-414.5 2676,-408.5 2682,-408.5 2682,-408.5 2755,-408.5 2755,-408.5 2761,-408.5 2767,-414.5 2767,-420.5 2767,-420.5 2767,-449.5 2767,-449.5 2767,-455.5 2761,-461.5 2755,-461.5\"/>\n<text text-anchor=\"start\" x=\"2689.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2679\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2678\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 150&#45;&gt;156 -->\n<g id=\"edge156\" class=\"edge\">\n<title>150&#45;&gt;156</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2642.86,-504.88C2655.66,-493.23 2670.03,-480.14 2682.78,-468.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2685.44,-470.84 2690.48,-461.52 2680.73,-465.67 2685.44,-470.84\"/>\n</g>\n<!-- 152 -->\n<g id=\"node153\" class=\"node\">\n<title>152</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M2554,-365C2554,-365 2441,-365 2441,-365 2435,-365 2429,-359 2429,-353 2429,-353 2429,-309 2429,-309 2429,-303 2435,-297 2441,-297 2441,-297 2554,-297 2554,-297 2560,-297 2566,-303 2566,-309 2566,-309 2566,-353 2566,-353 2566,-359 2560,-365 2554,-365\"/>\n<text text-anchor=\"start\" x=\"2437\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Embarked_Q ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"2468.5\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"2458\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2457\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 151&#45;&gt;152 -->\n<g id=\"edge152\" class=\"edge\">\n<title>151&#45;&gt;152</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2568.41,-400.88C2559.06,-391.8 2548.81,-381.85 2539.09,-372.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2541.39,-369.76 2531.78,-365.3 2536.51,-374.78 2541.39,-369.76\"/>\n</g>\n<!-- 155 -->\n<g id=\"node156\" class=\"node\">\n<title>155</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2669,-357.5C2669,-357.5 2596,-357.5 2596,-357.5 2590,-357.5 2584,-351.5 2584,-345.5 2584,-345.5 2584,-316.5 2584,-316.5 2584,-310.5 2590,-304.5 2596,-304.5 2596,-304.5 2669,-304.5 2669,-304.5 2675,-304.5 2681,-310.5 2681,-316.5 2681,-316.5 2681,-345.5 2681,-345.5 2681,-351.5 2675,-357.5 2669,-357.5\"/>\n<text text-anchor=\"start\" x=\"2603.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2593\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2592\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 151&#45;&gt;155 -->\n<g id=\"edge155\" class=\"edge\">\n<title>151&#45;&gt;155</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2612.24,-400.88C2615.41,-390.11 2618.94,-378.11 2622.15,-367.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2625.53,-368.1 2624.99,-357.52 2618.81,-366.13 2625.53,-368.1\"/>\n</g>\n<!-- 153 -->\n<g id=\"node154\" class=\"node\">\n<title>153</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2432,-253.5C2432,-253.5 2359,-253.5 2359,-253.5 2353,-253.5 2347,-247.5 2347,-241.5 2347,-241.5 2347,-212.5 2347,-212.5 2347,-206.5 2353,-200.5 2359,-200.5 2359,-200.5 2432,-200.5 2432,-200.5 2438,-200.5 2444,-206.5 2444,-212.5 2444,-212.5 2444,-241.5 2444,-241.5 2444,-247.5 2438,-253.5 2432,-253.5\"/>\n<text text-anchor=\"start\" x=\"2366.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2356\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2355\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 152&#45;&gt;153 -->\n<g id=\"edge153\" class=\"edge\">\n<title>152&#45;&gt;153</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2464.38,-296.88C2452.84,-285.34 2439.89,-272.39 2428.36,-260.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2430.57,-258.12 2421.02,-253.52 2425.62,-263.07 2430.57,-258.12\"/>\n</g>\n<!-- 154 -->\n<g id=\"node155\" class=\"node\">\n<title>154</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2547,-253.5C2547,-253.5 2474,-253.5 2474,-253.5 2468,-253.5 2462,-247.5 2462,-241.5 2462,-241.5 2462,-212.5 2462,-212.5 2462,-206.5 2468,-200.5 2474,-200.5 2474,-200.5 2547,-200.5 2547,-200.5 2553,-200.5 2559,-206.5 2559,-212.5 2559,-212.5 2559,-241.5 2559,-241.5 2559,-247.5 2553,-253.5 2547,-253.5\"/>\n<text text-anchor=\"start\" x=\"2481.5\" y=\"-238.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2471\" y=\"-223.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2470\" y=\"-208.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 152&#45;&gt;154 -->\n<g id=\"edge154\" class=\"edge\">\n<title>152&#45;&gt;154</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2501.72,-296.88C2503.08,-286.22 2504.59,-274.35 2505.97,-263.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2509.46,-263.88 2507.25,-253.52 2502.51,-263 2509.46,-263.88\"/>\n</g>\n<!-- 159 -->\n<g id=\"node160\" class=\"node\">\n<title>159</title>\n<path fill=\"#eca06a\" stroke=\"black\" d=\"M2881.5,-573C2881.5,-573 2803.5,-573 2803.5,-573 2797.5,-573 2791.5,-567 2791.5,-561 2791.5,-561 2791.5,-517 2791.5,-517 2791.5,-511 2797.5,-505 2803.5,-505 2803.5,-505 2881.5,-505 2881.5,-505 2887.5,-505 2893.5,-511 2893.5,-517 2893.5,-517 2893.5,-561 2893.5,-561 2893.5,-567 2887.5,-573 2881.5,-573\"/>\n<text text-anchor=\"start\" x=\"2799.5\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.433</text>\n<text text-anchor=\"start\" x=\"2809\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"2803\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"2802\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 1]</text>\n</g>\n<!-- 158&#45;&gt;159 -->\n<g id=\"edge159\" class=\"edge\">\n<title>158&#45;&gt;159</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2842.5,-608.88C2842.5,-600.78 2842.5,-591.98 2842.5,-583.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2846,-583.3 2842.5,-573.3 2839,-583.3 2846,-583.3\"/>\n</g>\n<!-- 164 -->\n<g id=\"node165\" class=\"node\">\n<title>164</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2997,-565.5C2997,-565.5 2924,-565.5 2924,-565.5 2918,-565.5 2912,-559.5 2912,-553.5 2912,-553.5 2912,-524.5 2912,-524.5 2912,-518.5 2918,-512.5 2924,-512.5 2924,-512.5 2997,-512.5 2997,-512.5 3003,-512.5 3009,-518.5 3009,-524.5 3009,-524.5 3009,-553.5 3009,-553.5 3009,-559.5 3003,-565.5 2997,-565.5\"/>\n<text text-anchor=\"start\" x=\"2931.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2921\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2920\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 158&#45;&gt;164 -->\n<g id=\"edge164\" class=\"edge\">\n<title>158&#45;&gt;164</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2880.81,-608.88C2894.42,-597.12 2909.72,-583.89 2923.25,-572.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2925.7,-574.71 2930.98,-565.52 2921.12,-569.41 2925.7,-574.71\"/>\n</g>\n<!-- 160 -->\n<g id=\"node161\" class=\"node\">\n<title>160</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2874,-461.5C2874,-461.5 2801,-461.5 2801,-461.5 2795,-461.5 2789,-455.5 2789,-449.5 2789,-449.5 2789,-420.5 2789,-420.5 2789,-414.5 2795,-408.5 2801,-408.5 2801,-408.5 2874,-408.5 2874,-408.5 2880,-408.5 2886,-414.5 2886,-420.5 2886,-420.5 2886,-449.5 2886,-449.5 2886,-455.5 2880,-461.5 2874,-461.5\"/>\n<text text-anchor=\"start\" x=\"2808.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2798\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2797\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 159&#45;&gt;160 -->\n<g id=\"edge160\" class=\"edge\">\n<title>159&#45;&gt;160</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2840.88,-504.88C2840.35,-494.22 2839.77,-482.35 2839.24,-471.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2842.74,-471.34 2838.75,-461.52 2835.74,-471.68 2842.74,-471.34\"/>\n</g>\n<!-- 161 -->\n<g id=\"node162\" class=\"node\">\n<title>161</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M2989,-469C2989,-469 2916,-469 2916,-469 2910,-469 2904,-463 2904,-457 2904,-457 2904,-413 2904,-413 2904,-407 2910,-401 2916,-401 2916,-401 2989,-401 2989,-401 2995,-401 3001,-407 3001,-413 3001,-413 3001,-457 3001,-457 3001,-463 2995,-469 2989,-469\"/>\n<text text-anchor=\"start\" x=\"2917.5\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.06</text>\n<text text-anchor=\"start\" x=\"2923.5\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"2913\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2912\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 159&#45;&gt;161 -->\n<g id=\"edge161\" class=\"edge\">\n<title>159&#45;&gt;161</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2878.21,-504.88C2888.11,-495.71 2898.96,-485.65 2909.23,-476.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2911.64,-478.67 2916.59,-469.3 2906.88,-473.53 2911.64,-478.67\"/>\n</g>\n<!-- 162 -->\n<g id=\"node163\" class=\"node\">\n<title>162</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2931,-357.5C2931,-357.5 2858,-357.5 2858,-357.5 2852,-357.5 2846,-351.5 2846,-345.5 2846,-345.5 2846,-316.5 2846,-316.5 2846,-310.5 2852,-304.5 2858,-304.5 2858,-304.5 2931,-304.5 2931,-304.5 2937,-304.5 2943,-310.5 2943,-316.5 2943,-316.5 2943,-345.5 2943,-345.5 2943,-351.5 2937,-357.5 2931,-357.5\"/>\n<text text-anchor=\"start\" x=\"2865.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2855\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2854\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 161&#45;&gt;162 -->\n<g id=\"edge162\" class=\"edge\">\n<title>161&#45;&gt;162</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2933.67,-400.88C2927.42,-389.89 2920.44,-377.62 2914.13,-366.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2917,-364.48 2909.01,-357.52 2910.91,-367.94 2917,-364.48\"/>\n</g>\n<!-- 163 -->\n<g id=\"node164\" class=\"node\">\n<title>163</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3046,-357.5C3046,-357.5 2973,-357.5 2973,-357.5 2967,-357.5 2961,-351.5 2961,-345.5 2961,-345.5 2961,-316.5 2961,-316.5 2961,-310.5 2967,-304.5 2973,-304.5 2973,-304.5 3046,-304.5 3046,-304.5 3052,-304.5 3058,-310.5 3058,-316.5 3058,-316.5 3058,-345.5 3058,-345.5 3058,-351.5 3052,-357.5 3046,-357.5\"/>\n<text text-anchor=\"start\" x=\"2980.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2970\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"2969\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 161&#45;&gt;163 -->\n<g id=\"edge163\" class=\"edge\">\n<title>161&#45;&gt;163</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2971.01,-400.88C2977.15,-389.89 2984.01,-377.62 2990.21,-366.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2993.42,-367.96 2995.24,-357.52 2987.31,-364.54 2993.42,-367.96\"/>\n</g>\n<!-- 167 -->\n<g id=\"node168\" class=\"node\">\n<title>167</title>\n<path fill=\"#f6d5bd\" stroke=\"black\" d=\"M2906,-989C2906,-989 2827,-989 2827,-989 2821,-989 2815,-983 2815,-977 2815,-977 2815,-933 2815,-933 2815,-927 2821,-921 2827,-921 2827,-921 2906,-921 2906,-921 2912,-921 2918,-927 2918,-933 2918,-933 2918,-977 2918,-977 2918,-983 2912,-989 2906,-989\"/>\n<text text-anchor=\"start\" x=\"2825\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.922</text>\n<text text-anchor=\"start\" x=\"2833\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n<text text-anchor=\"start\" x=\"2823\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"2826\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 4]</text>\n</g>\n<!-- 166&#45;&gt;167 -->\n<g id=\"edge167\" class=\"edge\">\n<title>166&#45;&gt;167</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2897.57,-1024.88C2893.79,-1016.51 2889.68,-1007.4 2885.73,-998.63\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2888.82,-996.98 2881.52,-989.3 2882.44,-999.85 2888.82,-996.98\"/>\n</g>\n<!-- 176 -->\n<g id=\"node177\" class=\"node\">\n<title>176</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3021,-981.5C3021,-981.5 2948,-981.5 2948,-981.5 2942,-981.5 2936,-975.5 2936,-969.5 2936,-969.5 2936,-940.5 2936,-940.5 2936,-934.5 2942,-928.5 2948,-928.5 2948,-928.5 3021,-928.5 3021,-928.5 3027,-928.5 3033,-934.5 3033,-940.5 3033,-940.5 3033,-969.5 3033,-969.5 3033,-975.5 3027,-981.5 3021,-981.5\"/>\n<text text-anchor=\"start\" x=\"2955.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2945\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"2944\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 166&#45;&gt;176 -->\n<g id=\"edge176\" class=\"edge\">\n<title>166&#45;&gt;176</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2935.88,-1024.88C2943.79,-1013.67 2952.65,-1001.13 2960.6,-989.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2963.58,-991.71 2966.49,-981.52 2957.86,-987.67 2963.58,-991.71\"/>\n</g>\n<!-- 168 -->\n<g id=\"node169\" class=\"node\">\n<title>168</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M2880,-877.5C2880,-877.5 2807,-877.5 2807,-877.5 2801,-877.5 2795,-871.5 2795,-865.5 2795,-865.5 2795,-836.5 2795,-836.5 2795,-830.5 2801,-824.5 2807,-824.5 2807,-824.5 2880,-824.5 2880,-824.5 2886,-824.5 2892,-830.5 2892,-836.5 2892,-836.5 2892,-865.5 2892,-865.5 2892,-871.5 2886,-877.5 2880,-877.5\"/>\n<text text-anchor=\"start\" x=\"2814.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2804\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2803\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 167&#45;&gt;168 -->\n<g id=\"edge168\" class=\"edge\">\n<title>167&#45;&gt;168</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2859.03,-920.88C2856.63,-910.22 2853.95,-898.35 2851.51,-887.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2854.87,-886.51 2849.25,-877.52 2848.04,-888.04 2854.87,-886.51\"/>\n</g>\n<!-- 169 -->\n<g id=\"node170\" class=\"node\">\n<title>169</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M2995,-885C2995,-885 2922,-885 2922,-885 2916,-885 2910,-879 2910,-873 2910,-873 2910,-829 2910,-829 2910,-823 2916,-817 2922,-817 2922,-817 2995,-817 2995,-817 3001,-817 3007,-823 3007,-829 3007,-829 3007,-873 3007,-873 3007,-879 3001,-885 2995,-885\"/>\n<text text-anchor=\"start\" x=\"2921\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.62</text>\n<text text-anchor=\"start\" x=\"2929.5\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"2919\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"2918\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 4]</text>\n</g>\n<!-- 167&#45;&gt;169 -->\n<g id=\"edge169\" class=\"edge\">\n<title>167&#45;&gt;169</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2896.37,-920.88C2904.4,-911.98 2913.19,-902.24 2921.56,-892.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2924.37,-895.07 2928.47,-885.3 2919.17,-890.38 2924.37,-895.07\"/>\n</g>\n<!-- 170 -->\n<g id=\"node171\" class=\"node\">\n<title>170</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M2995,-773.5C2995,-773.5 2922,-773.5 2922,-773.5 2916,-773.5 2910,-767.5 2910,-761.5 2910,-761.5 2910,-732.5 2910,-732.5 2910,-726.5 2916,-720.5 2922,-720.5 2922,-720.5 2995,-720.5 2995,-720.5 3001,-720.5 3007,-726.5 3007,-732.5 3007,-732.5 3007,-761.5 3007,-761.5 3007,-767.5 3001,-773.5 2995,-773.5\"/>\n<text text-anchor=\"start\" x=\"2929.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"2919\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"2918\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 169&#45;&gt;170 -->\n<g id=\"edge170\" class=\"edge\">\n<title>169&#45;&gt;170</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2958.5,-816.88C2958.5,-806.33 2958.5,-794.6 2958.5,-783.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"2962,-783.52 2958.5,-773.52 2955,-783.52 2962,-783.52\"/>\n</g>\n<!-- 171 -->\n<g id=\"node172\" class=\"node\">\n<title>171</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M3112,-781C3112,-781 3037,-781 3037,-781 3031,-781 3025,-775 3025,-769 3025,-769 3025,-725 3025,-725 3025,-719 3031,-713 3037,-713 3037,-713 3112,-713 3112,-713 3118,-713 3124,-719 3124,-725 3124,-725 3124,-769 3124,-769 3124,-775 3118,-781 3112,-781\"/>\n<text text-anchor=\"start\" x=\"3033\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.072</text>\n<text text-anchor=\"start\" x=\"3037\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"3035\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"3034\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 2]</text>\n</g>\n<!-- 169&#45;&gt;171 -->\n<g id=\"edge171\" class=\"edge\">\n<title>169&#45;&gt;171</title>\n<path fill=\"none\" stroke=\"black\" d=\"M2996.16,-816.88C3006.6,-807.71 3018.04,-797.65 3028.87,-788.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3031.43,-790.53 3036.63,-781.3 3026.81,-785.27 3031.43,-790.53\"/>\n</g>\n<!-- 172 -->\n<g id=\"node173\" class=\"node\">\n<title>172</title>\n<path fill=\"#eca06a\" stroke=\"black\" d=\"M3113.5,-677C3113.5,-677 3035.5,-677 3035.5,-677 3029.5,-677 3023.5,-671 3023.5,-665 3023.5,-665 3023.5,-621 3023.5,-621 3023.5,-615 3029.5,-609 3035.5,-609 3035.5,-609 3113.5,-609 3113.5,-609 3119.5,-609 3125.5,-615 3125.5,-621 3125.5,-621 3125.5,-665 3125.5,-665 3125.5,-671 3119.5,-677 3113.5,-677\"/>\n<text text-anchor=\"start\" x=\"3031.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.081</text>\n<text text-anchor=\"start\" x=\"3041\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"3035\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"3034\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 1]</text>\n</g>\n<!-- 171&#45;&gt;172 -->\n<g id=\"edge172\" class=\"edge\">\n<title>171&#45;&gt;172</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3074.5,-712.88C3074.5,-704.78 3074.5,-695.98 3074.5,-687.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3078,-687.3 3074.5,-677.3 3071,-687.3 3078,-687.3\"/>\n</g>\n<!-- 175 -->\n<g id=\"node176\" class=\"node\">\n<title>175</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3229,-669.5C3229,-669.5 3156,-669.5 3156,-669.5 3150,-669.5 3144,-663.5 3144,-657.5 3144,-657.5 3144,-628.5 3144,-628.5 3144,-622.5 3150,-616.5 3156,-616.5 3156,-616.5 3229,-616.5 3229,-616.5 3235,-616.5 3241,-622.5 3241,-628.5 3241,-628.5 3241,-657.5 3241,-657.5 3241,-663.5 3235,-669.5 3229,-669.5\"/>\n<text text-anchor=\"start\" x=\"3163.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3153\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3152\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 171&#45;&gt;175 -->\n<g id=\"edge175\" class=\"edge\">\n<title>171&#45;&gt;175</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3112.81,-712.88C3126.42,-701.12 3141.72,-687.89 3155.25,-676.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3157.7,-678.71 3162.98,-669.52 3153.12,-673.41 3157.7,-678.71\"/>\n</g>\n<!-- 173 -->\n<g id=\"node174\" class=\"node\">\n<title>173</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3112,-565.5C3112,-565.5 3039,-565.5 3039,-565.5 3033,-565.5 3027,-559.5 3027,-553.5 3027,-553.5 3027,-524.5 3027,-524.5 3027,-518.5 3033,-512.5 3039,-512.5 3039,-512.5 3112,-512.5 3112,-512.5 3118,-512.5 3124,-518.5 3124,-524.5 3124,-524.5 3124,-553.5 3124,-553.5 3124,-559.5 3118,-565.5 3112,-565.5\"/>\n<text text-anchor=\"start\" x=\"3046.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3036\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"3035\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 0]</text>\n</g>\n<!-- 172&#45;&gt;173 -->\n<g id=\"edge173\" class=\"edge\">\n<title>172&#45;&gt;173</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3074.82,-608.88C3074.93,-598.33 3075.04,-586.6 3075.15,-575.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3078.65,-575.55 3075.25,-565.52 3071.65,-575.49 3078.65,-575.55\"/>\n</g>\n<!-- 174 -->\n<g id=\"node175\" class=\"node\">\n<title>174</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3227,-565.5C3227,-565.5 3154,-565.5 3154,-565.5 3148,-565.5 3142,-559.5 3142,-553.5 3142,-553.5 3142,-524.5 3142,-524.5 3142,-518.5 3148,-512.5 3154,-512.5 3154,-512.5 3227,-512.5 3227,-512.5 3233,-512.5 3239,-518.5 3239,-524.5 3239,-524.5 3239,-553.5 3239,-553.5 3239,-559.5 3233,-565.5 3227,-565.5\"/>\n<text text-anchor=\"start\" x=\"3161.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3151\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3150\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 172&#45;&gt;174 -->\n<g id=\"edge174\" class=\"edge\">\n<title>172&#45;&gt;174</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3112.16,-608.88C3125.54,-597.12 3140.58,-583.89 3153.88,-572.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3156.28,-574.75 3161.48,-565.52 3151.66,-569.49 3156.28,-574.75\"/>\n</g>\n<!-- 179 -->\n<g id=\"node180\" class=\"node\">\n<title>179</title>\n<path fill=\"#e6853f\" stroke=\"black\" d=\"M3398,-1197C3398,-1197 3317,-1197 3317,-1197 3311,-1197 3305,-1191 3305,-1185 3305,-1185 3305,-1141 3305,-1141 3305,-1135 3311,-1129 3317,-1129 3317,-1129 3398,-1129 3398,-1129 3404,-1129 3410,-1135 3410,-1141 3410,-1141 3410,-1185 3410,-1185 3410,-1191 3404,-1197 3398,-1197\"/>\n<text text-anchor=\"start\" x=\"3318\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.225</text>\n<text text-anchor=\"start\" x=\"3320\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.056</text>\n<text text-anchor=\"start\" x=\"3314\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 69</text>\n<text text-anchor=\"start\" x=\"3313\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [67, 2]</text>\n</g>\n<!-- 178&#45;&gt;179 -->\n<g id=\"edge179\" class=\"edge\">\n<title>178&#45;&gt;179</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3357.5,-1232.88C3357.5,-1224.78 3357.5,-1215.98 3357.5,-1207.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3361,-1207.3 3357.5,-1197.3 3354,-1207.3 3361,-1207.3\"/>\n</g>\n<!-- 190 -->\n<g id=\"node191\" class=\"node\">\n<title>190</title>\n<path fill=\"#e88f4f\" stroke=\"black\" d=\"M3581,-1197C3581,-1197 3500,-1197 3500,-1197 3494,-1197 3488,-1191 3488,-1185 3488,-1185 3488,-1141 3488,-1141 3488,-1135 3494,-1129 3500,-1129 3500,-1129 3581,-1129 3581,-1129 3587,-1129 3593,-1135 3593,-1141 3593,-1141 3593,-1185 3593,-1185 3593,-1191 3587,-1197 3581,-1197\"/>\n<text text-anchor=\"start\" x=\"3497.5\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.789</text>\n<text text-anchor=\"start\" x=\"3503\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.182</text>\n<text text-anchor=\"start\" x=\"3497\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 69</text>\n<text text-anchor=\"start\" x=\"3496\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [62, 7]</text>\n</g>\n<!-- 178&#45;&gt;190 -->\n<g id=\"edge190\" class=\"edge\">\n<title>178&#45;&gt;190</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3414.4,-1234.29C3434.96,-1222.82 3458.26,-1209.84 3479.19,-1198.17\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3480.97,-1201.19 3488,-1193.26 3477.56,-1195.07 3480.97,-1201.19\"/>\n</g>\n<!-- 180 -->\n<g id=\"node181\" class=\"node\">\n<title>180</title>\n<path fill=\"#e68743\" stroke=\"black\" d=\"M3337,-1093C3337,-1093 3256,-1093 3256,-1093 3250,-1093 3244,-1087 3244,-1081 3244,-1081 3244,-1037 3244,-1037 3244,-1031 3250,-1025 3256,-1025 3256,-1025 3337,-1025 3337,-1025 3343,-1025 3349,-1031 3349,-1037 3349,-1037 3349,-1081 3349,-1081 3349,-1087 3343,-1093 3337,-1093\"/>\n<text text-anchor=\"start\" x=\"3253.5\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.811</text>\n<text text-anchor=\"start\" x=\"3259\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.091</text>\n<text text-anchor=\"start\" x=\"3253\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 42</text>\n<text text-anchor=\"start\" x=\"3252\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [40, 2]</text>\n</g>\n<!-- 179&#45;&gt;180 -->\n<g id=\"edge180\" class=\"edge\">\n<title>179&#45;&gt;180</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3337.7,-1128.88C3332.58,-1120.33 3327.01,-1111.01 3321.66,-1102.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3324.55,-1100.09 3316.41,-1093.3 3318.54,-1103.68 3324.55,-1100.09\"/>\n</g>\n<!-- 189 -->\n<g id=\"node190\" class=\"node\">\n<title>189</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3460,-1085.5C3460,-1085.5 3379,-1085.5 3379,-1085.5 3373,-1085.5 3367,-1079.5 3367,-1073.5 3367,-1073.5 3367,-1044.5 3367,-1044.5 3367,-1038.5 3373,-1032.5 3379,-1032.5 3379,-1032.5 3460,-1032.5 3460,-1032.5 3466,-1032.5 3472,-1038.5 3472,-1044.5 3472,-1044.5 3472,-1073.5 3472,-1073.5 3472,-1079.5 3466,-1085.5 3460,-1085.5\"/>\n<text text-anchor=\"start\" x=\"3390.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3376\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 27</text>\n<text text-anchor=\"start\" x=\"3375\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [27, 0]</text>\n</g>\n<!-- 179&#45;&gt;189 -->\n<g id=\"edge189\" class=\"edge\">\n<title>179&#45;&gt;189</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3377.63,-1128.88C3384.38,-1117.78 3391.92,-1105.37 3398.72,-1094.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3401.78,-1095.88 3403.99,-1085.52 3395.8,-1092.25 3401.78,-1095.88\"/>\n</g>\n<!-- 181 -->\n<g id=\"node182\" class=\"node\">\n<title>181</title>\n<path fill=\"#e78a47\" stroke=\"black\" d=\"M3235,-989C3235,-989 3154,-989 3154,-989 3148,-989 3142,-983 3142,-977 3142,-977 3142,-933 3142,-933 3142,-927 3148,-921 3154,-921 3154,-921 3235,-921 3235,-921 3241,-921 3247,-927 3247,-933 3247,-933 3247,-977 3247,-977 3247,-983 3241,-989 3235,-989\"/>\n<text text-anchor=\"start\" x=\"3151.5\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.815</text>\n<text text-anchor=\"start\" x=\"3157\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.124</text>\n<text text-anchor=\"start\" x=\"3151\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30</text>\n<text text-anchor=\"start\" x=\"3150\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [28, 2]</text>\n</g>\n<!-- 180&#45;&gt;181 -->\n<g id=\"edge181\" class=\"edge\">\n<title>180&#45;&gt;181</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3263.38,-1024.88C3254.3,-1015.8 3244.35,-1005.85 3234.9,-996.4\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3237.35,-993.9 3227.8,-989.3 3232.4,-998.85 3237.35,-993.9\"/>\n</g>\n<!-- 188 -->\n<g id=\"node189\" class=\"node\">\n<title>188</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3358,-981.5C3358,-981.5 3277,-981.5 3277,-981.5 3271,-981.5 3265,-975.5 3265,-969.5 3265,-969.5 3265,-940.5 3265,-940.5 3265,-934.5 3271,-928.5 3277,-928.5 3277,-928.5 3358,-928.5 3358,-928.5 3364,-928.5 3370,-934.5 3370,-940.5 3370,-940.5 3370,-969.5 3370,-969.5 3370,-975.5 3364,-981.5 3358,-981.5\"/>\n<text text-anchor=\"start\" x=\"3288.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3274\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\n<text text-anchor=\"start\" x=\"3273\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [12, 0]</text>\n</g>\n<!-- 180&#45;&gt;188 -->\n<g id=\"edge188\" class=\"edge\">\n<title>180&#45;&gt;188</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3303.32,-1024.88C3305.51,-1014.22 3307.96,-1002.35 3310.19,-991.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3313.66,-992.02 3312.25,-981.52 3306.8,-990.61 3313.66,-992.02\"/>\n</g>\n<!-- 182 -->\n<g id=\"node183\" class=\"node\">\n<title>182</title>\n<path fill=\"#e68640\" stroke=\"black\" d=\"M3250.5,-885C3250.5,-885 3138.5,-885 3138.5,-885 3132.5,-885 3126.5,-879 3126.5,-873 3126.5,-873 3126.5,-829 3126.5,-829 3126.5,-823 3132.5,-817 3138.5,-817 3138.5,-817 3250.5,-817 3250.5,-817 3256.5,-817 3262.5,-823 3262.5,-829 3262.5,-829 3262.5,-873 3262.5,-873 3262.5,-879 3256.5,-885 3250.5,-885\"/>\n<text text-anchor=\"start\" x=\"3134.5\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Embarked_C ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"3157\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.067</text>\n<text text-anchor=\"start\" x=\"3151\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 29</text>\n<text text-anchor=\"start\" x=\"3150\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [28, 1]</text>\n</g>\n<!-- 181&#45;&gt;182 -->\n<g id=\"edge182\" class=\"edge\">\n<title>181&#45;&gt;182</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3194.5,-920.88C3194.5,-912.78 3194.5,-903.98 3194.5,-895.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3198,-895.3 3194.5,-885.3 3191,-895.3 3198,-895.3\"/>\n</g>\n<!-- 187 -->\n<g id=\"node188\" class=\"node\">\n<title>187</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3366,-877.5C3366,-877.5 3293,-877.5 3293,-877.5 3287,-877.5 3281,-871.5 3281,-865.5 3281,-865.5 3281,-836.5 3281,-836.5 3281,-830.5 3287,-824.5 3293,-824.5 3293,-824.5 3366,-824.5 3366,-824.5 3372,-824.5 3378,-830.5 3378,-836.5 3378,-836.5 3378,-865.5 3378,-865.5 3378,-871.5 3372,-877.5 3366,-877.5\"/>\n<text text-anchor=\"start\" x=\"3300.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3290\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3289\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 181&#45;&gt;187 -->\n<g id=\"edge187\" class=\"edge\">\n<title>181&#45;&gt;187</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3238.33,-920.88C3254.2,-908.9 3272.06,-895.4 3287.74,-883.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3289.85,-886.34 3295.72,-877.52 3285.63,-880.76 3289.85,-886.34\"/>\n</g>\n<!-- 183 -->\n<g id=\"node184\" class=\"node\">\n<title>183</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3235,-773.5C3235,-773.5 3154,-773.5 3154,-773.5 3148,-773.5 3142,-767.5 3142,-761.5 3142,-761.5 3142,-732.5 3142,-732.5 3142,-726.5 3148,-720.5 3154,-720.5 3154,-720.5 3235,-720.5 3235,-720.5 3241,-720.5 3247,-726.5 3247,-732.5 3247,-732.5 3247,-761.5 3247,-761.5 3247,-767.5 3241,-773.5 3235,-773.5\"/>\n<text text-anchor=\"start\" x=\"3165.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3151\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 21</text>\n<text text-anchor=\"start\" x=\"3150\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [21, 0]</text>\n</g>\n<!-- 182&#45;&gt;183 -->\n<g id=\"edge183\" class=\"edge\">\n<title>182&#45;&gt;183</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3194.5,-816.88C3194.5,-806.33 3194.5,-794.6 3194.5,-783.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3198,-783.52 3194.5,-773.52 3191,-783.52 3198,-783.52\"/>\n</g>\n<!-- 184 -->\n<g id=\"node185\" class=\"node\">\n<title>184</title>\n<path fill=\"#e99355\" stroke=\"black\" d=\"M3350,-781C3350,-781 3277,-781 3277,-781 3271,-781 3265,-775 3265,-769 3265,-769 3265,-725 3265,-725 3265,-719 3271,-713 3277,-713 3277,-713 3350,-713 3350,-713 3356,-713 3362,-719 3362,-725 3362,-725 3362,-769 3362,-769 3362,-775 3356,-781 3350,-781\"/>\n<text text-anchor=\"start\" x=\"3274.5\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.88</text>\n<text text-anchor=\"start\" x=\"3276\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.219</text>\n<text text-anchor=\"start\" x=\"3274\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"3273\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [7, 1]</text>\n</g>\n<!-- 182&#45;&gt;184 -->\n<g id=\"edge184\" class=\"edge\">\n<title>182&#45;&gt;184</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3233.14,-816.88C3243.94,-807.62 3255.8,-797.45 3267.01,-787.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3269.34,-790.46 3274.65,-781.3 3264.78,-785.15 3269.34,-790.46\"/>\n</g>\n<!-- 185 -->\n<g id=\"node186\" class=\"node\">\n<title>185</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3344,-669.5C3344,-669.5 3271,-669.5 3271,-669.5 3265,-669.5 3259,-663.5 3259,-657.5 3259,-657.5 3259,-628.5 3259,-628.5 3259,-622.5 3265,-616.5 3271,-616.5 3271,-616.5 3344,-616.5 3344,-616.5 3350,-616.5 3356,-622.5 3356,-628.5 3356,-628.5 3356,-657.5 3356,-657.5 3356,-663.5 3350,-669.5 3344,-669.5\"/>\n<text text-anchor=\"start\" x=\"3278.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3268\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"3267\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 184&#45;&gt;185 -->\n<g id=\"edge185\" class=\"edge\">\n<title>184&#45;&gt;185</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3311.55,-712.88C3310.92,-702.22 3310.23,-690.35 3309.59,-679.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3313.08,-679.3 3309,-669.52 3306.09,-679.71 3313.08,-679.3\"/>\n</g>\n<!-- 186 -->\n<g id=\"node187\" class=\"node\">\n<title>186</title>\n<path fill=\"#eca06a\" stroke=\"black\" d=\"M3459,-669.5C3459,-669.5 3386,-669.5 3386,-669.5 3380,-669.5 3374,-663.5 3374,-657.5 3374,-657.5 3374,-628.5 3374,-628.5 3374,-622.5 3380,-616.5 3386,-616.5 3386,-616.5 3459,-616.5 3459,-616.5 3465,-616.5 3471,-622.5 3471,-628.5 3471,-628.5 3471,-657.5 3471,-657.5 3471,-663.5 3465,-669.5 3459,-669.5\"/>\n<text text-anchor=\"start\" x=\"3389\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.32</text>\n<text text-anchor=\"start\" x=\"3383\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"3382\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 1]</text>\n</g>\n<!-- 184&#45;&gt;186 -->\n<g id=\"edge186\" class=\"edge\">\n<title>184&#45;&gt;186</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3348.89,-712.88C3361.35,-701.23 3375.33,-688.14 3387.74,-676.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3390.32,-678.91 3395.23,-669.52 3385.54,-673.8 3390.32,-678.91\"/>\n</g>\n<!-- 191 -->\n<g id=\"node192\" class=\"node\">\n<title>191</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M3577,-1093C3577,-1093 3504,-1093 3504,-1093 3498,-1093 3492,-1087 3492,-1081 3492,-1081 3492,-1037 3492,-1037 3492,-1031 3498,-1025 3504,-1025 3504,-1025 3577,-1025 3577,-1025 3583,-1025 3589,-1031 3589,-1037 3589,-1037 3589,-1081 3589,-1081 3589,-1087 3583,-1093 3577,-1093\"/>\n<text text-anchor=\"start\" x=\"3503\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp ≤ 1.0</text>\n<text text-anchor=\"start\" x=\"3503\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"3501\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"3500\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 190&#45;&gt;191 -->\n<g id=\"edge191\" class=\"edge\">\n<title>190&#45;&gt;191</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3540.5,-1128.88C3540.5,-1120.78 3540.5,-1111.98 3540.5,-1103.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3544,-1103.3 3540.5,-1093.3 3537,-1103.3 3544,-1103.3\"/>\n</g>\n<!-- 194 -->\n<g id=\"node195\" class=\"node\">\n<title>194</title>\n<path fill=\"#e78b49\" stroke=\"black\" d=\"M3711,-1093C3711,-1093 3630,-1093 3630,-1093 3624,-1093 3618,-1087 3618,-1081 3618,-1081 3618,-1037 3618,-1037 3618,-1031 3624,-1025 3630,-1025 3630,-1025 3711,-1025 3711,-1025 3717,-1025 3723,-1031 3723,-1037 3723,-1037 3723,-1081 3723,-1081 3723,-1087 3717,-1093 3711,-1093\"/>\n<text text-anchor=\"start\" x=\"3627.5\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.261</text>\n<text text-anchor=\"start\" x=\"3637\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.14</text>\n<text text-anchor=\"start\" x=\"3627\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 66</text>\n<text text-anchor=\"start\" x=\"3626\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [61, 5]</text>\n</g>\n<!-- 190&#45;&gt;194 -->\n<g id=\"edge194\" class=\"edge\">\n<title>190&#45;&gt;194</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3582.71,-1128.88C3594.63,-1119.53 3607.72,-1109.26 3620.07,-1099.57\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3622.35,-1102.23 3628.06,-1093.3 3618.03,-1096.72 3622.35,-1102.23\"/>\n</g>\n<!-- 192 -->\n<g id=\"node193\" class=\"node\">\n<title>192</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3473,-981.5C3473,-981.5 3400,-981.5 3400,-981.5 3394,-981.5 3388,-975.5 3388,-969.5 3388,-969.5 3388,-940.5 3388,-940.5 3388,-934.5 3394,-928.5 3400,-928.5 3400,-928.5 3473,-928.5 3473,-928.5 3479,-928.5 3485,-934.5 3485,-940.5 3485,-940.5 3485,-969.5 3485,-969.5 3485,-975.5 3479,-981.5 3473,-981.5\"/>\n<text text-anchor=\"start\" x=\"3407.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3397\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"3396\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 191&#45;&gt;192 -->\n<g id=\"edge192\" class=\"edge\">\n<title>191&#45;&gt;192</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3506.73,-1024.88C3494.85,-1013.23 3481.51,-1000.14 3469.67,-988.53\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3472.11,-986.02 3462.52,-981.52 3467.21,-991.02 3472.11,-986.02\"/>\n</g>\n<!-- 193 -->\n<g id=\"node194\" class=\"node\">\n<title>193</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3588,-981.5C3588,-981.5 3515,-981.5 3515,-981.5 3509,-981.5 3503,-975.5 3503,-969.5 3503,-969.5 3503,-940.5 3503,-940.5 3503,-934.5 3509,-928.5 3515,-928.5 3515,-928.5 3588,-928.5 3588,-928.5 3594,-928.5 3600,-934.5 3600,-940.5 3600,-940.5 3600,-969.5 3600,-969.5 3600,-975.5 3594,-981.5 3588,-981.5\"/>\n<text text-anchor=\"start\" x=\"3522.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3512\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3511\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 191&#45;&gt;193 -->\n<g id=\"edge193\" class=\"edge\">\n<title>191&#45;&gt;193</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3544.07,-1024.88C3545.22,-1014.22 3546.5,-1002.35 3547.67,-991.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3551.16,-991.84 3548.75,-981.52 3544.2,-991.09 3551.16,-991.84\"/>\n</g>\n<!-- 195 -->\n<g id=\"node196\" class=\"node\">\n<title>195</title>\n<path fill=\"#e99559\" stroke=\"black\" d=\"M3711,-989C3711,-989 3630,-989 3630,-989 3624,-989 3618,-983 3618,-977 3618,-977 3618,-933 3618,-933 3618,-927 3624,-921 3630,-921 3630,-921 3711,-921 3711,-921 3717,-921 3723,-927 3723,-933 3723,-933 3723,-977 3723,-977 3723,-983 3717,-989 3711,-989\"/>\n<text text-anchor=\"start\" x=\"3635.5\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.3</text>\n<text text-anchor=\"start\" x=\"3633\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.239</text>\n<text text-anchor=\"start\" x=\"3627\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 36</text>\n<text text-anchor=\"start\" x=\"3626\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 5]</text>\n</g>\n<!-- 194&#45;&gt;195 -->\n<g id=\"edge195\" class=\"edge\">\n<title>194&#45;&gt;195</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3670.5,-1024.88C3670.5,-1016.78 3670.5,-1007.98 3670.5,-999.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3674,-999.3 3670.5,-989.3 3667,-999.3 3674,-999.3\"/>\n</g>\n<!-- 214 -->\n<g id=\"node215\" class=\"node\">\n<title>214</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3834,-981.5C3834,-981.5 3753,-981.5 3753,-981.5 3747,-981.5 3741,-975.5 3741,-969.5 3741,-969.5 3741,-940.5 3741,-940.5 3741,-934.5 3747,-928.5 3753,-928.5 3753,-928.5 3834,-928.5 3834,-928.5 3840,-928.5 3846,-934.5 3846,-940.5 3846,-940.5 3846,-969.5 3846,-969.5 3846,-975.5 3840,-981.5 3834,-981.5\"/>\n<text text-anchor=\"start\" x=\"3764.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3750\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30</text>\n<text text-anchor=\"start\" x=\"3749\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [30, 0]</text>\n</g>\n<!-- 194&#45;&gt;214 -->\n<g id=\"edge214\" class=\"edge\">\n<title>194&#45;&gt;214</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3710.43,-1024.88C3724.63,-1013.12 3740.57,-999.89 3754.67,-988.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3757.26,-990.6 3762.73,-981.52 3752.79,-985.21 3757.26,-990.6\"/>\n</g>\n<!-- 196 -->\n<g id=\"node197\" class=\"node\">\n<title>196</title>\n<path fill=\"#e89153\" stroke=\"black\" d=\"M3708,-885C3708,-885 3627,-885 3627,-885 3621,-885 3615,-879 3615,-873 3615,-873 3615,-829 3615,-829 3615,-823 3621,-817 3627,-817 3627,-817 3708,-817 3708,-817 3714,-817 3720,-823 3720,-829 3720,-829 3720,-873 3720,-873 3720,-879 3714,-885 3708,-885\"/>\n<text text-anchor=\"start\" x=\"3624.5\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.358</text>\n<text text-anchor=\"start\" x=\"3630\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.202</text>\n<text text-anchor=\"start\" x=\"3624\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 35</text>\n<text text-anchor=\"start\" x=\"3623\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 4]</text>\n</g>\n<!-- 195&#45;&gt;196 -->\n<g id=\"edge196\" class=\"edge\">\n<title>195&#45;&gt;196</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3669.53,-920.88C3669.29,-912.78 3669.03,-903.98 3668.78,-895.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3672.27,-895.19 3668.48,-885.3 3665.27,-895.4 3672.27,-895.19\"/>\n</g>\n<!-- 213 -->\n<g id=\"node214\" class=\"node\">\n<title>213</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3823,-877.5C3823,-877.5 3750,-877.5 3750,-877.5 3744,-877.5 3738,-871.5 3738,-865.5 3738,-865.5 3738,-836.5 3738,-836.5 3738,-830.5 3744,-824.5 3750,-824.5 3750,-824.5 3823,-824.5 3823,-824.5 3829,-824.5 3835,-830.5 3835,-836.5 3835,-836.5 3835,-865.5 3835,-865.5 3835,-871.5 3829,-877.5 3823,-877.5\"/>\n<text text-anchor=\"start\" x=\"3757.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3747\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3746\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 195&#45;&gt;213 -->\n<g id=\"edge213\" class=\"edge\">\n<title>195&#45;&gt;213</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3708.16,-920.88C3721.54,-909.12 3736.58,-895.89 3749.88,-884.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3752.28,-886.75 3757.48,-877.52 3747.66,-881.49 3752.28,-886.75\"/>\n</g>\n<!-- 197 -->\n<g id=\"node198\" class=\"node\">\n<title>197</title>\n<path fill=\"#e78b49\" stroke=\"black\" d=\"M3705,-781C3705,-781 3624,-781 3624,-781 3618,-781 3612,-775 3612,-769 3612,-769 3612,-725 3612,-725 3612,-719 3618,-713 3624,-713 3624,-713 3705,-713 3705,-713 3711,-713 3717,-719 3717,-725 3717,-725 3717,-769 3717,-769 3717,-775 3711,-781 3705,-781\"/>\n<text text-anchor=\"start\" x=\"3621.5\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.745</text>\n<text text-anchor=\"start\" x=\"3627\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.137</text>\n<text text-anchor=\"start\" x=\"3621\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 27</text>\n<text text-anchor=\"start\" x=\"3620\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [25, 2]</text>\n</g>\n<!-- 196&#45;&gt;197 -->\n<g id=\"edge197\" class=\"edge\">\n<title>196&#45;&gt;197</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3666.53,-816.88C3666.29,-808.78 3666.03,-799.98 3665.78,-791.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3669.27,-791.19 3665.48,-781.3 3662.27,-791.4 3669.27,-791.19\"/>\n</g>\n<!-- 206 -->\n<g id=\"node207\" class=\"node\">\n<title>206</title>\n<path fill=\"#eeab7b\" stroke=\"black\" d=\"M3820,-781C3820,-781 3747,-781 3747,-781 3741,-781 3735,-775 3735,-769 3735,-769 3735,-725 3735,-725 3735,-719 3741,-713 3747,-713 3747,-713 3820,-713 3820,-713 3826,-713 3832,-719 3832,-725 3832,-725 3832,-769 3832,-769 3832,-775 3826,-781 3820,-781\"/>\n<text text-anchor=\"start\" x=\"3744\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.263</text>\n<text text-anchor=\"start\" x=\"3746\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"3744\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"3743\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 2]</text>\n</g>\n<!-- 196&#45;&gt;206 -->\n<g id=\"edge206\" class=\"edge\">\n<title>196&#45;&gt;206</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3705.16,-816.88C3715.6,-807.71 3727.04,-797.65 3737.87,-788.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3740.43,-790.53 3745.63,-781.3 3735.81,-785.27 3740.43,-790.53\"/>\n</g>\n<!-- 198 -->\n<g id=\"node199\" class=\"node\">\n<title>198</title>\n<path fill=\"#e99355\" stroke=\"black\" d=\"M3582,-677C3582,-677 3501,-677 3501,-677 3495,-677 3489,-671 3489,-665 3489,-665 3489,-621 3489,-621 3489,-615 3495,-609 3501,-609 3501,-609 3582,-609 3582,-609 3588,-609 3594,-615 3594,-621 3594,-621 3594,-665 3594,-665 3594,-671 3588,-677 3582,-677\"/>\n<text text-anchor=\"start\" x=\"3498.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ &#45;0.778</text>\n<text text-anchor=\"start\" x=\"3504\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.219</text>\n<text text-anchor=\"start\" x=\"3498\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"start\" x=\"3497\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [14, 2]</text>\n</g>\n<!-- 197&#45;&gt;198 -->\n<g id=\"edge198\" class=\"edge\">\n<title>197&#45;&gt;198</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3624.57,-712.88C3613.39,-703.62 3601.14,-693.45 3589.55,-683.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3591.59,-680.99 3581.66,-677.3 3587.12,-686.38 3591.59,-680.99\"/>\n</g>\n<!-- 205 -->\n<g id=\"node206\" class=\"node\">\n<title>205</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3705,-669.5C3705,-669.5 3624,-669.5 3624,-669.5 3618,-669.5 3612,-663.5 3612,-657.5 3612,-657.5 3612,-628.5 3612,-628.5 3612,-622.5 3618,-616.5 3624,-616.5 3624,-616.5 3705,-616.5 3705,-616.5 3711,-616.5 3717,-622.5 3717,-628.5 3717,-628.5 3717,-657.5 3717,-657.5 3717,-663.5 3711,-669.5 3705,-669.5\"/>\n<text text-anchor=\"start\" x=\"3635.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3621\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"start\" x=\"3620\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 0]</text>\n</g>\n<!-- 197&#45;&gt;205 -->\n<g id=\"edge205\" class=\"edge\">\n<title>197&#45;&gt;205</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3664.5,-712.88C3664.5,-702.33 3664.5,-690.6 3664.5,-679.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3668,-679.52 3664.5,-669.52 3661,-679.52 3668,-679.52\"/>\n</g>\n<!-- 199 -->\n<g id=\"node200\" class=\"node\">\n<title>199</title>\n<path fill=\"#e78a47\" stroke=\"black\" d=\"M3522,-573C3522,-573 3441,-573 3441,-573 3435,-573 3429,-567 3429,-561 3429,-561 3429,-517 3429,-517 3429,-511 3435,-505 3441,-505 3441,-505 3522,-505 3522,-505 3528,-505 3534,-511 3534,-517 3534,-517 3534,-561 3534,-561 3534,-567 3528,-573 3522,-573\"/>\n<text text-anchor=\"start\" x=\"3442\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 1.117</text>\n<text text-anchor=\"start\" x=\"3444\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.124</text>\n<text text-anchor=\"start\" x=\"3438\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 15</text>\n<text text-anchor=\"start\" x=\"3437\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [14, 1]</text>\n</g>\n<!-- 198&#45;&gt;199 -->\n<g id=\"edge199\" class=\"edge\">\n<title>198&#45;&gt;199</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3522.02,-608.88C3516.99,-600.33 3511.51,-591.01 3506.25,-582.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3509.17,-580.14 3501.09,-573.3 3503.14,-583.69 3509.17,-580.14\"/>\n</g>\n<!-- 204 -->\n<g id=\"node205\" class=\"node\">\n<title>204</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3637,-565.5C3637,-565.5 3564,-565.5 3564,-565.5 3558,-565.5 3552,-559.5 3552,-553.5 3552,-553.5 3552,-524.5 3552,-524.5 3552,-518.5 3558,-512.5 3564,-512.5 3564,-512.5 3637,-512.5 3637,-512.5 3643,-512.5 3649,-518.5 3649,-524.5 3649,-524.5 3649,-553.5 3649,-553.5 3649,-559.5 3643,-565.5 3637,-565.5\"/>\n<text text-anchor=\"start\" x=\"3571.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3561\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3560\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 198&#45;&gt;204 -->\n<g id=\"edge204\" class=\"edge\">\n<title>198&#45;&gt;204</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3560.66,-608.88C3567.08,-597.78 3574.26,-585.37 3580.73,-574.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3583.76,-575.93 3585.74,-565.52 3577.7,-572.42 3583.76,-575.93\"/>\n</g>\n<!-- 200 -->\n<g id=\"node201\" class=\"node\">\n<title>200</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3462,-461.5C3462,-461.5 3381,-461.5 3381,-461.5 3375,-461.5 3369,-455.5 3369,-449.5 3369,-449.5 3369,-420.5 3369,-420.5 3369,-414.5 3375,-408.5 3381,-408.5 3381,-408.5 3462,-408.5 3462,-408.5 3468,-408.5 3474,-414.5 3474,-420.5 3474,-420.5 3474,-449.5 3474,-449.5 3474,-455.5 3468,-461.5 3462,-461.5\"/>\n<text text-anchor=\"start\" x=\"3392.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3378\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\n<text text-anchor=\"start\" x=\"3377\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [12, 0]</text>\n</g>\n<!-- 199&#45;&gt;200 -->\n<g id=\"edge200\" class=\"edge\">\n<title>199&#45;&gt;200</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3462.02,-504.88C3455.49,-493.78 3448.19,-481.37 3441.61,-470.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3444.6,-468.36 3436.51,-461.52 3438.57,-471.91 3444.6,-468.36\"/>\n</g>\n<!-- 201 -->\n<g id=\"node202\" class=\"node\">\n<title>201</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M3577,-469C3577,-469 3504,-469 3504,-469 3498,-469 3492,-463 3492,-457 3492,-457 3492,-413 3492,-413 3492,-407 3498,-401 3504,-401 3504,-401 3577,-401 3577,-401 3583,-401 3589,-407 3589,-413 3589,-413 3589,-457 3589,-457 3589,-463 3583,-469 3577,-469\"/>\n<text text-anchor=\"start\" x=\"3501\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 1.382</text>\n<text text-anchor=\"start\" x=\"3503\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"3501\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"3500\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 1]</text>\n</g>\n<!-- 199&#45;&gt;201 -->\n<g id=\"edge201\" class=\"edge\">\n<title>199&#45;&gt;201</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3500.66,-504.88C3505.6,-496.33 3510.99,-487.01 3516.16,-478.07\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3519.26,-479.71 3521.24,-469.3 3513.2,-476.2 3519.26,-479.71\"/>\n</g>\n<!-- 202 -->\n<g id=\"node203\" class=\"node\">\n<title>202</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3519,-357.5C3519,-357.5 3446,-357.5 3446,-357.5 3440,-357.5 3434,-351.5 3434,-345.5 3434,-345.5 3434,-316.5 3434,-316.5 3434,-310.5 3440,-304.5 3446,-304.5 3446,-304.5 3519,-304.5 3519,-304.5 3525,-304.5 3531,-310.5 3531,-316.5 3531,-316.5 3531,-345.5 3531,-345.5 3531,-351.5 3525,-357.5 3519,-357.5\"/>\n<text text-anchor=\"start\" x=\"3453.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3443\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3442\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 201&#45;&gt;202 -->\n<g id=\"edge202\" class=\"edge\">\n<title>201&#45;&gt;202</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3521.67,-400.88C3515.42,-389.89 3508.44,-377.62 3502.13,-366.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3505,-364.48 3497.01,-357.52 3498.91,-367.94 3505,-364.48\"/>\n</g>\n<!-- 203 -->\n<g id=\"node204\" class=\"node\">\n<title>203</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3634,-357.5C3634,-357.5 3561,-357.5 3561,-357.5 3555,-357.5 3549,-351.5 3549,-345.5 3549,-345.5 3549,-316.5 3549,-316.5 3549,-310.5 3555,-304.5 3561,-304.5 3561,-304.5 3634,-304.5 3634,-304.5 3640,-304.5 3646,-310.5 3646,-316.5 3646,-316.5 3646,-345.5 3646,-345.5 3646,-351.5 3640,-357.5 3634,-357.5\"/>\n<text text-anchor=\"start\" x=\"3568.5\" y=\"-342.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3558\" y=\"-327.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"3557\" y=\"-312.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 201&#45;&gt;203 -->\n<g id=\"edge203\" class=\"edge\">\n<title>201&#45;&gt;203</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3559.01,-400.88C3565.15,-389.89 3572.01,-377.62 3578.21,-366.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3581.42,-367.96 3583.24,-357.52 3575.31,-364.54 3581.42,-367.96\"/>\n</g>\n<!-- 207 -->\n<g id=\"node208\" class=\"node\">\n<title>207</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3820,-669.5C3820,-669.5 3747,-669.5 3747,-669.5 3741,-669.5 3735,-663.5 3735,-657.5 3735,-657.5 3735,-628.5 3735,-628.5 3735,-622.5 3741,-616.5 3747,-616.5 3747,-616.5 3820,-616.5 3820,-616.5 3826,-616.5 3832,-622.5 3832,-628.5 3832,-628.5 3832,-657.5 3832,-657.5 3832,-663.5 3826,-669.5 3820,-669.5\"/>\n<text text-anchor=\"start\" x=\"3754.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3744\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3743\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 206&#45;&gt;207 -->\n<g id=\"edge207\" class=\"edge\">\n<title>206&#45;&gt;207</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3783.5,-712.88C3783.5,-702.33 3783.5,-690.6 3783.5,-679.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3787,-679.52 3783.5,-669.52 3780,-679.52 3787,-679.52\"/>\n</g>\n<!-- 208 -->\n<g id=\"node209\" class=\"node\">\n<title>208</title>\n<path fill=\"#e9965a\" stroke=\"black\" d=\"M3935,-677C3935,-677 3862,-677 3862,-677 3856,-677 3850,-671 3850,-665 3850,-665 3850,-621 3850,-621 3850,-615 3856,-609 3862,-609 3862,-609 3935,-609 3935,-609 3941,-609 3947,-615 3947,-621 3947,-621 3947,-665 3947,-665 3947,-671 3941,-677 3935,-677\"/>\n<text text-anchor=\"start\" x=\"3859\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 0.815</text>\n<text text-anchor=\"start\" x=\"3861\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.245</text>\n<text text-anchor=\"start\" x=\"3859\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"3858\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 1]</text>\n</g>\n<!-- 206&#45;&gt;208 -->\n<g id=\"edge208\" class=\"edge\">\n<title>206&#45;&gt;208</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3820.84,-712.88C3831.18,-703.71 3842.52,-693.65 3853.26,-684.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3855.8,-686.55 3860.96,-677.3 3851.15,-681.32 3855.8,-686.55\"/>\n</g>\n<!-- 209 -->\n<g id=\"node210\" class=\"node\">\n<title>209</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3850,-565.5C3850,-565.5 3777,-565.5 3777,-565.5 3771,-565.5 3765,-559.5 3765,-553.5 3765,-553.5 3765,-524.5 3765,-524.5 3765,-518.5 3771,-512.5 3777,-512.5 3777,-512.5 3850,-512.5 3850,-512.5 3856,-512.5 3862,-518.5 3862,-524.5 3862,-524.5 3862,-553.5 3862,-553.5 3862,-559.5 3856,-565.5 3850,-565.5\"/>\n<text text-anchor=\"start\" x=\"3784.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3774\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"3773\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 0]</text>\n</g>\n<!-- 208&#45;&gt;209 -->\n<g id=\"edge209\" class=\"edge\">\n<title>208&#45;&gt;209</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3870.9,-608.88C3861.46,-597.56 3850.9,-584.88 3841.43,-573.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3843.86,-570.96 3834.77,-565.52 3838.48,-575.44 3843.86,-570.96\"/>\n</g>\n<!-- 210 -->\n<g id=\"node211\" class=\"node\">\n<title>210</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M3965,-573C3965,-573 3892,-573 3892,-573 3886,-573 3880,-567 3880,-561 3880,-561 3880,-517 3880,-517 3880,-511 3886,-505 3892,-505 3892,-505 3965,-505 3965,-505 3971,-505 3977,-511 3977,-517 3977,-517 3977,-561 3977,-561 3977,-567 3971,-573 3965,-573\"/>\n<text text-anchor=\"start\" x=\"3889\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 1.231</text>\n<text text-anchor=\"start\" x=\"3891\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"3889\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"3888\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 1]</text>\n</g>\n<!-- 208&#45;&gt;210 -->\n<g id=\"edge210\" class=\"edge\">\n<title>208&#45;&gt;210</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3908.24,-608.88C3910.68,-600.6 3913.32,-591.6 3915.88,-582.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3919.24,-583.88 3918.71,-573.3 3912.53,-581.91 3919.24,-583.88\"/>\n</g>\n<!-- 211 -->\n<g id=\"node212\" class=\"node\">\n<title>211</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3907,-461.5C3907,-461.5 3834,-461.5 3834,-461.5 3828,-461.5 3822,-455.5 3822,-449.5 3822,-449.5 3822,-420.5 3822,-420.5 3822,-414.5 3828,-408.5 3834,-408.5 3834,-408.5 3907,-408.5 3907,-408.5 3913,-408.5 3919,-414.5 3919,-420.5 3919,-420.5 3919,-449.5 3919,-449.5 3919,-455.5 3913,-461.5 3907,-461.5\"/>\n<text text-anchor=\"start\" x=\"3841.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3831\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3830\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 210&#45;&gt;211 -->\n<g id=\"edge211\" class=\"edge\">\n<title>210&#45;&gt;211</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3909.67,-504.88C3903.42,-493.89 3896.44,-481.62 3890.13,-470.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3893,-468.48 3885.01,-461.52 3886.91,-471.94 3893,-468.48\"/>\n</g>\n<!-- 212 -->\n<g id=\"node213\" class=\"node\">\n<title>212</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4022,-461.5C4022,-461.5 3949,-461.5 3949,-461.5 3943,-461.5 3937,-455.5 3937,-449.5 3937,-449.5 3937,-420.5 3937,-420.5 3937,-414.5 3943,-408.5 3949,-408.5 3949,-408.5 4022,-408.5 4022,-408.5 4028,-408.5 4034,-414.5 4034,-420.5 4034,-420.5 4034,-449.5 4034,-449.5 4034,-455.5 4028,-461.5 4022,-461.5\"/>\n<text text-anchor=\"start\" x=\"3956.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3946\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"3945\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 210&#45;&gt;212 -->\n<g id=\"edge212\" class=\"edge\">\n<title>210&#45;&gt;212</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3947.01,-504.88C3953.15,-493.89 3960.01,-481.62 3966.21,-470.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3969.42,-471.96 3971.24,-461.52 3963.31,-468.54 3969.42,-471.96\"/>\n</g>\n<!-- 217 -->\n<g id=\"node218\" class=\"node\">\n<title>217</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3638,-1397.5C3638,-1397.5 3565,-1397.5 3565,-1397.5 3559,-1397.5 3553,-1391.5 3553,-1385.5 3553,-1385.5 3553,-1356.5 3553,-1356.5 3553,-1350.5 3559,-1344.5 3565,-1344.5 3565,-1344.5 3638,-1344.5 3638,-1344.5 3644,-1344.5 3650,-1350.5 3650,-1356.5 3650,-1356.5 3650,-1385.5 3650,-1385.5 3650,-1391.5 3644,-1397.5 3638,-1397.5\"/>\n<text text-anchor=\"start\" x=\"3572.5\" y=\"-1382.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3562\" y=\"-1367.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"3561\" y=\"-1352.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4]</text>\n</g>\n<!-- 216&#45;&gt;217 -->\n<g id=\"edge217\" class=\"edge\">\n<title>216&#45;&gt;217</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3601.5,-1440.88C3601.5,-1430.33 3601.5,-1418.6 3601.5,-1407.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3605,-1407.52 3601.5,-1397.52 3598,-1407.52 3605,-1407.52\"/>\n</g>\n<!-- 218 -->\n<g id=\"node219\" class=\"node\">\n<title>218</title>\n<path fill=\"#f0b68c\" stroke=\"black\" d=\"M3967,-1405C3967,-1405 3878,-1405 3878,-1405 3872,-1405 3866,-1399 3866,-1393 3866,-1393 3866,-1349 3866,-1349 3866,-1343 3872,-1337 3878,-1337 3878,-1337 3967,-1337 3967,-1337 3973,-1337 3979,-1343 3979,-1349 3979,-1349 3979,-1393 3979,-1393 3979,-1399 3973,-1405 3967,-1405\"/>\n<text text-anchor=\"start\" x=\"3881\" y=\"-1389.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.394</text>\n<text text-anchor=\"start\" x=\"3885\" y=\"-1374.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.416</text>\n<text text-anchor=\"start\" x=\"3879\" y=\"-1359.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 88</text>\n<text text-anchor=\"start\" x=\"3874\" y=\"-1344.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [62, 26]</text>\n</g>\n<!-- 216&#45;&gt;218 -->\n<g id=\"edge218\" class=\"edge\">\n<title>216&#45;&gt;218</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3658.15,-1456C3713.45,-1438.43 3797.56,-1411.7 3856,-1393.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3857.41,-1396.36 3865.88,-1389.99 3855.29,-1389.68 3857.41,-1396.36\"/>\n</g>\n<!-- 219 -->\n<g id=\"node220\" class=\"node\">\n<title>219</title>\n<path fill=\"#e78c49\" stroke=\"black\" d=\"M3963,-1301C3963,-1301 3882,-1301 3882,-1301 3876,-1301 3870,-1295 3870,-1289 3870,-1289 3870,-1245 3870,-1245 3870,-1239 3876,-1233 3882,-1233 3882,-1233 3963,-1233 3963,-1233 3969,-1233 3975,-1239 3975,-1245 3975,-1245 3975,-1289 3975,-1289 3975,-1295 3969,-1301 3963,-1301\"/>\n<text text-anchor=\"start\" x=\"3881\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.922</text>\n<text text-anchor=\"start\" x=\"3885\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.142</text>\n<text text-anchor=\"start\" x=\"3879\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13</text>\n<text text-anchor=\"start\" x=\"3878\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [12, 1]</text>\n</g>\n<!-- 218&#45;&gt;219 -->\n<g id=\"edge219\" class=\"edge\">\n<title>218&#45;&gt;219</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3922.5,-1336.88C3922.5,-1328.78 3922.5,-1319.98 3922.5,-1311.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3926,-1311.3 3922.5,-1301.3 3919,-1311.3 3926,-1311.3\"/>\n</g>\n<!-- 224 -->\n<g id=\"node225\" class=\"node\">\n<title>224</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M4150,-1301C4150,-1301 4061,-1301 4061,-1301 4055,-1301 4049,-1295 4049,-1289 4049,-1289 4049,-1245 4049,-1245 4049,-1239 4055,-1233 4061,-1233 4061,-1233 4150,-1233 4150,-1233 4156,-1233 4162,-1239 4162,-1245 4162,-1245 4162,-1289 4162,-1289 4162,-1295 4156,-1301 4150,-1301\"/>\n<text text-anchor=\"start\" x=\"4064\" y=\"-1285.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.167</text>\n<text text-anchor=\"start\" x=\"4068\" y=\"-1270.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"4062\" y=\"-1255.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 75</text>\n<text text-anchor=\"start\" x=\"4057\" y=\"-1240.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [50, 25]</text>\n</g>\n<!-- 218&#45;&gt;224 -->\n<g id=\"edge224\" class=\"edge\">\n<title>218&#45;&gt;224</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3979.4,-1338.29C3998.6,-1327.59 4020.18,-1315.56 4039.99,-1304.51\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4041.92,-1307.45 4048.95,-1299.52 4038.51,-1301.33 4041.92,-1307.45\"/>\n</g>\n<!-- 220 -->\n<g id=\"node221\" class=\"node\">\n<title>220</title>\n<path fill=\"#ffffff\" stroke=\"black\" d=\"M3872,-1197C3872,-1197 3797,-1197 3797,-1197 3791,-1197 3785,-1191 3785,-1185 3785,-1185 3785,-1141 3785,-1141 3785,-1135 3791,-1129 3797,-1129 3797,-1129 3872,-1129 3872,-1129 3878,-1129 3884,-1135 3884,-1141 3884,-1141 3884,-1185 3884,-1185 3884,-1191 3878,-1197 3872,-1197\"/>\n<text text-anchor=\"start\" x=\"3793\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ &#45;0.998</text>\n<text text-anchor=\"start\" x=\"3805.5\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n<text text-anchor=\"start\" x=\"3795\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"3794\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 1]</text>\n</g>\n<!-- 219&#45;&gt;220 -->\n<g id=\"edge220\" class=\"edge\">\n<title>219&#45;&gt;220</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3893.93,-1232.88C3886.24,-1223.98 3877.84,-1214.24 3869.84,-1204.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3872.41,-1202.58 3863.23,-1197.3 3867.11,-1207.16 3872.41,-1202.58\"/>\n</g>\n<!-- 223 -->\n<g id=\"node224\" class=\"node\">\n<title>223</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3995,-1189.5C3995,-1189.5 3914,-1189.5 3914,-1189.5 3908,-1189.5 3902,-1183.5 3902,-1177.5 3902,-1177.5 3902,-1148.5 3902,-1148.5 3902,-1142.5 3908,-1136.5 3914,-1136.5 3914,-1136.5 3995,-1136.5 3995,-1136.5 4001,-1136.5 4007,-1142.5 4007,-1148.5 4007,-1148.5 4007,-1177.5 4007,-1177.5 4007,-1183.5 4001,-1189.5 3995,-1189.5\"/>\n<text text-anchor=\"start\" x=\"3925.5\" y=\"-1174.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3911\" y=\"-1159.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\n<text text-anchor=\"start\" x=\"3910\" y=\"-1144.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [11, 0]</text>\n</g>\n<!-- 219&#45;&gt;223 -->\n<g id=\"edge223\" class=\"edge\">\n<title>219&#45;&gt;223</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3932.89,-1232.88C3936.27,-1222.11 3940.03,-1210.11 3943.46,-1199.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3946.84,-1200.11 3946.49,-1189.52 3940.16,-1198.01 3946.84,-1200.11\"/>\n</g>\n<!-- 221 -->\n<g id=\"node222\" class=\"node\">\n<title>221</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M3833,-1085.5C3833,-1085.5 3760,-1085.5 3760,-1085.5 3754,-1085.5 3748,-1079.5 3748,-1073.5 3748,-1073.5 3748,-1044.5 3748,-1044.5 3748,-1038.5 3754,-1032.5 3760,-1032.5 3760,-1032.5 3833,-1032.5 3833,-1032.5 3839,-1032.5 3845,-1038.5 3845,-1044.5 3845,-1044.5 3845,-1073.5 3845,-1073.5 3845,-1079.5 3839,-1085.5 3833,-1085.5\"/>\n<text text-anchor=\"start\" x=\"3767.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3757\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3756\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 220&#45;&gt;221 -->\n<g id=\"edge221\" class=\"edge\">\n<title>220&#45;&gt;221</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3822.16,-1128.88C3818.15,-1118.11 3813.68,-1106.11 3809.61,-1095.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3812.78,-1093.67 3806.01,-1085.52 3806.22,-1096.11 3812.78,-1093.67\"/>\n</g>\n<!-- 222 -->\n<g id=\"node223\" class=\"node\">\n<title>222</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M3948,-1085.5C3948,-1085.5 3875,-1085.5 3875,-1085.5 3869,-1085.5 3863,-1079.5 3863,-1073.5 3863,-1073.5 3863,-1044.5 3863,-1044.5 3863,-1038.5 3869,-1032.5 3875,-1032.5 3875,-1032.5 3948,-1032.5 3948,-1032.5 3954,-1032.5 3960,-1038.5 3960,-1044.5 3960,-1044.5 3960,-1073.5 3960,-1073.5 3960,-1079.5 3954,-1085.5 3948,-1085.5\"/>\n<text text-anchor=\"start\" x=\"3882.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3872\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"3871\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 220&#45;&gt;222 -->\n<g id=\"edge222\" class=\"edge\">\n<title>220&#45;&gt;222</title>\n<path fill=\"none\" stroke=\"black\" d=\"M3859.5,-1128.88C3868.05,-1117.56 3877.62,-1104.88 3886.2,-1093.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"3889,-1095.61 3892.23,-1085.52 3883.42,-1091.39 3889,-1095.61\"/>\n</g>\n<!-- 225 -->\n<g id=\"node226\" class=\"node\">\n<title>225</title>\n<path fill=\"#7bbeee\" stroke=\"black\" d=\"M4142,-1197C4142,-1197 4069,-1197 4069,-1197 4063,-1197 4057,-1191 4057,-1185 4057,-1185 4057,-1141 4057,-1141 4057,-1135 4063,-1129 4069,-1129 4069,-1129 4142,-1129 4142,-1129 4148,-1129 4154,-1135 4154,-1141 4154,-1141 4154,-1185 4154,-1185 4154,-1191 4148,-1197 4142,-1197\"/>\n<text text-anchor=\"start\" x=\"4069\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 1.0</text>\n<text text-anchor=\"start\" x=\"4068\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"4066\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 8</text>\n<text text-anchor=\"start\" x=\"4065\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 6]</text>\n</g>\n<!-- 224&#45;&gt;225 -->\n<g id=\"edge225\" class=\"edge\">\n<title>224&#45;&gt;225</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4105.5,-1232.88C4105.5,-1224.78 4105.5,-1215.98 4105.5,-1207.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4109,-1207.3 4105.5,-1197.3 4102,-1207.3 4109,-1207.3\"/>\n</g>\n<!-- 228 -->\n<g id=\"node229\" class=\"node\">\n<title>228</title>\n<path fill=\"#efb387\" stroke=\"black\" d=\"M4311,-1197C4311,-1197 4222,-1197 4222,-1197 4216,-1197 4210,-1191 4210,-1185 4210,-1185 4210,-1141 4210,-1141 4210,-1135 4216,-1129 4222,-1129 4222,-1129 4311,-1129 4311,-1129 4317,-1129 4323,-1135 4323,-1141 4323,-1141 4323,-1185 4323,-1185 4323,-1191 4317,-1197 4311,-1197\"/>\n<text text-anchor=\"start\" x=\"4225.5\" y=\"-1181.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 1.051</text>\n<text text-anchor=\"start\" x=\"4229\" y=\"-1166.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.406</text>\n<text text-anchor=\"start\" x=\"4223\" y=\"-1151.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 67</text>\n<text text-anchor=\"start\" x=\"4218\" y=\"-1136.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [48, 19]</text>\n</g>\n<!-- 224&#45;&gt;228 -->\n<g id=\"edge228\" class=\"edge\">\n<title>224&#45;&gt;228</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4157.77,-1232.88C4173.03,-1223.21 4189.85,-1212.56 4205.59,-1202.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4207.64,-1205.43 4214.21,-1197.12 4203.89,-1199.52 4207.64,-1205.43\"/>\n</g>\n<!-- 226 -->\n<g id=\"node227\" class=\"node\">\n<title>226</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4067,-1085.5C4067,-1085.5 3994,-1085.5 3994,-1085.5 3988,-1085.5 3982,-1079.5 3982,-1073.5 3982,-1073.5 3982,-1044.5 3982,-1044.5 3982,-1038.5 3988,-1032.5 3994,-1032.5 3994,-1032.5 4067,-1032.5 4067,-1032.5 4073,-1032.5 4079,-1038.5 4079,-1044.5 4079,-1044.5 4079,-1073.5 4079,-1073.5 4079,-1079.5 4073,-1085.5 4067,-1085.5\"/>\n<text text-anchor=\"start\" x=\"4001.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3991\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"3990\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 6]</text>\n</g>\n<!-- 225&#45;&gt;226 -->\n<g id=\"edge226\" class=\"edge\">\n<title>225&#45;&gt;226</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4081.15,-1128.88C4072.9,-1117.67 4063.68,-1105.13 4055.39,-1093.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4058.01,-1091.5 4049.26,-1085.52 4052.37,-1095.65 4058.01,-1091.5\"/>\n</g>\n<!-- 227 -->\n<g id=\"node228\" class=\"node\">\n<title>227</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4182,-1085.5C4182,-1085.5 4109,-1085.5 4109,-1085.5 4103,-1085.5 4097,-1079.5 4097,-1073.5 4097,-1073.5 4097,-1044.5 4097,-1044.5 4097,-1038.5 4103,-1032.5 4109,-1032.5 4109,-1032.5 4182,-1032.5 4182,-1032.5 4188,-1032.5 4194,-1038.5 4194,-1044.5 4194,-1044.5 4194,-1073.5 4194,-1073.5 4194,-1079.5 4188,-1085.5 4182,-1085.5\"/>\n<text text-anchor=\"start\" x=\"4116.5\" y=\"-1070.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4106\" y=\"-1055.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"4105\" y=\"-1040.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 225&#45;&gt;227 -->\n<g id=\"edge227\" class=\"edge\">\n<title>225&#45;&gt;227</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4118.49,-1128.88C4122.76,-1118 4127.51,-1105.86 4131.83,-1094.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4135.1,-1096.11 4135.49,-1085.52 4128.58,-1093.55 4135.1,-1096.11\"/>\n</g>\n<!-- 229 -->\n<g id=\"node230\" class=\"node\">\n<title>229</title>\n<path fill=\"#eb9d66\" stroke=\"black\" d=\"M4307,-1093C4307,-1093 4226,-1093 4226,-1093 4220,-1093 4214,-1087 4214,-1081 4214,-1081 4214,-1037 4214,-1037 4214,-1031 4220,-1025 4226,-1025 4226,-1025 4307,-1025 4307,-1025 4313,-1025 4319,-1031 4319,-1037 4319,-1037 4319,-1081 4319,-1081 4319,-1087 4313,-1093 4307,-1093\"/>\n<text text-anchor=\"start\" x=\"4225.5\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.511</text>\n<text text-anchor=\"start\" x=\"4229\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.301</text>\n<text text-anchor=\"start\" x=\"4223\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 38</text>\n<text text-anchor=\"start\" x=\"4222\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [31, 7]</text>\n</g>\n<!-- 228&#45;&gt;229 -->\n<g id=\"edge229\" class=\"edge\">\n<title>228&#45;&gt;229</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4266.5,-1128.88C4266.5,-1120.78 4266.5,-1111.98 4266.5,-1103.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4270,-1103.3 4266.5,-1093.3 4263,-1103.3 4270,-1103.3\"/>\n</g>\n<!-- 244 -->\n<g id=\"node245\" class=\"node\">\n<title>244</title>\n<path fill=\"#f7dac5\" stroke=\"black\" d=\"M4467,-1093C4467,-1093 4378,-1093 4378,-1093 4372,-1093 4366,-1087 4366,-1081 4366,-1081 4366,-1037 4366,-1037 4366,-1031 4372,-1025 4378,-1025 4378,-1025 4467,-1025 4467,-1025 4473,-1025 4479,-1031 4479,-1037 4479,-1037 4479,-1081 4479,-1081 4479,-1087 4473,-1093 4467,-1093\"/>\n<text text-anchor=\"start\" x=\"4381.5\" y=\"-1077.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 1.175</text>\n<text text-anchor=\"start\" x=\"4385\" y=\"-1062.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.485</text>\n<text text-anchor=\"start\" x=\"4379\" y=\"-1047.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 29</text>\n<text text-anchor=\"start\" x=\"4374\" y=\"-1032.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [17, 12]</text>\n</g>\n<!-- 228&#45;&gt;244 -->\n<g id=\"edge244\" class=\"edge\">\n<title>228&#45;&gt;244</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4317.15,-1128.88C4331.8,-1119.3 4347.92,-1108.76 4363.06,-1098.86\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4365.38,-1101.53 4371.84,-1093.12 4361.55,-1095.67 4365.38,-1101.53\"/>\n</g>\n<!-- 230 -->\n<g id=\"node231\" class=\"node\">\n<title>230</title>\n<path fill=\"#f3c5a4\" stroke=\"black\" d=\"M4184,-989C4184,-989 4103,-989 4103,-989 4097,-989 4091,-983 4091,-977 4091,-977 4091,-933 4091,-933 4091,-927 4097,-921 4103,-921 4103,-921 4184,-921 4184,-921 4190,-921 4196,-927 4196,-933 4196,-933 4196,-977 4196,-977 4196,-983 4190,-989 4184,-989\"/>\n<text text-anchor=\"start\" x=\"4104\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pclass ≤ 1.5</text>\n<text text-anchor=\"start\" x=\"4106\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.455</text>\n<text text-anchor=\"start\" x=\"4100\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 20</text>\n<text text-anchor=\"start\" x=\"4099\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 7]</text>\n</g>\n<!-- 229&#45;&gt;230 -->\n<g id=\"edge230\" class=\"edge\">\n<title>229&#45;&gt;230</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4226.57,-1024.88C4215.39,-1015.62 4203.14,-1005.45 4191.55,-995.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4193.59,-992.99 4183.66,-989.3 4189.12,-998.38 4193.59,-992.99\"/>\n</g>\n<!-- 243 -->\n<g id=\"node244\" class=\"node\">\n<title>243</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4307,-981.5C4307,-981.5 4226,-981.5 4226,-981.5 4220,-981.5 4214,-975.5 4214,-969.5 4214,-969.5 4214,-940.5 4214,-940.5 4214,-934.5 4220,-928.5 4226,-928.5 4226,-928.5 4307,-928.5 4307,-928.5 4313,-928.5 4319,-934.5 4319,-940.5 4319,-940.5 4319,-969.5 4319,-969.5 4319,-975.5 4313,-981.5 4307,-981.5\"/>\n<text text-anchor=\"start\" x=\"4237.5\" y=\"-966.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4223\" y=\"-951.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n<text text-anchor=\"start\" x=\"4222\" y=\"-936.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [18, 0]</text>\n</g>\n<!-- 229&#45;&gt;243 -->\n<g id=\"edge243\" class=\"edge\">\n<title>229&#45;&gt;243</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4266.5,-1024.88C4266.5,-1014.33 4266.5,-1002.6 4266.5,-991.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4270,-991.52 4266.5,-981.52 4263,-991.52 4270,-991.52\"/>\n</g>\n<!-- 231 -->\n<g id=\"node232\" class=\"node\">\n<title>231</title>\n<path fill=\"#f9e3d3\" stroke=\"black\" d=\"M4147,-885C4147,-885 4068,-885 4068,-885 4062,-885 4056,-879 4056,-873 4056,-873 4056,-829 4056,-829 4056,-823 4062,-817 4068,-817 4068,-817 4147,-817 4147,-817 4153,-817 4159,-823 4159,-829 4159,-829 4159,-873 4159,-873 4159,-879 4153,-885 4147,-885\"/>\n<text text-anchor=\"start\" x=\"4068\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 1.759</text>\n<text text-anchor=\"start\" x=\"4070\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.492</text>\n<text text-anchor=\"start\" x=\"4064\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16</text>\n<text text-anchor=\"start\" x=\"4067\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 7]</text>\n</g>\n<!-- 230&#45;&gt;231 -->\n<g id=\"edge231\" class=\"edge\">\n<title>230&#45;&gt;231</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4131.81,-920.88C4128.89,-912.6 4125.71,-903.6 4122.65,-894.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4125.88,-893.56 4119.25,-885.3 4119.28,-895.89 4125.88,-893.56\"/>\n</g>\n<!-- 242 -->\n<g id=\"node243\" class=\"node\">\n<title>242</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4262,-877.5C4262,-877.5 4189,-877.5 4189,-877.5 4183,-877.5 4177,-871.5 4177,-865.5 4177,-865.5 4177,-836.5 4177,-836.5 4177,-830.5 4183,-824.5 4189,-824.5 4189,-824.5 4262,-824.5 4262,-824.5 4268,-824.5 4274,-830.5 4274,-836.5 4274,-836.5 4274,-865.5 4274,-865.5 4274,-871.5 4268,-877.5 4262,-877.5\"/>\n<text text-anchor=\"start\" x=\"4196.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4186\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"4185\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 0]</text>\n</g>\n<!-- 230&#45;&gt;242 -->\n<g id=\"edge242\" class=\"edge\">\n<title>230&#45;&gt;242</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4170.12,-920.88C4179.23,-909.56 4189.42,-896.88 4198.55,-885.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4201.45,-887.51 4204.98,-877.52 4195.99,-883.12 4201.45,-887.51\"/>\n</g>\n<!-- 232 -->\n<g id=\"node233\" class=\"node\">\n<title>232</title>\n<path fill=\"#bddef6\" stroke=\"black\" d=\"M4165.5,-781C4165.5,-781 4045.5,-781 4045.5,-781 4039.5,-781 4033.5,-775 4033.5,-769 4033.5,-769 4033.5,-725 4033.5,-725 4033.5,-719 4039.5,-713 4045.5,-713 4045.5,-713 4165.5,-713 4165.5,-713 4171.5,-713 4177.5,-719 4177.5,-725 4177.5,-725 4177.5,-769 4177.5,-769 4177.5,-775 4171.5,-781 4165.5,-781\"/>\n<text text-anchor=\"start\" x=\"4041.5\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_C ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"4072\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n<text text-anchor=\"start\" x=\"4062\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10</text>\n<text text-anchor=\"start\" x=\"4065\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 6]</text>\n</g>\n<!-- 231&#45;&gt;232 -->\n<g id=\"edge232\" class=\"edge\">\n<title>231&#45;&gt;232</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4106.85,-816.88C4106.69,-808.78 4106.52,-799.98 4106.35,-791.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4109.85,-791.23 4106.15,-781.3 4102.85,-791.37 4109.85,-791.23\"/>\n</g>\n<!-- 239 -->\n<g id=\"node240\" class=\"node\">\n<title>239</title>\n<path fill=\"#ea9a61\" stroke=\"black\" d=\"M4281,-781C4281,-781 4208,-781 4208,-781 4202,-781 4196,-775 4196,-769 4196,-769 4196,-725 4196,-725 4196,-719 4202,-713 4208,-713 4208,-713 4281,-713 4281,-713 4287,-713 4293,-719 4293,-725 4293,-725 4293,-769 4293,-769 4293,-775 4287,-781 4281,-781\"/>\n<text text-anchor=\"start\" x=\"4205\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 3.233</text>\n<text text-anchor=\"start\" x=\"4207\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.278</text>\n<text text-anchor=\"start\" x=\"4205\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"4204\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 1]</text>\n</g>\n<!-- 231&#45;&gt;239 -->\n<g id=\"edge239\" class=\"edge\">\n<title>231&#45;&gt;239</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4151.98,-816.88C4164.66,-807.44 4178.6,-797.06 4191.73,-787.29\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4193.84,-790.08 4199.77,-781.3 4189.66,-784.46 4193.84,-790.08\"/>\n</g>\n<!-- 233 -->\n<g id=\"node234\" class=\"node\">\n<title>233</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4050,-669.5C4050,-669.5 3977,-669.5 3977,-669.5 3971,-669.5 3965,-663.5 3965,-657.5 3965,-657.5 3965,-628.5 3965,-628.5 3965,-622.5 3971,-616.5 3977,-616.5 3977,-616.5 4050,-616.5 4050,-616.5 4056,-616.5 4062,-622.5 4062,-628.5 4062,-628.5 4062,-657.5 4062,-657.5 4062,-663.5 4056,-669.5 4050,-669.5\"/>\n<text text-anchor=\"start\" x=\"3984.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"3974\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"3973\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 4]</text>\n</g>\n<!-- 232&#45;&gt;233 -->\n<g id=\"edge233\" class=\"edge\">\n<title>232&#45;&gt;233</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4075.63,-712.88C4065.31,-701.45 4053.76,-688.63 4043.44,-677.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4045.81,-674.6 4036.52,-669.52 4040.62,-679.29 4045.81,-674.6\"/>\n</g>\n<!-- 234 -->\n<g id=\"node235\" class=\"node\">\n<title>234</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M4165,-677C4165,-677 4092,-677 4092,-677 4086,-677 4080,-671 4080,-665 4080,-665 4080,-621 4080,-621 4080,-615 4086,-609 4092,-609 4092,-609 4165,-609 4165,-609 4171,-609 4177,-615 4177,-621 4177,-621 4177,-665 4177,-665 4177,-671 4171,-677 4165,-677\"/>\n<text text-anchor=\"start\" x=\"4092\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 0.46</text>\n<text text-anchor=\"start\" x=\"4091\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"4089\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"4088\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 2]</text>\n</g>\n<!-- 232&#45;&gt;234 -->\n<g id=\"edge234\" class=\"edge\">\n<title>232&#45;&gt;234</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4112.97,-712.88C4114.82,-704.69 4116.82,-695.79 4118.76,-687.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4122.21,-687.82 4120.99,-677.3 4115.38,-686.28 4122.21,-687.82\"/>\n</g>\n<!-- 235 -->\n<g id=\"node236\" class=\"node\">\n<title>235</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4137,-565.5C4137,-565.5 4064,-565.5 4064,-565.5 4058,-565.5 4052,-559.5 4052,-553.5 4052,-553.5 4052,-524.5 4052,-524.5 4052,-518.5 4058,-512.5 4064,-512.5 4064,-512.5 4137,-512.5 4137,-512.5 4143,-512.5 4149,-518.5 4149,-524.5 4149,-524.5 4149,-553.5 4149,-553.5 4149,-559.5 4143,-565.5 4137,-565.5\"/>\n<text text-anchor=\"start\" x=\"4071.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4061\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"4060\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 0]</text>\n</g>\n<!-- 234&#45;&gt;235 -->\n<g id=\"edge235\" class=\"edge\">\n<title>234&#45;&gt;235</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4119.41,-608.88C4116.45,-598.11 4113.16,-586.11 4110.16,-575.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4113.53,-574.24 4107.51,-565.52 4106.78,-576.09 4113.53,-574.24\"/>\n</g>\n<!-- 236 -->\n<g id=\"node237\" class=\"node\">\n<title>236</title>\n<path fill=\"#9ccef2\" stroke=\"black\" d=\"M4252,-573C4252,-573 4179,-573 4179,-573 4173,-573 4167,-567 4167,-561 4167,-561 4167,-517 4167,-517 4167,-511 4173,-505 4179,-505 4179,-505 4252,-505 4252,-505 4258,-505 4264,-511 4264,-517 4264,-517 4264,-561 4264,-561 4264,-567 4258,-573 4252,-573\"/>\n<text text-anchor=\"start\" x=\"4179\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"4178\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"4176\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"4175\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 2]</text>\n</g>\n<!-- 234&#45;&gt;236 -->\n<g id=\"edge236\" class=\"edge\">\n<title>234&#45;&gt;236</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4156.75,-608.88C4164.34,-599.98 4172.65,-590.24 4180.57,-580.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4183.27,-583.18 4187.1,-573.3 4177.95,-578.64 4183.27,-583.18\"/>\n</g>\n<!-- 237 -->\n<g id=\"node238\" class=\"node\">\n<title>237</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4223,-461.5C4223,-461.5 4150,-461.5 4150,-461.5 4144,-461.5 4138,-455.5 4138,-449.5 4138,-449.5 4138,-420.5 4138,-420.5 4138,-414.5 4144,-408.5 4150,-408.5 4150,-408.5 4223,-408.5 4223,-408.5 4229,-408.5 4235,-414.5 4235,-420.5 4235,-420.5 4235,-449.5 4235,-449.5 4235,-455.5 4229,-461.5 4223,-461.5\"/>\n<text text-anchor=\"start\" x=\"4157.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4147\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"4146\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 236&#45;&gt;237 -->\n<g id=\"edge237\" class=\"edge\">\n<title>236&#45;&gt;237</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4206.08,-504.88C4203.02,-494.11 4199.61,-482.11 4196.5,-471.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4199.86,-470.18 4193.76,-461.52 4193.12,-472.1 4199.86,-470.18\"/>\n</g>\n<!-- 238 -->\n<g id=\"node239\" class=\"node\">\n<title>238</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4338,-461.5C4338,-461.5 4265,-461.5 4265,-461.5 4259,-461.5 4253,-455.5 4253,-449.5 4253,-449.5 4253,-420.5 4253,-420.5 4253,-414.5 4259,-408.5 4265,-408.5 4265,-408.5 4338,-408.5 4338,-408.5 4344,-408.5 4350,-414.5 4350,-420.5 4350,-420.5 4350,-449.5 4350,-449.5 4350,-455.5 4344,-461.5 4338,-461.5\"/>\n<text text-anchor=\"start\" x=\"4272.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4262\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"4261\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 236&#45;&gt;238 -->\n<g id=\"edge238\" class=\"edge\">\n<title>236&#45;&gt;238</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4243.42,-504.88C4253.07,-493.45 4263.87,-480.63 4273.52,-469.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4276.21,-471.42 4279.98,-461.52 4270.86,-466.91 4276.21,-471.42\"/>\n</g>\n<!-- 240 -->\n<g id=\"node241\" class=\"node\">\n<title>240</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4280,-669.5C4280,-669.5 4207,-669.5 4207,-669.5 4201,-669.5 4195,-663.5 4195,-657.5 4195,-657.5 4195,-628.5 4195,-628.5 4195,-622.5 4201,-616.5 4207,-616.5 4207,-616.5 4280,-616.5 4280,-616.5 4286,-616.5 4292,-622.5 4292,-628.5 4292,-628.5 4292,-657.5 4292,-657.5 4292,-663.5 4286,-669.5 4280,-669.5\"/>\n<text text-anchor=\"start\" x=\"4214.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4204\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 5</text>\n<text text-anchor=\"start\" x=\"4203\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 0]</text>\n</g>\n<!-- 239&#45;&gt;240 -->\n<g id=\"edge240\" class=\"edge\">\n<title>239&#45;&gt;240</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4244.18,-712.88C4244.07,-702.33 4243.96,-690.6 4243.85,-679.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4247.35,-679.49 4243.75,-669.52 4240.35,-679.55 4247.35,-679.49\"/>\n</g>\n<!-- 241 -->\n<g id=\"node242\" class=\"node\">\n<title>241</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4395,-669.5C4395,-669.5 4322,-669.5 4322,-669.5 4316,-669.5 4310,-663.5 4310,-657.5 4310,-657.5 4310,-628.5 4310,-628.5 4310,-622.5 4316,-616.5 4322,-616.5 4322,-616.5 4395,-616.5 4395,-616.5 4401,-616.5 4407,-622.5 4407,-628.5 4407,-628.5 4407,-657.5 4407,-657.5 4407,-663.5 4401,-669.5 4395,-669.5\"/>\n<text text-anchor=\"start\" x=\"4329.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4319\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"4318\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 239&#45;&gt;241 -->\n<g id=\"edge241\" class=\"edge\">\n<title>239&#45;&gt;241</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4281.51,-712.88C4294.66,-701.12 4309.44,-687.89 4322.51,-676.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4324.86,-678.8 4329.98,-669.52 4320.19,-673.58 4324.86,-678.8\"/>\n</g>\n<!-- 245 -->\n<g id=\"node246\" class=\"node\">\n<title>245</title>\n<path fill=\"#5aade9\" stroke=\"black\" d=\"M4482,-989C4482,-989 4363,-989 4363,-989 4357,-989 4351,-983 4351,-977 4351,-977 4351,-933 4351,-933 4351,-927 4357,-921 4363,-921 4363,-921 4482,-921 4482,-921 4488,-921 4494,-927 4494,-933 4494,-933 4494,-977 4494,-977 4494,-983 4488,-989 4482,-989\"/>\n<text text-anchor=\"start\" x=\"4359\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_E ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"4385\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.245</text>\n<text text-anchor=\"start\" x=\"4383\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"4382\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 6]</text>\n</g>\n<!-- 244&#45;&gt;245 -->\n<g id=\"edge245\" class=\"edge\">\n<title>244&#45;&gt;245</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4422.5,-1024.88C4422.5,-1016.78 4422.5,-1007.98 4422.5,-999.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4426,-999.3 4422.5,-989.3 4419,-999.3 4426,-999.3\"/>\n</g>\n<!-- 248 -->\n<g id=\"node249\" class=\"node\">\n<title>248</title>\n<path fill=\"#efb083\" stroke=\"black\" d=\"M4644,-989C4644,-989 4525,-989 4525,-989 4519,-989 4513,-983 4513,-977 4513,-977 4513,-933 4513,-933 4513,-927 4519,-921 4525,-921 4525,-921 4644,-921 4644,-921 4650,-921 4656,-927 4656,-933 4656,-933 4656,-977 4656,-977 4656,-983 4650,-989 4644,-989\"/>\n<text text-anchor=\"start\" x=\"4521\" y=\"-973.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cabin_letter_B ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"4547\" y=\"-958.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.397</text>\n<text text-anchor=\"start\" x=\"4541\" y=\"-943.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 22</text>\n<text text-anchor=\"start\" x=\"4540\" y=\"-928.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [16, 6]</text>\n</g>\n<!-- 244&#45;&gt;248 -->\n<g id=\"edge248\" class=\"edge\">\n<title>244&#45;&gt;248</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4475.1,-1024.88C4490.45,-1015.21 4507.37,-1004.56 4523.21,-994.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4525.29,-997.41 4531.89,-989.12 4521.56,-991.49 4525.29,-997.41\"/>\n</g>\n<!-- 246 -->\n<g id=\"node247\" class=\"node\">\n<title>246</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4384,-877.5C4384,-877.5 4311,-877.5 4311,-877.5 4305,-877.5 4299,-871.5 4299,-865.5 4299,-865.5 4299,-836.5 4299,-836.5 4299,-830.5 4305,-824.5 4311,-824.5 4311,-824.5 4384,-824.5 4384,-824.5 4390,-824.5 4396,-830.5 4396,-836.5 4396,-836.5 4396,-865.5 4396,-865.5 4396,-871.5 4390,-877.5 4384,-877.5\"/>\n<text text-anchor=\"start\" x=\"4318.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4308\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6</text>\n<text text-anchor=\"start\" x=\"4307\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 6]</text>\n</g>\n<!-- 245&#45;&gt;246 -->\n<g id=\"edge246\" class=\"edge\">\n<title>245&#45;&gt;246</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4398.15,-920.88C4389.9,-909.67 4380.68,-897.13 4372.39,-885.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4375.01,-883.5 4366.26,-877.52 4369.37,-887.65 4375.01,-883.5\"/>\n</g>\n<!-- 247 -->\n<g id=\"node248\" class=\"node\">\n<title>247</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4499,-877.5C4499,-877.5 4426,-877.5 4426,-877.5 4420,-877.5 4414,-871.5 4414,-865.5 4414,-865.5 4414,-836.5 4414,-836.5 4414,-830.5 4420,-824.5 4426,-824.5 4426,-824.5 4499,-824.5 4499,-824.5 4505,-824.5 4511,-830.5 4511,-836.5 4511,-836.5 4511,-865.5 4511,-865.5 4511,-871.5 4505,-877.5 4499,-877.5\"/>\n<text text-anchor=\"start\" x=\"4433.5\" y=\"-862.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4423\" y=\"-847.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"4422\" y=\"-832.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 245&#45;&gt;247 -->\n<g id=\"edge247\" class=\"edge\">\n<title>245&#45;&gt;247</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4435.49,-920.88C4439.76,-910 4444.51,-897.86 4448.83,-886.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4452.1,-888.11 4452.49,-877.52 4445.58,-885.55 4452.1,-888.11\"/>\n</g>\n<!-- 249 -->\n<g id=\"node250\" class=\"node\">\n<title>249</title>\n<path fill=\"#ea9a61\" stroke=\"black\" d=\"M4625,-885C4625,-885 4544,-885 4544,-885 4538,-885 4532,-879 4532,-873 4532,-873 4532,-829 4532,-829 4532,-823 4538,-817 4544,-817 4544,-817 4625,-817 4625,-817 4631,-817 4637,-823 4637,-829 4637,-829 4637,-873 4637,-873 4637,-879 4631,-885 4625,-885\"/>\n<text text-anchor=\"start\" x=\"4548\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"4547\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.278</text>\n<text text-anchor=\"start\" x=\"4541\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\n<text text-anchor=\"start\" x=\"4540\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [15, 3]</text>\n</g>\n<!-- 248&#45;&gt;249 -->\n<g id=\"edge249\" class=\"edge\">\n<title>248&#45;&gt;249</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4584.5,-920.88C4584.5,-912.78 4584.5,-903.98 4584.5,-895.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4588,-895.3 4584.5,-885.3 4581,-895.3 4588,-895.3\"/>\n</g>\n<!-- 258 -->\n<g id=\"node259\" class=\"node\">\n<title>258</title>\n<path fill=\"#7bbeee\" stroke=\"black\" d=\"M4741,-885C4741,-885 4668,-885 4668,-885 4662,-885 4656,-879 4656,-873 4656,-873 4656,-829 4656,-829 4656,-823 4662,-817 4668,-817 4668,-817 4741,-817 4741,-817 4747,-817 4753,-823 4753,-829 4753,-829 4753,-873 4753,-873 4753,-879 4747,-885 4741,-885\"/>\n<text text-anchor=\"start\" x=\"4668\" y=\"-869.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Parch ≤ 0.5</text>\n<text text-anchor=\"start\" x=\"4667\" y=\"-854.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.375</text>\n<text text-anchor=\"start\" x=\"4665\" y=\"-839.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"4664\" y=\"-824.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 3]</text>\n</g>\n<!-- 248&#45;&gt;258 -->\n<g id=\"edge258\" class=\"edge\">\n<title>248&#45;&gt;258</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4623.46,-920.88C4634.36,-911.62 4646.32,-901.45 4657.62,-891.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4659.97,-894.44 4665.32,-885.3 4655.44,-889.11 4659.97,-894.44\"/>\n</g>\n<!-- 250 -->\n<g id=\"node251\" class=\"node\">\n<title>250</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M4511,-781C4511,-781 4438,-781 4438,-781 4432,-781 4426,-775 4426,-769 4426,-769 4426,-725 4426,-725 4426,-719 4432,-713 4438,-713 4438,-713 4511,-713 4511,-713 4517,-713 4523,-719 4523,-725 4523,-725 4523,-769 4523,-769 4523,-775 4517,-781 4511,-781\"/>\n<text text-anchor=\"start\" x=\"4435\" y=\"-765.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age ≤ 1.306</text>\n<text text-anchor=\"start\" x=\"4437\" y=\"-750.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"4435\" y=\"-735.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"4434\" y=\"-720.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 3]</text>\n</g>\n<!-- 249&#45;&gt;250 -->\n<g id=\"edge250\" class=\"edge\">\n<title>249&#45;&gt;250</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4548.79,-816.88C4538.89,-807.71 4528.04,-797.65 4517.77,-788.12\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4520.12,-785.53 4510.41,-781.3 4515.36,-790.67 4520.12,-785.53\"/>\n</g>\n<!-- 257 -->\n<g id=\"node258\" class=\"node\">\n<title>257</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4626,-773.5C4626,-773.5 4553,-773.5 4553,-773.5 4547,-773.5 4541,-767.5 4541,-761.5 4541,-761.5 4541,-732.5 4541,-732.5 4541,-726.5 4547,-720.5 4553,-720.5 4553,-720.5 4626,-720.5 4626,-720.5 4632,-720.5 4638,-726.5 4638,-732.5 4638,-732.5 4638,-761.5 4638,-761.5 4638,-767.5 4632,-773.5 4626,-773.5\"/>\n<text text-anchor=\"start\" x=\"4560.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4550\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9</text>\n<text text-anchor=\"start\" x=\"4549\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [9, 0]</text>\n</g>\n<!-- 249&#45;&gt;257 -->\n<g id=\"edge257\" class=\"edge\">\n<title>249&#45;&gt;257</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4586.12,-816.88C4586.65,-806.22 4587.23,-794.35 4587.76,-783.52\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4591.26,-783.68 4588.25,-773.52 4584.26,-783.34 4591.26,-783.68\"/>\n</g>\n<!-- 251 -->\n<g id=\"node252\" class=\"node\">\n<title>251</title>\n<path fill=\"#e9965a\" stroke=\"black\" d=\"M4511.5,-677C4511.5,-677 4437.5,-677 4437.5,-677 4431.5,-677 4425.5,-671 4425.5,-665 4425.5,-665 4425.5,-621 4425.5,-621 4425.5,-615 4431.5,-609 4437.5,-609 4437.5,-609 4511.5,-609 4511.5,-609 4517.5,-609 4523.5,-615 4523.5,-621 4523.5,-621 4523.5,-665 4523.5,-665 4523.5,-671 4517.5,-677 4511.5,-677\"/>\n<text text-anchor=\"start\" x=\"4433.5\" y=\"-661.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 1.566</text>\n<text text-anchor=\"start\" x=\"4437\" y=\"-646.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.245</text>\n<text text-anchor=\"start\" x=\"4435\" y=\"-631.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 7</text>\n<text text-anchor=\"start\" x=\"4434\" y=\"-616.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 1]</text>\n</g>\n<!-- 250&#45;&gt;251 -->\n<g id=\"edge251\" class=\"edge\">\n<title>250&#45;&gt;251</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4474.5,-712.88C4474.5,-704.78 4474.5,-695.98 4474.5,-687.47\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4478,-687.3 4474.5,-677.3 4471,-687.3 4478,-687.3\"/>\n</g>\n<!-- 256 -->\n<g id=\"node257\" class=\"node\">\n<title>256</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4627,-669.5C4627,-669.5 4554,-669.5 4554,-669.5 4548,-669.5 4542,-663.5 4542,-657.5 4542,-657.5 4542,-628.5 4542,-628.5 4542,-622.5 4548,-616.5 4554,-616.5 4554,-616.5 4627,-616.5 4627,-616.5 4633,-616.5 4639,-622.5 4639,-628.5 4639,-628.5 4639,-657.5 4639,-657.5 4639,-663.5 4633,-669.5 4627,-669.5\"/>\n<text text-anchor=\"start\" x=\"4561.5\" y=\"-654.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4551\" y=\"-639.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"4550\" y=\"-624.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 2]</text>\n</g>\n<!-- 250&#45;&gt;256 -->\n<g id=\"edge256\" class=\"edge\">\n<title>250&#45;&gt;256</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4512.16,-712.88C4525.54,-701.12 4540.58,-687.89 4553.88,-676.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4556.28,-678.75 4561.48,-669.52 4551.66,-673.49 4556.28,-678.75\"/>\n</g>\n<!-- 252 -->\n<g id=\"node253\" class=\"node\">\n<title>252</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4424,-565.5C4424,-565.5 4351,-565.5 4351,-565.5 4345,-565.5 4339,-559.5 4339,-553.5 4339,-553.5 4339,-524.5 4339,-524.5 4339,-518.5 4345,-512.5 4351,-512.5 4351,-512.5 4424,-512.5 4424,-512.5 4430,-512.5 4436,-518.5 4436,-524.5 4436,-524.5 4436,-553.5 4436,-553.5 4436,-559.5 4430,-565.5 4424,-565.5\"/>\n<text text-anchor=\"start\" x=\"4358.5\" y=\"-550.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4348\" y=\"-535.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4</text>\n<text text-anchor=\"start\" x=\"4347\" y=\"-520.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 0]</text>\n</g>\n<!-- 251&#45;&gt;252 -->\n<g id=\"edge252\" class=\"edge\">\n<title>251&#45;&gt;252</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4446.25,-608.88C4436.5,-597.45 4425.57,-584.63 4415.81,-573.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4418.42,-570.86 4409.27,-565.52 4413.09,-575.4 4418.42,-570.86\"/>\n</g>\n<!-- 253 -->\n<g id=\"node254\" class=\"node\">\n<title>253</title>\n<path fill=\"#f2c09c\" stroke=\"black\" d=\"M4540.5,-573C4540.5,-573 4466.5,-573 4466.5,-573 4460.5,-573 4454.5,-567 4454.5,-561 4454.5,-561 4454.5,-517 4454.5,-517 4454.5,-511 4460.5,-505 4466.5,-505 4466.5,-505 4540.5,-505 4540.5,-505 4546.5,-505 4552.5,-511 4552.5,-517 4552.5,-517 4552.5,-561 4552.5,-561 4552.5,-567 4546.5,-573 4540.5,-573\"/>\n<text text-anchor=\"start\" x=\"4462.5\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Fare ≤ 2.067</text>\n<text text-anchor=\"start\" x=\"4466\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.444</text>\n<text text-anchor=\"start\" x=\"4464\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"4463\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 1]</text>\n</g>\n<!-- 251&#45;&gt;253 -->\n<g id=\"edge253\" class=\"edge\">\n<title>251&#45;&gt;253</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4483.92,-608.88C4486.25,-600.69 4488.78,-591.79 4491.22,-583.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4494.66,-583.88 4494.03,-573.3 4487.93,-581.96 4494.66,-583.88\"/>\n</g>\n<!-- 254 -->\n<g id=\"node255\" class=\"node\">\n<title>254</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4453,-461.5C4453,-461.5 4380,-461.5 4380,-461.5 4374,-461.5 4368,-455.5 4368,-449.5 4368,-449.5 4368,-420.5 4368,-420.5 4368,-414.5 4374,-408.5 4380,-408.5 4380,-408.5 4453,-408.5 4453,-408.5 4459,-408.5 4465,-414.5 4465,-420.5 4465,-420.5 4465,-449.5 4465,-449.5 4465,-455.5 4459,-461.5 4453,-461.5\"/>\n<text text-anchor=\"start\" x=\"4387.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4377\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"4376\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1]</text>\n</g>\n<!-- 253&#45;&gt;254 -->\n<g id=\"edge254\" class=\"edge\">\n<title>253&#45;&gt;254</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4475.25,-504.88C4465.5,-493.45 4454.57,-480.63 4444.81,-469.19\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4447.42,-466.86 4438.27,-461.52 4442.09,-471.4 4447.42,-466.86\"/>\n</g>\n<!-- 255 -->\n<g id=\"node256\" class=\"node\">\n<title>255</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4568,-461.5C4568,-461.5 4495,-461.5 4495,-461.5 4489,-461.5 4483,-455.5 4483,-449.5 4483,-449.5 4483,-420.5 4483,-420.5 4483,-414.5 4489,-408.5 4495,-408.5 4495,-408.5 4568,-408.5 4568,-408.5 4574,-408.5 4580,-414.5 4580,-420.5 4580,-420.5 4580,-449.5 4580,-449.5 4580,-455.5 4574,-461.5 4568,-461.5\"/>\n<text text-anchor=\"start\" x=\"4502.5\" y=\"-446.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4492\" y=\"-431.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2</text>\n<text text-anchor=\"start\" x=\"4491\" y=\"-416.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 0]</text>\n</g>\n<!-- 253&#45;&gt;255 -->\n<g id=\"edge255\" class=\"edge\">\n<title>253&#45;&gt;255</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4512.59,-504.88C4515.55,-494.11 4518.84,-482.11 4521.84,-471.18\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4525.22,-472.09 4524.49,-461.52 4518.47,-470.24 4525.22,-472.09\"/>\n</g>\n<!-- 259 -->\n<g id=\"node260\" class=\"node\">\n<title>259</title>\n<path fill=\"#e58139\" stroke=\"black\" d=\"M4741,-773.5C4741,-773.5 4668,-773.5 4668,-773.5 4662,-773.5 4656,-767.5 4656,-761.5 4656,-761.5 4656,-732.5 4656,-732.5 4656,-726.5 4662,-720.5 4668,-720.5 4668,-720.5 4741,-720.5 4741,-720.5 4747,-720.5 4753,-726.5 4753,-732.5 4753,-732.5 4753,-761.5 4753,-761.5 4753,-767.5 4747,-773.5 4741,-773.5\"/>\n<text text-anchor=\"start\" x=\"4675.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4665\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1</text>\n<text text-anchor=\"start\" x=\"4664\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 0]</text>\n</g>\n<!-- 258&#45;&gt;259 -->\n<g id=\"edge259\" class=\"edge\">\n<title>258&#45;&gt;259</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4704.5,-816.88C4704.5,-806.33 4704.5,-794.6 4704.5,-783.85\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4708,-783.52 4704.5,-773.52 4701,-783.52 4708,-783.52\"/>\n</g>\n<!-- 260 -->\n<g id=\"node261\" class=\"node\">\n<title>260</title>\n<path fill=\"#399de5\" stroke=\"black\" d=\"M4856,-773.5C4856,-773.5 4783,-773.5 4783,-773.5 4777,-773.5 4771,-767.5 4771,-761.5 4771,-761.5 4771,-732.5 4771,-732.5 4771,-726.5 4777,-720.5 4783,-720.5 4783,-720.5 4856,-720.5 4856,-720.5 4862,-720.5 4868,-726.5 4868,-732.5 4868,-732.5 4868,-761.5 4868,-761.5 4868,-767.5 4862,-773.5 4856,-773.5\"/>\n<text text-anchor=\"start\" x=\"4790.5\" y=\"-758.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n<text text-anchor=\"start\" x=\"4780\" y=\"-743.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3</text>\n<text text-anchor=\"start\" x=\"4779\" y=\"-728.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 3]</text>\n</g>\n<!-- 258&#45;&gt;260 -->\n<g id=\"edge260\" class=\"edge\">\n<title>258&#45;&gt;260</title>\n<path fill=\"none\" stroke=\"black\" d=\"M4741.84,-816.88C4755.1,-805.12 4770.01,-791.89 4783.19,-780.2\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"4785.57,-782.77 4790.73,-773.52 4780.92,-777.54 4785.57,-782.77\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": "<graphviz.sources.Source at 0x1baa5f279d0>"
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(dt, out_file=None,\n",
    "                      feature_names=X_train.loc[:, X_train.columns != 'PassengerId'].columns,\n",
    "                      filled=True, rounded=True,\n",
    "                      special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, the complexity of the tree is very large. Perhaps this is also why it is not good at modeling data and making good predictions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### K Nearest Neighbor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.856      0.848      0.84677419 0.83870968 0.83870968]\n",
      "0.8456387096774194\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "cv = cross_val_score(knn,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I wasn't expecting good accuracies like this. In fact, I believed that the algorithm would have made it difficult to define which were the closest points. In fact, having a 38-dimensional space, I didn't think it was easy to define the distance between points in space."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random forest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.832      0.856      0.86290323 0.83870968 0.7983871 ]\n",
      "0.8376000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state = 1)\n",
    "cv = cross_val_score(rf,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7827715355805244"
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(y_pred, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Support vector machine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84       0.872      0.81451613 0.83870968 0.83064516]\n",
      "0.8391741935483872\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(probability=True)\n",
    "cv = cross_val_score(svc,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8127340823970037"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svc.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(y_pred, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### XGboost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.792      0.808      0.87096774 0.84677419 0.81451613]\n",
      "0.8264516129032259\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "cv = cross_val_score(xgb,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Voting classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(estimators = [('lr',lr),('knn',knn),('rf',rf),('gnb',gnb),('svm',svc),('xgb',xgb)], voting = 'soft')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "cv = cross_val_score(voting_clf,X_train.loc[:, X_train.columns != 'PassengerId'],y_train,cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88       0.848      0.87096774 0.83870968 0.82258065]\n",
      "0.8520516129032257\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This method consists in having the various models vote. I expected it to be the best because different models can and are able to capture information other than data. I compensate each other for the shortcomings."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8014981273408239"
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "p_v = voting_clf.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(p_v, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If we try it with the test data, perhaps we see that this voting model goes into overfitting a bit."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### GridSearch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "from utils import clf_performance"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "param_grid_lr = {'max_iter' : [2000],\n",
    "              'penalty' : ['l1', 'l2'],\n",
    "              'C' : np.logspace(-4, 4, 20),\n",
    "              'solver' : ['liblinear']}\n",
    "\n",
    "param_grid_knn = {'n_neighbors' : [3,5,7,9],\n",
    "              'weights' : ['uniform', 'distance'],\n",
    "              'algorithm' : ['auto', 'ball_tree','kd_tree'],\n",
    "              'p' : [1,2]}\n",
    "\n",
    "param_grid_svc = tuned_parameters = [{'kernel': ['rbf'], 'gamma': [.1,.5,1,2,5,10],\n",
    "                                  'C': [.1, 1, 10, 100, 1000]},\n",
    "                                 {'kernel': ['linear'], 'C': [.1, 1, 10, 100, 1000]},\n",
    "                                 {'kernel': ['poly'], 'degree' : [2,3,4,5], 'C': [.1, 1, 10, 100, 1000]}]\n",
    "\n",
    "param_grid_rf =  {'n_estimators': [100,500,1000],\n",
    "                                  'bootstrap': [True,False],\n",
    "                                  'max_depth': [3,5,10,20,50,75,100,None],\n",
    "                                  'max_features': ['auto','sqrt'],\n",
    "                                  'min_samples_leaf': [1,2,4,10],\n",
    "                                  'min_samples_split': [2,5,10]}\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [20, 50, 100, 250, 500,1000],\n",
    "    'colsample_bytree': [0.2, 0.5, 0.7, 0.8, 1],\n",
    "    'max_depth': [2, 5, 10, 15, 20, 25, None],\n",
    "    'reg_alpha': [0, 0.5, 1],\n",
    "    'reg_lambda': [1, 1.5, 2],\n",
    "    'subsample': [0.5,0.6,0.7, 0.8, 0.9],\n",
    "    'learning_rate':[.01,0.1,0.2,0.3,0.5, 0.7, 0.9],\n",
    "    'gamma':[0,.01,.1,1,10,100],\n",
    "    'min_child_weight':[0,.01,0.1,1,10,100],\n",
    "    'sampling_method': ['uniform', 'gradient_based']\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "lr_g = LogisticRegression()\n",
    "knn_g = KNeighborsClassifier()\n",
    "svc_g = SVC(probability = True)\n",
    "rf_g = RandomForestClassifier(random_state = 1)\n",
    "xgb_g = XGBClassifier(random_state = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "Logistic Regression\n",
      "Best Score: 0.8359741935483871\n",
      "Best Parameters: {'C': 11.288378916846883, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "clf_lr = GridSearchCV(lr_g, param_grid = param_grid_lr, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_lr = clf_lr.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_lr,'Logistic Regression')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "KNN\n",
      "Best Score: 0.8552645161290323\n",
      "Best Parameters: {'algorithm': 'auto', 'n_neighbors': 5, 'p': 1, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "clf_knn = GridSearchCV(knn_g, param_grid = param_grid_knn, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_knn = clf_knn.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_knn,'KNN')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7752808988764045"
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_best = KNeighborsClassifier(algorithm= 'auto', n_neighbors= 5, p= 1, weights= 'uniform')\n",
    "knn_best.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "\n",
    "y_pred_best_knn = knn_best.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(y_pred_best_knn, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 55 candidates, totalling 275 fits\n",
      "SVC\n",
      "Best Score: 0.8456516129032258\n",
      "Best Parameters: {'C': 1, 'gamma': 0.5, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "clf_svc = GridSearchCV(svc_g, param_grid = param_grid_svc, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_svc = clf_svc.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_svc,'SVC')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "outputs": [
    {
     "data": {
      "text/plain": "0.797752808988764"
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_best = SVC(C= 1, gamma= 0.5, kernel= 'rbf')\n",
    "svc_best.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "\n",
    "y_pred_best = svc_best.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(y_pred_best, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Random Forest\n",
      "Best Score: 0.8681290322580646\n",
      "Best Parameters: {'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 20, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "clf_rf_rnd = RandomizedSearchCV(rf_g, param_distributions = param_grid_rf, n_iter = 100, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_rf_rnd = clf_rf_rnd.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_rf_rnd,'Random Forest')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1152 candidates, totalling 5760 fits\n",
      "Random Forest\n",
      "Best Score: 0.8697419354838709\n",
      "Best Parameters: {'bootstrap': False, 'max_depth': 50, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "clf_rf = GridSearchCV(rf_g, param_grid = param_grid_rf, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_rf = clf_rf.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_rf,'Random Forest')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "outputs": [
    {
     "data": {
      "text/plain": "0.797752808988764"
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_best = RandomForestClassifier(bootstrap= False, max_depth= 50, max_features= 'auto', min_samples_leaf= 2, min_samples_split= 10, n_estimators= 500)\n",
    "rf_best.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "pred_rf_best = rf_best.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(pred_rf_best, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "2525 fits failed out of a total of 5000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:02] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:03] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:04] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:05] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:06] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "19 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:07] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "26 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:08] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:09] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:10] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:11] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "28 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:12] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:13] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:17] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:18] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:20] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:21] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:22] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:23] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:24] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:25] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "11 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:28] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:27] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:31] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:32] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "11 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:33] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:34] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:35] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "22 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:36] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "17 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:37] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:38] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "11 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:39] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:40] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:41] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:43] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:42] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:44] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:45] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:46] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:47] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:49] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:50] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:51] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:52] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:53] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:54] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:55] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:57] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:57:59] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:00] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "11 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:02] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "23 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:03] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:04] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:05] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:06] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:07] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:10] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:11] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:12] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:13] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:14] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:17] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:19] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:21] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:22] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:24] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:26] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:27] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:29] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:30] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:34] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:35] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:36] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:38] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:39] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:40] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:42] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:44] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:46] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:49] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "29 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:50] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:51] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:55] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:56] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:58:59] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:01] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:02] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:03] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:08] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:09] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:10] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:11] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:12] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:13] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:14] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:15] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "44 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:16] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "17 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:17] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:19] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:18] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:21] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "26 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:23] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:22] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:24] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:26] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:27] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:28] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:29] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:30] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:33] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:37] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:38] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:39] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:40] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:41] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:42] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:43] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:44] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "26 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:46] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:53] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:45] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "29 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:47] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:50] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:51] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:52] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "34 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:54] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "55 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:55] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "23 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:56] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "23 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:57] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:01] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [10:59:59] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:06] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:02] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:05] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:07] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:09] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:10] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:13] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:15] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:14] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "21 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:17] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "29 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:16] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:18] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:19] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:23] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:26] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:27] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:28] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:30] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:31] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:32] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:33] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:34] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:38] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:37] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:39] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:40] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:42] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:44] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:45] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "17 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:46] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "37 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:47] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:48] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:49] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:55] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:53] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:56] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:54] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:59] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "17 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:57] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:00:58] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:00] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:01] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:03] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:04] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:09] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "23 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:12] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:13] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:14] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:15] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:17] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:22] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:23] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:25] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:26] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:28] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:30] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:33] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:36] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:39] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:40] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:44] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:49] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:50] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:55] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:56] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:57] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:58] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:01:59] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:02:00] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:02:01] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:02:02] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "14 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:02:03] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "51 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:02:04] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:02:07] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:02:09] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:02:10] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:02:15] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 1733, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\xgboost\\core.py\", line 203, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [11:02:16] C:/Users/Administrator/workspace/xgboost-win64_release_1.6.0/src/tree/updater_colmaker.cc:226: Check failed: param_.sampling_method == TrainParam::kUniform (1 vs. 0) : Only uniform sampling is supported, gradient-based sampling is only support by GPU Hist.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB\n",
      "Best Score: 0.868141935483871\n",
      "Best Parameters: {'subsample': 0.9, 'sampling_method': 'uniform', 'reg_lambda': 2, 'reg_alpha': 0.5, 'n_estimators': 20, 'min_child_weight': 0.01, 'max_depth': 15, 'learning_rate': 0.3, 'gamma': 0.1, 'colsample_bytree': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\39320\\Desktop\\myProjects_python\\Titanic\\venvimg\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.85209032 0.83272258        nan 0.82157419        nan\n",
      "        nan        nan 0.78451613 0.77965161 0.61414194        nan\n",
      " 0.61414194        nan 0.82473548        nan        nan 0.61414194\n",
      " 0.61414194        nan        nan 0.82313548        nan        nan\n",
      "        nan 0.61414194        nan        nan        nan        nan\n",
      "        nan 0.61414194 0.81509677 0.80708387        nan        nan\n",
      "        nan 0.82482581        nan        nan        nan        nan\n",
      " 0.79576774        nan        nan 0.61414194        nan 0.81509677\n",
      "        nan 0.61414194        nan        nan        nan 0.61414194\n",
      "        nan 0.81188387        nan        nan        nan        nan\n",
      "        nan        nan 0.8295871  0.75256774        nan        nan\n",
      " 0.61414194        nan 0.78294194        nan        nan 0.81673548\n",
      " 0.75064516 0.61414194        nan 0.79259355 0.78934194        nan\n",
      " 0.82309677 0.83925161 0.8280129         nan 0.80056774 0.80385806\n",
      "        nan 0.61414194 0.83283871 0.81987097        nan        nan\n",
      " 0.83605161        nan 0.61414194 0.81513548        nan        nan\n",
      "        nan        nan 0.78616774 0.79095484 0.83122581        nan\n",
      "        nan 0.61414194 0.85209032 0.80058065        nan        nan\n",
      " 0.80538065 0.83763871 0.84085161 0.80543226        nan 0.61414194\n",
      "        nan 0.68027097        nan        nan        nan 0.85049032\n",
      " 0.61414194 0.85049032        nan        nan 0.81510968        nan\n",
      "        nan        nan        nan 0.81188387        nan        nan\n",
      "        nan        nan        nan        nan 0.83447742        nan\n",
      " 0.61414194 0.80865806        nan 0.83122581        nan        nan\n",
      "        nan        nan 0.78616774 0.79900645        nan 0.84245161\n",
      "        nan 0.8215871         nan 0.80869677 0.61414194        nan\n",
      "        nan 0.8407871  0.828             nan 0.83762581        nan\n",
      "        nan        nan 0.8328129         nan        nan        nan\n",
      "        nan        nan 0.78770323        nan 0.78451613        nan\n",
      " 0.83925161        nan        nan        nan        nan        nan\n",
      " 0.78451613 0.84892903        nan 0.79579355        nan 0.84407742\n",
      "        nan 0.81836129 0.84725161        nan 0.61414194 0.81028387\n",
      " 0.84567742        nan 0.61414194        nan 0.8312     0.72030968\n",
      "        nan 0.81183226 0.78294194 0.80868387 0.8231871         nan\n",
      " 0.80863226        nan 0.79579355        nan        nan        nan\n",
      " 0.79580645        nan        nan        nan 0.81829677        nan\n",
      " 0.61414194        nan 0.80863226        nan 0.81349677 0.81992258\n",
      "        nan 0.81990968        nan 0.83117419 0.81672258 0.82632258\n",
      "        nan 0.61414194        nan 0.81993548        nan        nan\n",
      " 0.8424129         nan        nan 0.82477419        nan 0.81503226\n",
      " 0.85370323 0.82954839        nan        nan        nan 0.82965161\n",
      "        nan        nan 0.82636129 0.82796129 0.8135871  0.61414194\n",
      " 0.8151871         nan 0.82472258 0.61414194 0.61414194        nan\n",
      " 0.81348387 0.81673548 0.78616774        nan        nan        nan\n",
      "        nan        nan 0.83116129        nan 0.79415484 0.84243871\n",
      " 0.78616774        nan 0.8392129         nan 0.78451613 0.84246452\n",
      " 0.78451613        nan        nan 0.61414194        nan 0.81512258\n",
      "        nan 0.80700645 0.82153548 0.8183871  0.81830968        nan\n",
      " 0.61414194        nan 0.68188387        nan 0.75256774 0.83762581\n",
      " 0.8327871  0.80381935 0.81030968 0.84403871        nan 0.80536774\n",
      "        nan 0.80379355        nan 0.828      0.81357419        nan\n",
      "        nan        nan 0.61414194        nan        nan        nan\n",
      " 0.84883871        nan 0.78294194 0.78294194        nan 0.61414194\n",
      "        nan 0.8168            nan 0.81830968        nan        nan\n",
      "        nan 0.83282581 0.78771613 0.61414194 0.8392129  0.81505806\n",
      "        nan        nan        nan 0.79899355        nan 0.82317419\n",
      " 0.61414194 0.61414194 0.80221935 0.81508387 0.61414194 0.74611613\n",
      " 0.80063226 0.80064516        nan 0.61414194        nan 0.76527742\n",
      "        nan        nan        nan        nan        nan 0.84565161\n",
      "        nan 0.83283871 0.828             nan        nan 0.82805161\n",
      "        nan        nan 0.85206452        nan 0.80861935 0.61414194\n",
      " 0.8344129  0.78616774 0.86814194        nan 0.84567742 0.83285161\n",
      " 0.80060645        nan 0.71736774 0.84083871        nan        nan\n",
      " 0.61414194        nan        nan 0.80387097 0.84406452 0.61414194\n",
      "        nan 0.61414194 0.75242581 0.61414194        nan 0.83434839\n",
      "        nan        nan 0.83443871        nan 0.79583226        nan\n",
      " 0.61414194 0.61414194 0.83603871 0.82157419 0.61414194        nan\n",
      " 0.61414194        nan        nan 0.8263871  0.81030968        nan\n",
      " 0.81985806 0.61414194 0.8216            nan 0.61414194 0.61414194\n",
      " 0.77485161        nan 0.81025806        nan        nan        nan\n",
      " 0.81187097        nan        nan        nan        nan        nan\n",
      " 0.81994839        nan 0.8231871         nan        nan 0.82313548\n",
      "        nan 0.84082581 0.83603871 0.83442581        nan 0.8247871\n",
      "        nan 0.61414194 0.76370323 0.85205161        nan        nan\n",
      "        nan 0.8247871         nan        nan 0.61414194 0.85207742\n",
      " 0.82956129        nan        nan        nan        nan 0.81347097\n",
      "        nan        nan 0.84085161 0.82793548 0.67704516 0.8264\n",
      " 0.78616774        nan        nan        nan        nan 0.61414194\n",
      "        nan        nan 0.79579355        nan        nan        nan\n",
      "        nan 0.61414194 0.78451613 0.78451613 0.78772903 0.85047742\n",
      "        nan        nan 0.8215871  0.84085161        nan        nan\n",
      " 0.61414194 0.61414194 0.84245161 0.61414194        nan        nan\n",
      "        nan 0.83923871 0.61414194 0.8311871  0.61414194        nan\n",
      " 0.84246452        nan 0.82482581 0.61414194 0.81670968 0.64934194\n",
      "        nan 0.61414194 0.8344129         nan 0.81672258 0.79898065\n",
      " 0.78616774 0.83283871        nan        nan 0.78771613        nan\n",
      "        nan 0.78451613 0.61414194        nan 0.61414194 0.84242581\n",
      " 0.61414194 0.61414194 0.61414194 0.83925161 0.61414194        nan\n",
      " 0.79743226        nan 0.61414194        nan 0.61414194        nan\n",
      " 0.61414194        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.78451613        nan        nan        nan\n",
      "        nan        nan        nan 0.8280129         nan 0.8408\n",
      " 0.8343871  0.82145806        nan 0.61414194        nan        nan\n",
      " 0.81833548        nan        nan 0.79091613        nan 0.82156129\n",
      "        nan 0.80056774        nan        nan        nan        nan\n",
      "        nan        nan 0.8280129         nan 0.83603871        nan\n",
      " 0.80708387 0.61414194 0.78126452 0.8343871         nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.77971613 0.61414194        nan 0.83276129 0.84409032\n",
      "        nan        nan        nan        nan        nan 0.80384516\n",
      "        nan        nan        nan        nan 0.83606452 0.81027097\n",
      " 0.82470968        nan 0.61414194 0.84245161        nan        nan\n",
      "        nan 0.83274839 0.61414194 0.79736774        nan        nan\n",
      "        nan        nan        nan 0.81183226 0.80052903        nan\n",
      "        nan 0.8424129  0.84565161        nan 0.8327871         nan\n",
      "        nan        nan 0.61414194 0.61414194        nan 0.83610323\n",
      "        nan        nan        nan 0.61414194 0.83436129 0.61414194\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.61414194 0.80864516 0.82474839 0.81996129        nan\n",
      " 0.84402581        nan        nan        nan        nan        nan\n",
      "        nan 0.81674839        nan        nan 0.80705806        nan\n",
      "        nan 0.79254194 0.61414194 0.61414194        nan        nan\n",
      "        nan 0.78932903 0.84085161        nan 0.85363871        nan\n",
      " 0.79416774        nan 0.84407742 0.84886452 0.8360129  0.8216\n",
      "        nan 0.84889032        nan 0.61414194 0.78451613        nan\n",
      " 0.83763871 0.61414194        nan        nan 0.61414194 0.81833548\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.82802581 0.84889032        nan        nan 0.8279871\n",
      "        nan        nan 0.82642581        nan 0.80381935 0.81669677\n",
      "        nan        nan 0.82803871 0.82645161 0.83765161        nan\n",
      "        nan        nan        nan 0.61414194        nan 0.61414194\n",
      " 0.8456129         nan        nan        nan 0.61414194        nan\n",
      "        nan 0.83450323 0.83927742        nan 0.61414194 0.84569032\n",
      " 0.83763871 0.61414194 0.79898065        nan 0.61414194 0.81347097\n",
      " 0.79255484 0.85049032        nan 0.82477419 0.84562581 0.61414194\n",
      "        nan        nan 0.83274839 0.61414194 0.81985806        nan\n",
      "        nan 0.8472129         nan 0.61414194 0.82152258        nan\n",
      " 0.61414194 0.8328            nan        nan        nan        nan\n",
      "        nan        nan 0.81348387        nan 0.85367742        nan\n",
      " 0.78451613 0.75254194        nan 0.84086452 0.8232129         nan\n",
      "        nan        nan        nan        nan 0.8215871         nan\n",
      " 0.61414194        nan        nan 0.79256774        nan        nan\n",
      "        nan 0.83273548        nan        nan        nan        nan\n",
      "        nan 0.61414194        nan        nan 0.61414194 0.61414194\n",
      "        nan        nan 0.82317419 0.61414194        nan 0.61414194\n",
      " 0.80867097        nan 0.61414194 0.61414194 0.61414194        nan\n",
      " 0.61414194        nan        nan        nan 0.8248     0.80060645\n",
      " 0.82793548 0.84406452        nan        nan        nan        nan\n",
      "        nan 0.77971613        nan        nan 0.80867097        nan\n",
      " 0.81996129 0.83286452        nan        nan        nan 0.83925161\n",
      " 0.61414194        nan        nan        nan 0.82470968        nan\n",
      " 0.77971613 0.82157419 0.81350968 0.84090323 0.61414194        nan\n",
      "        nan 0.83606452        nan        nan 0.61414194 0.82963871\n",
      "        nan        nan 0.61414194        nan 0.81992258        nan\n",
      "        nan        nan 0.84886452 0.8472129  0.82634839 0.85531613\n",
      "        nan        nan        nan 0.81503226 0.82317419        nan\n",
      " 0.71736774        nan 0.81029677 0.8231871  0.82472258        nan\n",
      " 0.79901935        nan        nan 0.84403871 0.85370323 0.79416774\n",
      " 0.81828387 0.83597419 0.61414194 0.7587871         nan 0.61414194\n",
      " 0.81514839 0.78935484        nan 0.83926452        nan        nan\n",
      " 0.82482581 0.80865806 0.8199871         nan 0.83922581        nan\n",
      "        nan 0.61414194 0.61414194 0.84885161 0.84407742        nan\n",
      "        nan        nan        nan 0.81674839        nan 0.8280129\n",
      " 0.85372903        nan 0.82637419 0.83122581 0.61414194        nan\n",
      "        nan        nan 0.8312            nan 0.61414194        nan\n",
      "        nan 0.80701935        nan 0.61414194 0.81347097        nan\n",
      " 0.83442581        nan 0.80865806 0.8295871         nan 0.83603871\n",
      " 0.84245161        nan        nan        nan 0.81516129 0.84247742\n",
      "        nan        nan        nan 0.61414194        nan 0.81672258\n",
      " 0.83763871 0.8424129  0.81676129 0.86007742        nan        nan\n",
      "        nan        nan 0.844             nan        nan 0.61414194\n",
      "        nan        nan 0.79260645        nan        nan        nan\n",
      "        nan 0.61414194        nan 0.61414194 0.85692903 0.61414194\n",
      " 0.84723871 0.8280129  0.82469677        nan 0.80704516 0.78936774\n",
      " 0.81669677 0.61414194 0.84726452 0.80704516 0.77971613 0.61414194\n",
      "        nan        nan 0.61414194 0.61414194        nan        nan\n",
      " 0.78616774 0.8264129         nan 0.78932903]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf_xgb_rnd = RandomizedSearchCV(xgb_g, param_distributions = param_grid_xgb, n_iter = 1000, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_xgb_rnd = clf_xgb_rnd.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_xgb_rnd,'XGB')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8127340823970037"
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_best = XGBClassifier(subsample= 0.9, sampling_method= 'uniform', reg_lambda= 2, reg_alpha= 0.5, n_estimators= 20, min_child_weight= 0.01, max_depth= 15, learning_rate= 0.3, gamma= 0.1, colsample_bytree= 0.8)\n",
    "xgb_best.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "\n",
    "y_pred_best_xgb = xgb_best.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(y_pred_best_xgb, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "\"clf_xgb = GridSearchCV(xgb_g, param_grid = param_grid_xgb, cv = 5, verbose = True, n_jobs = -1)\\nbest_clf_xgb = clf_xgb.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\\nclf_performance(best_clf_xgb,'XGB')\""
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"clf_xgb = GridSearchCV(xgb_g, param_grid = param_grid_xgb, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_xgb = clf_xgb.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_xgb,'XGB')\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "best_lr = best_clf_lr.best_estimator_\n",
    "best_knn = best_clf_knn.best_estimator_\n",
    "best_svc = best_clf_svc.best_estimator_\n",
    "best_rf = best_clf_rf.best_estimator_\n",
    "best_xgb = best_clf_xgb_rnd.best_estimator_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "voting_clf_hard = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc)], voting = 'hard')\n",
    "voting_clf_soft = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc)], voting = 'soft')\n",
    "voting_clf_all = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc), ('lr', best_lr)], voting = 'soft')\n",
    "voting_clf_xgb = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc), ('xgb', best_xgb),('lr', best_lr)], voting = 'soft')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voting_clf_hard : [0.72       0.688      0.74193548 0.68548387 0.72580645]\n",
      "voting_clf_hard mean : 0.7122451612903224\n",
      "voting_clf_soft : [0.808      0.816      0.78225806 0.75       0.79032258]\n",
      "voting_clf_soft mean : 0.7845032258064515\n",
      "voting_clf_all : [0.824      0.856      0.83870968 0.82258065 0.7983871 ]\n",
      "voting_clf_all mean : 0.8295483870967741\n",
      "voting_clf_xgb : [0.84       0.856      0.84677419 0.84677419 0.83064516]\n",
      "voting_clf_xgb mean : 0.8456516129032258\n"
     ]
    }
   ],
   "source": [
    "print('voting_clf_hard :',cross_val_score(voting_clf_hard,X_train,y_train,cv=5))\n",
    "print('voting_clf_hard mean :',cross_val_score(voting_clf_hard,X_train,y_train,cv=5).mean())\n",
    "\n",
    "print('voting_clf_soft :',cross_val_score(voting_clf_soft,X_train,y_train,cv=5))\n",
    "print('voting_clf_soft mean :',cross_val_score(voting_clf_soft,X_train,y_train,cv=5).mean())\n",
    "\n",
    "print('voting_clf_all :',cross_val_score(voting_clf_all,X_train,y_train,cv=5))\n",
    "print('voting_clf_all mean :',cross_val_score(voting_clf_all,X_train,y_train,cv=5).mean())\n",
    "\n",
    "print('voting_clf_xgb :',cross_val_score(voting_clf_xgb,X_train,y_train,cv=5))\n",
    "print('voting_clf_xgb mean :',cross_val_score(voting_clf_xgb,X_train,y_train,cv=5).mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "params_voting = {'weights' : [[1,1,1,1,1],[1,1,1,1,2],[1,1,1,2,2],[1,1,2,2,2],[1,2,2,2,2],\n",
    "                              [3,4,2,3,1]]}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "VC Weights\n",
      "Best Score: 0.8584903225806452\n",
      "Best Parameters: {'weights': [3, 4, 2, 3, 1]}\n"
     ]
    }
   ],
   "source": [
    "vote_weight = GridSearchCV(voting_clf_xgb, param_grid = params_voting, cv = 5, verbose = True, n_jobs = -1)\n",
    "best_clf_weight = vote_weight.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "clf_performance(best_clf_weight,'VC Weights')\n",
    "voting_clf_sub = best_clf_weight.best_estimator_.predict(X_test.loc[:, X_test.columns != 'PassengerId'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [
    {
     "data": {
      "text/plain": "0.797752808988764"
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf_best = VotingClassifier(estimators = [('knn',best_knn),('rf',best_rf),('svc',best_svc), ('xgb', best_xgb),('lr', best_lr)], voting = 'soft', weights=[3,4,2,3,1])\n",
    "voting_clf_best.fit(X_train.loc[:, X_train.columns != 'PassengerId'],y_train)\n",
    "p_v_best = voting_clf_best.predict(X_test.loc[:, X_test.columns != 'PassengerId'])\n",
    "accuracy_score(p_v_best, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The weights chosen as the best are the ones I entered by hand. In fact, looking at the performance of the various models from the cells above, I gave a greater weight to the best models and a lesser weight to the models that had earlier had lower accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### At the end the best model is the xgb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Deep learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section I try to implement some simple neural networks in keras. I don't expect good performance because neural networks are too complex for this task and will likely overfit the model right away. In any case it is necessary to do some tests."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "keras_classifier = Sequential()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "keras_classifier.add(Dense(16, input_dim=X_train.shape[1]-1, kernel_initializer='uniform', activation='relu'))\n",
    "keras_classifier.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "keras_classifier.add(Dense(4, kernel_initializer='uniform', activation='relu'))\n",
    "keras_classifier.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "keras_classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 1s 2ms/step - loss: 0.6920 - accuracy: 0.6093\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.6141\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.6141\n",
      "Epoch 4/5\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.6141\n",
      "Epoch 5/5\n",
      "20/20 [==============================] - 0s 5ms/step - loss: 0.6637 - accuracy: 0.6141\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1baa376f400>"
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_classifier.fit(X_train.loc[:, X_train.columns != 'PassengerId'], y_train, epochs = 5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [],
   "source": [
    "#keras_prediction = keras_classifier.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "#k_pred = np.rint(keras_prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "outputs": [],
   "source": [
    "#accuracy_score(k_pred, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6479 - accuracy: 0.6255\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.6479284167289734, 0.6254681944847107]"
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_classifier.evaluate(X_test.loc[:, X_test.columns != 'PassengerId'], y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### keras 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "20/20 [==============================] - 0s 891us/step - loss: 0.6922 - accuracy: 0.6029\n",
      "Epoch 2/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.6141\n",
      "Epoch 3/25\n",
      "20/20 [==============================] - 0s 682us/step - loss: 0.6862 - accuracy: 0.6141\n",
      "Epoch 4/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.6141\n",
      "Epoch 5/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.6576\n",
      "Epoch 6/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.7251\n",
      "Epoch 7/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.5720 - accuracy: 0.7894\n",
      "Epoch 8/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.5200 - accuracy: 0.7990\n",
      "Epoch 9/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.7958\n",
      "Epoch 10/25\n",
      "20/20 [==============================] - 0s 617us/step - loss: 0.4529 - accuracy: 0.8006\n",
      "Epoch 11/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4385 - accuracy: 0.8006\n",
      "Epoch 12/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8023\n",
      "Epoch 13/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8023\n",
      "Epoch 14/25\n",
      "20/20 [==============================] - 0s 853us/step - loss: 0.4160 - accuracy: 0.8119\n",
      "Epoch 15/25\n",
      "20/20 [==============================] - 0s 835us/step - loss: 0.4138 - accuracy: 0.8103\n",
      "Epoch 16/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8183\n",
      "Epoch 17/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4066 - accuracy: 0.8248\n",
      "Epoch 18/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4059 - accuracy: 0.8215\n",
      "Epoch 19/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.4024 - accuracy: 0.8280\n",
      "Epoch 20/25\n",
      "20/20 [==============================] - 0s 967us/step - loss: 0.4007 - accuracy: 0.8296\n",
      "Epoch 21/25\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3993 - accuracy: 0.8280\n",
      "Epoch 22/25\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8264\n",
      "Epoch 23/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8280\n",
      "Epoch 24/25\n",
      "20/20 [==============================] - 0s 830us/step - loss: 0.3966 - accuracy: 0.8312\n",
      "Epoch 25/25\n",
      "20/20 [==============================] - 0s 880us/step - loss: 0.3944 - accuracy: 0.8328\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1baa48679d0>"
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_classifier2 = Sequential()\n",
    "\n",
    "keras_classifier2.add(Dense(16, input_dim=X_train.shape[1]-1, kernel_initializer='uniform', activation='relu'))\n",
    "keras_classifier2.add(Dense(6, kernel_initializer='uniform', activation='relu'))\n",
    "keras_classifier2.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "keras_classifier2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "keras_classifier2.fit(X_train.loc[:, X_train.columns != 'PassengerId'], y_train, epochs =25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8052\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.4467730224132538, 0.8052434325218201]"
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_classifier2.evaluate(X_test.loc[:, X_test.columns != 'PassengerId'], y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### keras 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.6459 - accuracy: 0.7588\n",
      "Epoch 2/25\n",
      "20/20 [==============================] - 0s 828us/step - loss: 0.4896 - accuracy: 0.7958\n",
      "Epoch 3/25\n",
      "20/20 [==============================] - 0s 830us/step - loss: 0.4192 - accuracy: 0.8071\n",
      "Epoch 4/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.4062 - accuracy: 0.8312\n",
      "Epoch 5/25\n",
      "20/20 [==============================] - 0s 553us/step - loss: 0.4000 - accuracy: 0.8280\n",
      "Epoch 6/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8360\n",
      "Epoch 7/25\n",
      "20/20 [==============================] - 0s 823us/step - loss: 0.3957 - accuracy: 0.8312\n",
      "Epoch 8/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3936 - accuracy: 0.8344\n",
      "Epoch 9/25\n",
      "20/20 [==============================] - 0s 570us/step - loss: 0.3959 - accuracy: 0.8408\n",
      "Epoch 10/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3872 - accuracy: 0.8441\n",
      "Epoch 11/25\n",
      "20/20 [==============================] - 0s 838us/step - loss: 0.3837 - accuracy: 0.8473\n",
      "Epoch 12/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8424\n",
      "Epoch 13/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3760 - accuracy: 0.8473\n",
      "Epoch 14/25\n",
      "20/20 [==============================] - 0s 828us/step - loss: 0.3767 - accuracy: 0.8473\n",
      "Epoch 15/25\n",
      "20/20 [==============================] - 0s 913us/step - loss: 0.3800 - accuracy: 0.8376\n",
      "Epoch 16/25\n",
      "20/20 [==============================] - 0s 597us/step - loss: 0.3757 - accuracy: 0.8457\n",
      "Epoch 17/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3776 - accuracy: 0.8457\n",
      "Epoch 18/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3741 - accuracy: 0.8392\n",
      "Epoch 19/25\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.8441\n",
      "Epoch 20/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3629 - accuracy: 0.8473\n",
      "Epoch 21/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3615 - accuracy: 0.8505\n",
      "Epoch 22/25\n",
      "20/20 [==============================] - 0s 826us/step - loss: 0.3646 - accuracy: 0.8489\n",
      "Epoch 23/25\n",
      "20/20 [==============================] - 0s 824us/step - loss: 0.3633 - accuracy: 0.8489\n",
      "Epoch 24/25\n",
      "20/20 [==============================] - 0s 867us/step - loss: 0.3621 - accuracy: 0.8457\n",
      "Epoch 25/25\n",
      "20/20 [==============================] - 0s 1ms/step - loss: 0.3550 - accuracy: 0.8505\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1baa49c69b0>"
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_classifier3 = Sequential()\n",
    "\n",
    "keras_classifier3.add(Dense(10, input_dim=X_train.shape[1]-1, kernel_initializer='uniform', activation='relu'))\n",
    "keras_classifier3.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "# Compile model\n",
    "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "keras_classifier3.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "keras_classifier3.fit(X_train.loc[:, X_train.columns != 'PassengerId'], y_train, epochs =25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 0s/step - loss: 0.4934 - accuracy: 0.7940\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.49344363808631897, 0.7940074801445007]"
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_classifier3.evaluate(X_test.loc[:, X_test.columns != 'PassengerId'], y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Among the deep learning classifiers the best classifier is the keras_classifier2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_112 (Dense)           (None, 16)                608       \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 6)                 102       \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 717\n",
      "Trainable params: 717\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_classifier2.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}